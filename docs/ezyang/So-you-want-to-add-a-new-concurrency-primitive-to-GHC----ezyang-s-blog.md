<!--yml

category: 未分类

date: 2024-07-01 18:17:16

-->

# 所以你想要向 GHC 添加一个新的并发原语…：ezyang 的博客

> 来源：[`blog.ezyang.com/2014/01/so-you-want-to-add-a-new-concurrency-primitive-to-ghc/`](http://blog.ezyang.com/2014/01/so-you-want-to-add-a-new-concurrency-primitive-to-ghc/)

GHC 的一个吸引人之处在于，即使你不想修补编译器本身，编译器也令人惊讶地易于修改。这种可修改性来自[编译器插件](http://www.haskell.org/ghc/docs/latest/html/users_guide/compiler-plugins.html)，允许你编写自定义优化通道来操作 Core，以及[外部原语](https://ghc.haskell.org/trac/ghc/wiki/Commentary/PrimOps#Foreignout-of-linePrimOpsandforeignimportprim)，允许你嵌入低级别的 C-- 代码来操纵各种原语的低级别表示。这些钩子允许人们实现和分发那些否则会太不稳定或者过于投机以至于无法放入编译器本身的功能。

最近引起了一定兴趣的一个特定用例是并发原语。我们工程师喜欢开玩笑地说，为了性能的名义，我们愿意承担几乎无限复杂的层次：但是当涉及到并发原语时，这几乎肯定是真的，其中使用更多异步内存屏障和并发数据结构可以带来显著的性能提升（只需[问问 Linux 内核开发人员](http://lwn.net/Articles/576486/)）。看到这种情况，很容易想到，“嘿，我们也可以在 GHC 中实现这些东西，使用提供的编译器钩子！”但是这里有很多注意事项。

在 `ghc-devs` 列表上回答了几个与这个主题相关的问题后，注意到其他回答有些混乱，我觉得应该在一篇合适的博客文章中详细展开我的回答。我想回答以下问题：

1.  在像 Haskell 这样的高级语言中有什么意义拥有内存模型？（如果你知道什么是内存模型，可以安全地跳过这一节。）

1.  什么是（GHC）Haskell 的内存模型？

1.  如何在 GHC Haskell 中实现（快速）内存屏障？

### 内存模型是语义

什么是内存模型？如果你问一个硬件人员，他们可能会告诉你：“内存模型是描述多处理器 CPU 如何与其内存交互的方式，例如一个处理器写入的内容在何种情况下可以被另一个处理器看到。”如果你问一个编译器人员，他们可能会告诉你：“内存模型说明我可以在修改共享变量的操作上进行什么样的编译器优化。”内存模型必须同时满足这两个目的（一个常见的误解是它只能满足其中一个）。为了明确起见，我们定义内存模型如下（改编自[Adve-Boehm](http://cacm.acm.org/magazines/2010/8/96610-memory-models-a-case-for-rethinking-parallel-languages-and-hardware/fulltext)）：

> **内存模型**是共享变量的*语义*，即程序中读取操作被允许返回的值集合。

没错：内存模型定义了编程语言中最基本操作的行为。没有它，你无法真正说出你的程序应该做什么。

那么，为什么在一个如此注重语义的语言社区中，内存模型如此少被讨论？在没有并发性的情况下，内存模型是无关紧要的：显而易见的语义适用。在[数据竞争](http://blog.regehr.org/archives/490)不存在的情况下，可以相当简单地描述内存模型。例如，仅使用 MVars 进行线程间通信的 Haskell 程序可以完全使用相对简单的非确定性操作语义来描述其行为（见[并发 Haskell 论文 (PS)](http://www.haskell.org/ghc/docs/papers/concurrent-haskell.ps.gz)）；软件事务内存提供了关于事务变量读取的原子性的高级保证。当程序包含数据竞争时，内存模型变得至关重要：当多个线程在没有任何同步的情况下写入和读取 IORefs 时，内存模型负责定义此程序的行为。在现代处理器上，这种行为可以非常复杂：我们称这些模型为*松散的内存模型*。复杂的同步原语通常会利用松散的内存模型来避免昂贵的同步操作，并提升额外的性能。

### GHC Haskell 的内存（非）模型

有人可能会说 Haskell 的传统强调语义的重要性... 除了一些显著的盲点。内存模型就是其中之一。最初的[Haskell98 规范](http://www.haskell.org/onlinereport/)没有包含任何并发规范。[并发 Haskell 论文 (PS)](http://www.haskell.org/ghc/docs/papers/concurrent-haskell.ps.gz)描述了如何向语言添加并发性的语义，但该论文仅假定了 MVars 的存在，并未说明 MVars 应如何与 IORefs 交互。

在 2006 年成立的 haskell-prime 委员会上进行的第一次讨论之一是[是否应该标准化并发 Haskell](http://www.haskell.org/pipermail/haskell-prime/2006-March/001046.html)。在讨论中很快发现[IORefs 需要一个内存模型](http://www.haskell.org/pipermail/haskell-prime/2006-March/001193.html)（[续在此处](http://www.haskell.org/pipermail/haskell-prime/2006-April/001237.html)）。截至目前，[尚未作出决定](https://ghc.haskell.org/trac/haskell-prime/wiki/Concurrency#a3.SemanticsofIORefs)，即使 IORefs 是否应具有强内存模型或弱内存模型。

结果是，就标准化语言 Haskell 而言，这里的行为是完全未定义的。要真正能够说些什么，我们将不得不选择一个实现（GHC Haskell），并推断实现的哪些方面是指定的行为，而不是偶然发生的事情。值得注意的是，内存模型对你堆栈的*所有*层级都有影响（有一个普遍的误解是，可以在没有编译器协作的情况下使用内存屏障），因此为了进行此分析，我们需要查看 GHC 编译链的所有阶段。此外，我们将限制自己在单子读/写上，以避免必须处理惰性带来的麻烦。

简而言之，这是 GHC 的编译流水线：

在编译器流水线的最顶层是中间语言 Core 和 STG。这些语言将通过单子的使用保持顺序一致性，读取和写入的顺序由此固定，并在去糖化和优化传递中保留：对于优化器而言，实现读/写的基本操作是完全的黑盒子。事实上，在许多情况下，单子将过度顺序化！（值得注意的是，重写规则和 GHC 插件可以应用不保留单子强加顺序的优化。当然，这两种方法也可以用于完全改变程序的含义；在考虑内存模型时，这些规则仅仅有更高的正确性负担。）

流水线的下一步是将其翻译成 C--，一种高级汇编语言。在这里，对诸如`readMutVar#`和`writeMutVar#`之类的基本操作的调用被翻译为 C-- 中的实际内存读取和写入。重要的是，现在消除了在 Core 和 STG 中存在的单子结构，GHC 现在可以应用重新排列读取和写入的优化。实际发生的情况高度依赖于生成的 C-- 以及 GHC 应用的优化，而 C-- [没有内存模型](http://www.cs.tufts.edu/~nr/c--/)，所以我们甚至无法依赖于它。

话虽如此，我们可以从研究 GHC 实施的优化传递中推断出一些事实：

+   GHC 保留重新排序存储的权利：`WriteBarrier` 机器操作（注意：Haskell 中不可用！）被定义为防止将来的存储发生在前面的存储之前。实际上，GHC 实现的任何 C-- 优化都没有重新排序存储，因此，如果你有一个处理流水线后续阶段的方案，你可以**危险地**假设在这个阶段不会重新排序存储。

+   GHC 保留重新排序加载的权利，并且广泛地这样做。 我们执行的最重要的优化之一是下沉传递，其中对本地变量的赋值尽可能地浮动到其使用位置。 在撰写本文时，尚不支持读取屏障，这将阻止此浮动发生。

有一些情况下我们偶然避免读取重新排序（可能会**危险地**假设）：

+   读取似乎不会在*foreign primops*（使用`foreign prim`关键字定义的 primops）之间重新排序。 这是因为 foreign primops 被实现为跳转到另一个过程（primop），目前没有跨过程的 C--优化。

+   堆读取似乎不会在堆写入之间重新排序。 这是因为我们目前不执行任何别名分析，并且保守地假设写入会破坏读取。 （这是一个危险的假设，因为您可以轻松地想象从前端获取一些别名信息。）

最后，C--被翻译为汇编（通过 NCG—N 代表本机）或 LLVM。 在翻译过程中，我们将 write-barrier mach-op 转换为适当的汇编指令（在 x86 上为无操作）或 LLVM 内在函数（顺序一致性屏障）；此时，行为取决于处理器和/或 LLVM 定义的内存模型。

值得总结这里的讨论，将其与[Data.IORef](http://hackage.haskell.org/package/base-4.6.0.1/docs/Data-IORef.html)中的文档进行比较，该文档对 IORef 内存模型进行了非正式描述：

> 在并发程序中，IORef 操作可能对另一个线程呈现出无序状态，这取决于底层处理器架构的内存模型...实现必须确保内存操作的重新排序不会导致类型正确的代码出错。 特别是，在检查从 IORef 读取的值时，创建该值的内存写入必须从当前线程的角度发生。

换句话说，“我们不保证重新排序，除非您不会发生任何类型安全违规。” 这种行为很容易发生，因为重新排序存储或加载。 然而，类型安全保证是一个有趣的保证：最后一句话指出，IORef 不允许指向未初始化的内存；也就是说，我们不允许将写入 IORef 与初始化值的写入重新排序。 这在 x86 上很容易实现，因为 C--不会重新排序存储；我对我们在 ARM 的新代码生成器上是否做对了事情持怀疑态度（但是还没有人提交错误！）

### 这一切是什么意思？

这次深入 GHC 的内部细节很好，但对于您，即准备实现时髦新并发数据结构的人，这意味着什么？ 有三个主要观点：

1.  如果没有内联外部原语，您将无法说服 GHC 发出您寻找的快速路径汇编代码。正如我们之前提到的，外部原语当前总是编译为跳转到外部的跳转，如果分支预测器无法理解控制流，这将导致一些额外的成本。另一方面，任何外部原语调用都会无意中强制执行您寻找的编译器侧写/读障碍。

1.  使用内联外部原语，您仍然需要修改 GHC，以确保优化过程尊重您时髦的新内存障碍。例如，[John Lato 的](http://comments.gmane.org/gmane.comp.lang.haskell.glasgow.user/24162) 对加载-加载障碍的渴望（启动此帖子的电子邮件）将通过外部的外部原语而无需编译器更改实现，但不会通过假设的内联外部原语实现。

1.  这些东西真的很微妙；请参阅位置论文 [Relaxed memory models must be rigorous](http://www.cl.cam.ac.uk/~so294/documents/ec209.pdf)，该论文认为内存模型的非正式描述（比如本博文！）太过模糊，无法提供有用的信息：如果您希望正确无误，必须将其形式化！这表明一个立即的第一步：给 C-- 一个内存模型。（这应该是 C 和 C++ 最近收到的内存模型的一项适度创新。）

对于我们其他人来说，我们将改用 STM，进入一个缓慢但组合和无死锁的涅槃境界。
