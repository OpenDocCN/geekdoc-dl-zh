<!--yml

category: 未分类

date: 2024-07-01 18:16:59

-->

# MOCHA: Federated Multi-Tasks Learning (Virginia Smith) : ezyang’s blog

> 来源：[`blog.ezyang.com/2017/12/mocha-federated-multi-tasks-learning-virginia-smith/`](http://blog.ezyang.com/2017/12/mocha-federated-multi-tasks-learning-virginia-smith/)

下面是[Virginia Smith](https://people.eecs.berkeley.edu/~vsmith/)在[MOCHA](https://arxiv.org/abs/1705.10467)上的讲话记录，于[ML Systems Workshop](https://nips.cc/Conferences/2017/Schedule?showEvent=8774)上进行，这在 NIPS'17 上举办。

* * *

这项工作的动机来自于我们在实际中解决机器学习问题的方式正在改变。典型的机器学习工作流程是这样的。你从数据集和要解决的问题开始。假设你想建立一个分类器来识别高质量的新闻文章。下一步是选择一个机器学习模型来解决问题。在幕后，为了将模型拟合到你的数据上，你必须选择一个优化算法。目标是找到一个能在数据上最小化某个函数的最优模型。

在实践中，工作流程中有一个非常重要的部分缺失。对于新的数据集、有趣的系统和系统属性，优化算法的选择起着重要作用。举个例子，在过去几年中，数据量变得非常大，必须分布在多台机器上，处于数据中心环境中。我一直在思考如何在这种情况下进行快速的分布式优化，当数据如此之大时。

但越来越频繁地，数据并非从数据中心优雅地包装而来。它来自手机、设备，分布在全国乃至全球各地。在这种设置下进行机器学习训练是具有挑战性的。首先，在数据中心中，你有数百到数千台设备，而在这里，你有数百万甚至数十亿个设备。此外，在数据中心中，设备具有相似的能力；而在这里，你有旧手机、低电量、未连接 wifi 的情况。这会影响到每次迭代中进行计算的能力。

此外，数据本身的异质性也很重要。出于隐私和计算原因，数据可能在网络中变得非常不平衡。它可能是非独立同分布的，因此数据本身可能存在有趣的底层结构。我很兴奋，因为这些挑战可以分解为系统和统计挑战。这项工作的一句总结是，在联邦设置中思考系统和统计问题；关键在于系统设置不仅在优化算法中起作用，而且在选择适合的模型时也起作用。在整个工作流程中，系统设置扮演着更加重要的角色。

我们将全面解决系统和统计挑战的方法进行概述。

从统计学角度出发。目标是我们有一堆生成数据的设备，可能是不平衡的；一些设备比其他设备拥有更多的数据。过去使用的一种方法是在所有这些数据上拟合单一模型。所有数据可以聚合；您找到一个在所有数据上同时实现准确性的模型。另一个极端是为每个数据设备找到一个模型，并且不共享信息。从系统的角度来看这是很好的，但从统计学角度来看，你可能会有一些设备只有…在实践中表现不佳。我们提出的是介于这两个极端之间的方法。我们想为每个设备找到本地模型，但以一种结构化的方式共享信息。这可以在一个称为多任务学习的框架中捕获。

目标是为每个设备拟合单独的损失函数。这些模型可以在矩阵 W 中进行聚合，并且正则化函数的作用是强制施加某种结构 omega 在其上。这个 omega 是一个任务关系矩阵，捕捉有趣的关系，例如，所有任务相关并且你想学习权重，或者大多数任务相关并且有一些异常值，或者有集群和群体，或者更复杂的关系像是非对称的关系。所有这些都可以在多任务中捕获。

我们开发了一个真实的联合数据基准集。这包括尝试从手机预测人类活动，预测是否进食或饮酒，地雷和车辆传感器；分布式传感器来确定车辆是否经过。

对于这些不同的数据集，我们比较了全局、本地和多任务学习（MTL）。目标是拟合一个奇异值分解（SVD）模型。对于每个数据集，我们查看了跨任务的平均误差，其中每个模型都是一个任务。您可以看到，对于 SVD，平均误差显著低于全局和本地方法。这是有道理的，因为多任务学习更加表达丰富；它让您可以在这些极端之间切换。有趣的是，在这些真实数据集中，它确实有所帮助。实践中减少了一半。这在实践中是一个显著的改进。

鉴于我们喜欢在联合环境中使用多任务学习来建模数据，下一个问题是如何在分布式设置中训练这个模型，考虑到大规模分布式。特别是，目标是解决以下优化目标。在研究如何解决这个目标时，我们注意到通常是交替解决 W 和 omega 的问题。当你解决 omega 时，它是集中的，你只需要访问模型。但是 W 必须是分布式的，因为数据分布在设备之间。在实践中解决这个问题的关键组成部分是 W 的更新。做这件事的挑战是通信非常昂贵。并且由于异构性，你可能会遇到大量的问题，如拖延者和容错性问题；例如，有人把手机关掉。

我们正在实施这个高层次的想法，采用一种通信高效的方法，在数据中心中运行良好，并修改为在联邦设置中运行。它将处理多任务学习以及 stragglers 和容错。

我们正在使用的方法是什么？我们正在使用的方法是 COCOA，这是一种用于经验风险最小化问题的最先进方法。COCOA 的优点在于它涵盖了迷你批处理和一次性通信的先前工作，通过将通信作为方法的第一类参数来实现灵活性。它通过不解决原始形式而解决对偶形式来实现这一点。对偶形式之所以好，是因为我们可以通过形成客观函数的二次近似来轻松地近似它；这种方法更容易在多台机器之间分解。

要将其分布到联邦设置，一个关键挑战是找出如何将其推广到 MTL 框架。第二个挑战；在 COCOA 中，假设子问题解决到某个精度θ。这很好，因为θ从 0 到 1 变化，其中 0 是精确解，1 是不精确解。这可以看作是本地通信与通信时间的比例。然而，在实际中，这并不像在联邦设置中应该那样灵活。对所有迭代和所有节点设置的唯一θ。由于θ不能完全设定为 1，所以它无法处理容错，在任何迭代中都没有工作执行。在实践中，这使得通信参数更加灵活。

我们是如何做到这一点的？我们开发了 MOCHA。其目标是解决多任务学习框架；以交替的方式解决 W 和Ω。特别是，我们能够形成以下类似于 COCOA 的对偶形式，使其分解。相比之下，我们对子问题参数做出了更加灵活的假设。这是重要的，因为 stragglers 有统计原因、不平衡、不同分布，解决这些子问题的难度可能会有很大不同。此外，由于系统问题，还可能出现 stragglers。以及容错问题。因此，看起来这是一个简单的修复：我们使这个准确性参数更加灵活：允许它根据节点和迭代 t 变化，并让它确切为 1。困难在于表明它收敛到最优解。

在采纳这一新假设之后，你不能让设备每一轮都出现问题，我们展示了以下的收敛保证。对于 L-Lipschitz 损失，我们得到 1/ε的收敛率；对于平滑模型（逻辑回归），我们得到线性率。

在实践中，这种方法表现如何？这种方法非常简单。假设我们的数据存储在 m 个不同的设备上。我们在解决Ω和 W 存储在每个设备上时交替进行。在解决 w 更新时，它通过为每台机器定义这些本地子问题，并调用进行近似解的求解器来工作。这是灵活的，因为它可以根据节点和迭代变化。

就比较这个方法与其他方法而言，我们所看到的是以下内容。将 MOCHA 与 CoCoA、Mb-SDCA 和 Mb-SGD 进行比较。我们有模拟，用真实数据来看如果我们在 WiFi 上进行会发生什么。我们有模拟的时间以及接近最优解的情况。你可以看到的是，MoCHA 更快地收敛到最优解，因为 MoCHA 没有统计异质性的问题，并且不会被拖累。这对所有不同类型的网络都适用；LET 和 3G。蓝线和 MOCHA 以及 CoCOA，在高通信环境中表现良好，因为它们更灵活。但与 CoCOA 相比，MOCHA 对统计异质性更加稳健。

有趣的是，如果我们施加一些系统异质性，一些设备比其他设备慢，我们看了低和高系统异质性的情况，MOCHA 在这种额外的异质性下，达到最优解的速度提高了两个数量级。

特别是对于 MOCHA，我们关注了容错性的问题。我们在这里展示的是，我们增加了设备在任何分布中掉线的概率。直到有一半的设备，我们对 MOCHA 的收敛仍然相当稳健，几乎在同样的时间内。但是我们看到绿色虚线，如果同一设备每次迭代都掉线，它就不会收敛。这表明我们实际做出的假设是合理的。

关键是，在思考这种新的设置中，在这些大规模设备网络上训练 ML，这既是统计问题也是系统问题。我们已经以整体的方式解决了这个问题。代码位于[`cs.berkeley.edu/~vsmith`](http://cs.berkeley.edu/~vsmith)，我还想重申一下 SysML 会议将于 2 月举行。

Q: 当你比较全局和本地时？为什么总是比全局好？

A: 你想使用本地模型而不是全局模型的动机是，如果你有大量本地数据，你可能会表现得更好。这提升了整体样本量。我有一些额外的实验，我们在那里采取了原始数据，并且比它已经存在的情况更进一步倾斜。我们采取了本地数据，那里的数据更少，它们有全局方法。这只是设备中数据的功能。

Q: 我真的很喜欢你的方法有保证，但我想知道一种在本地创建元学习算法并在本地运行的方法？

A: 从经验来看，这是值得研究的，因为你可以在本地进行微调。我们最初试图达到确切的最优解，但你可能只想要在经验上表现良好，与此设置进行比较将是很好的。
