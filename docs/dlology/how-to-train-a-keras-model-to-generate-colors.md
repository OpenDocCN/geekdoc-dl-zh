# 如何训练 Keras 模型生成颜色

> 原文：<https://www.dlology.com/blog/how-to-train-a-keras-model-to-generate-colors/>

###### 发帖人:[程维](/blog/author/Chengwei/) 4 年 7 个月前

([评论](/blog/how-to-train-a-keras-model-to-generate-colors/#disqus_thread))

![color-names-crayons](img/cee6b1238162123f1dfdba2b3213a1c2.png)

想知道油漆颜色是如何命名的吗？"象牙公主"，"公牛奶油。"而“喀拉斯红”呢？原来 [人就是靠给那些颜色取名](https://www.reddit.com/r/IAmA/comments/3tyt69/we_create_the_names_of_paint_colors_for_a_living/)谋生的。在这篇文章中，我将向你展示如何建立一个简单的深度学习模型来做类似的事情——给模型一个颜色名称作为输入，并让模型提出颜色的名称。

这个帖子是初学者友好的。我给大家介绍一下深度学习处理文本数据的基本概念。

**概述**

1.  选择最能代表输入文本的语言模型
2.  清理和准备培训数据
3.  建立一个基本的 Keras 序列神经网络模型。
4.  应用递归神经网络(RNN)处理字符序列。
5.  生成 3 通道 RGB 彩色输出。

让我们来看看我们将要构建的大图，

![build_overview](img/304ef6a547f452e0a9076afb034e9e6d.png)

### 语言模型

语言建模有两个通用选项:单词级模型和字符级模型。各有利弊。让我们现在过一遍。

### 单词级语言模型

单词级语言模型可以处理相对长且干净的句子。所谓“干净”，我的意思是文本数据集中的单词没有错别字，并且几乎没有英语词汇之外的单词。单词级语言模型将每个唯一的单词编码成相应的整数，并且有一个预定义的固定大小的词汇字典来查找单词到整数的映射。单词级语言模型的一个主要好处是它能够利用预先训练的单词嵌入，如 Word2Vec 或 GLOVE。这些嵌入将单词表示为具有有用属性的向量。上下文中相近的词在欧几里德距离上是相近的，可以用来理解类似“男人之于女人，之于国王之于王后”的比喻。使用这些想法，您可以用相对较小的标记训练集来训练单词级模型。

### 字符级语言模型

但是有一个更简单的语言模型，它将一个文本字符串分割成多个字符，并将一个唯一的整数与每个字符相关联。您可能会选择使用字符级语言模型而不是更流行的单词级模型，这有一些原因:

*   您的文本数据集包含大量不在词汇表中的单词或不常用的单词。在我们的例子中，一些合法的颜色名称可能是“ aquatone ”、“黄绿色”和“紫红色”。对我来说，我必须查字典，找出它们的意思，传统的单词级嵌入可能不包含它们。
*   大多数文本字符串都是长度有限的短字符串。如果您正在寻找一个特定的长度限制，我一直在处理一个字符级编码字符长度为 60 的 Yelp 评论生成模型，并且仍然得到了不错的结果。你可以在这里找到博文:  [如何用 Keras](https://www.dlology.com/blog/how-to-generate-realistic-yelp-restaurant-reviews-with-keras/) 生成逼真的 yelp 餐厅评论。通常，字符级语言生成模型可以创建更多样化的文本，因为它的想象力不受预定义词汇词典的约束。

您可能也意识到了采用字符级语言的局限性:

*   长序列可能不像单词级语言模型那样捕捉长距离依赖性。
*   字符级模型的训练在计算上也更昂贵——给定相同的文本数据集，这些模型序列更长，因此需要更长的训练时间。

幸运的是，这些限制不会对我们的颜色生成任务构成威胁。我们将颜色名称的长度限制在 25 个字符以内，而且我们只有 14157 个训练样本。

![dataset](img/510cca91a2968157211bc0cdbb845e4a.png)

我们提到我们将颜色名称限制在 25 个字符以内。为了得出这个数字，我们检查了所有训练样本中颜色名称的长度分布，并将其可视化，以确保我们选择的长度限制是合理的。

这给了我们这个图，你可以清楚地看到，大多数颜色名称字符串的长度小于或等于 25，即使最大长度达到 30。

在我们的例子中，我们可以选择最大长度 30，但是我们将要构建的模型也需要在更长的序列上训练更长的时间。我们选择较短序列长度的折衷降低了模型训练的复杂性，同时不损害训练数据的完整性。

![char length distribution](img/f4162be1c8b51ca9ec7688a3d7f6a0df.png)

在做出最大长度的艰难决定后，字符级数据预处理的下一步是将每个颜色名称字符串转换为 25 个整数值的列表，这通过 Keras 文本标记化实用程序变得很容易。

现在**将具有(14157，25)的形状，其中 14157 是总训练样本的数量，25 是最大序列长度。如果字符串少于 25 个字符，将从序列的开始处用值0s 填充。**

 **您可能会想，现在所有的输入都是整数形式，我们的模型应该能够处理它。但是我们还可以多走一步，让后期的模型训练更加有效。

### 一键编码

我们可以通过检查 Keras 的 Tokenizer 实例的  **t.word_index** 属性来查看字符到整数的映射。

```py
{' ': 4,  'a': 2, 'b': 18, 'c': 11, 'd': 13, 'e': 1, 'f': 22, 'g': 14, 'h': 16, 'i': 5, 'j': 26, 'k': 21, 'l': 7, 'm': 17, 'n': 6, 'o': 8, 'p': 15, 'q': 25, 'r': 3, 's': 10, 't': 9,'u': 12, 'v': 23, 'w': 20, 'x': 27, 'y': 19, 'z': 24}
```

整数值之间没有自然的有序关系，我们的模型可能无法从中获益。更糟糕的是，我们的模型最初会假设这些字符之间的这种排序关系(即“a”是 2，“e”是 1，但这不应该表示一种关系)，这可能导致不希望的结果。我们将使用独热编码来表示输入序列。

每个整数将由一个布尔数组表示，其中只有一个元素的值为 1。最大整数值将决定字符字典中布尔数组的长度。

在我们的例子中，最大整数值是**【x】:27**，所以一个独热布尔数组的长度将是 28(考虑到最小值从 0 开始，这是填充)。

例如，我们不使用整数值 2 来表示字符“a ”,而是使用独热数组[0，0，1，0 ……..0].

在 Keras 中也可以使用一键编码。

生成的 one_hot_names 的形状为(14157，25，28)，代表(#个训练样本，最大序列长度，#个唯一令牌)

### 数据标准化

请记住，我们预测的是 3 个颜色通道值，每个值的范围在 0–255 之间。数据规范化没有金科玉律。数据规范化纯粹是实用的，因为在实践中，如果训练数据值过于分散，模型可能会永远收敛。一种常见的归一化技术是将值缩放到[-1，1]。在我们的模型中，我们在最后一层使用了 ReLu 激活函数。由于 ReLu 输出非负数，我们将把这些值规范化为[0，1]。

### 建立模型

为了建立我们的模型，我们将使用两种类型的神经网络，一个前馈神经网络和一个递归神经网络。前馈神经网络是迄今为止最常见的神经网络类型。在这种神经网络中，信息进入输入单元，并通过隐藏层沿一个方向流动，直到每个信息到达输出单元。

在循环神经网络中，信息可以循环流动。这些网络可以长时间记忆信息。递归网络是建模顺序数据的一种非常自然的方式。在我们的特定模型中，我们使用了一个最强大的循环网络，名为长短期记忆(LSTM)。

在 Keras 中建立深度学习模型最简单的方法是使用它的顺序 API，我们只需通过调用它的 model.add()函数来连接每个神经网络层，就像连接乐高积木一样。

通过调用 model.fit()函数来训练模型再简单不过了。请注意，我们将保留 10%的样品用于验证目的。如果结果表明模型在训练集上实现了很高的准确性，但在验证集上却低得多，则很可能模型过拟合。你可以在我的另一个博客上获得更多关于处理过度合身的信息: [过度合身模特的两个简单食谱](https://www.dlology.com/blog/two-simple-recipes-for-over-fitted-model/) 。

#### 生成 RGB 颜色

让我们定义一些函数来生成和显示预测的颜色。

对于一个颜色名称输入，我们需要将其转换成同一个 hot 表示。为了实现这一点，我们使用与处理训练数据相同的标记器将字符标记为整数，将其填充到最大序列长度 25，然后对整数序列应用一键编码。

对于输出的 RGB 值，我们需要将其缩放回 0–255，这样我们才能正确显示它们。

让我们试试 predict()函数。

![predict-colors](img/23f1c50a603cc0a9915d605707eb24a4.png)

“喀拉斯红”看起来比我们熟悉的颜色要深一点，但不管怎样，这就是我们提出的模型。

### 结论和进一步阅读

在这篇文章中，我们讨论了如何构建一个 Keras 模型，它可以采用任何颜色名称，并得出一个 RGB 颜色值。更具体地说，我们研究了如何将一键编码应用于字符级语言模型，用一个前馈神经网络和递归神经网络构建一个神经网络模型。

这里有一个图表来总结我们在帖子中构建的内容，从底部开始，显示数据流的每一步。

![data-pipeline](img/db211651350abfd7fc47411362fc3948.png)

如果你是深度学习或 Keras 图书馆的新手，有一些很好的资源，阅读或实验起来既简单又有趣。

[TensorFlow playground](http://playground.tensorflow.org/) :在浏览器上运行的神经网络的交互式可视化。

[Coursera 深度学习课程](https://www.coursera.org/learn/neural-networks-deep-learning):学习深度学习的基础和大量实用建议。

[Keras 入门指南](https://keras.io/getting-started/sequential-model-guide/):用户友好、模块化 deep Python 深度学习库的官方指南。

另外，在  [我的 GitHub repo](https://github.com/Tony607/Keras-Colors) 中查看这篇文章的源代码。

*   标签:
*   [深度学习](/blog/tag/deep-learning/)，
*   [keras](/blog/tag/keras/) ,
*   [教程](/blog/tag/tutorial/)

[Share on Twitter](https://twitter.com/intent/tweet?url=https%3A//www.dlology.com/blog/how-to-train-a-keras-model-to-generate-colors/&text=How%20to%20train%20a%20Keras%20model%20to%20generate%20colors) [Share on Facebook](https://www.facebook.com/sharer/sharer.php?u=https://www.dlology.com/blog/how-to-train-a-keras-model-to-generate-colors/)

*   [←如何用 Keras 做无监督聚类](/blog/how-to-do-unsupervised-clustering-with-keras/)
*   [Keras +通用语句编码器=文本数据的迁移学习→](/blog/keras-meets-universal-sentence-encoder-transfer-learning-for-text-data/)**