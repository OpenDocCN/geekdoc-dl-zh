# 7 人工智能在教育中的未来

DOI: [10.4324/9781003459026-7](https://dx.doi.org/10.4324/9781003459026-7)

> 对于世界上将要发生的大多数事件，我们推测人工智能无法比人类更好地预测未来，这一点非常重要。
> 
> 托马斯·科洛顿

## 7.1 引言

在整本书中，我们讨论了人工智能在教育中的应用和生成式人工智能（GenAI），提供了其历史概述和技术细节。我们阐述了人工智能素养的必要性以及 GenAI 如何影响课程设计、评估和教育政策。我们提供了定义和指导这些领域变化的框架，旨在确保实现最佳预期结果。我们还深入探讨了为什么 GenAI 达到了一个将对教育产生变革性影响的节点，以及教育机构和政策制定者应该如何应对。

在本章中，我们推测未来可能的情况。我们审视了社会规范的整体图景，以及政府、雇主和人工智能产品公司的角色和地位，以帮助我们形成观点。我们回顾了教育内外已经发生的变化。最后，我们探讨了教育机构的未来，以及整体图景将如何影响这一技术在教育中的采用。

## 7.2 以前的技术采用

社会规范影响我们的日常行为。它们可以从我们吃饭的时间到我们穿的衣服，再到我们使用手机的方式，影响任何事情。一个社会如果没有这样的社会规范来影响个人行为，就无法长期成功运作，反之，这些规范有助于促进团结和秩序（Rachlinski, 2000）。通过考察社会对以前创新技术的采用，我们可能能够揭示一个模型，说明人工智能和 GenAI 的采用可能同样受到社会规范的影响，甚至可能重塑我们的社会规范。

如果我们回顾 20 世纪 80 年代和 90 年代个人电脑(PC)的采用情况，最初只是一小部分人成为了早期用户（是的，那些极客们！）。直到很久以后，这种采用才逐渐增加。有人可能会说，直到互联网发展到足够满足广泛兴趣的程度，个人电脑对普通人来说才变得非常有用。在个人电脑的早期，玩电脑游戏和编写简单的软件对大多数人来说还没有什么兴趣；此外，对电子表格和文字处理等工具的广泛需求只有在它们在普通人群中达到相对较高程度的常规使用时才出现。这在工作环境中对这些工具和相关技能的需求得到了帮助，或者可能是由这些需求推动的。最终，它们也成为了教育系统中的必需品。与现在提交报告的人数相比，有多少人在 20 世纪 90 年代为他们的学位课程提交了手写报告？

2019 年，全球约有 47%的家庭拥有电脑(Statista PCs, 2019)；这个比例可能看起来并不大，但它可能受到了智能手机普及的影响。根据 Statista 的数据，到 2020 年，全球 78%的人口拥有智能手机；而在 2016 年，这一比例还不到一半(Statista Mobiles, 2019)。在这里，我们看到智能手机在各个社会经济群体中的普及速度更快、范围更广。智能手机的兴起部分得益于其实用性、个人化特性、手持式便利性，就像口袋里的电脑一样，以及在成本和样式方面提供的巨大选择多样性。

## 7.3 对通用 GenAI 影响的预测

GenAI 的采用将受到其在更广泛社会中一般使用方式的影响。目前，GenAI 正处于其生命周期的初期，但已经有相当一部分人群开始接受并使用这项技术，从专业人士和技术爱好者到孩子们。

### 7.3.1 通用人群对 GenAI 的采用

与 PC 最初缓慢的普及不同，PC 需要像电子表格这样的软件来吸引企业，以及快速互联网连接来吸引更广泛的公众，生成式 AI 因其立即可用性而脱颖而出，无需额外的工具或技术。然而，尽管其功能广泛，**我们预测**生成式 AI 不会像移动电话和智能手机技术那样与社会的广泛比例产生共鸣。**我们预测**AI 的主要用户将是社会中的受教育程度较高的人，无论他们的经济背景如何，其中相当一部分是年轻人。尽管如此，**我们预测**生成式 AI 将迅速被社会接受，涵盖大多数社会和经济群体，并预期将有许多有用的生成式 AI 工具可供使用和获取（例如，零成本或低成本选项）。**我们预测**将有各种生成式 AI 产品，包括聊天机器人、个人助理，以及生成式 AI 与文字处理和文本编辑器无缝集成的可能性，类似于拼写或语法检查器现在如何集成到这些工具中。有了这一广泛的应用范围，**我们也预测**准确衡量生成式 AI 的使用、可用性和渗透率将具有挑战性。

### 7.3.2 职业影响

关于 AI 和生成式 AI 对就业市场的影响已经做出了许多预测，正如高盛的一份报告所示(Briggs & Kodnani, 2023a)。这一点在许多新闻标题中被强调，福布斯报道称，“高盛预测，人工智能将导致 3 亿个工作岗位丢失或降低”(Kelly, 2023](#ref7_12))。相反，另一篇关于同一高盛报告的文章标题为，“生成式 AI 可能将全球 GDP 提高 7%”(Briggs & Kodnani, 2023b)。这说明了新闻媒体如何将相同的信息进行不同的解读，以在受众中创造正面或负面的印象。**我们预测**关于 AI 的影响，尤其是对工作和就业市场的影响，将出现重大的“戏剧性”事件。

某些公司和甚至整个特定行业将更加深刻地感受到这些影响。例如，Stack Overflow – 一个致力于支持软件开发专业人士的网站 – 宣布在 2023 年下半年裁员高达 28% (Davis, 2023)。同时，他们推出了自己的 AI 产品(Chandrasekar, 2023)，并计划向使用 AI 数据的公司收费(Dave, 2023)。尽管裁员可能看起来突然且极端，但值得注意的是，Stack Overflow 在大约 12 个月前进行了一次重大招聘；当时，许多其他科技公司都在由于普遍的经济环境而减少员工人数。因此，并非所有这些员工流失都可以直接归因于生成式 AI。

高盛的报告估计，人工智能自动化将影响美国和欧洲多个行业的工作任务，影响办公室和行政支持行业的 46%的工作，法律行业的 44%，建筑和工程行业的 37%，以及生命、物理和社会科学领域的 36% (Briggs & Kodnani, 2023a)。报告还强调，人工智能技术仍然需要人类的干预和指导，表明这些行业中的所有角色不会受到同等程度的影响。它指出，能够被人工智能自动化的工作在发达市场比在新兴市场更为普遍，日本、以色列和香港受到的影响最为严重。报告进一步强调，在向更大程度自动化任务转变的过程中，任何新创造的就业岗位都将构成就业增长的大部分。例如，在当前的美国就业率中，只有 40%的人从事自 1940 年以来存在的职业，而 60%的人从事在此之后出现的职业。

事实上，目前通用人工智能（GenAI）更多地充当辅助工具的角色，帮助个人更高效地完成工作。GenAI 仍然需要人类的干预来指导方向、确定目的，并推动其向有用、有益和富有成效的结果发展。这意味着通用人工智能的兴起并不一定会危及任何人的工作——只有从事这项工作的人需要不断更新必要的技能和知识，以便最好地利用 GenAI 来提高工作效率——而且总体上，它可能被认为具有积极影响。这可能意味着，那些员工已经开始使用 GenAI 来协助其职责的公司，在新的项目中不需要雇佣额外的人手，因为现有的团队——在 GenAI 的帮助下——可以处理额外的负担。

因此，**我们的预测**是，任何对就业的负面影响都不会减缓或显著影响通用人工智能（GenAI）的采用。**我们还预测**，通用人工智能将对基于知识的经济发展中的角色产生比例如基于体力劳动的角色更大的影响，并且在这些基于知识的职业中工作的人更有可能成为通用人工智能的早期使用者。这导致受影响的劳动力由于他们相对较高的教育水平，比以往任何时候都更有能力适应新的现实。这些变化将很难衡量，对关键就业数字的影响将不会明显，类似于美国在疫情期间的“大规模离职”情况（Ellingrud 等人，2023）。**我们预测**，最终，由于新增的角色、公司和需求，知识经济中的就业人数将增加，这远远超过由于人工智能带来的效率而发生的现有角色的整合。**我们还预测**，未来的知识经济将涉及比以往任何时候都更加强大的综合能力和知识技能的结合。

目前，许多行业正在拥抱通用人工智能，从软件开发公司到法律服务公司。他们采用这项技术的速度很快，尤其是在较小的组织中。另一方面，由于对商业隐私、信任和风险的担忧，较大的组织正在更加谨慎地进行。他们需要了解由于这项技术的创新性和可能触及的法律领域，他们需要理解法律风险和潜在责任。例如，他们通过使用通用人工智能模型，可能会因为开发者如何训练模型而产生的版权问题而承担潜在责任吗（例如，OpenAI 在其产品中使用哈利·波特作品产生的版权问题；Usman，2023）？尽管在大型组织中整合的速度较慢，但似乎他们完全拥抱通用人工智能只是时间问题。如果人工智能产品公司通过针对其风险偏好的特定产品来解决企业担忧，或者如果这些企业对涉及的风险感到更加舒适，借鉴他们在云计算或外包服务等方面的先前经验，这可能会加速这一进程。

**我们预测**，在商业世界中通用人工智能采用的上升趋势将继续，人工智能和通用人工智能的使用将成为组织中各种角色的预期技能和能力。它甚至可能成为一种基本且广泛要求的技能，类似于如今基本计算机技能的必要性，并最终成为人们进入职场时被认为应具备的技能集。在此之前，工作描述很可能会继续具体说明对特定角色在特定通用人工智能工具和用途方面的经验和熟练度的期望。在较小的组织和初创企业中，这些关键期望可能更为明显。这种技能要求的转变不仅会影响新毕业生的就业，还会影响所有级别的现有工作角色。因此，**我们预测**，随着个人开始将通用人工智能整合到他们的工作中，对担任角色的期望将发生变化，特别是在知识经济领域；此外，虽然他们的能力将增强，但随着时间的推移，对现有角色类型的人力需求将减少，这些角色的技能组合也将演变，例如，更加重视整体能力，如团队合作、领导技能、批判性思维。还将出现不同和新类型的角色，例如“人工智能工程师”、“对话式人工智能负责人”、“人工智能伦理学家”、“人机团队合作经理”、“数字戒断治疗师”、“人工智能个性设计师”、“人工智能约会助手”和“负责任的人工智能内容安全管理员”。这些预期的头衔促使我们思考现有角色可能如何演变，以及以前从未考虑过的新角色如何出现。

**我们也预测**，在组织中，那些拥抱人工智能和通用人工智能技术的员工将展示并断言他们对不断发展的技术环境的适应性，从而增加他们长期保留工作的可能性。新创建的职位将内在地期望员工具备人工智能和通用人工智能的熟练度；这种转变将使组织能够相应地调整其人员配置，以充分利用其人工智能和通用人工智能赋能员工的增强生产力和能力。

### 7.3.3 人工智能安全影响 - 采用

由于大数据泄露的增多，如 2013 年雅虎的 3 亿账户受到影响（BBC, 2017），人们现在对数据隐私问题了解得更多。同样，领英在 2021 年发生数据泄露，影响了 7 亿账户（Taylor, 2021），而 Facebook 在 2019 年发生数据泄露，影响了 5.33 亿账户（Wong, 2021）。尽管存在这样的泄露和 Facebook-Cambridge Analytica 丑闻，其中用户数据未经许可被共享，并在 2016 年美国总统大选中以争议的方式使用（Wong, 2019），但人们仍然继续使用这些平台并在网上分享他们的个人信息。

可能会有一个时刻，人们会说，关于他们数据的共享或滥用已经足够了，但现在看来，我们似乎还没有达到那个阶段。对数据安全和隐私的担忧可能是一个未知数，可能会影响人们使用和互动 GenAI 的方式，但它也可能只影响他们选择的 GenAI 的类型，可能塑造对智能手机上嵌入式个性化 GenAI 助手的偏好，这种助手不会通过网络传输任何个人详细信息。

很可能一开始，人们会信任 GenAI 提供的信息，即使是在有争议的话题上。对于 AI 开发者和产品公司来说，拥有高采用率和吸引尽可能多的人（跨越所有生活领域）是有利的。人们接受和使用 AI 产品及服务的程度已经投入了大量努力进行衡量，并将继续这样做。在衡量 AI 安全时，也可以考虑 AI 的接受和使用情况，或者将其作为 AI 对齐适当性的简单代理指标，接受或使用它的人越多，AI 对齐就越好。这可能会很好地掩盖情况的复杂性，例如竞争压力驱使人们使用技术，而不管个人层面的对齐或接受程度。

**我们预测**，即使有隐私和数据安全等担忧，人们仍然会继续使用 AI 技术，尽管有些人会寻找提供更高保障的 AI 平台、工具和产品，以解决上述问题。

### 7.3.4 AI 安全影响 – 采用后

考察 AI 安全不仅是在初始采用阶段，而且在它融入社会之后也是至关重要的。这是因为一旦 AI 产品获得大量用户基础，AI 产品公司的动机就会发生变化。随着 AI 获得广泛的信任和使用，公司和国家机构可能会试图利用 AI 来影响公众舆论。这种操纵可能源于各种动机，例如改变社会规范或追求经济利益。以下有两个例子来说明这一点：

提供的例子，尽管是假设性的，旨在说明目的，但也反映了观察到的现有搜索引擎技术和社交媒体平台中存在的真实担忧，某些结果因未公开的政治或财务因素而被淡化。这种偏差的检测将对普通大众构成重大挑战。一旦足够多的人开始使用 AI，开发 AI 产品的公司的目标可能会改变。此外，即使人们意识到他们目前使用的产品存在问题，他们可能也难以转向不同的 AI 产品。这种情况是 AI 的真正威胁，比《终结者》中的“天网末日”等假设性场景更现实。

**我们预测**，人工智能安全和人工智能对齐问题在未来只会被看作是不同的，只有当负面影响变得广泛且难以解决时，公众才会更加重视这些问题。

### 7.3.5 政府的影响

由于商业、地缘政治或甚至由于当地法律要求等原因，特定地理区域内通用人工智能工具的可用性将对通用人工智能的采用方式产生影响。例如，类似于加密货币等技术在许多司法管辖区被禁止或高度限制的方式，如果一个国家禁止使用这些技术，它将影响该地区或该区域的技术融合。

很明显，目前人工智能被视为将在国家、地区和地缘政治层面提供竞争优势的东西。因此，大多数政府不太可能对人工智能和相关技术实施全面限制。然而，鉴于世界各地采用的方法大相径庭，提供的护栏将对人工智能发展的类型和速度产生不同的影响。

第五章描述了与人工智能相关的政府政策的一些已完成和正在进行的工作，概述了采取的不同方法。在中国，重点是国家安全；在欧盟，重点是基于风险的方法；同时，美国目前正采取一种更加放任自流的方法。例如，在一个更加放任自流的体制中，你可能会期望有更多的商业方法，以及广泛的行业选择利用人工智能，以及他们在这一方面的使用程度存在差异。然而，对于基于风险的方法，你可能会期望在高度监管或禁止使用人工智能的高风险类别中，如玩具、航空、汽车、医疗设备和电梯，人工智能的发展很少；或者你可能会期望这些领域的科技成本由于监管成本而显著更高。

**我们预测**，监管将高度多样化，其影响将难以预测，尤其是在考虑到全球经济相互关联性的情况下。然而，人工智能和通用人工智能的采用以及它们的技术进步速度不太可能受到重大影响。很可能会看到，监管将高度适应，试图在技术的潜在利益和风险与其他考虑因素之间取得平衡，包括地缘政治状况以及国家和地区的竞争力。

**我们预测**，未来的法规和政策将不会解决与 AI 训练相关的问题，例如训练数据集的选择或审查、过滤的指导方式以及 AI 在底层算法方面的决策方式。实际引入的法规和政策将无法帮助解决用户在不同 AI 产品之间轻松切换的便携性问题。此外，引入的法规和政策将无法阻止少数大玩家控制整个行业。一旦这些大玩家确立地位，**我们预测**，政策制定者和这些大玩家将强烈抵制任何试图改变其集中控制权的尝试。

### 7.3.6 AI 开发公司

包括 OpenAI、微软、Meta、Alphabet/谷歌和 Anthropic 在内的公司处于创建和发展 AI 和通用 AI 技术的最前沿。他们对所提供内容的需求是明确的，但仍有未被挖掘的个性化通用 AI 应用和开源 AI 模型潜力。新兴公司如 Tiny Corp 和 Mistral AI 正在进入这些领域以满足需求。该领域的竞争激烈，新玩家，包括 Mistral AI，在短时间内获得了相当大的动力(Bradshaw & Abboud, 2023)，而像 Meta 这样的老牌玩家也在调整其策略，以更商业化的开放许可证来推广其通用 AI 模型(Moreno, 2023)。还值得记住的是，这些服务中的大多数目前都仅提供测试版(Anthropic Claude)，仅用于研究目的(OpenAI 直到大约 2023 年 2 月)，作为实验(Google Bard)，或仅用于娱乐目的(Bing，根据其使用条款，第九部分)。

这些公司面临的一个重大障碍来自法律挑战，尤其是来自被人工智能开发者和产品公司用于训练其模型的版权内容的所有者。已经发起了许多诉讼，包括第 1 号案件：23-cv-08292，该案件是在纽约南区地方法院提起的，代表多位作者指控版权侵权（Creamer, 2023）。此类案件的判决可能具有决定性，可能需要从头开始重新训练 AI 模型，更不用说财务影响。来自人工智能开发领域最大玩家的最新消息包括他们承诺对其 AI 产品生成的内容承担责任和赔偿。一些公司正在积极应对使用 AI 技术产生的法律影响，特别是关于版权侵权。例如，微软表示，它致力于解决其 Copilot 工具的法律问题，旨在在使用此工具生成代码时为用户提供清晰和信心（Microsoft, 2023）。同样，Adobe 通过为其基于 Firefly AI 的图像应用程序的用户提供版权赔偿，采取了积极主动的立场，以保护用户免受与版权侵权相关的潜在法律诉讼（Gold, 2023）。谷歌也加入了这一行列，承诺为通用 AI 技术的用户辩护，以版权主张，从而在提供保障的同时也促进了负责任的 AI 使用（Brittain, 2023）。这些举措反映了人工智能开发者和产品公司对 AI 使用法律复杂性的日益认识，以及共同朝着为用户和开发者创造更安全的法律环境迈进的集体行动。

人工智能产品公司对监管框架有着相当大的影响力。他们还经常被咨询以确保拟议的法规是合理的，不会过度阻碍技术进步和竞争力。**我们预测**，监管变化不太可能显著阻碍更广泛的 AI 和通用 AI 行业。

AI 开发者和产品提供商正在迅速推进他们的策略，以抢占市场和心智份额。同时，由于投资者的巨额资本注入，新公司以加速的速度涌现。这些动态表明，存在多样化的公司、商业模式和资金，所有这些都将推动 AI 和通用 AI 产品在一定时期内的进步。在过去，例如一些社交媒体公司推迟了他们的货币化策略，直到他们获得了显著的市场份额；相比之下，AI 和通用 AI 公司的商业化路径似乎更为直接。他们可以通过直接订阅来早期启动收入生成，并从希望针对这些订阅者的广告商或其他收入来源中获益。**我们预测**将持续有资金流入 AI 和通用 AI 的开发者和产品提供商，这将有助于推动技术进步的不断驱动。这最初将导致许多不同公司和领域的创新，但最终我们将看到围绕少数几个关键提供商的整合，这些提供商将在订阅者数量上拥有非常显著的优势。

硬件和训练数据的需求可能成为这些公司的挑战。然而，这些公司正在积极制定策略，以最佳方式利用他们拥有的资源，找出模型大小和所需训练数据量之间的正确平衡，以及数据质量、使用的算法和 AI 模型的设计如何影响硬件需求以及开发模型的实用性。尽管对硬件可用性的担忧可能仍然存在，**我们预测**这不会显著减缓 AI 和通用 AI 产品的增长。硬件和环境问题可能会促使开发者和产品提供商设计更高效且可能更小的模型（与当前最大的 1.8T 模型相比），以便广泛使用。

**我们预测**AI 和通用 AI 产品公司将继续增长并推出各种产品。尽管预计一些大玩家将带头，但我们相信一些新的和有创意的初创公司将在后来加入主流，提供他们独特的服务。技术进步和产品种类的多样性将使服务对大多数人来说保持可负担性，尽管可能会有一些权衡；例如，提供商可能要求用户同意将他们的客户数据用于未来的训练目的。地缘政治因素仍将影响特定地点服务的可用性和提供的服务类型。

## 7.4 对通用 AI 在高等教育中影响的预测

以下章节讨论了我们对于高等教育机构未来可能面临的看法。人工智能和通用人工智能不是第一个具有重大影响潜力的技术；计算器、个人电脑、互联网以及最近几年的智能手机，都产生了重大影响。值得进行一些反思，以更好地理解和建立与人工智能和通用人工智能对教育潜在影响相关的内容。

### 7.4.1 高等教育中的教学法与评估

人工智能和通用人工智能技术的浪潮不仅正在改变各个行业的运营格局，正如之前提到的，也在很大程度上影响了雇主对其未来员工的期望，尤其是那些刚从大学毕业的员工。雇主可能会优先考虑那些对使用和应用这些技术有良好基础理解和熟练度的候选人。人工智能素养，包括对人工智能基础知识的了解、其应用、伦理影响以及与或开发通用人工智能解决方案的能力，将成为求职者渴望的，如果不是必需的，资格。

对于大学生来说，**我们预测**雇主将寻求那些具备人工智能素养的候选人。因此，人工智能素养培训将被纳入他们的本科教育中。随着对人工智能素养在就业市场需求的不断上升，这种需求将回响到教育机构，大学可能会感受到修订和更新其课程以包括全面的人工智能和通用人工智能教育的动力，确保他们的学生在毕业后能够充分准备并在就业市场上具有竞争力。因此，**我们预测**大学将需要并会相应地调整，将这些工具引入其课程中。**我们预测**这些变化将逐渐发生；最初，这将是基于临时性的、逐个教师的基础，可能遵循机构关于人工智能和通用人工智能的早期政策迭代，进行轻微的整合。然而，**我们预测**大多数机构将资助并促进更广泛的方法，以将这些技术更深入地整合到课程中，但看到这种影响需要更多时间。

人工智能和通用人工智能对高等教育评估的潜在影响也标志着向更多技术驱动、个性化和创新评估策略的转变。然而，这种变化的程度和性质可能会因不同机构和地区而大不相同，基于众多因素，包括机构优先事项、监管框架以及社会对人工智能驱动教育实践的接受程度。

在通用人工智能（GenAI）的推动下，向更真实、更具创新性的评估方法过渡，提供了一个引人入胜的机会。然而，我们应该在多大程度上拥抱这些新方法，以及机构如何确定哪些方法有效、实用和可行，远未明朗。机构可能以不同的速度和不同程度的热情来应对这一转变，这主要受当地教育政策、社会接受度和内部变革准备情况的影响。考虑到这一点，**我们预测**，评估的变化将在不同机构以及不同地区之间高度多样化。一些机构将根据社会态度和维持公平的目标进行最小限度的调整。一些机构可能会回归到监考考试。一些机构将利用这个机会进行更广泛的机构变革，并推动采用本书中提出的更真实、创新和与 GenAI 合作的评估方法。

**我们预测**，私立高等教育机构将以更加审慎的方式采用这些技术，并特别关注将它们融入其课程和评估中。他们将把这一点定位为自己与公立机构之间的重要区别，尤其是在该行业对通用人工智能（GenAI）采用初期阶段。此外，他们将尝试使用这些方法，特别是评估方法，看到他们取得的结果将非常有趣。我们进一步相信，他们从这些变化中产生真实、可衡量的收益的可能性很大。

**我们同样预测**，那些在课程和评估方法中敏捷地引入人工智能（AI）和通用人工智能（GenAI）的机构，将最好地利用与这些技术相关的更广泛的行业变化和进步。将有一大批现有劳动力急于快速证明他们的 AI 和 GenAI 技能，寻求从合适的高等教育机构获得证书，以此证明他们的能力和对当前及未来雇主的承诺。精明的机构应抓住 AI 消费主义的扩张浪潮，积极开拓这一领域。通过这样做，他们可以为学生提供宝贵的沉浸式学习机会，使他们能够从市场需求日益增长的人工智能中心教育范式中获得熟练技能。

### 7.4.2 高等教育研究

人工智能和通用人工智能的出现极大地扩展了研究生、他们的导师和考官可用的资源。学生可以利用这些工具作为顾问和导师，以增强他们在所选研究领域的理解。他们可以使用通用人工智能来总结论文、掌握关键概念、将思想与理论联系起来，并更好地理解这些理论与他们自己的研究之间的关系。通用人工智能还可以在写作过程中帮助学生，包括处理参考文献格式、语法、拼写，并增强清晰度和学术写作风格。导师也可以利用这些工具快速审查研究提案或起草论文。专门的 AI 或通用人工智能模型可以帮助详细审查研究工作，确保方法细节的适当性、数据分析的准确性和适用性，甚至分析发现的深度和洞察力。考官和审稿人也可以从中受益，其中通用人工智能可以用来检查文献综述的彻底性并评估所提出发现的创新性。

总体而言，人工智能和通用人工智能使所有参与研究过程的人都能节省时间、提高效率并提升工作的质量。通用人工智能的采用程度将很大程度上取决于有关此类技术的机构政策。**我们预测**，高等教育机构将朝着给予通用人工智能采用强有力的支持的方向发展，并采取措施来维护学术诚信，例如要求声明使用通用人工智能，并推广使用荣誉体系进行用户自我监管。**我们预测**，那些对此持抵制态度的机构可能会面临来自所有利益相关者的巨大压力，采取行动，如果该机构被认为在现代研究方法上落后，可能会影响其吸引研究候选人的能力。**我们预测**，监督者和机构在实现跨机构一致性方面可能会面临有趣的挑战。这可能导致某些机构群体之间达成区域或特定协议，以建立一致性并制定一套可互操作的政策，从而更容易实现跨机构合作。

### 7.4.3 资金提案的起草

就像研究一样，AI 和 GenAI 可以在起草资助申请的过程中提供实质性帮助。Parrilla (2023) 对该过程进行了概述，强调 GenAI 如何大幅减少撰写和审查提案中其他各方可能感到繁琐的工作量。在他的文章中，Parrilla 思考是否可以通过从提案内容中删除某些组件来简化资助提案系统，从而降低利用 GenAI 撰写这些部分的机会。然而，考虑到大多数资助资金来自公共资源或慈善组织，透明度和可审计性即使在完成拟议和实施的研究多年后仍然至关重要。

由于 GenAI 还可以帮助资助评审员解决诸如应用的新颖性和主要研究员（PI）的资历等关键问题，**我们预测** GenAI 不会简化资助申请流程本身，而将提高 PI 和评审员双方流程的质量和效率。

### 7.4.4 提交和审查期刊文章

不同期刊在关于 GenAI 的使用和归属方面采用了不同的标准。例如，**《自然》** (《自然》编辑，2023a；《自然》编辑，2023b；《自然组合》，2023) 在某些条件下允许进行文本生成，但禁止生成图像和视频。在生成文本时，必须详细记录工具的使用方式，并且所有来源都必须准确引用。此外，他们不允许将 GenAI 工具列为文章或论文的作者或合著者，因为作者有特定的责任和声明需要履行，而这些工具无法履行或执行。

另一方面，**《柳叶刀》** (《柳叶刀微生物》，2023) 限制作者使用 GenAI 仅限于“提高作品的阅读性和语言”，而不包括替代研究者的任务，如产生科学见解、分析和解释数据以及得出科学结论。作者必须承担最终责任，并披露其作品中任何 AI 或 AI 辅助技术的使用情况。许多其他期刊尚未就 GenAI 技术的适当和可接受使用建立具体、正式的政策。

考虑到 GenAI 对研究人员和学者的益处，以及为学术目的而出现的越来越专业化的 AI 工具和模型，**我们预测**GenAI 的使用将增加，这将导致允许其使用的压力。这反过来又可能促使期刊标准扩展，以说明何时有必要声明使用这些技术。**我们预测**这些工具将由作者、编辑和审稿人广泛使用，可能有助于从强调传统、同行评审和高影响因子期刊转向提供和衡量研究真实影响的替代方案。这些替代方案更有可能与实现审查过程更大透明度和开放性的目标相一致，朝着更强调科学验证、影响和可重复性的方法发展，而不是目前对同行意见的重视。

**我们预测**，从同行评审转向透明度和科学验证的评审将分阶段进行，当发生重大转变时，可能会看到明确的阈值。这一时刻可能是由为研究和学术目的开发的、能力显著超过其前辈的专用 AI 或 GenAI 模型发布所触发。可能出现一种情况，即新的 AI 或 GenAI 模型能够识别现有同行评审出版物中的有效性问题，这些出版物迄今为止一直被认为是正确的，然后利用这些信息来否定其他发现。

此外，**我们预测**人工智能和通用人工智能的能力将创造更多突破性的发现，人工智能和通用人工智能在加速研究发现的进程方面具有巨大的潜力。

## 7.5 AI 或 GenAI 能预测未来吗？

在上一节中提供了我们的预测后，我们现在提出一个问题：一个 LLM——一个预测下一个单词/标记的工具——在预测未来方面能做得有多好？

### 7.5.1 OpenAI ChatGPT 说了什么？

| 用户 | 你能给我一些关于 GenAI 在未来 5 到 10 年内如何影响教育的预测吗？ |
| --- | --- |

| OpenAI ChatGPT GPT-4 | 当然。虽然我不能确定未来，但根据当前趋势和通用人工智能（GenAI）技术的潜力，我可以做出一些有根据的推测。以下是关于未来 5 到 10 年内 GenAI 对教育影响的几个预测：

1.  **个性化学习**：GenAI 系统可以适应个别学生的需求、学习方式和节奏。这可能允许提供更个性化的教育体验，其中内容根据学生的当前理解和偏好进行交付。例如，如果一个学生在代数方面有困难但在几何方面表现出色，AI 可以相应地调整课程。

1.  **虚拟教学助手**：通用人工智能可能作为教学助手，帮助学生解答问题，提供即时反馈批改作业，甚至帮助教师管理行政任务。这些虚拟助手可以全天候提供服务，在传统课堂时间之外提供支持。

1.  **交互式模拟**：通用人工智能可以帮助创建动态和逼真的模拟，用于复杂学科。例如，生物学学生可以探索虚拟细胞，而历史学生可以亲身体验历史事件。这种沉浸式学习可能导致对学科的更深入理解。

1.  **全球课堂**：借助人工智能驱动的语言翻译和自适应内容交付，来自世界各地的学生可以加入同一个虚拟课堂，无论语言或背景如何。这促进了更具包容性和多元化的学习环境。

1.  **持续评估**：与定期测试不同，通用人工智能（GenAI）可以持续评估学生的理解程度，并实时调整教学计划。这将最大限度地减少高风险测试的压力，并专注于稳步、持续的进步。

1.  **技能差距识别**：通用人工智能可以识别学生遇到困难的地方，并提出针对性的资源或练习。这在高等教育和职业培训中可能特别有用，确保学生毕业时具备必要的技能。

1.  **可访问性和包容性**：对于有残疾或学习差异的学生，通用人工智能可以根据他们的独特需求定制资源，使教育更加可访问和包容。

1.  **终身学习**：随着就业格局的不断演变，通用人工智能可以帮助成人学习者适应，通过识别技能差距并提供填补这些差距的资源，促进持续的专业发展。

1.  **行政效率**：在行政方面，通用人工智能可以自动化与运营教育机构相关的许多任务，从排程到资源分配，从而实现成本节约和更高效的运营。

1.  **伦理和偏见问题**：与任何技术一样，人们会对通用人工智能在教育中的应用产生担忧。数据隐私、算法中的潜在偏见以及对技术的过度依赖将是讨论的重点。教育机构和监管机构积极应对这些担忧将至关重要。

记住，这些都是推测性的，人工智能（AI）对教育的影响将取决于各种因素，包括技术进步、政策法规、社会接受度和伦理考量。教育中人工智能的整合提供了有希望的机会，但也带来了需要深思熟虑解决的挑战和伦理困境。

### 7.5.2 谷歌 Bard 都说了些什么？

| 用户 | 你能预测一下通用人工智能在未来 5 到 10 年内对教育的影响吗？ |
| --- | --- |

| Google Bard | 这里有一些关于通用人工智能在未来 5 到 10 年内如何影响教育的预测：

+   个性化学习：通用人工智能可以用来为每个学生创建个性化的学习体验。这可能包括根据学生的个人需求和兴趣调整课程，提供实时反馈，以及提供个性化的辅导支持。

+   更吸引人的学习体验：通用人工智能可以用来创建更吸引人和互动的学习体验。例如，通用人工智能可以用来创建虚拟世界、模拟和游戏，这些可以帮助学生在更沉浸和动手的方式中学习。

+   教育的普及：通用人工智能可以帮助提高所有人的教育获取机会，无论他们的地理位置或情况如何。例如，通用人工智能可以用来开发适用于资源匮乏环境的教育工具和资源，或为有特殊需求的学生提供个性化的学习支持。

+   新技能和知识：通用人工智能将在劳动力中对技能和知识提出新的要求。这意味着教育需要适应，为学生的未来工作做好准备。例如，学校可能需要更加注重教授学生批判性思维、解决问题的能力和创造力技能。

这里有一些通用人工智能在教育中应用的特定例子：

+   人工智能辅导老师：人工智能辅导老师可以为学生提供个性化的指导和反馈，全天候 24/7。

+   AI 生成的学习内容：AI 可以用于根据每个学生的个人需求和兴趣生成个性化的学习内容。

+   人工智能评估工具：AI 可以用来开发评估工具，为学生提供更准确和及时的反馈。 |

+   人工智能虚拟学习环境：AI 可以用来创建虚拟学习环境，使学生能够以更沉浸和动手的方式学习。

总体而言，通用人工智能有潜力彻底改变教育。它可以帮助我们为所有学生创造更个性化、吸引人和易于获取的学习体验。它还可以帮助我们为学生未来的工作做好准备。然而，需要注意的是，通用人工智能仍在开发中。在通用人工智能在教育中得到广泛应用之前，需要解决一些挑战。例如，我们需要确保人工智能教育工具是公平和无偏见的，并且与我们的教育价值观相一致。我们还需要确保教师能够有效地使用人工智能教育工具，并接受适当的培训。 |

### 7.5.3 微软必应聊天说了什么？

| 用户 | 你能给我一些关于通用人工智能在未来 5 到 10 年内如何影响教育的预测吗？ |
| --- | --- |

| 微软必应聊天 | 生成式 AI 是制造业到医疗保健等各个行业必须应对的主要力量，但可能面临最大颠覆风险的行业或许是教育¹。生成式 AI 并不一定是教育的丧钟，但教育工作者必须学习如何有效地与之互动¹。超过 90%的教师表示，他们从未接受过任何关于如何在学校使用生成式 AI 的培训或建议¹。为了确保它对社会和教育行业是净收益，我们必须停止害怕这项技术，而是深入思考如何最好地使用它¹。生成式 AI 有可能颠覆或增强我们的思考和行动方式。它可能会改变现在和未来一代的认知，因为人类的社会化和有机、人类的教学方法正在被人工导师和自动化反馈循环所取代¹。然而，年轻人知道信息可以在网上找到。现在的学生面临被批评使用手机在维基百科上查找答案的风险，不是因为答案错误，而是因为他们使用了互联网来找到它。试图阻止他们访问它至少是问题重重¹。随着生成式 AI 的普及、易用性增强，它将继续影响我们在高等教育中参与教学、学习和评估的方式²。UCL 选择推广与 GenAI 工具的道德和透明互动，而不是寻求禁止它们²。在这篇论文中，作者探讨了生成式 AI（GenAI）对进一步教育环境中评估学生作业的影响。随着 GenAI 的广泛应用，它给评估带来了潜在风险，如学习虚假证据、学生易受学术诚信不公的侵害，以及对独立学习和创造力的含义³。这项研究探讨了大学生对生成式 AI（GenAI）技术，如 ChatGPT，在高等教育中的看法，重点关注熟悉度、他们参与意愿、潜在利益和挑战，以及有效整合⁴。值得注意的是，这只是生成式 AI 在未来 5-10 年内可能对教育产生影响的几个例子。可能性是无限的！了解更多信息：

1.  [weforum.org](http://weforum.org)

1.  [ucl.ac.uk](http://ucl.ac.uk)

1.  [studiolab.ide.tudelft.nl](http://studiolab.ide.tudelft.nl)

1.  [educationaltechnologyjournal.springeropen.com](http://educationaltechnologyjournal.springeropen.com)

1.  [unesco.org](http://unesco.org)

|

## 7.6 结论

生成式 AI 有众多应用，从协助日常任务到更专业领域的使用。生成式 AI 的实用性将推动社会对这项技术的采用，最终成为社会规范的一部分，就像我们今天看待智能手机一样。

行业正在适应，并将继续采用和适应生成式人工智能及其带来的利益和挑战。一般来说，那些迅速适应的员工将能够从这种动力中获得更多好处，而所有级别的新的员工都需要掌握生成式人工智能的使用和素养技能。特别是，将生成式人工智能整合到知识经济中的角色和行业中——在这些行业中，知识和信息的创造、获取和应用推动经济增长和发展——将对教育机构施加压力，要求在课程中融入生成式人工智能的技能和能力，以便新毕业生为现实世界做好准备。

政府法规将因地区而异；然而，总的来说，由人工智能带来的技术进步和领导力创新潜力意味着，过度监管的可能性大于不足监管。在出现过度监管的情况下，可能会出现巨大的压力，要求迅速减轻或撤销限制。

在大学教育中，最大的压力将是适应不断变化的市场和社会期望，确保毕业生一旦进入职场，就能准备好并具备有效利用这些工具的必要技能。评估方式的改变将需要，以适应不断变化的环境并确保公平性。研究生将在其研究和工作中采用这些技术，但需遵守各自机构的政策。

在研究方面，最大的影响将在同行评审期刊的实践中感受到。有潜力开发出专门的 AI 工具和模型，这些工具和模型将协助作者、编辑和审稿人，并推动行业向更高的透明度和开放性转变，更加重视科学验证、影响和验证，而不是同行意见。

随着这些变化的发生，很可能会出现相当多的“戏剧性”事件，因为劳动力在变化，因为技术以意想不到的方式被使用，因为新的发现被做出，或者因为已经发布的作品中出现的问题被检测到。有时，这些干扰是有正当理由的；然而，大多数时候，鉴于整体环境和人类未来地平线上的变化，这将是茶杯里的风暴。

最后，**我们推测**，AI **无法**比人类更好地预测世界将发生的大多数事件，这一点很重要。我们不应该比信任一个非专家的朋友更加信任 AI。即使是盲目信任专家也是不可取的；我们需要运用我们的判断力，并提高我们的批判性思维能力，以做出明智的决定。话虽如此，我们将等待并密切关注，看看这些预测是否成真，以及它们是否通过我们的推测努力或通过 GenAI 的预测能力得以预见。

## 参考文献

+   BBC (2017 年 10 月 3 日). 2013 年雅虎数据泄露影响“所有三十亿账户”。从 [`www.bbc.com/news/business-41493494`](https://www.bbc.com) 获取。

+   布拉德肖，T. & 阿布德，L. (2023 年 10 月 22 日). *四周大的 AI 初创公司在欧洲融资中创下 1.05 亿欧元纪录*。金融时报。从 [`www.ft.com/`](https://www.ft.com) 获取。

+   布里格斯，J.，& 科达纳尼，D. (2023a，3 月 26 日). 人工智能对经济增长可能产生重大影响。从 [`www.ansa.it/documents/1680080409454_ert.pdf`](https://www.ansa.it) 获取。

+   布里格斯，J.，& 科达纳尼，D. (2023b，4 月 5 日). 生成式 AI 可能将全球 GDP 提高 7%。高盛。从 [`www.goldmansachs.com/intelligence/pages/generative-ai-could-raise-global-gdp-by-7-percent.html`](https://www.goldmansachs.com) 获取。

+   布里特恩，B. (2023 年 10 月 13 日). *谷歌将捍卫生成式 AI 用户免受版权索赔*。路透社。从 [`www.reuters.com/technology/google-defend-generative-ai-users-copyright-claims-2023-10-12/`](https://www.reuters.com) 获取。

+   钱德拉塞卡拉，P. (2023 年 7 月 27 日). 宣布 OverflowAI. Stack Overflow 博客. 从 [`stackoverflow.blog/2023/07/27/announcing-overflowai/`](https://stackoverflow.blog) 获取。

+   克里默，E. (2023 年 7 月 5 日). 作者对 OpenAI 提起诉讼，指控其非法“吞噬”他们的书籍。卫报。从 [`www.theguardian.com/books/2023/jul/05/authors-file-a-lawsuit-against-openai-for-unlawfully-ingesting-their-books`](https://www.theguardian.com) 获取。

+   戴夫，P. (2023 年 4 月 20 日). Stack Overflow 将向 AI 巨头收费以获取训练数据。Wired。从 [`www.wired.com/story/stack-overflow-will-charge-ai-giants-for-training-data/`](https://www.wired.com) 获取。

+   戴维斯，W. (2023 年 10 月 16 日). Stack Overflow 裁员与 AI 盈利能力。The Verge. 从 [`www.theverge.com/2023/10/16/23919004/stack-overflow-layoff-ai-profitability`](https://www.theverge.com) 获取。

+   Ellingrud, K., Sanghvi, S., Dandona, G. S., Madgavkar, A., Chui, M., White, O., & Hasebe, P. (2023, July 26)。*生成式 AI 和美国工作的未来*。麦肯锡全球研究院。从[`www.mckinsey.com/mgi/our-research/generative-ai-and-the-future-of-work-in-america`](https://www.mckinsey.com)获取。

+   Gold, J. (2023, June 8). Adobe 为基于 Firefly AI 的图像应用用户提供版权赔偿。计算机世界。从[`www.computerworld.com/article/3699053/adobe-offers-copyright-indemnification-for-firefly-ai-based-image-app-users.html`](https://www.computerworld.com)获取。

+   Kelly, J. (2023, March 31)。高盛预测将有 3 亿个工作岗位因人工智能而丢失或降低。福布斯。从[`www.forbes.com/sites/jackkelly/2023/03/31/goldman-sachs-predicts-300-million-jobs-will-be-lost-or-degraded-by-artificial-intelligence/`](https://www.forbes.com)获取。

+   Majewska, D. Rushton, N. & Shaw, S. (2022). 我们是如何到达这里的？展示英国和美国数学教育变化的时序。剑桥大学出版社 & 评估。

+   Microsoft. (2023, September 7). 我们对 Copilot 的版权承诺和法律关注。微软问题。从[`blogs.microsoft.com/on-the-issues/2023/09/07/copilot-copyright-commitment-ai-legal-concerns/`](https://blogs.microsoft.com)获取。

+   Moreno, J. (2023, April 26)。*扎克伯格表示 Meta 将把生成式 AI 添加到所有产品中*。福布斯。从[`www.forbes.com/sites/johanmoreno/2023/04/26/zuckerberg-says-meta-will-add-generative-ai-to-all-its-products/`](https://www.forbes.com)获取。

+   Nature Editorial。(2023a, June 7)。为什么自然不会允许在图像和视频中使用生成式 AI。自然。从[`www.nature.com/articles/d41586-023-01546-4`](https://www.nature.com)获取。

+   Nature Editorial. (2023b, January 24)。工具如 ChatGPT 威胁透明科学；以下是它们使用的规则。自然。从[`www.nature.com/articles/d41586-023-00191-1`](https://www.nature.com)获取。

+   Nature Portfolio. (2023). 编辑政策：人工智能（AI）。自然。2023 年 10 月 15 日检索，来自[`www.nature.com/nature-portfolio/editorial-policies/ai`](https://www.nature.com)。

+   Parrilla, J. M. (2023, October 13). ChatGPT 的使用表明资助申请系统存在问题。自然。从[`www.nature.com/articles/d41586-023-03238-5`](https://www.nature.com)获取。

+   Jeffrey J. Rachlinski, 《社会规范的限制》，74 Chi.-Kent L. Rev. 1537 (2000)。从[`scholarship.kentlaw.iit.edu/cklawreview/vol74/iss4/6`](https://scholarship.kentlaw.iit.edu)获取。

+   Statista Mobiles. (2019)。[`www.statista.com/statistics/263437/global-smartphone-sales-to-end-users-since-2007/`](https://www.statista.com)。

+   Statista PCs. (2019 年). 从[`www.statista.com/statistics/748551/worldwide-households-with-computer/`](https://www.statista.com)获取。

+   Taylor, S. (2021 年 6 月 27 日). 新的领英数据泄露导致 7 亿用户受影响. RestorePrivacy. 从[`restoreprivacy.com/linkedin-data-leak-700-million-users/`](https://restoreprivacy.com)获取。

+   《柳叶刀微生物学》. (2023 年 6 月). 作者信息. 柳叶刀. 从[`www.thelancet.com/pb-assets/Lancet/authors/tlmicro-info-for-authors-1686637130753.pdf`](https://www.thelancet.com)获取。

+   Usman, R. (2023 年 8 月 16 日). 魔法与版权：ChatGPT 对哈利·波特的恶作剧变得棘手. 数字信息世界. 从[`www.digitalinformationworld.com/2023/08/magic-and-copyright-chatgpts-mischief.html`](https://www.digitalinformationworld.com)获取。

+   Wong, J. C. (2019 年 3 月 18 日). 剑桥分析公司丑闻改变了世界——但它没有改变 Facebook. 卫报. 从[`www.theguardian.com/technology/2019/mar/17/the-cambridge-analytica-scandal-changed-the-world-but-it-didnt-change-facebook`](https://www.theguardian.com)获取。

+   Wong, J. C. (2021 年 4 月 6 日). 究竟是什么导致了 Facebook 5 亿用户的隐私泄露？ 硅谷杂志. 从[`www.wired.com/story/facebook-data-leak-500-million-users-phone-numbers/`](https://www.wired.com)获取。
