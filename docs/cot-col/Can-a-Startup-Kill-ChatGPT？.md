<!--yml

category: COT 专栏

date: 2024-05-08 11:04:20

-->

# 一家初创公司能够击败 ChatGPT 吗？

> 来源：[`every.to/chain-of-thought/can-a-startup-kill-chatgpt`](https://every.to/chain-of-thought/can-a-startup-kill-chatgpt)

[目的地聊天机器人市场](https://every.to/chain-of-thought/will-google-s-bard-be-a-destination-chatbot) 已经成为了主导地位的一场搏斗。

在 OpenAI 推出 ChatGPT-4 一年后，谷歌和 Anthropic 在其聊天机器人产品质量上已经赶上。他们都发布了公开或私人 beta 模型（[Gemini 1.5 Pro](https://every.to/chain-of-thought/i-spent-a-week-with-gemini-pro-1-5-it-s-fantastic?sid=37573) 和 [Claude 3 Opus](https://every.to/napkin-math/claude-3-is-the-most-human-ai-yet?sid=37574)，分别）具有比 GPT-4 更大的上下文窗口。在某些情况下，他们在氛围方面甚至超过了 GPT-4。

尽管如此，OpenAI 明显仍是受欢迎的赢家。如果谷歌或 Anthropic 在不久的将来真正威胁到其主流采用率，我会感到惊讶。我很好奇 OpenAI 接下来会做些什么。不过，今天我想谈谈初创公司。

聊天机器人 ChatGPT 对干扰有多脆弱？假设 OpenAI 保持其对现有公司的主导地位——它能够抵御干扰吗？

谷歌的 Gemini 事件和 ChatGPT 过去几个月响应质量的有时倒退的轨迹表明，我认为大型聊天机器人公司容易受到干扰的影响——除非他们调整其产品战略。让我解释一下为什么。

## 关于干扰的快速入门

“干扰”一词在口语中被用来指任何初创公司击败现有公司的情况，但在其最初的制定中，它有着特定的含义。

[干扰](https://en.wikipedia.org/wiki/Disruptive_innovation)，由克莱顿·克里斯坦森在 1990 年代初提出的理论，是一个过程，其中一家初创公司提供了一个在标准性能维度上表现较差的低成本产品，针对主流市场之外的一小部分客户。该产品得到了采纳，因为它在对其特定客户群体重要的新性能维度上表现更好。随着时间的推移，干扰者改善了标准性能指标，以便可以向更高价值的客户推广，同时保持其其他优势。

由于后者认为初创公司的原始产品成本较低、利润率较低，并且通常表现更差，所以它看起来像是一个不好的业务。因此，该公司在为时已晚之前无法做出反应。

这是一个巧妙的理论，因为它提出企业失败并不是因为经理们愚蠢，而是因为在职的聪明经理们正确地遵循了他们业务的激励机制，并紧密围绕着他们的客户，变得盲目地对颠覆性创新视而不见。（欲了解更多关于颠覆理论的信息，请[参见我之前的文章](https://every.to/superorganizers/how-new-ideas-happen-755569?sid=37578)。）

## 颠覆，跌宕，翻滚，颠覆

颠覆发生在一家初创公司发布了一款成本较低、性能较低的产品，比大型在职公司的产品要好的*一个*维度。

在聊天机器人领域有一个非常明确的应用领域：返回有风险的响应。

2022 年 12 月我在["人工非智能"](https://every.to/chain-of-thought/artificial-limits?sid=37577)中写道：

“我们已经到了 AI 发展的一个点，其局限性不总是取决于技术的能力。相反，限制是出于自我限制的方式，作为减轻商业（和社会）风险的手段。”

换句话说，虽然大型在职公司正在争抢每一块可用的 GPU，吸收他们能找到的每一丝数据来训练越来越大的模型，但他们忽视了一个事实，那就是推断质量并不受他们用于训练运行的数据量的限制。相反，它受到他们愿意看起来糟糕或被起诉的程度的限制。

随着聊天机器人的广泛分布，它们返回的响应往往变得平淡无奇。它们将拒绝复制受版权保护的作品，在棘手的政治问题上采取立场，或提供医疗和法律建议。

为什么会这样？大型在职公司需要在给用户想要的东西之间保持微妙的平衡——而不至于让他们的法律、传播和合规部门抓狂。

在聊天机器人中，潜在的法律和声誉风险比在搜索中要严重得多。为什么呢？搜索结果是一系列链接，指向*其他人*的网站。谷歌不必对其提供的链接负太多责任，因为它链接到最符合用户查询的网站。

在聊天机器人领域情况就不同了。聊天机器人给出的答案是为一个用户编写的，上面标有谷歌（或任何其他 LLM 提供商的）名字。随着聊天机器人的规模扩大，其母公司将迫使其行事更像一名企业公关人员：平淡无奇，棱角被磨掉，小心翼翼地不想惹怒任何人。这不是技术上的必要性，而是大型组织内许多利益相关者为限制其沟通方式而采取的必要手段。

这为小型初创公司提供了机会。你不必在构建具有最大数据量的最大模型方面击败 OpenAI 或谷歌。你只需要愿意承担风险，比如允许你的聊天机器人说出 OpenAI 或谷歌模型不允许说出的话。突然间，你就超越了前沿模型的性能，而不需要最先进的技术。

你仍然只能服务于特定的利基市场，并且没有明确的扩展路径，而且可能会遇到老牌企业面临的同样的单调问题。 你还必须处理法律、道德和声誉的后果。 但是有办法创造这样的产品。

## 老牌企业可能会如何回应

正如我在[2022 年 12 月](https://every.to/chain-of-thought/artificial-limits?sid=37537)所写的，老牌企业很可能学会将法律、道德和声誉风险分散给他们的用户。 随着时间的推移，风险形势将更像搜索（“我们只是提供链接！”）而不是它们将自己的名字与模型返回的每个结果相关联的情况。

我看到了三种分散风险的方式：

1.  **开源**：与 Google 的 Gemini 或 OpenAI 的 ChatGPT 相比，Meta 对其开源模型的使用风险较小。 这是因为该公司本身不托管模型。

1.  **API 以启用第三方应用程序**：所有主要参与者都允许任何人使用他们的模型构建应用程序，并且他们公开的模型对响应的限制已经比第一方应用程序上可用的限制要少。

1.  **自定义聊天机器人个性**：如果 ChatGPT 或 Gemini 的响应不是来自 ChatGPT 或 Gemini 本身，而是来自例如某个个体品牌或消费者调整模型的方式，那么公司可以逃脱更多风险。ChatGPT 的自定义 GPT 功能是朝这个方向迈出的一步。

或许这是作为一名互联网作家的偏见，但自定义聊天机器人个性选项是最有趣的。我认为大型老牌企业的最佳业务定位是允许由吸引特定受众的另一品牌或“作者”编写由 AI 生成的响应。（对于像 Arc（我是投资者之一）和 Perplexity 这样的工具也是一样，它们将搜索结果自动总结成用户的“文章”。 输出是通用的，但我预计随着时间的推移，它将是与声音和个性相关的。）

例如，我可以想象这样的情景：本通讯的读者选择 ChatGPT 或 Perplexity 来以一种模仿我们读者的好奇、技术和企业家精神的 Every house 风格编写答案。 我也可以想象对于那些喜欢我觉得不吸引人的写作和观点的人，比如 Breitbart 或 TMZ，也会有同样的情况发生。

最终，我认为允许 AI 代表各种（在一定限度内）观点和视角是老牌企业的最佳业务决策，也是用户的最佳体验，同时也为新一代的出版商和内容创作者在以 AI 为先的世界中蓬勃发展留下了空间。 如果老牌企业不支持它，我预计初创公司会。

游戏开始了。

* * *

*丹·希帕（Dan Shipper）是 Every 的联合创始人兼首席执行官，在那里他撰写* [*思维链*](https://every.to/chain-of-thought) *专栏并主持* [你如何使用 ChatGPT？](https://open.spotify.com/show/5qX1nRTaFsfWdmdj5JWO1G) *播客。您可以在 X 上关注他* [*@danshipper*](https://twitter.com/danshipper) *，在* [*LinkedIn*](https://www.linkedin.com/in/danshipper/) *上关注他，以及在 Every 在 X 上关注* [*@every*](https://twitter.com/every) *，在* [*LinkedIn*](https://www.linkedin.com/company/everyinc/) *上关注 Every。*
