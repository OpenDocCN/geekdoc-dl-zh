<!--yml

类别：COT 专栏

日期：2024-05-08 11:02:34

-->

# 语言模型实际上能做什么？

> 来源：[`every.to/chain-of-thought/what-can-language-models-actually-do`](https://every.to/chain-of-thought/what-can-language-models-actually-do)

*这是我写的关于在人工智能时代重新定义人类创造力的五篇系列文章中的第一篇。*

* * *

我想要帮助拯救我们对人类创造力的理解。

人工智能可以写作、插图、设计、编码等等。但是，与其消除人类创造力的需要，这些新能力可以帮助我们重新定义和扩展它。

我们需要对语言模型进行[技术解剖](https://every.to/chain-of-thought/chatgpt-and-the-future-of-the-human-mind)，定义它们擅长做什么，以及它们不能做什么。通过这样做，我们可以分离出创造过程中自己的角色。

如果我们能做到这一点，我们将能够使用语言模型进行创造性工作，并且仍然称之为创造力。

首先，让我们谈谈语言模型*能够*做什么。

## 语言模型的心理和行为

当前一代语言模型被称为*transformers*，为了理解它们的功能，我们需要认真对待这个词。transformers 能做什么样的*转换*？

从数学上讲，语言模型是递归的下一个标记预测器。它们接收一系列文本，并预测序列中的下一个文本位。这个过程一遍又一遍地运行，自我引用地建立在其先前的输出之上，直到达到一个停止点。这有点像一个滚动下坡并沿途捡起越来越多雪的雪球。

但是，这个问题最好是在比单纯的数学可能性更高的层面上提出。相反，我们从今天的语言模型中观察到什么样的输入和输出？以及我们可以从中推断出它们的思维方式？

本质上，我们需要研究语言模型的行为和心理，而不是它们的生物学和物理学。

这是一个基于经验的草图。这是我为了与人工智能一起做出伟大的创造性工作而建立的框架。

## 语言模型的工作框架

语言模型以以下方式转换文本：

+   **压缩：** 它们将一个大的提示压缩成一个简短的回答。

+   **扩展：** 它们将一个简短的提示扩展成一个长的回答。

+   **翻译：** 它们将一个形式的提示转换成另一种形式的回应。

这些都是它们外在行为的表现。从那里，我们可以推断出它们心理的一个特性——产生它们行为的潜在思维过程：

+   **混合：** 它们将两个或更多文本（或文本的学习表示）混合在一起，并在它们之间进行插值。

我将在接下来的几周中，本系列的后续部分中分解这些元素。这些答案都不是最终答案，所以请将其视为一次公开的、可供批评的探索。今天，我想和你谈谈第一个操作：压缩。

## 语言模型作为压缩器

语言模型可以对任何文本进行压缩：

*来源：所有图片由作者提供。*

这可能看起来很简单，但实际上，这是一个奇迹。语言模型可以将大段文本压缩成像脚踩扁可乐罐一样。除了它不会被压扁——它会成为一个完美打包和比例的迷你可乐。而且它甚至是可以喝的！这就像是一场威利·旺卡式的魔术表演，没有瓦工小矮人。

语言模型压缩有许多不同的风味。其中一种常见的是我称之为*全面*压缩，或者摘要。

## 语言模型是全面的压缩器

人类一直在全面压缩事物——这就是摘要。语言模型在这方面表现得很好，就像五年级学生为书面报告总结儿童小说一样，或者应用程序[Blinkist](https://www.blinkist.com/en/lp)为忙碌的专业人士总结非虚构书籍一样。

这种总结旨在从源文本中提取解释其主要观点的思想，并将其重组成压缩形式以供更快地消费：

这些摘要旨在既全面（它们记录了所有主要观点），又对普通读者有帮助（它们以高水平表达主要观点，几乎不需要背景知识）。

同样，像 Anthropic 的 Claude 这样的语言模型，给定 Ursula K. LeGuin 经典作品《地海巫师》的文本，将轻松输出该书的主要情节的全面摘要：

但全面压缩并不是语言模型能做的唯一事情。你可以在不全面的情况下压缩文本——这为完全不同形式的压缩留下了空间。

### 语言模型是引人入胜的压缩器

如果我们要求我们的压缩是*有趣的*，而不是全面的，压缩看起来不太像书面报告，而更像是电子邮件主题行、文章标题、书名和副标题。如果我们按消耗注意力的程度对它们进行图表化，它看起来会像这样：

通过这个视角，书名只是一种

*压缩*

就像一个孩子的书面报告一样；他们只是优先考虑压缩尝试捕捉的不同要求。语言模型在这种类型的压缩方面也表现出色。

例如，在 Every，我们使用内部 AI 工具帮助我们将故事内容转化为标题。它专门针对趣味性，而不是全面性。当我输入《地海》的文本时，它建议了以下标题：

+   *暗影的名字*

+   *战士法师的暗影追寻*

+   *暗影的失败*

这些都很不错！但语言模型的压缩不仅局限于这两个压缩维度。

## 语言模型在许多不同的维度上进行压缩

压缩可以在许多不同的维度上运行。以下是一些标题的例子，都是由 Claude 编写的：

+   **Clickbaiting:** “你绝对不会相信这位年轻巫师在影岛上发现了什么！”

+   **Intrigue:** “神秘的暗影法师岛的秘密”

+   **Vibe-y:** “冷静的巫师探索阴暗的岛屿，找到自我”

+   **Alliteration:** “巫师的蜿蜒、奇妙的征途”

+   **Snark:** “哦，又是一个在岛上设定的‘选中之人’巫师故事，多么原创啊”

+   **Paranoia:** “他们在观察着：一个巫师的惊心动魄的阴影奥德赛”

+   **Pessimism:** “绝望的影岩上，一个注定失败的法师的阴郁故事”

+   **Confusion:** “等等，发生了什么？一个巫师去了一个阴影的地方，我想是吗？”

+   **Absurdist:** “薛定谔的巫师同时访问和不访问影岛”

+   **Ironic detachment:** “我猜这个巫师去了某个愚蠢的岛屿或者什么的”

+   **Gaslighting:** “没有影岛，你只是想象出来的”

当我们开始讨论压缩时，我们从这个图表开始：

如果我们想根据我们对多个不同维度压缩的扩展想法进行修订，我们可能会做出类似这样的修改：

语言模型压缩不仅仅是将一个大灰色矩形变成一个小灰色矩形。它可以将其变成一个微小的矩形，或者一个带有圆角的红色矩形，或者一个带有渐变填充的长方形。

每个压缩输出都与原始输入有一定的[家族相似性](https://en.wikipedia.org/wiki/Family_resemblance)。换句话说，提示和回复之间总会有一定程度的共同之处，但确切的重叠程度（以及不同之处）将取决于你运行的压缩类型。

压缩的维度也可以是任意具体的，并且可以结合在一起。以下是一些示例提示：

+   丹·席佩风格的推文，但带有更多的嘲讽和偏执

+   以乔治·桑德斯的风格进行分析，但让它具有煽动性

+   以斯科特·亚历山大书评风格的书摘，但要简洁明了

例如，以最后一个提示作为出发点，这是克劳德用斯科特·亚历山大的风格在[Slate Star Codex](https://www.astralcodexten.com/)上创建的《地海传说》简明书摘：

> 《地海传说》讲述了权力无智慧的危险。
> 
> 年轻的巫师盖德，在年轻的骄傲和愤怒中，从死者之境召唤出一只影子生物。结果可想而知。影子在世界各地追逐盖德，他不得不逃避，直到最后他的老师告诉他，他不能逃避自己的影子。盖德意识到唯一的出路是：他必须转身，追逐影子，并将其重新融入自己。
> 
> 这是一个相当标准的“权力腐化”故事，但在描绘盖德的缺陷时异常明智，不是渴望权力本身，而是缺乏如何使用权力的教育。盖德并不邪恶，他只是年轻而愚蠢。
> 
> 他最终的胜利来自于理解宇宙的运作方式，而不是来自于压倒性的火力。真正的宝藏是他在路上获得的智慧。
> 
> 勒·格温曾经说过，她的书是关于“内在之旅，而不是其他旅程”的。
> 
> *地海巫师* 正是如此，当盖德追随他的阴影越来越远离已知的土地时，他将其纳入自己的一部分。我们都必须最终经历这段旅程。阴影代表了我们试图否认和推开的自己的部分。但是没有逃避——最终，成长的唯一途径就是承认你的阴影，接受它，并变得完整。

我不知道这是否*确切地*是斯科特·亚历山大会写关于*地海巫师*的东西，但它肯定是在附近。它有一些东西是正确的。第一句是对书的主要观点的简洁而引人入胜的摘要，这方面亚历山大比几乎任何人都做得更好。而且这句话，“这是一个相当标准的‘权力腐败’故事”，感觉非常像是他的声音。

所以我们取得了一些进展。我们对语言模型的概念现在包括了这样一个想法，即它们在任意数量的维度或要求上“压缩”文本。

在创意工作中什么时候有用呢？

## 压缩的有用之处

让我们从像书报告这样的全面压缩开始。如果我们通过它们所传达的深度和所需的注意力来绘制它们，它们可能会位于图表的左下象限——深度不够，所需注意力不多：

存在于这个左下象限的东西具有贬义含义，因为它们需要对复杂想法进行低水平的参与：

全面的压缩就像是知识领域的麦当劳薯条：无处不在，美味，便宜，地位低下。

但是这种摘要是创意工作的重要产物，因为它尊重人类的基本有限注意力。人类需要在深入之前广泛地漫游在知识的领域中，而这种摘要允许我们对可能有用的想法进行抽样，而无需太多投入。在这种方式上，它就像是包含其中的想法的迷你广告——就像一朵绽放的花是花蜜的广告一样。

问题在于像这样做压缩通常是枯燥乏味的。任何不得不为他们的文章写摘要或不得不花几个小时重读复杂话题以便能够用几句话概括的人，都会明白我的意思。

但是语言模型擅长于更多地处于与想法的交流漏斗的底部的压缩。它们帮助你更深入地理解一个想法的细微差别，而不仅仅是浅尝辄止：

在草堆中找针一般的压缩，他们能在一长段文本中找到困难问题的答案。例如，我一直是鲁德维希·维根斯坦哲学思想的粉丝，但他的著作极其晦涩。我将他的一本书输入到克劳德中，得到了对特定问题的答案——这是将书本压缩成我可以使用的形式：

我可以想出新点子，创作以前不可能的新作品，而不是费力去理解文本。信息太多，太复杂，没有这种支持我无法理解。

一旦你开始以这种方式看待事物，你会发现压缩无处不在。电子邮件通常是会议中人们说的话的压缩。诗歌是对感官体验的压缩。良好的决策是对先前决策结果的压缩。基本编程是对 Stack Overflow 答案的压缩。

这种对世界的看法将帮助你看到语言模型在创意工作中可以发挥作用的许多情况。

认知科学家艾莉森·戈皮克写道，语言模型是[文化技术](https://every.to/chain-of-thought/chatgpt-and-the-future-of-the-human-mind?sid=41918)。它们向我们展示了人类在任何主题上所知的最佳信息——以适当的形式呈现在任何给定的环境中。用这种方式，语言模型是从写作开始延伸的趋势的延伸，一直延伸到印刷机、互联网，最终到我们的现在时刻的人工智能。

这是创意工作者的超能力：

知识可以找到你——无论你在哪里，无论你何时需要，都以适合你使用的形式压缩过来。

你想用它做什么？

—

下周，我们将讨论语言模型的下一步操作：

扩张。

* * *

***丹·希珀*** *是 Every 公司的联合创始人兼首席执行官，他在那里撰写* [*Chain of Thought*](https://every.to/chain-of-thought) *专栏并主持播客* [你如何使用 ChatGPT？](https://open.spotify.com/show/5qX1nRTaFsfWdmdj5JWO1G) *你可以在* [*@danshipper*](https://twitter.com/danshipper) *上关注他，在 Every 公司* [*@every*](https://twitter.com/every) *上关注，以及在* [*LinkedIn*](https://www.linkedin.com/company/everyinc/) *上关注他，而 Every 公司在* [*LinkedIn*](https://www.linkedin.com/company/everyinc/) *上关注。*
