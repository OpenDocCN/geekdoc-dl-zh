<!--yml

类别：COT 专栏

日期：2024-05-08 11:05:01

-->

# 我与 Gemini Pro 1.5 共度了一周——它真是太棒了

> 来源：[`every.to/chain-of-thought/i-spent-a-week-with-gemini-pro-1-5-it-s-fantastic`](https://every.to/chain-of-thought/i-spent-a-week-with-gemini-pro-1-5-it-s-fantastic)

#### 由 Destiny 赞助

##### ![](https://destiny.xyz/every)

##### 拥有改变游戏规则的公司

长期以来，风险投资一直局限于少数精英——直到现在。

使用 [Destiny Tech100（DXYZ）](https://destiny.xyz/every)，您将能够从您的经纪账户方便地投资于像 OpenAI 和 SpaceX 这样的顶级私营公司。

[**免费领取你的股票**](https://destiny.xyz/every) 在纽约证券交易所上市之前。由 Destiny 赞助。

本周我获得了 Gemini Pro 1.5 的使用权限，这是谷歌推出的新一代私人测试版 LLM，明显比该公司之前发布的模型要好得多。（这与公开发布的 Gemini 版本不同，后者因[拒绝创建白人图片](https://www.theverge.com/2024/2/21/24079371/google-ai-gemini-generative-inaccurate-historical)而成为新闻头条。那将在一周内被遗忘；而这个版本将在未来数月甚至数年内仍然相关。）

Gemini 1.5 Pro 阅读了整部小说，并详细告诉我其中隐藏的场景。它阅读了一个完整的代码库，并建议在其中插入一个新功能的位置，并提供了示例代码。它甚至阅读了我在阅读应用 Readwise 上的所有摘要，并为我正在写的一篇文章选中了一篇。

不知何故，谷歌找到了一种构建 AI 模型的方法，可以舒适地接受每个提示的 *100 万令牌*。为了方便理解，你可以将 Eliezer Yudkowsky 的 1967 页长篇著作 *《哈利·波特与理性方法》* 放入你发送给 Gemini 的 *每条消息* 中。 （你为什么要这样做，你会问？当然是为了科学。）

Gemini Pro 1.5 有两个重要成就：

1）**Gemini Pro 1.5 的上下文窗口远远大于其他最接近的模型。**虽然 Gemini Pro 1.5 轻松地消耗整个理性厌世者幻想小说作品，但 GPT-4 Turbo 只能接受 128,000 个令牌。这大约足以接受 Peter Singer 相对较瘦的 354 页书 *《动物解放》*，这是有效利他主义运动的奠基之作之一。

上周 GPT-4 的上下文窗口似乎很大；但是在使用 Gemini Pro 1.5 后，它看起来就像是会让 Derek Zoolander 的头发卷曲的数量：

2）

**Gemini Pro 1.5 可以使用整个上下文窗口。**

在我的测试中，Gemini Pro 1.5 处理大段提示表现出色。与当前模型相比，这是一个巨大的进步，当前模型的性能随着提示的增大而显著下降。即使它们的上下文窗口较小，但随着提示接近其大小限制，它们的表现也不佳。它们往往会忘记您在提示开头说的内容，或者错过位于中间的关键信息。而 Gemini 不会出现这种情况。

这些上下文窗口的改进非常重要，因为它们使模型更聪明，更容易使用。 可能可以通过 GPT-4 获得相同的性能，但是您需要编写大量额外的代码才能做到。 我马上会解释原因，但是现在你应该知道：Gemini 意味着你不需要任何基础设施。 它只是有效。

让我们通过一个例子来走一遍，然后谈谈 Gemini Pro 1.5 带来的新用例。

VC 投资传统上是为少数特权人士保留的。 但现在[Destiny Tech100（DXYZ）](https://destiny.xyz/every)正在改变这一点。 你可以拥有突破性的私人公司的一部分，比如 OpenAI 和 SpaceX，所有这些都可以通过你的经纪账户方便地拥有。 在它上市之前索取你的免费股份。 由 Destiny 赞助。

## 当谈到上下文窗口时，大小为何至关重要

我一直在阅读 Chaim Potok 的 1967 年小说《The Chosen》。 它以两位布鲁克林犹太人之间的经典敌人到恋人的故事线为特色，在一次可怕的橄榄球意外中找到了友谊和个人成长。（作为一个犹太人，让我说是的，“可怕的橄榄球意外”自从摩西分开红海以来就是一本书中最犹太的激发事件。）

在书中，Reuven Malter 和他的正统叶史瓦梨橄榄球队正在与由 Danny Saunders 领导的 Hasidic 团队比赛，后者是 rebbe 的儿子。 在一个关键的早期场景中，Danny 在打击位置上充满了愤怒。 他朝着 Reuven 打出一记直线球，Reuven 用他的脸接住了球。 眼镜被打碎，玻璃碎片喷进他的眼睛，几乎使他失明。 尽管受伤，Reuven 还是接住了球。 他的队友们关心的第一件事不是他的眼睛或他刚刚遭受的创伤性头部受伤，而是他接住了球。

如果你像我这样是一个作家，正在输入像我刚才写的那样的轶事，你可能想把 Reuven 的队友之一在他接住球后的话插入你的文章中，使其生动起来。

如果你去找 ChatGPT 求助，它一开始做得不会很好：

这是错误的。 因为，正如我所说，Sydney Goldberg 并不关心 Reuven 的受伤——他关心的是比赛！ 但并非一切都失去了。 如果你给 ChatGPT 一个纯文本版本

*The Chosen*

并且问同样的问题，它会给出一个很棒的答案：

这是正确的！（它也为我们确认了 Sydney Goldberg 的优先事项是正确的。）那么发生了什么事？

ChatGPT 表现得好像我给了它一个开卷考试。 当我们向它提问问题时，我们可以通过给它一张小纸条，上面写有一些额外信息，让它可能用来回答问题。

在这种情况下，我们让它阅读整本书。 但是你会注意到一个问题：整本书无法放入 ChatGPT 的上下文窗口。 那么它是如何工作的呢？

为了回答我的问题，ChatGPT 中有很多执行**检索**的代码：它将*被选择的*分成小块，通过这些块搜索似乎与查询相关的部分。检索代码将原始问题“悉尼·戈德伯格在被棒球击中眼睛后对鲁文说的第一句话是什么？”*以及*在书中找到的最相关的文本部分传递给 GPT-4，后者产生答案。（有关更详细的解释，请[阅读这篇文章](https://every.to/chain-of-thought/how-to-build-a-chatbot-with-gpt-3?sid=35036)。）

再次强调，我们必须传递给 GPT-4 *文本块*而不是整本书-因为 GPT-4 只能将有限的文本放入其上下文窗口。 如果您注意到，您会看到问题所在：由于上下文窗口太小，我们的模型对于回答某些类型的查询的性能受到我们搜索相关信息块的能力的限制。（我大约一年前在[这篇文章](https://every.to/chain-of-thought/gpt-4-is-a-reasoning-engine)中写了这种现象。）

如果我们的搜索功能没有找到相关的文本块，那么 GPT-4 的答案就不会好。 GPT-4 有多聪明都无所谓-它只有我们找到的块好。

假设我们在几周后继续阅读*被选择*。我们已经读完了前两节，在我们开始第三节之前，我们想要获取书中已经发生的事情的摘要。我们将其上传到 ChatGPT 并要求它进行总结：

ChatGPT 给了我们一个模糊的答案，正确但不够详细，因为它无法将足够的书籍放入其上下文窗口以输出一个很好的答案。

让我们看看当我们不必将书分成块时会发生什么。 相反，我们使用 Gemini，它可以一次阅读整本书：

您会注意到 Gemini 的答案明显更详细，并提供了 ChatGPT 无法提供的书中的关键情节。 （从技术上讲，如果我们设计了一个聪明的系统来分块和总结它，我们可能会从 GPT-4 中得到类似的摘要，但这需要大量工作，而 Gemini 使得这项工作不必要。）

Gemini 的用例不仅限于通过垒球事故自我发现的小说阅读。 还有数百种其他用例，它解锁了以前使用 ChatGPT 或自定义解决方案难以实现的用例。

例如，在 Every，我们正在孵化一个可以帮助[您使用 AI 组织文件](https://twitter.com/danshipper/status/1735398395752198442)的软件产品。我编写了文件组织者的原始代码，我们的首席工程师 Avishek 编写了一个 GPT-4 集成。他想知道在现有代码库中的哪里连接 GPT-4 集成。因此，我们将其上传到 Gemini 并问：

它找到了代码中的正确位置，并编写了 Avishek 需要完成集成的代码。这几乎就是魔法，极大地加速了开发者的生产力，尤其是在较大的项目中。

这还不止于此。我长期以来一直在探讨转换模型可能如何成为[思想的共同驾驶员](https://every.to/chain-of-thought/gpt-4-a-copilot-for-the-mind?sid=35073)——并永远结束我们整理笔记的需求。Gemini Pro 1.5 是朝这个方向迈出的一步。例如，最近我正在写一篇关于我注意到的一种效应的文章，我称之为“我可以自己做”，人们倾向于不使用 ChatGPT 和类似的工具，因为他们觉得如果自己做，可以更快地完成相同的任务，质量也更好。这就像是经验不足的经理人，他们对下属进行微观管理，直至几乎把所有工作都自己做完，保证它们按照他们想要的方式完成，但在这个过程中牺牲了很多的影响力。

我想要一个轶事来开篇，所以我让 Gemini 在我的阅读摘要中找一个。它给出了一个完美的选择：

我找不到比这更好的轶事了，而且它并不是一个通用的轶事——它来自我的阅读历史和口味。

*除此之外：* 我后来得知这个轶事是虚构的。这个想法的总体方向是正确的——Luce 确实同时负责过《时代》杂志的编辑和商业部门——所以它引导了我朝着正确的方向。但是在我回顾了我的 Readwise 高亮之后，我找不到 Gemini 给出的确切引用。 （在此文的早期版本中，Gwern 和其他精明的 Hacker News 评论者在我之前就指出了这一点。）

所以 Gemini 不是完美的。你确实需要检查它的工作。但是如果你小心谨慎，它是一个强大的工具。

再次强调，所有这些都与上下文窗口有关。正是因为有了 Gemini，这种性能才成为可能，我们不需要在将信息交给模型之前搜索或排序相关信息。我们只需将所有信息都提供给它，让模型完成剩下的工作。

与大型上下文窗口一起工作要容易得多，它们可以提供更一致和更强大的结果，而无需额外的检索代码。问题是：接下来是什么？

## 大型上下文模型的未来

大约一年前，[我写道](https://every.to/chain-of-thought/gpt-4-is-a-reasoning-engine?sid=35075)：

“人们长期以来一直在说数据是新的石油。但我认为，在这种情况下，如果你花了很多时间收集和整理自己的个人笔记、文章、书籍和重点，那将相当于在石油输出国家组织危机期间在你的卧室里有一个装满了油的桶。”

Gemini 是这一事实的完美例证。有了它的大上下文窗口，你收集的所有个人数据都准备就绪，随时可以在正确的地点和正确的时间部署，在你需要的任何任务中使用。你拥有的个人数据越多——即使它是杂乱无章的——越好。

但还有一些重要的注意事项：

首先，这是一个我可以免费使用的私人测试版。这些模型在公开发布时通常会表现出不同的性能（读：更差），而我们不知道当 Gemini 被要求在 Google 规模下运行时会表现如何。当它正式上线时，向 Gemini 注入 100 万个令牌会花费多少是无法预料的。随着时间的推移，使用它的成本可能会显著降低，但这需要一段时间。

其次，Gemini 速度相当慢。许多请求需要一分钟或更长时间才能返回，因此它并不是每个 LLM 使用案例的即插即用替代品。它是用于不能通过 ChatGPT 完成的繁重工作，而这些工作你可能不需要经常进行。我预计随着时间的推移速度会显著提高，但目前还没有达到这一点。

OpenAI 还有一些赶上的工作要做，我将密切关注他们的反应。但我关心的其他参与者——像 Langchain、LlamaIndex（我是一名投资者）、Pinecone 和 Weaviate——在某种程度上正在押注*检索*是 LLM 使用中的一个重要组成部分。它们提供的是库，用于分块和搜索信息以传递给 LLM，或者是保持信息可搜索和安全的数据存储库。正如我之前提到的，当你拥有一个大的上下文窗口时，检索就不那么重要了，因为你可以将所有信息输入到每个请求中。

这些公司可能会陷入困境。Gemini 的巨大上下文窗口确实使他们正在构建的一些内容对于基本查询不那么重要。但我认为检索长期来看仍然很重要。

如果有一件事我们了解的是，那就是我们的野心会随着我们可用的工具的增加而扩大。如果 100 万个令牌的上下文模型成为常态，我们会学会如何填充它们。每个聊天提示都会包含我们所有的电子邮件，以及我们所有的日记条目，也许还有一两本书作为补充。检索仍然会被用来找出哪些 100 万个令牌是最相关的，而不是像现在这样用来找出哪些 1000 个令牌是最相关的。

这是一个令人兴奋的时刻。期待接下来几周我会进行更多的实验！

* * *

***丹·希珀*** *是 Every 的联合创始人兼首席执行官，在那里他撰写* [*Chain of Thought*](https://every.to/chain-of-thought) *专栏并主持* [你如何使用 ChatGPT？](https://open.spotify.com/show/5qX1nRTaFsfWdmdj5JWO1G) *播客。您可以在 X 上关注他* [*@danshipper*](https://twitter.com/danshipper) *，在* [*LinkedIn*](https://www.linkedin.com/in/danshipper/) *上关注他，以及在 Every 上在 X 上关注* [*@every*](https://twitter.com/every) *，在* [*LinkedIn*](https://www.linkedin.com/company/everyinc/) *上关注 Every。*

* * *

***更正：*** *本文早期版本未注明亨利·卢斯的引述是虚构的。已更新包含该信息的内容。*
