<!--yml

类别：COT 专栏

日期：2024-05-08 11:10:39

-->

# GPT-4 是一个推理引擎。

> 来源：[`every.to/chain-of-thought/gpt-4-is-a-reasoning-engine`](https://every.to/chain-of-thought/gpt-4-is-a-reasoning-engine)

#### 赞助商：Mindsera

本文由 [Mindsera](https://www.mindsera.com/) 提供，这是一款由人工智能驱动的日记，为你提供个性化的指导和反馈，帮助你改善心态、认知能力、心理健康和健身。

在 1894 年，波士顿的一位名叫佩西瓦尔·洛威尔的天文学家在火星上发现了智慧生命。

从他的私人天文台通过望远镜观察，他观察到了火星表面的黑色直线。他相信这些直线是由一种先进但陷入困境的外星文明建造的运河，试图从极地冰盖中获取水。

他花了多年时间制作这些线条的精致图纸，他的发现当时引起了公众的想象。但是你从来没有听说过他，因为他的结论是错误的。

在 1960 年代，NASA 的水手号任务捕捉到了火星的高分辨率图像，揭示了这些“运河”只不过是行星表面撒布的陨石坑造成的光学错觉。在当时他的望远镜可用的低分辨率下，这些陨石坑看起来像是直线，由此洛威尔推理，他理论上认为这是由智慧生命建造的运河。

洛威尔的故事表明思考至少有两个重要组成部分：推理和知识。没有推理的知识是惰性的——你无法利用它做任何事情。但是没有知识的推理会变成令人信服、自信的虚构。

有趣的是，这种二元性不仅限于人类认知。这也是人们对人工智能根本性质的一个关键误解：

尽管我们的人工智能模型通过阅读整个互联网进行了训练，但这种训练主要是增强了它们的推理能力，而不是它们所知道的东西有多少。因此，今天的人工智能模型的性能受到它们缺乏知识的限制。

我上周在旧金山的一场小型 Sequoia 活动上听到了 Sam Altman 的讲话，他强调了这一点：GPT 模型实际上是推理引擎，而不是知识数据库。

这一点至关重要，因为它预测了人工智能的有用性进步将来自于其在正确的时间访问正确的知识的能力，而不仅仅是其推理能力的进步。

[Mindsera](https://www.mindsera.com/)通过基于有用的框架和心理模型的日记模板来构建你的思维，让你能够做出更好的决策，解决复杂的问题，提高生产力。

我们创新的人工智能辅导帮助您通过使心智模型可操作来实现您的目标。您可以获得专业教练的力量，而不必支付每小时 250 美元以上的费用。

[Mindsera](https://www.mindsera.com/) 的智能分析基于您的写作生成原创艺术品，测量您的情绪状态，反映您的个性，并提供个性化建议，帮助您改善。

建立自我意识，清晰思考，并在日益不确定的世界中取得成功。

## GPT 模型中的知识和推理

以下是一个例子来说明这一点。GPT-4 是市场上最先进的模型。它的推理能力非常好，以至于它可以在 AP 生物学考试上得到 5 分。但是如果我问它我是谁，它会说以下内容：

这几乎是正确的，除了一个大问题……我是几家公司的联合创始人，但它们中没有一个是 Superhuman 或 Reify。

AI 批评者会很快地说，这证明了 GPT-4 只不过是一个随机鹦鹉，其结果应该被一脚踢开。但他们错了。一旦它有了正确的信息，它的表现会显著提高。

例如，我可以访问一个版本的 ChatGPT，它可以使用网络搜索来*联系*其答案与互联网上找到的内容。

换句话说，它不是用其推理能力提出一个在理论上合理的答案，而是进行网页搜索以为自己创建一个知识库。然后，它分析收集到的信息，并提炼出一个更准确的答案：

现在，这很不错！底层模型是一样的——但答案显著改善了，因为它有了正确的信息可以推理。

这是怎么回事？GPT-4 的架构不是公开的，但我们可以根据之前发布的模型做一些有根据的猜测。

当 GPT-4 被训练时，它被喂了大量互联网上的可用材料。训练将这些数据转化为一个统计模型，该模型非常擅长于在给定一串词的情况下，知道哪些词应该跟随它——这被称为下一个令牌预测。

然而，这个统计模型中包含的“知识”类型是模糊的和不明确的。该模型没有任何长期记忆或查找它看到的信息的方法——它只记得在训练集中遇到的东西，形式是一个统计模型。

当它遇到我的名字时，它使用这个模型来对我是谁做出一个有根据的猜测。它得出了一个大致正确的结论，但在细节上完全错误，因为它没有任何明确的方法来查找答案。

但是当 GPT-4 连接到互联网（或任何像数据库的东西）时，它就不必依赖于其模糊的统计理解。相反，它可以检索明确的事实，比如“丹·希普是 Every 的联合创始人”，并使用这些来创建它的答案

那么，这对未来意味着什么呢？我认为至少有两个有趣的结论：

1.  对于 AI 进步来说，知识数据库与基础模型一样重要

1.  那些组织、存储和编目自己的思想和阅读的人在一个由 AI 驱动的世界中将拥有优势。他们可以将这些资源提供给模型，并用它来增强其响应的智能和相关性。

让我们一次讨论一个。

## **知识数据库非常重要**

当涉及到你希望能够存储大量知识，并且在正确的时间找到正确的知识时，你希望能够使用向量数据库。在 AI 中，这通常是通过向量数据库完成的。

向量数据库允许您轻松索引和存储大量信息，然后在需要时快速查询类似的信息以提供给您的模型。它们在 AI 应用中非常常见，以至于过去几个月中您尝试的几乎每个演示都包含了某个部分的向量数据库功能。

实际上，如果你想进行一项投资，以整体衡量建设人工智能的公司的成功，一个明智的举措将是投资于一个向量数据库提供商，或者一篮子向量数据库提供商。（其他选择可能是投资于 OpenAI，或者一篮子像微软和谷歌这样的大型软件公司，它们构建人工智能，或者像 NVIDIA 这样构建 AI 运行的 GPU 的芯片制造商。）

比我更聪明的投资者似乎是同意的。Pinecone，最受欢迎的向量数据库，刚刚在 [7 亿美元的估值](https://www.businessinsider.com/chroma-weaviate-pinecone-raise-funding-a16z-index-vector-database-ai-2023-3) 上筹集了资金。较小的替代品，如 Weaviate 和 Chroma，并没有落后太远，据报道它们也正在以高估值筹集资金。

有趣的是，大多数这些向量数据库最初是在大语言模型（[LLM](https://en.wikipedia.org/wiki/Large_language_model)）热潮之前构建的。向量对于所有类型的先前一代机器学习算法（如[推荐系统](https://every.to/napkin-math/recommendation-algorithims-are-good-sort-of)）都非常重要。因此，Pinecone 等提供商的数据库工具不是专门为像 ChatGPT 这样的大语言模型构建的。

我们已经看到了一些新的替代品涌现出来，它们在数据库层面上包装了一些[业务逻辑](https://en.wikipedia.org/wiki/Business_logic)，以便于 AI 开发人员执行常见任务。其中一些是开发人员库，如 Langchain 和 LlamaIndex。还有一些似乎是更全面的开发人员工具，如 [Metal](https://www.getmetal.io?utm_source=every) 和 [Baseplate](https://www.baseplate.ai?utm_source=every)。就像 Pinecone 一样，它们也很可能筹集了大量资金，或者已经筹集到了！AI 的进步是一场舞蹈，从 Patagonia 背心穿戴的天使那里召唤资本。

我觉得这非常令人兴奋，因为它将大大简化制作人工智能应用程序的过程。 目前已经编写了大量的样板代码，用于处理、解析、分割、存储和检索 PDF 或包含有趣信息的网页，以供人工智能应用程序使用。 能够用一两行代码来完成这一切，这样做越多越好。

当我跟人们谈论向量数据库——即使是那些一直关注人工智能的人们——他们通常会说，“那是什么？” 我认为，随着时间的推移，随着我们开始理解这些模型能够访问其所包含知识的重要性，这种情况将发生显著变化。

向量数据库是信息存储和提供给人工智能应用的方式。我认为他们会从私人的、个人的知识库中获得大量有价值的信息。

## **私人知识库将会非常有价值**

人们长期以来一直在说数据是新的石油。 但在这种情况下，我认为，如果你花了很多时间收集和整理你自己的个人笔记、文章、书籍和重点，这将相当于在石油输出国家组织危机期间在卧室里有一桶装满的石油。

为什么？找到与你所思考的事情相关的信息是[昂贵且耗时的](https://every.to/chain-of-thought/gpt-4-a-copilot-for-the-mind)。 即使你让人工智能访问搜索引擎，让它进行查询以找到正确的信息，这也会花费你金钱和时间。

如果相反，你一生都在收集和整理对你重要的信息，你可以自定义你的人工智能体验，使其一开始对你更加有用。

类似[Readwise Reader](https://read.readwise.io/)、Pocket 或 Instapaper 的应用，允许您存储您阅读过的文章（或您想阅读的文章），将成为一座金矿，因为它们连接到人工智能工具。 它们将会格外有用，因为它们记录了您明确收藏和阅读的文章，这将使得人工智能工具更容易知道在其回复中给予哪些信息更多的权重。

但个人知识库的使用将会变得更加奇怪和先进。

例如，Rewind 是一个工具，可以记录您在计算机上看到的一切和您键入的一切。 为了保护隐私，所有这些都存储在本地，并且您已经可以将其连接到 ChatGPT。

在他们的演示中，他们展示了一个用户询问：“上周我做了什么？” 人工智能能够总结出他们在计算机上完成的所有任务：

就我而言，我已经安装了 Rewind，并且一直在尝试构建一些小工具来保存我在网上遇到的更多内容。 我做了一个叫做 Tend 的小应用程序，它整天都在我浏览器上开启，我可以向它提供任何具有有趣信息的文章进行索引和存储。 后来，我会制作一个小的 ChatGPT 插件，让我可以访问我用它保存的所有信息。

## 总结

当我们谈论人工智能的未来时，我们往往集中在其输出上。给定提示后，它可以思考一个复杂的问题，撰写一篇文章，或在没有太多人类参与的情况下创造出新的科学突破。

我们往往低估了输入的重要性——我们提供什么样的信息来产生这些结果。它的答案在很大程度上取决于我们为其提供的用于分析的信息。它只有在起点强大时才会强大。

我们没有足够注意其知识的限制——有多少信息被锁在其中，无法访问到这些系统。我们也忘记了穿越信息源并找到相关事实的代价是多么昂贵（无论是时间上还是[计算](https://www.techopedia.com/definition/6580/compute)上）。最后，我们低估了在正确的时间为模型提供相关信息的困难程度。

但解决这些问题与解决底层模型的推理能力一样基础。我很兴奋地期待着看到人们构建什么。
