# 答案 1.4

> 原文：[`boramorka.github.io/LLM-Book/en/CHAPTER-1/Answers%201.4/`](https://boramorka.github.io/LLM-Book/en/CHAPTER-1/Answers%201.4/)

## 理论

1.  思维链（CoT）将问题解决分解为连续步骤，提高准确性并使决策过程可理解。

1.  CoT 透明度让用户能够看到模型的逻辑，从而增强信任。

1.  在教育中，CoT 模仿导师：逐步引导并培养批判性思维。

1.  在客户支持中，CoT 帮助逐步拆解复杂请求并得出精确答案，从而减少代理工作量。

1.  内心独白隐藏了中间推理过程，只显示结果——与 CoT 不同，CoT 中步骤对用户是可见的。

1.  对于敏感信息，内心独白减少了意外泄露细节的可能性。

1.  在“引导学习”中，内心独白提供提示而不“泄露”完整解决方案。

1.  环境准备包括加载 OpenAI 密钥和导入所需的 Python 库。

1.  `get_response_for_queries` 向 API 发送提示并返回模型的答案，封装了交互。

1.  CoT 提示引导模型在直接答案不明显或需要复杂逻辑时通过步骤。

1.  在支持中，系统/用户提示结构指导详细产品答案的推理。

1.  使用内心独白，您可以提取答案的最后一部分，以保持界面简洁明了。

## 练习

任务 1：CoT — 详细产品答案

1.  实现 `detailed_product_info_cot(product_name, user_question)` 函数，该函数使用 CoT 构建详细、逐步的答案。

1.  步骤：

1.  第 1 步：识别所涉及的产品。

1.  第 2 步：收集关键特征（类型、功能、好处）。

1.  第 3 步：使用收集到的数据清晰、逻辑地回答 `user_question`。

任务 2：内心独白 — 简洁摘要

1.  实现 `concise_product_summary_inner_monologue(product_name, user_question)` 函数，该函数使用内心独白来生成简洁的答案。

1.  步骤：

1.  内部：执行与 CoT 相同的步骤，但不暴露中间推理。

1.  最终：仅返回对 `user_question` 的简短、直接答案。

1.  比较两个函数的输出并解释它们适当的用例。
