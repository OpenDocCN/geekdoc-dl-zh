# 什么是神经网络的权重初始化？

> 原文：<https://www.assemblyai.com/blog/what-is-weight-initialization-for-neural-networks/>

权重初始化，即使是一个小问题，也会对我们训练的深度前馈神经网络产生严重影响。

感谢 Xavier Glorot 和 Yoshua Bengio，我们意识到使用正态分布初始化平均值为 0、方差为 1 的权重会导致不稳定的梯度问题。这就是为什么提出了新技术来克服这些问题。

在这个视频中，我们了解这些技术是什么，它们之间有什么不同，以及它们的完美激活功能匹配是什么。

[https://www.youtube.com/embed/tYFO434Lpm0?feature=oembed](https://www.youtube.com/embed/tYFO434Lpm0?feature=oembed)