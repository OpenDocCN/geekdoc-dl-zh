# 为什么数据不必那么大

> 原文：<https://web.archive.org/web/20221129040116/https://www.datacamp.com/blog/why-data-doesnt-have-to-be-that-big>

## 定义大数据

大数据是数据领域最热门的词汇之一。但是到底多大才算大呢？一种思考方式是从体积或者你拥有的数据量的角度。根据容量，我们可以将大数据定义为远远超过现代笔记本电脑或硬盘所能存储的数据。因此，它需要分布在计算机集群中进行处理、传输和分析。我们可以扩展大数据的定义，以涵盖**三个 Vs** :数量、速度和多样性。

*   **量**:数据量
*   **速度**:移动和分析数据的速度
*   **多样性**:你拥有的不同类型的数据

## 大数据是理论的终结吗？

2008 年，克里斯·安德森在《连线》杂志上写了一篇挑衅性的文章，名为[理论的终结，数据洪流让科学方法过时](https://web.archive.org/web/20220522143352/https://www.wired.com/2008/06/pb-theory/)。前提是我们有足够的数据对世界做出令人满意的预测，我们不需要理论来理解世界。这种争论的部分推动力是我们在谷歌身上看到的情况——他们能够对海量数据进行操作，然后以数据产品的形式提供预测模型，用于程序化广告购买。此外，他们能够通过足够先进的预测分析做到这一点，而无需了解或理论化所研究的系统。

这一切都是为了利用捕捉到的人类行为来制造更好的产品和服务。谷歌使那些想要购买广告的人能够在谷歌 AdWords 上轻松购买，AdWords 背后的模型不依赖于任何关于有人会不会点击的理论。谷歌有足够的数据做出“足够好”的预测。克里斯·安德森(Chris Anderson)的挑衅性假设是，大数据包含了如此多的信息，以至于我们不再需要对世界进行建模，我们也不需要理解它背后的理论或实际发生的事情。

大数据实际上兑现了对我们的承诺吗？思考这个问题的一种方法是在 Gartner 炒作周期中建模。

[![](img/034dbdf382f9ab5bae90328a0bc92f23.png)](https://web.archive.org/web/20220522143352/https://en.wikipedia.org/wiki/Hype_cycle)

Gartner 炒作周期告诉我们一项技术创新和围绕它的预期是时间的函数。我们从创新触发器开始，在大数据的情况下，它是存储、传输和分析大量数据的能力。然后人们对此议论纷纷，导致过高的期望。之后，我们看不到与期望相反的价值，因此我们进入了幻灭的低谷。只有在这之后，我们才能看到真正的价值开始在几个不同的垂直行业中传递——我们进入了启蒙阶段。

大数据目前处于 Gartner 炒作周期的哪个阶段？思考预期的一种方式是，将人们在谷歌上搜索的内容视为时间的函数。以下是谷歌自 2004 年以来的“大数据”趋势。您可以看到，Chris Anderson 走在了时代的前面，但由于小数据和厚数据的重要性，他错误地认为大数据是理论的终结。

[![](img/2c3c0572eb5823b232c89cc24ef64ad3.png)](https://web.archive.org/web/20220522143352/https://www.datacamp.com/resources/ebooks/definitive-guide-to-machine-learning-for-business-leaders)

如果我们接受 Gartner 炒作周期作为思考大数据的有效模型，如果我们接受 Google trends 作为预期的代理，我们可以看到膨胀的预期的峰值是在 2014 年左右，我们还没有到达幻灭的低谷。

## 小数据也很强大

虽然数据科学中的许多最新创新都集中在我们高效处理日益增长的海量数据的能力上，但重要的是要认识到，现实世界中分析的绝大多数数据确实适合现代笔记本电脑的内存。作为业务领导者，在决定采用哪些工具和架构之前，您应该仔细考虑您的数据组织的需求。

我想带你们回到约翰尼斯·开普勒，他发现了行星运动的三大定律，还有丹麦天文学家第谷·布拉尼，他收集了开普勒最终分析的数据，构建了他的运动三大定律，然后形成了牛顿的万有引力理论。我们从布拉赫收集的数据中获得了大量的科学知识，这些数据仅由大约 2000 个数据点组成。与我们今天谈论的数据集相比，这是一个很小的数据集，有时包含数亿个数据点。但是 Brahe 收集的数据质量很高。如果你有良好的，适当收集的数据，强大的分析性和原则性的理论模型，以及一种做统计建模的方法，你可以从你的数据中获得巨大的数量。

[![](img/131c98bf1a84fa941574cf7f236fa543.png)](https://web.archive.org/web/20220522143352/https://www.datacamp.com/resources/ebooks/definitive-guide-to-machine-learning-for-business-leaders)

让我们来看看 Andrew Gelman 的文章中探讨的另一个例子，[一个只有 1004 名美国人的民意调查怎么能代表 2 . 6 亿人，误差只有 3 %?](https://web.archive.org/web/20220522143352/https://www.scientificamerican.com/article/howcan-a-poll-of-only-100/) Gelman 通过数学向您展示，当您增加数据量时，您会在减少误差幅度方面获得严重的收益递减。声明:只有当你对你的人口进行了某种代表性的抽样时，这个结果才是真实的，但在民意调查中绝对不是这样。但统计学家现在有了对非代表性样本的复杂校正方法，他们可以用这些方法来了解更多人的投票偏好。

同样，我们从少量的数据中看到一个重要的结果，它告诉我们人类行为和人类偏好的本质。同样的原则也适用于商业——它是关于理解和能够预测未来人类行为的，尤其是就你的利益相关者而言。那么，为什么我们在没有必要的时候谈论大数据呢？一个主要的原因是，如今它很容易获得，而且是可计算的。

底线是《哈佛商业评论》在[中的观点，有时“小数据”足以创造智能产品](https://web.archive.org/web/20220522143352/https://hbr.org/2017/07/sometimes-small-data-is-enough-to-create-smart-products)“这不是关于堆积如山的数据，而是关于小的、高精度的数据。”

## 不要低估厚数据的力量

既然我们已经讨论了小数据的力量，我想转到另一种类型的数据，称为厚数据，或定性数据。薄数据涉及数字和表格，而厚数据，一个来自社会学和人类学的术语，更具有定性和描述性。一个名为 ReD Associates 的咨询集团利用厚数据帮助人们建立分析模型和机器学习模型，做了出色的工作。

我想提到的一个例子是他们在[检测信用卡欺诈](https://web.archive.org/web/20220522143352/https://www.redassociates.com/press-1/2017/10/18/forbes-big-data-insights-or-illusions)方面的工作。这是一个巨大的挑战，机器学习在过去已经被用于检测信用卡欺诈，使用诸如交易金额、交易时间、位置等特征。ReD Associates 试图收集大量数据，采用社会学方法来解决这个问题。

为了做到这一点，ReD Associates 与信用卡欺诈者坐在一起，了解他们实际上在做什么，他们的流程是什么样的。他们在黑暗网络上发现了一个信用卡诈骗者社区，并在现实生活中与他们见面，了解他们的流程和习惯。

他们发现，信用卡诈骗者最有可能被抓住的时间点是他们在现实世界中不得不做一些事情的时候——比如取快递。他们精通技术，很少能在网上被发现。欺诈者在物理领域也很小心——他们通常不会将包裹寄到自己的地址、工作地址或朋友的地址。取而代之的是，他们把快递送到废弃的或房地产市场上的房产地址。

有了这些知识，ReD Associates 建立了一个信用卡欺诈检测模型，使用包裹被送往的位置作为一个特征，并将废弃房屋和市场上房屋的公开数据加入其中。他们观察到，与更传统的欺诈交易模型相比，这种基于定性数据的模型在准确性上有了显著提高。这是一个很好的例子，说明了厚数据的重要性，以及采取社会学方法可以提供更多的价值。我推荐这两篇文章，以进一步详细探讨优质数据如何比大数据更重要:[‘厚’数据的力量](https://web.archive.org/web/20220522143352/https://www.redassociates.com/press-1/2017/10/18/forbes-big-data-insights-or-illusions)和[大数据只是营销人员所需数据的一半](https://web.archive.org/web/20220522143352/https://store.hbr.org/product/big-data-is-only-half-the-data-marketers-need/H02GX9)。

## 行动呼吁

选择一个对您的业务有价值的数据源，并考虑您真正需要这些数据中的多少来为决策提供信息。衡量这一点的一种方法是考虑增加 2 倍、5X 和 10 倍的附加值，特别是在收集、存储和分析这些数据的投资方面。然后，回答这个问题:您可以使用什么样的厚数据来提高这个数据源的质量？

在[商业领袖机器学习权威指南](https://web.archive.org/web/20220522143352/https://www.datacamp.com/resources/ebooks/definitive-guide-to-machine-learning-for-business-leaders)中了解更多利用数据的最佳实践。

[![](img/7f03104da8d0b094d04335f7dad522c0.png)](https://web.archive.org/web/20220522143352/https://www.datacamp.com/resources/ebooks/definitive-guide-to-machine-learning-for-business-leaders)