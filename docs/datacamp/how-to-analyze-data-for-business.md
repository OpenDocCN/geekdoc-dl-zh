# 如何通过 5 个步骤为您的企业分析数据

> 原文：<https://web.archive.org/web/20221212135909/https://www.datacamp.com/blog/how-to-analyze-data-for-business>

大数据是大生意。我们社会的快速数字化导致了前所未有的数据增长。此外，随着新技术和基础设施的出现，如虚拟现实、元宇宙、物联网(IoT)和 5G，这一趋势可能会在未来保持下去。因此，了解如何分析数据至关重要。

数据已经成为 21 世纪经济中最宝贵的资产之一。政府、公司和个人使用数据来改善他们的决策过程。这导致了对合格专业人员处理和分析大量数据的巨大需求。

然而，许多公司仍然难以管理和理解数据。根据 Splunk 的[调查，公司收集的所有数据中有 55%被认为是“暗数据”——即公司在日常业务活动中收集但未使用的数据。虽然有时公司根本没有意识到数据的存在，但在大多数情况下，公司不会分析数据，因为他们缺乏合适的人才来做这件事。](https://web.archive.org/web/20221116214818/https://www.splunk.com/en_us/form/the-state-of-dark-data.html)

使用内部数据科学计划培训员工是解决数据科学家短缺的最佳策略之一。与普遍的看法相反，开始分析数据并不需要统计学的高级学位或计算机科学的博士学位。市场对各种人和各种情况都有很多选择。例如，在 DataCamp，我们为个人和组织提供全面的数据培训。

在本文中，我们将介绍数据分析过程。我们将介绍一个简单的框架，即数据科学工作流，以及从原始数据到有价值见解的简单步骤。

## 如何使用数据科学工作流分析数据

当数据专业人员开始一个涉及数据分析的新项目时，他们通常会遵循一个五步流程。这就是我们所说的数据科学工作流，您可以在下面看到它的各个部分:

1.  **确定业务问题**
2.  **收集和存储数据**
3.  **清理和准备数据**
4.  **分析数据**
5.  **可视化和交流数据**

数据科学工作流程

在下面几节中，我们将更详细地了解每个步骤。

虽然数据科学工作流程可能会因任务的不同而有所差异，但每次开始新的数据项目时，坚持一致且定义明确的框架是非常重要的。它将帮助你计划、实施和优化你的工作。

### 1.识别业务问题

数据只和你问的问题一样好。许多组织花费数百万从不同来源收集各种数据，但许多组织未能从中创造价值。事实是，无论您的公司拥有多少数据，或者部门中有多少数据科学家，只有在您确定了正确的业务问题后，数据才会成为游戏规则的改变者。

将数据转化为见解的第一步是定义一组清晰的目标和问题。下面是一些例子:

*   公司需要什么？
*   我们试图解决什么类型的问题？
*   数据如何帮助解决问题或业务问题？
*   需要什么类型的数据？
*   我们将使用哪些编程语言和技术？
*   我们将在数据分析过程中使用什么方法或技术？
*   我们将如何衡量结果？
*   数据任务将如何在团队中分配？

在数据科学工作流程的第一步结束时，您应该对如何继续有一个清晰明确的想法。这个大纲将帮助你驾驭数据的复杂性，实现你的目标。

不要担心在这一步花费额外的时间。识别正确的业务问题对于提高效率至关重要，最终将为您的公司节省时间和其他资源。

### 2.收集和存储数据

现在你已经有了一套清晰的问题，是时候动手了。首先，您需要收集数据并将其存储在一个安全的地方，以便进行分析。

在我们这个数据驱动的社会中，每秒钟都会产生大量的数据。数据的三个主要来源是:

*   **公司数据**。它是由公司在日常活动中创造的。它可以是 web 事件、客户数据、金融交易或调查数据。这些数据通常存储在关系数据库中。
*   **机器数据**。随着敏化和物联网技术的最新进展，越来越多的电子设备正在生成数据。它们的范围从相机和智能手表到智能房屋和卫星。
*   **打开数据**。鉴于数据为经济创造价值的潜力，政府和公司正在发布可以免费使用的数据。这可以通过开放数据门户和 API(应用编程接口)来实现。

然后我们可以将数据分为两种类型:

*   **定量数据**。它是可以用数值计算或测量的信息。它通常由电子表格或 [SQL 数据库](https://web.archive.org/web/20221116214818/https://www.datacamp.com/courses/introduction-to-sql)构成。
*   **定性数据**。今天生成的大部分数据都是定性的。一些常见的例子是文本、音频、视频、图像或[社交媒体数据。](https://web.archive.org/web/20221116214818/https://www.datacamp.com/courses/analyzing-social-media-data-in-python)定性数据通常是非结构化的，难以在标准电子表格或关系数据库中存储和处理。

根据你要回答的商业问题，会用到不同类型的数据和技术。通常，收集、存储和分析定性数据需要比定量数据更先进的方法。

### 3.清理和准备数据

一旦你收集并存储了数据，下一步就是评估它的质量。请务必记住，数据分析的成功在很大程度上取决于数据的质量。如果你的信息不准确、不完整或不一致，你的见解将是错误的或误导的。这就是为什么花时间打扫卫生和准备时间是强制性的。查看我们关于坏数据的[迹象](https://web.archive.org/web/20221116214818/https://www.datacamp.com/blog/10-signs-bad-data-quality)的文章，了解更多信息。

原始数据很少用于分析。评估数据质量对于发现和纠正数据中的错误至关重要。该过程包括修复错误，如:

*   删除重复的行、列或单元格。
*   删除分析过程中不需要的行和列。如果您正在处理消耗大量内存的大型数据集，这一点尤其重要。
*   处理数据集中的空白，也称为空值
*   管理异常值和极值，也称为异常值
*   标准化数据结构和类型，以便所有数据以相同的方式表示。

发现数据中的错误和异常本身就是一种数据分析，通常称为[探索性数据分析。](https://web.archive.org/web/20221116214818/https://www.datacamp.com/tutorial/exploratory-data-analysis-python)

#### 探索性数据分析

探索性数据分析旨在研究和总结数据的特征。实现这一点的主要方法是统计和数据可视化:

*   **统计数据**提供汇总数据的简要信息系数。一些常见的统计数据是均值、中值、标准差和相关系数。
*   **数据可视化**是数据的图形化表示。根据数据的类型，一些图表会比其他图表更有用。例如，箱线图是可视化数据分布和分割极值的绝佳图形。

这个阶段投入的时间在很大程度上取决于数据量和您想要分析的数据的质量。然而，数据清理通常是数据科学工作流程中最耗时的步骤。事实上，[数据科学家在数据科学工作流程的这个阶段花费了他们 80%的](https://web.archive.org/web/20221116214818/https://www.forbes.com/sites/gilpress/2016/03/23/data-preparation-most-time-consuming-least-enjoyable-data-science-task-survey-says)时间。

如果你在一家数据分析是日常业务活动的一部分的公司工作，在这个阶段提高效率的一个伟大策略是实施一个[数据治理策略](https://web.archive.org/web/20221116214818/https://www.datacamp.com/resources/webinars/data-governance-enables-scalable-data-science)。有了关于如何清理和处理数据的明确规则和政策，您的公司将能够更好地处理数据并减少数据清理所需的时间。

如果您对数据清理过程如何工作以及数据问题的主要类型感兴趣，请查看我们的 Python 课程中的[清理数据和 R 课程中的](https://web.archive.org/web/20221116214818/https://www.datacamp.com/courses/cleaning-data-in-python)[清理数据。](https://web.archive.org/web/20221116214818/https://www.datacamp.com/courses/cleaning-data-in-r)此外，如果您想了解数据探索性分析在实践中是如何工作的，我们的[SQL 探索性数据分析](https://web.archive.org/web/20221116214818/https://www.datacamp.com/courses/exploratory-data-analysis-in-sql)课程将帮助您入门。

### 4.分析数据

现在您的数据看起来很干净，您已经准备好分析数据了。发现模式、联系、见解和预测通常是数据科学家工作中最令人满意的部分。

根据分析的目标和数据的类型，可以使用不同的技术。多年来，出现了处理各种数据的新技术和方法。它们的范围从简单的线性回归到尖端领域的先进技术，如机器学习、自然语言处理(NLP)和计算机视觉。

下面您可以找到一些最流行的数据分析方法列表，以便更深入地分析:

#### 机器学习

人工智能的这一分支提供了一套算法，使机器能够从可用的历史数据中学习模式和趋势。一旦算法经过训练，它们就能够以越来越高的精度做出概括的预测。根据要解决的问题类型，有三种类型的机器学习:

*   **监督学习**涉及在历史数据的标记训练集上教授模型，它从该训练集中学习输入和输出数据之间的关系。然后，它使用预先知道的输出值来估计测试集上预测的准确性，以便稍后可以使用该模型对未知数据进行预测。要了解更多关于监督学习的信息，请参加 Datacamp 的[监督学习与 scikit-learn 课程](https://web.archive.org/web/20221116214818/https://www.datacamp.com/courses/supervised-learning-with-scikit-learn)。
*   **无监督学习**处理在没有给定因变量的情况下识别数据的内在结构，检测其中的共同模式，根据属性对数据点进行分类，然后根据这些信息对新数据进行预测。如果你想扩展你在无监督学习方面的知识，可以考虑我们的[Python 课程](https://web.archive.org/web/20221116214818/http://datacamp.com/courses/unsupervised-learning-in-python)中的无监督学习。
*   **强化学习**意味着一种算法通过与环境互动来逐步学习，决定哪些行动可以让它更接近解决方案，根据过去的经验确定哪些行动可以赶走它，然后为特定步骤执行最佳行动。这里的原则是，算法对错误的行为进行惩罚，对正确的行为进行奖励，这样它就可以为自己的表现找出最佳策略。准备好了解更多信息了吗？查看这个[强化学习介绍](https://web.archive.org/web/20221116214818/https://www.datacamp.com/tutorial/introduction-reinforcement-learning)教程。

#### 深度学习:

机器学习的一个子领域，研究受人脑结构启发的人工神经网络算法。与传统的机器学习算法不同，深度学习算法的线性度更低，更加复杂和分层，能够从海量数据中学习，并能够产生高度准确的结果，特别是在处理非结构化数据时，如音频和图像。

#### 自然语言处理

机器学习的一个领域，研究如何赋予计算机理解人类语言的能力，包括书面语言和口头语言。NPL 是数据科学中发展最快的领域之一。要开始学习，您可以注册我们的[自然语言处理 Python 技能跟踪](https://web.archive.org/web/20221116214818/https://www.datacamp.com/tracks/natural-language-processing-in-python)。一些最流行的自然语言处理技术是:

*   **文本分类**。这是文本挖掘的重要任务之一。这是一种受监督的方法。它有助于识别给定文本的类别，如博客、书籍、网页、新闻文章和推文。
*   **情感分析**。一种涉及量化用户内容、想法、信念或意见的技术。[情感分析](https://web.archive.org/web/20221116214818/https://www.datacamp.com/courses/sentiment-analysis-in-python)有助于更好、更准确地理解人们。

#### 计算机视觉

计算机视觉的目标是帮助计算机看到并理解数字图像的内容。例如，计算机视觉对于实现自动驾驶汽车是必要的。在这个领域开始的一个很好的方法是使用我们的[Python 技能追踪进行图像处理。](https://web.archive.org/web/20221116214818/https://www.datacamp.com/tracks/image-processing)

一些最流行的计算机视觉技术是:

*   **图像分类**。这是最简单的计算机视觉技术。主要目的是将图像分为一个或多个类别。
*   **物体检测**。这项技术允许我们检测图像中存在哪些类，以及它们在图像中的位置。这里最常见的方法是在图像中找到该类，并用边界框定位该对象。

### 5.可视化和交流结果

数据科学工作流的最后一步是可视化和交流数据分析的结果。为了将你的见解转化为决策，你必须确保你的受众和关键利益相关者理解你的工作。

在这最后一步，数据可视化是跳舞皇后。如前所述，数据可视化是将数据转化为可视化上下文的行为。这可以通过图表、绘图、动画、信息图等等来实现。其背后的想法是让人类更容易识别数据中的趋势、异常值和模式。

无论是静态图表和图形还是[交互式仪表盘](https://web.archive.org/web/20221116214818/https://www.datacamp.com/blog/best-practices-for-designing-dashboards)，数据可视化对于让您的工作易于理解并有效传达您的见解至关重要。这里列出了[最流行的数据可视化工具](https://web.archive.org/web/20221116214818/https://www.datacamp.com/blog/12-of-the-best-data-visualizations-tools):

#### Python 包

Python 是一种高级、解释型、通用编程语言。它为数据可视化提供了几个很棒的图形包，例如:

*   Matplotlib
*   希伯恩
*   Plotly
*   散景
*   Geoplotlib

使用 Python 的[数据可视化](https://web.archive.org/web/20221116214818/https://www.datacamp.com/tracks/data-visualization-with-python)技能课程是一个很好的课程序列，使用 Python 最流行和最强大的数据可视化库来增强您的数据科学技能。

#### r 包

r 是一种用于统计计算和图形的编程语言。这是一个很好的数据分析工具，因为你可以使用它的各种包创建几乎任何类型的图表。流行的 R 数据可视化包包括:

*   ggplot2
*   格子木架
*   高价租船合同
*   传单
*   Plotly

查看技能跟踪中的[数据可视化与 R 课程](https://web.archive.org/web/20221116214818/https://www.datacamp.com/tracks/data-visualization-with-r)和[交互式数据可视化，提升您的 R 编程语言可视化技能。](https://web.archive.org/web/20221116214818/https://www.datacamp.com/tracks/interactive-data-visualization-in-r)

#### 无代码开源工具

对于没有编程知识的人来说，无代码工具是一个容易使用的解决方案——尽管有编程技能的人仍然会选择使用它们。更正式的说法是:无代码工具是图形用户界面，具有运行本地脚本来处理和扩充数据的能力。一些最受欢迎的是:

*   草图
*   数据包装器
*   谷歌图表

#### 商业智能工具

这些一体化工具被数据驱动的公司广泛使用。它们用于大量原始数据的收集、处理、集成、可视化和分析，从而有助于业务决策。一些最常见的商业智能工具有:

*   （舞台上由人扮的）静态画面
*   功率 I
*   Qlik

要了解这些工具的更多信息，我们强烈推荐我们的[Tableau 简介](https://web.archive.org/web/20221116214818/https://datacamp.com/courses/introduction-to-tableau)课程和[Power BI 简介](https://web.archive.org/web/20221116214818/https://www.datacamp.com/courses/introduction-to-power-bi)课程。

近年来，已经提出了改进数据通信的创新方法。其中之一是数据讲故事，这种方法提倡使用视觉、叙事和数据将数据见解转化为行动。查看我们的数据框架播客的[集，Brent Dykes 是《有效的数据故事讲述:如何用数据、叙事和视觉推动变革》的作者，以了解更多关于这种方法的信息。](https://web.archive.org/web/20221116214818/https://www.datacamp.com/blog/effective-data-storytelling-how-to-turn-insights-into-actions)

## 结论

我们希望您喜欢这篇文章，并准备开始自己的数据分析。一个很好的开始方式是报名参加我们的[面向所有人的数据科学](https://web.archive.org/web/20221116214818/https://www.datacamp.com/courses/data-science-for-everyone)课程。通过动手练习，参与者将了解不同的数据科学家角色、A/B 测试、时间序列分析和机器学习等基础主题，以及数据科学家如何从真实世界的数据中提取见解。

作为入门课程的后续，我们为学习者提供全面的跟踪，以继续他们的学习之旅。学生可以在职业生涯中选择他们喜欢的语言( [Data Scientist with Python](https://web.archive.org/web/20221116214818/https://www.datacamp.com/tracks/data-scientist-with-python) 、 [R](https://web.archive.org/web/20221116214818/https://www.datacamp.com/tracks/data-scientist-with-r) 或 [SQL](https://web.archive.org/web/20221116214818/https://www.datacamp.com/tracks/data-analyst-with-sql-server) )，在职业生涯中，通过对真实世界数据集进行系统的交互式练习来教授基本的数据技能。

一旦你完成了其中一项职业生涯，你就可以继续参加数据科学[认证计划](https://web.archive.org/web/20221116214818/https://www.datacamp.com/certification)，让专家验证和认证你的新技能。

数据分析是对数据进行收集、清理、转换和建模以发现有用信息的过程。

这是一个分析数据的五步框架。这五个步骤是:1)确定业务问题，2)收集和存储数据，3)清理和准备数据，4)分析数据，5)可视化和交流数据。

发现并修复数据中的异常。这是开始分析数据前的关键一步。

数据的图形表示。这可以通过绘图、图表、地图等等来实现。

不！虽然学习编码很有挑战性，但是数据科学欢迎每个人。有了耐心、决心和学习的意愿，前途无量。