# 新冠肺炎时代关于数据隐私的关键要点

> 原文：<https://web.archive.org/web/20230101103301/https://www.datacamp.com/blog/key-takeaways-about-data-privacy-in-the-age-of-covid-19>

[![](img/ec4410c2e85206d08b8b7af1a22f934b.png)](https://web.archive.org/web/20220525043538/https://www.datacamp.com/discover/enterprise)

[![](img/ec7cdb09d6e96a6962e381ed569ff416.png)](https://web.archive.org/web/20220525043538/https://www.datacamp.com/discover/enterprise)

在新冠肺炎危机之前，我们已经敏锐地意识到围绕数据隐私进行更广泛对话的必要性:只需看看斯诺登爆料、剑桥分析、纽约时报隐私项目、欧洲通用数据保护法规(GDPR)和加州消费者隐私法案(CCPA)就知道了。在新冠肺炎时代，这些问题要尖锐得多。我们也知道，政府和企业利用危机来巩固和重新安排权力，声称公民需要为了安全而放弃隐私。但是这种权衡是错误的二分法吗？我们正在开发什么样的工具来帮助我们度过这场危机？

在我们最近的 DCVirtual 网络研讨会周，Cape Privacy(一个安全、保护隐私的机器学习平台)的产品负责人 Katharine Jarmul 在与 DataCamp 的数据科学家和教育家 Hugo Bowne-Anderson 博士的对话中讨论了所有这些以及更多内容。[观看网上研讨会点播](https://web.archive.org/web/20220525043538/https://www.datacamp.com/resources/webinars/data-privacy-in-the-age-of-covid-19)或[听播客](https://web.archive.org/web/20220525043538/https://www.datacamp.com/community/podcast/Data-Privacy-Age-of-COVID-19)，或继续阅读一些要点。

## 数据隐私有内在的权衡吗？

Hugo 从 Stuart Russell 的书 [Human Compatible](https://web.archive.org/web/20220525043538/https://www.amazon.com/Human-Compatible-Artificial-Intelligence-Problem-ebook/dp/B07N5J5FTS) 中引出了一个挑衅性的问题:如果人工智能对你或像你这样的人一无所知，它能帮上忙吗？答案很可能不是。那么我们是不是被迫放弃自己的隐私，才能在日常生活中受益于 AI 呢？许多人在方便、实用和隐私之间，以及隐私和安全之间做出权衡。

政府和企业有时声称，为了安全，公民需要放弃隐私。这就是为什么如此多的消费者不信任人工智能个人助理，并干脆选择不购买 Alexa。但是，那些购买 Alexa 的人“应该”被侵犯隐私吗？底线是把举证责任放在想要保护自己隐私的人身上是不公平的。这种权衡是错误的二分法。

## 生产研究

凯瑟琳认为，关键是将研究生产化，这也是吸引她在 Cape Privacy 工作的原因。数据隐私领域的研究深度惊人。她说，我们可以用对我们来说很重要的真实世界的用例和威胁来推动研究。这意味着研究人员和工业人员之间的良好关系。

生产研究的最佳实践是，学习算法可以使用安全的多方计算技术对加密数据进行操作，以便用户可以从共享中受益，而不会损害个人隐私。

## 将隐私专业知识融入你的技能组合

数据隐私是一个需要跨职能部门协作的大问题。每个处理数据的人都需要意识到隐私问题，并感到有能力了解和解决他们实施的解决方案中的任何隐私威胁。许多公司已经采用数据隐私、安全或风险团队来保护他们的产品和品牌。数据科学家和机器学习专家将继续不得不将这些考虑因素构建到他们构建的系统中。这包括跟上先进的隐私和安全技术。

## 理解这是关于同意和满足期望

我们的数据隐私标准随着时间的推移不断发展。例如，10 年前，许多人在得知他们收到了基于电子邮件中关键词的定向广告后感到愤怒。但是今天，许多人认为这是谷歌的标准商业行为。

我们必须对政府和行业中的当权者保持高标准，以防止滥用。这些机构可以接触到如此多的数据——有些用户认为是公开的，有些用户认为是私人的。我们应该根据什么基准来判断那些有权访问和控制这些数据的人呢？

数据隐私和道德归结为同意并满足用户、公民和消费者对其数据使用方式的期望。它需要意识、理解和透明度。

## 隐私、道德和透明的需要

数据隐私和道德是相辅相成的。当然，在伦理研究中，我们必须认识到不完美的条件。这需要结合我们从理论角度了解的知识，尽我们所能创造出最好的生产系统。

有很多不好的做法需要透过这个镜头来看。根据我们所知道的，我们如何改进不好的做法？一个好办法是确保公司在文件中尽可能透明。条款和条件通常非常难以阅读——通常是故意的。《纽约时报》分析了 Airbnb 和脸书等公司的 150 项隐私政策，其中一些政策比康德*的《纯粹理性批判》等深奥的哲学文本更难阅读。*

公司还应该认真考虑应对挑战的最佳解决方案，而不仅仅是最方便的解决方案。例如，出于欺诈检测的目的， [Stripe 正在悄悄监控您在客户网站上的活动](https://web.archive.org/web/20220525043538/https://mtlynch.io/stripe-recording-its-customers/)。但在条款和条件中并没有真正明确他们正在这样做，而且有许多方法可以在不收集用户导航移动和浏览器历史的情况下防止欺诈。

## 保持信任关系

罗斯·安德森关于现实世界中的联系人追踪的文章驳斥了许多反对这篇博文开头提到的数据隐私折衷的错误观点。当权者继续声称，如果他们能更多地获取我们越来越多的私人信息，他们就能保证更多的安全。尤其是在今天，我们需要质疑强大机构持续整合数据的道德和影响。

这意味着我们需要让他们对处理数据的方式负责。如果他们出于某种目的收集数据，则应仅限于该用途，并在事后删除。例如，在数据伦理社区中，数据信任是在签订合同仅将特定数据集用于单一目的(如抗击癌症或绘制基因组)并且禁止用于其他目的的情况下建立的。建立该系统的治理将允许更好地强制数据用于其预期目的。如果公司明确同意删除某些数据，他们必须能够证实这些数据已经被删除。此外，如果数据被删除，但用于丰富其他信息，还必须澄清谁拥有这些丰富的数据。

## 人工智能在新冠肺炎的直接应用

人工智能不会是治愈新冠肺炎疫情的唯一方法，但我们可以利用我们在数据和机器学习方面的技能，以积极的方式做出贡献。这包括报告与冠状病毒相关的网络钓鱼和网络安全威胁、[医院的能力规划](https://web.archive.org/web/20220525043538/https://www.datacamp.com/resources/webinars/covid-19-and-hospital-capacity-planning)，以及优化物流运营以确保物资的公平分配。

如果你喜欢这些内容，请确保通过[播客](https://web.archive.org/web/20220525043538/https://www.datacamp.com/community/podcast/Data-Privacy-Age-of-COVID-19)或[网络研讨会](https://web.archive.org/web/20220525043538/https://www.datacamp.com/resources/webinars/data-privacy-in-the-age-of-covid-19)点播观看完整的对话。此外，请查看凯瑟琳和雨果 2018 年关于[数据安全、数据隐私和 GDPR](https://web.archive.org/web/20220525043538/https://www.datacamp.com/community/podcast/data-security-privacy-gdpr) 的对话。你可以在推特上关注凯瑟琳的 [@kjam](https://web.archive.org/web/20220525043538/https://twitter.com/kjam) 和雨果的 [@hugobowne](https://web.archive.org/web/20220525043538/https://twitter.com/hugobowne) 。如果你对探索自然语言处理的能力感兴趣，我们鼓励你参加 Katharine 的 DataCamp 课程，学习 Python 自然语言处理入门和她的项目，谁在发推特？特朗普还是特鲁多？

[![](img/f6059efbde16ddec64b866c349093d31.png)](https://web.archive.org/web/20220525043538/https://www.datacamp.com/business/demo)