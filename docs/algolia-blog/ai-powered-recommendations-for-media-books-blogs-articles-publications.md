# 人工智能推荐媒体、书籍、博客

> 原文：<https://www.algolia.com/blog/ai/ai-powered-recommendations-for-media-books-blogs-articles-publications/>

你在博客上浏览文章以供阅读。这个博客展示了一系列诱人的建议来帮助你选择。你的选择让人感觉不可预测，并且受你当前情绪等因素的影响——它会随着你阅读的每篇新文章而变化。机器推荐最佳文章的几率有多大？有多少过去的历史(你的和其他人的总和)可以教会机器如何根据口味预测未来的主观选择？机器如何预测或参与自发性？

关于推荐一部电影看或一个播客听，我们可以问同样的问题。

为了帮助我们回答这些问题，我们的一名 ML/AI 工程师 使用我们的[推荐 API](https://www.algolia.com/doc/guides/algolia-ai/recommend/) 开发了一款应用，为技术博客的读者推荐下一篇文章。场景是这样的:当一名工程师读完一篇文章时，推荐系统会显示与下一篇文章最相关的文章。该应用程序从 ML 模型生成的相关文章数据集中提取推荐，这些模型是由 Algolia 根据博客所有读者之前的集体活动建立的。

这里的目标是提出问题并提供一个回答问题的框架。这也是关于实施和评估我们的建议的简单性。虽然我们经常谈论电子商务的建议，但我们的 API 可以处理任何用例。如下所述，重要的部分是**捕捉正确的信号，并对每个信号的相关性进行“评分”,以确定两篇或多篇文章之间的关系强度。**

结合我们的建议和[点击&转换洞察 API](https://www.algolia.com/doc/guides/getting-analytics/search-analytics/advanced-analytics/) s，我们能够深入回答如下问题:

*   这些建议“准确”吗？“相关”？
*   好奇心——对于好奇的读者来说，它们是否足够令人惊讶，值得点击？是每个读者都对他们的下一个选择保持开放和好奇，还是他们只专注于寻找特定的东西？
*   见解深刻——这些建议是否过于明显？它们是多样的还是多余的？
*   机缘巧合——一台天真的机器能否创造出机缘巧合的时刻，让系统推荐读者从未想过的伟大的未知事物？
*   随机——这些推荐是奇怪的、平庸的、随机的、无用的吗？

虽然实验没有回答所有这些问题，也没有成功地创建一个可以预见未来的应用程序，但我们确实相信，在概念和具体的层面上，人们可以建立一个基于内容/媒体的网站[](https://www.algolia.com/search-solutions/media/)】，为其读者提供相关的[有用的推荐](https://www.algolia.com/blog/product/introducing-algolia-recommend-the-next-best-way-for-developers-to-increase-revenue/)。

## [](#building-ai-powered-recommendations-for-reading)建筑人工智能推荐阅读

推荐书籍很棘手。这需要非常直觉和熟练的书商或图书管理员。通常，他们会先问几个关于 *意图* 的问题——你想找什么类型的书或作者？你要找的是小说还是非小说？什么科目？然后他们转移到 *喜好*——口味、风格、时代、流派的问题。最好的顾问在咨询他们内在的经验和知识“数据库”时会仔细倾听。他们对读者有一种感觉，并且知道他们是如何设计他们的问题的。有了这些，个人顾问就可以推荐“正确的”或“最好的”书籍了。他们的推荐会很完美吗？经常，是的。或者至少是鼓舞人心的，有见地的。你永远无法取代人情味…或者你能吗？

一个[推荐系统](https://www.algolia.com/blog/ai/the-anatomy-of-high-performance-recommender-systems-part-1/)如何与这种个人感动竞争？例如，一个人刚读完 *莫比迪克* 又想读别的。下一本书是什么？

*   *十九世纪捕鲸业的历史*
*   更多 19 世纪的小说
*   其他书籍作者赫尔曼·梅尔维尔 *莫比·迪克*
*   *荷马史诗* 或 *少年派的一生* (其他海上冒险)
*   关于更小的鱼，像 *河流穿过它*
*   另一种类型的冒险(哈利·波特系列)
*   旅游书籍—*远航公海*
*   或者一些完全不同的有趣的事情，来摆脱莫比·迪克的沉重负担

谁知道呢？可能性太多了。推荐任何东西似乎都是随机的或瞎猜的。有时甚至读者都不知道…然而，这就是有趣的地方:

> **在推荐书籍时，书商和一个好的推荐系统并不仅仅关注** ***暗示*** **书籍，他们希望** ***启发我们*** **做出我们自己关于下一本书的最佳选择。**

挑战说的够多了。现在，我们如何面对这些挑战？

## [](#how-recommender-systems-calculate-the-best-recommendations)推荐系统如何计算最佳推荐

让我们从比较三个不同的用例开始:

1.  定义明确的读者群:在线图书馆研究平台上的学生
2.  一个更大但相当同质的读者群:技术博客的读者
3.  更大的异质读者群:通用博客的读者

我们研究了每种情况，但只试验了第二种。我们将利用第一个和最后一个为第三个——技术博客——打下基础。每个场景都给了推荐系统或多或少的上下文。所以我们会看到背景在避免随机性方面有多重要。但是首先，让我们看看可以用来帮助建立模型的 **启发式评分** 。

### [](#the-heuristic-of-scoring-books-based-on-user-reading-patterns)基于用户阅读模式的启发式图书评分

为了取代读者和书商之间的口头聊天，在线系统必须利用能够传达意图和偏好的用户信号。这是通过 **点击** (用户在阅读之前、期间和之后点击的内容)和 **转换** (用户阅读的内容或阅读的时长)来完成的。例如，如果许多用户在同一个阅读会话中阅读文章 X 和 Y，我们可以得出两个结论:

*   这些读者有强烈的意图将这两篇文章 *合在一起*
*   因此，文章 X 和 Y 在某种程度上是相关的。

另一个例子是当用户点击文章内部的链接，阅读链接的文章，然后返回继续阅读第一篇文章。这种行为表明这些文章是相关的。

这些关于意图的结论是启发性的。让我们更进一步，让我们给某些行为更多的权重:如果我们认为多次点击 *内的链接相同的* 文章，每次点击的阅读时间长，表明读者强烈倾向于认为所有这些文章都是相关的，那么我们可以有信心给这组行为 **更多的权重** 这是另一种启发式方法——看看哪些行为表现出强烈或微弱的意图，并相应地对它们进行衡量或评分。

这就是你如何使用我们的 [Algolia 推荐的](https://www.algolia.com/products/recommendations/) 产品。Algolia 客户在向我们推荐的产品发送点击量和转化率之前，可以考虑几个因素。例如，他们可以通过不发送信号，或者根据信号的强度发送一次或两次来增加或减少信号的强度。

然而，试探法的一个危险是，如果关于信号的潜在假设是错误的，那么将一个已经不正确的解释的分数加倍就会使错误加倍。这是一场赌博。

### [](#context-plays-a-role-in-recognizing-intent)上下文在识别意图时起作用

让我们回到上面的两个上下文:

1.  教育背景(学生图书馆)
2.  随机公开(一个通用博客)

## [](#scenario-1-%e2%80%93-creating-recommendations-for-students)场景 1–为学生创建推荐

学生们提供了一个定义清晰、界限分明的世界，为推荐系统提供了一个良好的开端。学生的选择范围很窄。他们的意图很明确，并且和其他读者有着相似的目标:了解某个特定的主题。

图书馆的在线目录可以自信地显示“推荐的下一本书”和“不太可能有帮助的书”。他们可以通过在每篇文章的文本中嵌入大量相关文章的超链接来使其特别准确。(注意，这些超链接可以使用推荐系统本身随着时间的推移而被刷新。)

### [](#clicks-conversions-%e2%80%93-the-signals-and-events-to-collect)点击&转换-要采集的信号和事件

我们将收集他们点击的链接和阅读次数，以记录他们实际阅读的内容。为了收集数据，我们称之为“发送事件”。如上所述，有两个事件要发送:点击和转换。点击和转换事件都在两本或更多本书之间建立“相关书”关系。转换也在两本或更多的书之间建立了一种“经常一起阅读”的关系。

出于我们的目的，我们对点击和转化做出以下假设和解释:

*   我们假设一个学生的相关书籍的集合可能与参加同一项目的其他学生的相关书籍的集合相似。
*   学生阅读的每篇 *下一篇博客* 无论是从一个链接，还是在搜索或浏览之后，都可能反映出与当前文章的合理相关性。所以我们发送一个点击事件。
*   为了确保下一本书是相关的，我们将 *阅读时间* 添加到等式中，并通过添加额外的 **权重** 来帮助 Algolia 的建模，以加强关系。我们通过过滤掉一些事件或加倍分数来进行加权:
    *   如果用户点击但没有阅读点击的文章，我们会放弃点击——也就是说，我们不会发送任何点击事件
    *   如果他们阅读了链接的文章，但时间不长，我们会发送一个点击，但不会发送一个转化事件
    *   如果他们阅读了被点击文章的大部分或全部内容，我们会发送点击和转换事件
    *   如果他们已经阅读了一篇文章的大部分或全部，然后回到原文并继续阅读，我们会再次发送点击和转换事件

这些只是说明区别对待每个事件的重要性的建议。我们可以使用其他信号。Medium 允许评论，不仅在整个博客上，而且在文本的选定部分。如果用户突出显示一个句子“喜欢它”或“评论它”，我们可以在阅读会话期间发送所有评论文章的点击事件，以加强这些文章之间的关系。假设在一个单独的会话中，一个学生正在阅读一个主题，因此所有的文章都将与该主题相关。

最后一个变化是推荐一篇文章或一本书的部分内容。我们可以把书籍分解成 *相关段落* 。这为下一次阅读提供了特别有用的细节。我们可以推荐“相关段落阅读”。

现在你可能同意或不同意这些例子，但关键是，你需要用你认为最能抓住用户阅读图书馆目录中的文章的意图的动作来建立模型。我们试图通过识别一心一意的学生选择连续阅读的内容来避免随机性。

## [](#scenario-2-%e2%80%93-public-blog-recommendations)场景 2——公众博客推荐

为学生推荐一个教育学阅读之旅包含了很多内在的可靠性。学生们分享学习特定科目的背景和目标。但是，面对一群兴趣广泛，但在阅读选择上没有明显亲和力的读者，我们该怎么办呢？虽然我们仍然可以依靠点击超链接，但我们需要意识到下一篇文章可能与点击的链接无关。因此，还有一个额外的因素可以帮助我们构建模型:

*   博客的 *分类* 。

如果每个博客都被准确分类，那么这些类别可以如下使用:

*   如果一本书被点击，并且在同一组类别中，那么在将它添加到模型中时，就可以得到那么高的分数
*   无论何时将任何书籍添加到模型中，算法本身都会使用类别作为一种方式来构建其相关项目推荐。

## [](#scenario-3-%e2%80%93-readers-of-a-technical-blog)场景 3——技术博客的读者

如上所述，在技术博客这样的单主题博客上推荐文章应该“更容易”，因为读者对技术有着共同的兴趣。虽然这种凝聚力不像学生博客那样强大，推荐系统获得了更紧密共享意图的额外好处(相同的课程材料，相同的测试)，但技术博客确实内置了一些类似的意图和偏好。

以下是一些挑战

*   会有很多 javascript 工程师想要提升自己的前端，所以就有了 *一些* 类似的意图和喜好，但并不完全——UI 的题材相当广泛。
*   有些后端工程师对 UI 一点也不感兴趣，但是他们可能会阅读相同的文章来帮助理解如何使用前端系统。
*   虽然所有工程师可能都想了解微服务的理论和实现，但前端工程师可能只想知道如何在他们的 UI 中使用它们。
*   一个额外的挑战是 *简档不平衡* ，例如，你有 80%的 JS 开发人员/ 20%的后端专家，所以对 80%的用户有效的推荐对于后一组可能仍然是 *错误的* 。解决方案？您需要基于每个细分市场得分较高的配置文件的配置文件细分推荐。

这些挑战表明，即使是对同一活动领域但具有不同意图和特征的读者，推荐书籍也可能并不容易。但这不是不可能的，你会看到的。我们的人工智能工程师构建的实验性应用程序调查了我们在这个时间点上可以取得的成功程度。

## [](#the-experiment-recommending-books-%e2%80%9cfrequently-read-together%e2%80%9d)实验:推荐书籍“常一起读”

在我们经常一起阅读的**场景中，我们可以考虑:**

 ***   将每个用户的阅读列表转换为单个多项内容
*   同一天的阅读作为多篇文章的单个转换，而超过 4 天的每天一篇文章将被视为 4 个单独的单个项目的转换。

我们将使用以下信号:

*   用户在短时间内(在明确定义的会话中)阅读了什么内容

未考虑的因素:

*   用户在阅读给定文章时点击并阅读的文章内的链接
*   用户已经阅读的文章的类别。我们不会给予更多或更少的权重，也不会添加一个信号事件，只是因为 2 篇或更多的文章属于同一类别。我们不这样做，不是因为这无关紧要，而是因为我们想专注于如何最好地将用户的意图与博客的内容相匹配。
*   一个用户的 *自己的* 阅读列表，正如没有理由相信一个用户想要阅读的内容一定是彼此相关的。
*   然而，请注意，当这些因素放在一起时，会创建一个相关项目的强指标；然而，我们在这里的目标是推荐“经常一起阅读”的文章，而不是“相关文章”。显然，相关项目是任何推荐系统的基础，但我们现在想限制这些因素。
*   我们没有考虑每次阅读来自哪里(链接，搜索，..).例如，我们完全不知道链接结构。另一个实验将需要测试链接点击对于提供有用建议的重要性——即使从表面上看，它似乎很重要。

## [](#results-of-the-experiment)实验结果

注意，完整的结果、技术细节和代码将在我们的下一篇文章中给出。

下面的百分比是置信分数:当展示给 Y 时，与 X 互动的人将成功地与 Y 互动的模型的确定程度。您可以在您的用户界面中通过将它标记为“匹配分数”、“相关性分数”或“可能性”(用户参与内容的可能性)来帮助用户理解这一点。

| ***如果你读到……*** |
| 

*   **添加 AI 到你的搜索框** :我们推荐 *添加微信到你的搜索*(**99.63**%)、 *如何用规则推广*(**98.54**%)、

 |
| 

*   **添加微信到你的搜索** :我们推荐 *添加 AI 到你的搜索框*(**99.63**%)， *更高 ROI 带个性化刻面*(**99.11**)

 |
| 

*   **添加搜索推荐** :我们推荐 *缩放你的搜索引擎*(**99.72**%)， *挖掘你的代码*(**99.13**%)，

 |
| 

*   **CSS for a Cool 前端** :推荐 *调试搜索*(**95.79**%)， *挖掘你的代码*(**95.06**

 |
| 

*   **调试搜索** :我们推荐 *挖掘你的代码*(**99.83**%)， *缩放你的搜索引擎*(**99.28**

 |
| 

*   **挖掘你的代码** :推荐 *调试搜索*(**99.83**%)， *缩放你的搜索引擎*(**99.39**%)， *添加搜索推荐* ()

 |
| 

*   **更高的 ROI 搭配个性化的刻面** :我们推荐 *开箱推荐用例*(**99.18**%)、 *添加微信到您的搜索*(**99.11**【T56 %)、

 |
| 

*   **如何用规则推广** :我们推荐 *添加 AI 到你的搜索框*(**98.54**%)， *添加微信到你的搜索*(**98.02**【T90)

 |
| 

*   **介绍推荐** :我们推荐 *开箱推荐用例*(**98.12**%)， *更高的 ROI 搭配个性化的刻面*(**97.76**

 |
| 

*   **开箱推荐用例** :我们推荐 *具有个性化刻面的更高 ROI*(**99.18**%)， *挖掘您的代码*(**99.07)**

 |
| 

*   **缩放您的搜索引擎** :我们推荐 *添加搜索推荐*(**99.72**%)， *挖掘您的代码*(**99.39**

 |

## [](#conclusion-evaluating-the-recommendations)结论——评估建议

最终，我们如何知道自己是对的？我们如何评估我们建议的质量？这让我们进入了任何推荐系统的评估阶段。我们将很快公布如何评估推荐系统的完整论述。

但是你可以通过心理评估这些数字来了解成功的概念

*   这些建议是多种多样的，还是你得到了循环的建议，其中项目 A 的建议项目对 B、C 和 D 有相同的整体建议组？(比如 A - >读作【B，C，D】；B - >读作【丙，丁，甲】；C - >读作【B，D，A】；D - >改为【A，B，C】)
*   分数是多种多样的，还是你总是得到大约 99%的推荐，这将暗示一些 *过拟合* ，系统实际上停止学习，将样本数据的结论应用于所有新书。

通过问自己类似这样的问题，你已经可以对你的推荐质量有一个很好的预感。

还有另一种方法:小步前进，观察用户对你的建议的反应。看看读者是否点击阅读你的推荐。还可以进行 AB 测试或者 live 用户测试，或者度量转换，或者看看被点击的是 *不是* 什么书。像这样的小步骤可以走很长的路。实验、实际分析和评估是任何推荐系统成功的关键。快乐阅读！**