- en: Conclusions and Further Reading
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论和进一步阅读
- en: 原文：[https://jax-ml.github.io/scaling-book/conclusion](https://jax-ml.github.io/scaling-book/conclusion)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://jax-ml.github.io/scaling-book/conclusion](https://jax-ml.github.io/scaling-book/conclusion)
- en: '<d-title>Part 11 of [How To Scale Your Model](/scaling-book) ([Part 10: JAX](../jax-stuff)
    | [Part 12: GPUs](../gpus))'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: <d-title>《如何扩展您的模型》的第11部分[How To Scale Your Model](/scaling-book) ([第10部分：JAX](../jax-stuff)
    | [第12部分：GPU](../gpus))
- en: Thank you for reading! Here we'll include a few more references for further
    study.</d-title>  <d-byline><d-article><d-contents>### Contents
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢您阅读！在这里，我们将包括一些更多参考资料以供进一步学习。</d-title>  <d-byline><d-article><d-contents>###
    内容
- en: '[Acknowledgments](#acknowledgments)[Further Reading](#further-reading)[Feedback](#feedback)</d-contents>'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[致谢](#acknowledgments)[进一步阅读](#further-reading)[反馈](#feedback)</d-contents>'
- en: '**Thank you for reading this set of essays and congratulations on making it
    all the way to the end.** Before we conclude, a few acknowledgments:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '**感谢您阅读这一系列论文，并祝贺您坚持到最后。** 在我们结束之前，有一些致谢：'
- en: Acknowledgments
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 致谢
- en: This document represents a significant collective investment from many people
    at Google DeepMind, who we’d like to briefly acknowledge!
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 这份文档代表了谷歌DeepMind许多人的重大集体投资，我们想简要地表示感谢！
- en: James Bradbury, Reiner Pope, and Blake Hechtman originally derived many of the
    ideas in this manuscript, and were early to understanding the systems view of
    the Transformer.
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 詹姆斯·布拉德伯里、雷纳·波佩和布莱克·赫奇曼最初从这份手稿中提炼了许多想法，并且是早期理解Transformer系统视图的人。
- en: Sholto Douglas wrote the first version of this doc and is responsible for kicking
    off the project. He is more than anyone responsible for the overall narrative
    of this doc.
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 詹姆斯·布拉德伯里负责撰写这份文档的第一版，并负责启动这个项目。他比任何人都更负责这份文档的整体叙述。
- en: Jacob Austin led the work of transforming this first version from rough notes
    into a more polished and comprehensive artifact. He did much of the work of editing,
    formatting, and releasing this document, and coordinated contributions from other
    authors.
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 杰克·奥斯汀领导了将这个初版从粗糙笔记转变为更加精致和全面的文档的工作。他做了大量的编辑、格式化和发布文档的工作，并协调了其他作者的贡献。
- en: Most of the figures and animations were made by Anselm Levskaya and Charlie
    Chen.
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大多数图表和动画都是由安塞尔姆·莱夫塞亚和查理·陈制作的。
- en: Charlie Chen wrote the inference section and drew many of the inference figures.
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查理·陈撰写了推理部分并绘制了许多推理图表。
- en: Roy Frostig helped with publication, editing, and many other steps of the journey.
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 罗伊·弗罗斯蒂格帮助了出版、编辑以及旅程中的许多其他步骤。
- en: We’d also like to thank many others gave critical feedback throughout the process,
    in particular Zak Stone, Nikhil Sethi, Caitlin Stanton, Alex Dimitriev, Sridhar
    Lakshmanamurthy, Albert Magyar, Diwakar Gupta, Jeff Dean, Corry Wang, Matt Johnson,
    Peter Hawkins, and many others. Thanks to Ruiqi Gao for help with the HTML formatting.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还感谢许多人在整个过程中提供了宝贵的反馈，特别是Zak Stone、Nikhil Sethi、Caitlin Stanton、Alex Dimitriev、Sridhar
    Lakshmanamurthy、Albert Magyar、Diwakar Gupta、Jeff Dean、Corry Wang、Matt Johnson、Peter
    Hawkins以及许多其他人。感谢高瑞琪在HTML格式化方面的帮助。
- en: '**Thank you all!**'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '**感谢大家！**'
- en: Before you go, you might also enjoy reading the new [Section 12](../gpus) on
    NVIDIA GPUs!
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在你离开之前，你也许会喜欢阅读关于NVIDIA GPU的新[第12节](../gpus)！
- en: Further Reading
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'There is a bunch of related writing, including the following:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 有很多相关的写作，包括以下内容：
- en: '[**TPU Deep Dive**](https://henryhmko.github.io/posts/tpu/tpu.html): a wonderful
    in-depth look at the TPU architecture in the spirit of this book.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**TPU深度解析**](https://henryhmko.github.io/posts/tpu/tpu.html)：这本书精神下的TPU架构的深入探讨。'
- en: '[**Domain specific architectures for AI inference**](https://fleetwood.dev/posts/domain-specific-architectures):
    a hardware and model deep dive in the spirit of this book.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**针对AI推理的特定领域架构**](https://fleetwood.dev/posts/domain-specific-architectures)：这本书精神下的硬件和模型深入探讨。'
- en: '[**A Domain-Specific Supercomputer for Training Deep Neural Networks**](https://dl.acm.org/doi/pdf/10.1145/3360307):
    one of the OG TPU paper, this has a lot of great details about the Google TPU
    program not covered here.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**用于训练深度神经网络的特定领域超级计算机**](https://dl.acm.org/doi/pdf/10.1145/3360307)：这是原始TPU论文之一，这里有很多关于谷歌TPU项目的详细信息，这里没有涵盖。'
- en: '[**Making Deep Learning Go Brrrr From First Principles**](https://horace.io/brrr_intro.html):
    a more GPU and PyTorch-focused tutorial on LLM rooflines and performance engineering.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**从原理出发让深度学习冷下来**](https://horace.io/brrr_intro.html)：一个更专注于GPU和PyTorch的教程，关于LLM
    rooflines和性能工程。'
- en: '[**Writing TPU Kernels with Pallas**](https://jax.readthedocs.io/en/latest/pallas/tpu/details.html):
    increasingly, TPU programming involves writing custom kernels in Pallas. This
    series discusses how to write kernels and many lower level TPU details that aren’t
    mentioned here.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**使用 Pallas 编写 TPU 内核**](https://jax.readthedocs.io/en/latest/pallas/tpu/details.html)：越来越多的
    TPU 编程涉及在 Pallas 中编写自定义内核。这个系列讨论了如何编写内核以及许多这里未提及的更低级别的 TPU 细节。'
- en: '[**How to Optimize a CUDA Matmul Kernel for cuBLAS-like Performance: a Worklog**](https://siboehm.com/articles/22/CUDA-MMM):
    while GPU and CUDA specific, this is an excellent blog post showing how to optimize
    a matmul kernel in CUDA. This might be a good deep dive into how TPUs and GPUs
    are different.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**如何优化 CUDA Matmul 内核以实现 cuBLAS 类似性能：工作日志**](https://siboehm.com/articles/22/CUDA-MMM)：虽然针对
    GPU 和 CUDA，但这是一篇出色的博客文章，展示了如何在 CUDA 中优化 matmul 内核。这可能是一个深入了解 TPUs 和 GPUs 如何不同的好机会。'
- en: '[**Distributed arrays and automatic parallelization**](https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html):
    this is a really nice guide to parallelism APIs in JAX and is a good way to learn
    how to actually implement some of the ideas we’ve discussed here.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**分布式数组和自动并行化**](https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html)：这是一份关于
    JAX 并行 API 的非常棒的指南，也是学习如何实际实现我们在这里讨论的一些想法的好方法。'
- en: '[**Rafi Witten’s High Performance LLMs 2024 Class**](https://github.com/rwitten/HighPerfLLMs2024):
    our former colleague Rafi gave a great course on TPU performance engineering and
    the slides are all on GitHub. This covers a bunch of things in more depth than
    we do here.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**Rafi Witten 的 2024 年高性能 LLMs 课程**](https://github.com/rwitten/HighPerfLLMs2024)：我们前同事
    Rafi 举办了一门关于 TPU 性能工程的精彩课程，幻灯片全部在 GitHub 上。这涵盖了比我们这里更深入的一些内容。'
- en: '[**[2211.05102] Efficiently Scaling Transformer Inference**](https://arxiv.org/abs/2211.05102):
    a detailed paper on the mathematics of Transformer inference. This is the inspiration
    for a lot of this document.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**[2211.05102] 高效扩展 Transformer 推理**](https://arxiv.org/abs/2211.05102)：一篇关于
    Transformer 推理数学的详细论文。这是本文档许多内容的灵感来源。'
- en: '[**Huggingface Ultra-Scale Playbook**](https://huggingface.co/spaces/nanotron/ultrascale-playbook):
    something of a GPU analog to this book, this talks more at depth about how PyTorch
    implements parallelism techniques and memory-saving techniques during training.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**Huggingface 超大规模操作手册**](https://huggingface.co/spaces/nanotron/ultrascale-playbook)：这本书的
    GPU 类似物，更深入地讨论了 PyTorch 在训练期间如何实现并行化技术和内存节省技术。'
- en: '[**Transformer Inference Arithmetic**](https://kipp.ly/transformer-inference-arithmetic/):
    a blog with many of the same ideas as this book and some excellent illustrations.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**Transformer 推理算术**](https://kipp.ly/transformer-inference-arithmetic/)：一篇包含与本书相同许多想法的博客，以及一些优秀的插图。'
- en: '[**Stanford CS336 Slides and Videos**](https://stanford-cs336.github.io/spring2025/index.html#coursework):
    a fantastic Stanford course covering many details of LLM training and serving,
    with some useful exercises. Assignments 1 and 2 are particularly relevant.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**斯坦福 CS336 课程幻灯片和视频**](https://stanford-cs336.github.io/spring2025/index.html#coursework)：这是一门精彩的斯坦福课程，涵盖了
    LLM 训练和服务的许多细节，还有一些有用的练习。作业 1 和 2 特别相关。'
- en: '[**Stas Bekman’s ML Engineering Handbook**](https://github.com/stas00/ml-engineering):
    a highly practical guide to ML infrastructure, covering topics not addressed in
    this book like how to negotiate with cloud providers, cluster management, and
    empirical measurements of GPU throughput.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**Stas Bekman 的机器学习工程手册**](https://github.com/stas00/ml-engineering)：一本高度实用的机器学习基础设施指南，涵盖了本书未涉及的主题，如如何与云服务提供商谈判、集群管理和
    GPU 吞吐量的经验测量。'
- en: There remains a lot of room for comprehensive writing in this area, so we hope
    this manuscript encourages more of it! We also believe that this is a fruitful
    area to study and research. In many cases, it can be done even without having
    many hardware accelerators on hand.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个领域还有很多综合写作的空间，所以我们希望这份手稿能鼓励更多人进行写作！我们也相信这是一个值得研究和探索的领域。在许多情况下，即使没有很多硬件加速器，也可以完成。
- en: Feedback
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 反馈
- en: Please leave comments or questions so that we can improve this further. You
    can reach our corresponding author, Jacob Austin, at jacobaustin123 [at] gmail
    [dot] com, or suggest edits by posting issues, pull requests, or discussions [on
    GitHub](https://github.com/jax-ml/scaling-book).</d-article>  <d-appendix><d-footnote-list><d-citation-list>###
    Miscellaneous
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 请留下评论或问题，以便我们进一步改进。您可以通过 jacobaustin123 [at] gmail [dot] com 联系我们的通讯作者 Jacob
    Austin，或者通过在 GitHub 上发布问题、拉取请求或讨论来提出编辑建议 [on GitHub](https://github.com/jax-ml/scaling-book)。
- en: ^*Work done at Google DeepMind, now at MatX.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: ^*在谷歌DeepMind完成的工作，现在在MatX。
- en: Citation
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 引用
- en: 'For attribution in academic contexts, please cite this work as:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在学术环境中进行归属时，请引用此作品如下：
- en: '[PRE0]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'or as a BibTeX entry:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 或者作为BibTeX条目：
- en: '[PRE1]</d-citation-list></d-footnote-list></d-appendix> <d-bibliography src="/scaling-book/assets/bibliography/"></d-bibliography></d-byline>'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE1]</d-citation-list></d-footnote-list></d-appendix> <d-bibliography src="/scaling-book/assets/bibliography/"></d-bibliography></d-byline>'
