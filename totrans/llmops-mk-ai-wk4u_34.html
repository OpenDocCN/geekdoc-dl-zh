<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Answers 2.4</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Answers 2.4</h1>
<blockquote>原文：<a href="https://boramorka.github.io/LLM-Book/en/CHAPTER-2/Answers%202.4/">https://boramorka.github.io/LLM-Book/en/CHAPTER-2/Answers%202.4/</a></blockquote>
                
                  


  
  



<h2 id="theory">Theory</h2>
<ol>
<li>Purpose of embeddings: convert text into numeric vectors that preserve semantic meaning, enabling computers to “understand” text.</li>
<li>Semantic similarity: reflected in similar vectors for words/sentences with related meaning in a high‑dimensional space.</li>
<li>How embeddings are learned: trained on text corpora; word vectors depend on usage context (distributional semantics).</li>
<li>Embeddings in semantic search: allow retrieving relevant documents by meaning, even without exact keyword matches.</li>
<li>Matching documents and queries: a document embedding represents overall meaning; a query embedding captures user intent; comparing them reveals relevant matches.</li>
<li>Vector store: a database for embeddings optimized for fast nearest‑neighbor search.</li>
<li>Choosing a store: depends on data size, persistence requirements, and purpose (research, prototype, production).</li>
<li>Chroma for prototyping: convenient for small/in‑memory scenarios (fast), but limited in persistence and scaling.</li>
<li>Typical pipeline: split text → generate embeddings → index in a vector store → handle query → generate answer.</li>
<li>Splitting: improves granularity; matching happens at the level of meaningful fragments (chunks), not entire documents.</li>
<li>Embedding generation: transforms text into vectors suitable for computational comparison.</li>
<li>Indexing in the store: enables fast retrieval of semantically similar fragments.</li>
<li>Query handling: create a query embedding and search for similar fragments using metrics (cosine similarity, Euclidean distance, etc.).</li>
<li>Answer generation: uses the retrieved fragments together with the original query to produce a coherent answer.</li>
<li>Environment setup: install libraries, configure API keys, and set up for embeddings and the vector store.</li>
<li>Loading and splitting documents: critical for effective text management and higher‑quality retrieval.</li>
<li>Illustrating similarity: can be shown via dot product or cosine similarity.</li>
<li>Chroma specifics: mind the persistence directory, clearing stale data, and correct collection initialization.</li>
<li>Similarity search: finds the fragments most relevant to the query.</li>
<li>Typical failures and remediation: duplicates and irrelevant results can be addressed via filtering and careful pipeline tuning.</li>
</ol>
<h2 id="practice">Practice</h2>
<p>1.
</p><div class="highlight"><pre><span/><code><span class="k">def</span><span class="w"> </span><span class="nf">generate_embeddings</span><span class="p">(</span><span class="n">sentences</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Generate a simple placeholder embedding for each sentence based on its length.</span>

<span class="sd">    Args:</span>
<span class="sd">    - sentences (list of str): List of sentences to embed.</span>

<span class="sd">    Returns:</span>
<span class="sd">    - list of int: One embedding per sentence (the sentence length).</span>
<span class="sd">    """</span>
    <span class="k">return</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">sentences</span><span class="p">]</span>

<span class="k">def</span><span class="w"> </span><span class="nf">cosine_similarity</span><span class="p">(</span><span class="n">vector_a</span><span class="p">,</span> <span class="n">vector_b</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Compute cosine similarity between two vectors.</span>

<span class="sd">    Args:</span>
<span class="sd">    - vector_a (list of float): First vector.</span>
<span class="sd">    - vector_b (list of float): Second vector.</span>

<span class="sd">    Returns:</span>
<span class="sd">    - float: Cosine similarity between `vector_a` and `vector_b`.</span>
<span class="sd">    """</span>
    <span class="n">dot_product</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">a</span><span class="o">*</span><span class="n">b</span> <span class="k">for</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">vector_a</span><span class="p">,</span> <span class="n">vector_b</span><span class="p">))</span>
    <span class="n">magnitude_a</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">a</span><span class="o">**</span><span class="mi">2</span> <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">vector_a</span><span class="p">)</span> <span class="o">**</span> <span class="mf">0.5</span>
    <span class="n">magnitude_b</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">b</span><span class="o">**</span><span class="mi">2</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">vector_b</span><span class="p">)</span> <span class="o">**</span> <span class="mf">0.5</span>
    <span class="k">return</span> <span class="n">dot_product</span> <span class="o">/</span> <span class="p">(</span><span class="n">magnitude_a</span> <span class="o">*</span> <span class="n">magnitude_b</span><span class="p">)</span>

<span class="c1"># Example usage:</span>
<span class="n">sentences</span> <span class="o">=</span> <span class="p">[</span><span class="s2">"Hello, world!"</span><span class="p">,</span> <span class="s2">"This is a longer sentence."</span><span class="p">,</span> <span class="s2">"Short"</span><span class="p">]</span>
<span class="n">embeddings</span> <span class="o">=</span> <span class="n">generate_embeddings</span><span class="p">(</span><span class="n">sentences</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Embeddings:"</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">)</span>

<span class="n">vector_a</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="n">vector_b</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span>
<span class="n">similarity</span> <span class="o">=</span> <span class="n">cosine_similarity</span><span class="p">(</span><span class="n">vector_a</span><span class="p">,</span> <span class="n">vector_b</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Cosine similarity:"</span><span class="p">,</span> <span class="n">similarity</span><span class="p">)</span>
</code></pre></div>
<p>2.
</p><div class="highlight"><pre><span/><code><span class="k">def</span><span class="w"> </span><span class="nf">cosine_similarity</span><span class="p">(</span><span class="n">vector_a</span><span class="p">,</span> <span class="n">vector_b</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Compute cosine similarity between two vectors."""</span>
    <span class="n">dot_product</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">a</span><span class="o">*</span><span class="n">b</span> <span class="k">for</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">vector_a</span><span class="p">,</span> <span class="n">vector_b</span><span class="p">))</span>
    <span class="n">magnitude_a</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">a</span><span class="o">**</span><span class="mi">2</span> <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">vector_a</span><span class="p">)</span> <span class="o">**</span> <span class="mf">0.5</span>
    <span class="n">magnitude_b</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">b</span><span class="o">**</span><span class="mi">2</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">vector_b</span><span class="p">)</span> <span class="o">**</span> <span class="mf">0.5</span>
    <span class="k">if</span> <span class="n">magnitude_a</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">magnitude_b</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">0</span>  <span class="c1"># Avoid division by zero</span>
    <span class="k">return</span> <span class="n">dot_product</span> <span class="o">/</span> <span class="p">(</span><span class="n">magnitude_a</span> <span class="o">*</span> <span class="n">magnitude_b</span><span class="p">)</span>
</code></pre></div>
<p>3.
</p><div class="highlight"><pre><span/><code><span class="k">class</span><span class="w"> </span><span class="nc">SimpleVectorStore</span><span class="p">:</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vectors</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># Initialize empty list to store vectors</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">add_vector</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vector</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""Add a vector to the store."""</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vectors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">vector</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">find_most_similar</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">query_vector</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""Find and return the vector most similar to `query_vector`."""</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">vectors</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span>  <span class="c1"># Return None if the store is empty</span>
        <span class="n">similarities</span> <span class="o">=</span> <span class="p">[</span><span class="n">cosine_similarity</span><span class="p">(</span><span class="n">query_vector</span><span class="p">,</span> <span class="n">vector</span><span class="p">)</span> <span class="k">for</span> <span class="n">vector</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">vectors</span><span class="p">]</span>
        <span class="n">max_index</span> <span class="o">=</span> <span class="n">similarities</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="n">similarities</span><span class="p">))</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">vectors</span><span class="p">[</span><span class="n">max_index</span><span class="p">]</span>
</code></pre></div>
<p>4.
</p><div class="highlight"><pre><span/><code><span class="kn">import</span><span class="w"> </span><span class="nn">sys</span>

<span class="k">def</span><span class="w"> </span><span class="nf">split_text_into_chunks</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">chunk_size</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Split the given text into chunks of the specified size."""</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">text</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">chunk_size</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">text</span><span class="p">),</span> <span class="n">chunk_size</span><span class="p">)]</span>

<span class="k">def</span><span class="w"> </span><span class="nf">load_and_print_chunks</span><span class="p">(</span><span class="n">file_path</span><span class="p">,</span> <span class="n">chunk_size</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Load text from a file, split it into chunks, and print each chunk."""</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">file_path</span><span class="p">,</span> <span class="s1">'r'</span><span class="p">)</span> <span class="k">as</span> <span class="n">file</span><span class="p">:</span>
            <span class="n">text</span> <span class="o">=</span> <span class="n">file</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
            <span class="n">chunks</span> <span class="o">=</span> <span class="n">split_text_into_chunks</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">chunk_size</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">chunks</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Chunk </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">:</span><span class="se">\n</span><span class="si">{</span><span class="n">chunk</span><span class="si">}</span><span class="se">\n</span><span class="si">{</span><span class="s1">'-'</span><span class="o">*</span><span class="mi">50</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">FileNotFoundError</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Error: File '</span><span class="si">{</span><span class="n">file_path</span><span class="si">}</span><span class="s2">' not found."</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Unexpected error: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">"__main__"</span><span class="p">:</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">argv</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">3</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"Usage: python script.py &lt;file_path&gt; &lt;chunk_size&gt;"</span><span class="p">)</span>
        <span class="n">sys</span><span class="o">.</span><span class="n">exit</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">file_path</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">argv</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">chunk_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">argv</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
    <span class="n">load_and_print_chunks</span><span class="p">(</span><span class="n">file_path</span><span class="p">,</span> <span class="n">chunk_size</span><span class="p">)</span>
</code></pre></div>
<p>5.
</p><div class="highlight"><pre><span/><code><span class="c1"># Assume SimpleVectorStore and cosine_similarity are defined earlier.</span>

<span class="k">def</span><span class="w"> </span><span class="nf">generate_query_embedding</span><span class="p">(</span><span class="n">query</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Generate a simple placeholder embedding for the query based on its length.</span>
<span class="sd">    In real scenarios, you would use a model for embeddings.</span>
<span class="sd">    """</span>
    <span class="k">return</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">query</span><span class="p">)]</span>

<span class="k">def</span><span class="w"> </span><span class="nf">query_processing</span><span class="p">(</span><span class="n">store</span><span class="p">,</span> <span class="n">query</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Process a query: generate its embedding, find the most similar fragment in the</span>
<span class="sd">    vector store, and print it.</span>
<span class="sd">    """</span>
    <span class="n">query_embedding</span> <span class="o">=</span> <span class="n">generate_query_embedding</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
    <span class="n">most_similar</span> <span class="o">=</span> <span class="n">store</span><span class="o">.</span><span class="n">find_most_similar</span><span class="p">(</span><span class="n">query_embedding</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">most_similar</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"Most similar document fragment:"</span><span class="p">,</span> <span class="n">most_similar</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"No document fragments found."</span><span class="p">)</span>
</code></pre></div>
<p>6.
</p><div class="highlight"><pre><span/><code><span class="k">def</span><span class="w"> </span><span class="nf">remove_duplicates</span><span class="p">(</span><span class="n">document_chunks</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Remove duplicate document fragments by exact content match."""</span>
    <span class="n">unique_chunks</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">document_chunks</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">chunk</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">unique_chunks</span><span class="p">:</span>
            <span class="n">unique_chunks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">unique_chunks</span>
</code></pre></div>
<p>7.
</p><div class="highlight"><pre><span/><code><span class="c1"># Initialize SimpleVectorStore for demonstration</span>
<span class="n">store</span> <span class="o">=</span> <span class="n">SimpleVectorStore</span><span class="p">()</span>

<span class="c1"># Placeholder document fragments and their embeddings</span>
<span class="n">document_chunks</span> <span class="o">=</span> <span class="p">[</span><span class="s2">"Document chunk 1"</span><span class="p">,</span> <span class="s2">"Document chunk 2"</span><span class="p">,</span> <span class="s2">"Document chunk 3"</span><span class="p">]</span>
<span class="c1"># Simulate embeddings based on length</span>
<span class="n">document_embeddings</span> <span class="o">=</span> <span class="p">[[</span><span class="nb">len</span><span class="p">(</span><span class="n">chunk</span><span class="p">)]</span> <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">document_chunks</span><span class="p">]</span>

<span class="c1"># Add generated document embeddings to the store</span>
<span class="k">for</span> <span class="n">embedding</span> <span class="ow">in</span> <span class="n">document_embeddings</span><span class="p">:</span>
    <span class="n">store</span><span class="o">.</span><span class="n">add_vector</span><span class="p">(</span><span class="n">embedding</span><span class="p">)</span>

<span class="c1"># Perform similarity search with a sample query</span>
<span class="n">query</span> <span class="o">=</span> <span class="s2">"Document"</span>
<span class="n">query_embedding</span> <span class="o">=</span> <span class="n">generate_query_embedding</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>

<span class="c1"># Find the most similar document fragments via cosine similarity</span>
<span class="n">similarities</span> <span class="o">=</span> <span class="p">[(</span><span class="n">cosine_similarity</span><span class="p">(</span><span class="n">query_embedding</span><span class="p">,</span> <span class="n">doc_embedding</span><span class="p">),</span> <span class="n">idx</span><span class="p">)</span> <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">doc_embedding</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">document_embeddings</span><span class="p">)]</span>
<span class="n">similarities</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># Sort by similarity descending</span>
<span class="n">top_n_indices</span> <span class="o">=</span> <span class="p">[</span><span class="n">idx</span> <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">similarities</span><span class="p">[:</span><span class="mi">3</span><span class="p">]]</span>  <span class="c1"># Indices of top‑3 fragments</span>

<span class="c1"># Print IDs or contents of the top‑3 most similar document fragments</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Top‑3 most similar document fragments:"</span><span class="p">)</span>
<span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">top_n_indices</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">idx</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">document_chunks</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</code></pre></div>
<p>8.
</p><div class="highlight"><pre><span/><code><span class="k">def</span><span class="w"> </span><span class="nf">embed_and_store_documents</span><span class="p">(</span><span class="n">document_chunks</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Generate embeddings for each document fragment and store them in SimpleVectorStore.</span>

<span class="sd">    Args:</span>
<span class="sd">    - document_chunks (list of str): List of document fragments.</span>

<span class="sd">    Returns:</span>
<span class="sd">    - SimpleVectorStore: Vector store initialized with document embeddings.</span>
<span class="sd">    """</span>
    <span class="n">store</span> <span class="o">=</span> <span class="n">SimpleVectorStore</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">document_chunks</span><span class="p">:</span>
        <span class="c1"># Placeholder embedding based on fragment length</span>
        <span class="n">embedding</span> <span class="o">=</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">chunk</span><span class="p">)]</span>
        <span class="n">store</span><span class="o">.</span><span class="n">add_vector</span><span class="p">(</span><span class="n">embedding</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">store</span>
</code></pre></div>
<p>9.
</p><div class="highlight"><pre><span/><code><span class="kn">import</span><span class="w"> </span><span class="nn">json</span>

<span class="k">def</span><span class="w"> </span><span class="nf">save_vector_store</span><span class="p">(</span><span class="n">store</span><span class="p">,</span> <span class="n">filepath</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Save the state of a SimpleVectorStore to the specified file.</span>

<span class="sd">    Args:</span>
<span class="sd">    - store (SimpleVectorStore): Vector store to save.</span>
<span class="sd">    - filepath (str): Path to the output file.</span>
<span class="sd">    """</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span> <span class="s1">'w'</span><span class="p">)</span> <span class="k">as</span> <span class="n">file</span><span class="p">:</span>
        <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">store</span><span class="o">.</span><span class="n">vectors</span><span class="p">,</span> <span class="n">file</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">load_vector_store</span><span class="p">(</span><span class="n">filepath</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Load a SimpleVectorStore from the specified file.</span>

<span class="sd">    Args:</span>
<span class="sd">    - filepath (str): Path to the input file.</span>

<span class="sd">    Returns:</span>
<span class="sd">    - SimpleVectorStore: Loaded vector store.</span>
<span class="sd">    """</span>
    <span class="n">store</span> <span class="o">=</span> <span class="n">SimpleVectorStore</span><span class="p">()</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span> <span class="s1">'r'</span><span class="p">)</span> <span class="k">as</span> <span class="n">file</span><span class="p">:</span>
        <span class="n">store</span><span class="o">.</span><span class="n">vectors</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">file</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">store</span>

<span class="k">def</span><span class="w"> </span><span class="nf">vector_store_persistence</span><span class="p">():</span>
<span class="w">    </span><span class="sd">"""Demonstrate saving and loading the state of SimpleVectorStore."""</span>
    <span class="n">store</span> <span class="o">=</span> <span class="n">SimpleVectorStore</span><span class="p">()</span>  <span class="c1"># Assume it is already populated</span>
    <span class="n">filepath</span> <span class="o">=</span> <span class="s1">'vector_store.json'</span>

    <span class="c1"># Example of saving and loading</span>
    <span class="n">save_vector_store</span><span class="p">(</span><span class="n">store</span><span class="p">,</span> <span class="n">filepath</span><span class="p">)</span>
    <span class="n">loaded_store</span> <span class="o">=</span> <span class="n">load_vector_store</span><span class="p">(</span><span class="n">filepath</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Vector store loaded with vectors:"</span><span class="p">,</span> <span class="n">loaded_store</span><span class="o">.</span><span class="n">vectors</span><span class="p">)</span>
</code></pre></div>
<p>10.
</p><div class="highlight"><pre><span/><code><span class="k">def</span><span class="w"> </span><span class="nf">evaluate_search_accuracy</span><span class="p">(</span><span class="n">queries</span><span class="p">,</span> <span class="n">expected_chunks</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Evaluate similarity‑search accuracy for a list of queries and expected results.</span>

<span class="sd">    Args:</span>
<span class="sd">    - queries (list of str): Query strings.</span>
<span class="sd">    - expected_chunks (list of str): Expected most similar document fragments for each query.</span>

<span class="sd">    Returns:</span>
<span class="sd">    - float: Retrieval accuracy (fraction of correctly found fragments).</span>
<span class="sd">    """</span>
    <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="c1"># Embed and store documents plus some extras to ensure uniqueness</span>
    <span class="n">store</span> <span class="o">=</span> <span class="n">embed_and_store_documents</span><span class="p">(</span><span class="n">expected_chunks</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">expected_chunks</span><span class="p">)</span> <span class="o">-</span> <span class="nb">set</span><span class="p">(</span><span class="n">queries</span><span class="p">)))</span>

    <span class="k">for</span> <span class="n">query</span><span class="p">,</span> <span class="n">expected</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">queries</span><span class="p">,</span> <span class="n">expected_chunks</span><span class="p">):</span>
        <span class="n">query_embedding</span> <span class="o">=</span> <span class="n">generate_query_embedding</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
        <span class="n">most_similar</span> <span class="o">=</span> <span class="n">store</span><span class="o">.</span><span class="n">find_most_similar</span><span class="p">(</span><span class="n">query_embedding</span><span class="p">)</span>
        <span class="c1"># Assume expected_chunks map to embeddings by length in the same way</span>
        <span class="k">if</span> <span class="n">most_similar</span> <span class="ow">and</span> <span class="n">most_similar</span> <span class="o">==</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">expected</span><span class="p">)]:</span>
            <span class="n">correct</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">correct</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">queries</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">accuracy</span>

<span class="c1"># Assume embed_and_store_documents, generate_query_embedding, and SimpleVectorStore</span>
<span class="c1"># are implemented as described above.</span>
</code></pre></div>












                
                  
</body>
</html>