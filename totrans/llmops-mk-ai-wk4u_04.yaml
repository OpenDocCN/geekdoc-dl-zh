- en: 1.1 Introduction
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1.1 简介
- en: 原文：[https://boramorka.github.io/LLM-Book/en/CHAPTER-1/1.1%20Introduction/](https://boramorka.github.io/LLM-Book/en/CHAPTER-1/1.1%20Introduction/)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://boramorka.github.io/LLM-Book/en/CHAPTER-1/1.1%20Introduction/](https://boramorka.github.io/LLM-Book/en/CHAPTER-1/1.1%20Introduction/)
- en: This chapter focuses on the practical integration of the OpenAI API into your
    services, with an emphasis on generating text responses using GPT models. We will
    briefly walk through the path from installation and secure setup to your first
    requests, interpreting responses, and embedding results into applications. The
    material is aimed at ML engineers, data scientists, software developers, and adjacent
    specialists who need to connect models to products quickly and reliably.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章重点介绍将OpenAI API集成到您的服务中的实际操作，着重于使用GPT模型生成文本响应。我们将简要介绍从安装和安全的设置到您的第一个请求、解释响应以及将结果嵌入应用程序的路径。这些材料面向需要快速且可靠地将模型连接到产品的机器学习工程师、数据科学家、软件开发人员和相关专业人士。
- en: 'OpenAI provides access to a family of language models (including Generative
    Pre‑trained Transformer, GPT) via an API. These models understand and generate
    human‑like text, making them a powerful tool for tasks ranging from automating
    customer support to content generation. Start by installing the current client
    version:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI通过API提供对一系列语言模型（包括生成预训练转换器GPT）的访问。这些模型理解并生成类似人类的文本，使它们成为从自动化客户支持到内容生成等任务的有力工具。首先，安装当前客户端版本：
- en: '[PRE0]'
  id: totrans-4
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Next, you need an API key, obtained after registering at OpenAI (https://openai.com/)
    and choosing an appropriate pricing plan. The key is unique, used to sign requests,
    and must be kept strictly confidential: store it in environment variables and,
    for local development, in `.env` files; in production, use a secrets manager.
    With this minimal setup, you can send a simple text‑generation request and print
    the answer to the console:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，你需要一个API密钥，在OpenAI（https://openai.com/）注册并选择合适的定价计划后获得。该密钥是唯一的，用于签名请求，必须严格保密：存储在环境变量中，在本地开发中存储在
    `.env` 文件中；在生产中，使用密钥管理器。有了这个最小设置，你可以发送一个简单的文本生成请求并将答案打印到控制台：
- en: '[PRE1]'
  id: totrans-6
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'To get predictable results, it is important to remember how requests are formed:
    you choose a model, craft a prompt (a question or instruction), and set generation
    parameters. For example, `temperature` controls creativity and randomness: the
    higher it is, the more diverse the answers. The client library reads the API key
    from the environment; with correct configuration, you simply assemble the message
    list and specify the model — the SDK handles the rest.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 为了获得可预测的结果，重要的是要记住请求是如何形成的：你选择一个模型，制作一个提示（一个问题或指令），并设置生成参数。例如，`temperature`
    控制创造性和随机性：它越高，答案就越多样化。客户端库从环境变量中读取API密钥；在正确配置的情况下，你只需组装消息列表并指定模型——SDK处理其余部分。
- en: 'The API response contains the generated text and useful metadata. Structurally
    it includes a `choices` field (one or more answer variants) and `usage` (token
    statistics) to help estimate cost and optimize requests:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: API响应包含生成的文本和有用的元数据。结构上包括一个 `choices` 字段（一个或多个答案变体）和 `usage`（令牌统计）以帮助估计成本并优化请求：
- en: '[PRE2]'
  id: totrans-9
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '**Note:** The response contains `choices[].message.content` with the generated
    text, and `usage` statistics to help estimate cost and optimize requests.'
  id: totrans-10
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**注意：** 响应包含 `choices[].message.content` 中的生成文本和 `usage` 统计数据，以帮助估计成本并优化请求。'
- en: 'When integrating, build in error handling: networks are unreliable, limits
    are finite, and request parameters may be invalid. A simple `try/except` scaffold
    helps you respond correctly to connection issues, quota exceedance, and API status
    errors without crashing your application:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在集成时，内置错误处理：网络不可靠，限制有限，请求参数可能无效。一个简单的 `try/except` 框架可以帮助你正确响应连接问题、配额超额和API状态错误，而不会使你的应用程序崩溃：
- en: '[PRE3]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Alongside error handling, use `usage` metadata and other response fields to
    monitor cost, timing, and effectiveness so you can adjust prompts, limit lengths,
    choose cost‑efficient models, and keep spend under control.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 除了错误处理之外，使用 `usage` 元数据和其它响应字段来监控成本、时间和有效性，这样你可以调整提示、限制长度、选择成本效益高的模型，并保持支出在控制之下。
- en: 'In applied scenarios, generation is most often embedded in conversational interfaces.
    Below is a concise example of an interactive client built with Panel: the user
    enters a query, the system processes it, and displays the answer. The code illustrates
    updating the history and laying out UI elements that are easy to adapt for your
    needs:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在应用场景中，生成通常嵌入在对话界面中。以下是一个使用Panel构建的交互式客户端的简要示例：用户输入查询，系统处理它，并显示答案。代码说明了更新历史记录和布局UI元素，这些元素很容易根据您的需求进行修改：
- en: '[PRE4]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Tip: improve UX with an “assistant is typing…” indicator and other feedback
    signals to make the dialogue feel alive. From there, it comes down to how you
    use the model’s answers. In chatbots you can display the replies directly, paying
    attention to formatting and relevance; for generating articles and reports, post‑processing
    helps — formatting, templating, and combining multiple answers into cohesive texts;
    for dynamic content in web apps, validate relevance and consistency and plan regular
    updates.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 小贴士：使用“助手正在输入...”指示器和其他反馈信号来改善用户体验，使对话感觉生动。从那里，关键在于您如何使用模型的答案。在聊天机器人中，您可以直接显示回复，注意格式和相关性；对于生成文章和报告，后处理有助于——格式化、模板化和将多个答案组合成连贯的文本；对于Web应用中的动态内容，验证相关性和一致性，并计划定期更新。
- en: 'It’s good practice to add post‑processing (grammar and style checks, aligning
    to your brand voice), personalization (respecting context, preferences, and user
    history), feedback collection to improve prompts and parameters, and monitoring/analytics:
    response time, engagement, token usage, and other metrics that help you optimize
    the system responsibly. For performance, consider caching frequent queries, batching,
    and choosing an appropriately sized model for the task and budget. Don’t blindly
    trust model output: verify accuracy and appropriateness, and add validation and
    filters.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 好的做法是添加后处理（语法和风格检查、与品牌声音保持一致），个性化（尊重上下文、偏好和用户历史），收集反馈以改进提示和参数，以及监控/分析：响应时间、参与度、token使用和其他有助于您负责任地优化系统的指标。为了性能，考虑缓存频繁查询、批处理，并为任务和预算选择适当大小的模型。不要盲目相信模型输出：验证准确性和适宜性，并添加验证和过滤器。
- en: To go deeper, study the official OpenAI documentation, follow updates, and participate
    in professional communities. This material lays a foundation for quick integration
    and opens the door to advanced scenarios of intelligent text interactions.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 要深入了解，请学习官方OpenAI文档，关注更新，并参与专业社区。这些材料为快速集成奠定了基础，并为智能文本交互的高级场景打开了大门。
- en: Theory Questions
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理论问题
- en: What are the main benefits of integrating the OpenAI API for ML engineers, data
    scientists, and developers?
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 集成OpenAI API对机器学习工程师、数据科学家和开发者有哪些主要好处？
- en: Describe how to obtain an OpenAI API key and explain why securing it is important.
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 描述如何获取OpenAI API密钥，并解释为什么保护它很重要。
- en: What is the role of `temperature`, and how does it affect generation results?
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`temperature`的作用是什么，它如何影响生成结果？'
- en: Why should API keys be stored in environment variables or secret managers rather
    than directly in code?
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为什么API密钥应该存储在环境变量或秘密管理器中，而不是直接在代码中？
- en: Why is model choice critical for quality, speed, and cost?
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为什么模型选择对质量、速度和成本至关重要？
- en: How do response metadata help optimize requests and manage token spend?
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 响应元数据如何帮助优化请求和管理token支出？
- en: List the steps to create a simple conversational interface and its key components.
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 列出创建简单对话界面及其关键组件的步骤。
- en: Which integration best practices fit chatbots, content generation, and dynamic
    content?
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 哪些集成最佳实践适用于聊天机器人、内容生成和动态内容？
- en: Name common pitfalls when working with the API and ways to prevent them.
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 列举在使用API时常见的陷阱以及预防方法。
- en: How can you ensure ethical standards and protect user privacy?
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如何确保道德标准和保护用户隐私？
- en: Practical Tasks
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实践任务
- en: Write a Python script that uses the OpenAI API to answer the question “What
    is the future of AI?”. Limit the answer to 100 tokens.
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编写一个Python脚本，使用OpenAI API回答“人工智能的未来是什么？”的问题。将答案限制在100个token以内。
- en: Modify the script from Task 1 to read the API key from an environment variable
    instead of hard‑coding it.
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将任务1中的脚本修改为从环境变量中读取API密钥，而不是将其硬编码。
- en: Extend the script from Task 2 to print, along with the answer text, the model
    name, token counts, and the reason generation stopped.
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将任务2中的脚本扩展，打印出答案文本、模型名称、token计数以及生成停止的原因。
- en: Add error handling to the script from Task 3 (e.g., handling rate limits, invalid
    requests, etc.) using `try/except`.
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`try/except`为任务3中的脚本添加错误处理（例如处理速率限制、无效请求等）。
- en: Create a simple command‑line interface (CLI) that sends prompts and streams
    answers in real time, with error handling.
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个简单的命令行界面（CLI），它可以实时发送提示并流式传输答案，并具有错误处理功能。
- en: 'For the CLI from Task 5, add answer post‑processing: trimming extra whitespace,
    basic grammar correction (e.g., using `textblob`) or your own formatting.'
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为任务5中的CLI添加答案后处理：去除多余的空白字符，进行基本的语法纠正（例如使用`textblob`）或进行自己的格式化。
- en: Develop a script that, for a user‑provided topic, generates a publishing plan
    and outputs it as a bulleted list.
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 开发一个脚本，对于用户提供的主题，生成一个发布计划并以项目符号列表的形式输出。
- en: In any of the scripts, add logging of response time and token usage, storing
    these metrics for later analysis and optimization.
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在任何脚本中，添加响应时间和令牌使用的日志记录，并将这些指标存储起来以供后续分析和优化。
