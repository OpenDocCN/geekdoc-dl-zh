- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: COT ä¸“æ '
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: ç±»åˆ«ï¼šCOT ä¸“æ 
- en: 'date: 2024-05-08 11:11:30'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: æ—¥æœŸï¼š2024-05-08 11:11:30
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: How to Build a Chatbot with GPT-3
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å¦‚ä½•ç”¨GPT-3æ„å»ºä¸€ä¸ªèŠå¤©æœºå™¨äºº
- en: æ¥æºï¼š[https://every.to/chain-of-thought/how-to-build-a-chatbot-with-gpt-3](https://every.to/chain-of-thought/how-to-build-a-chatbot-with-gpt-3)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: æ¥æºï¼š[https://every.to/chain-of-thought/how-to-build-a-chatbot-with-gpt-3](https://every.to/chain-of-thought/how-to-build-a-chatbot-with-gpt-3)
- en: 'On a Friday night a few weeks ago I woke up to an email from [Lenny Rachitsky](https://twitter.com/lennysan),
    writer of [Lennyâ€™s Newsletter](http://lennysnewsletter.com/), one of the largest
    newsletters on Substack. He wanted to know how I built one of our Every chatbots:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: å‡ å‘¨å‰çš„ä¸€ä¸ªæ˜ŸæœŸäº”æ™šä¸Šï¼Œæˆ‘é†’æ¥æ”¶åˆ°äº†ä¸€å°æ¥è‡ª[Lenny Rachitsky](https://twitter.com/lennysan)çš„ç”µå­é‚®ä»¶ï¼Œä»–æ˜¯[Lenny's
    Newsletter](http://lennysnewsletter.com/)çš„ä½œè€…ï¼Œæ˜¯Substackä¸Šæœ€å¤§çš„é€šè®¯ä¹‹ä¸€ã€‚ä»–æƒ³çŸ¥é“æˆ‘æ˜¯å¦‚ä½•æ„å»ºæˆ‘ä»¬Everyçš„ä¸€ä¸ªèŠå¤©æœºå™¨äººçš„ï¼š
- en: I
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘
- en: '*love*'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '*çˆ±*'
- en: Lenny. Heâ€™s a major inspiration for us at Every, so to see him interested in
    chatbots was exciting. It also created an opportunity for me to test a theory
    Iâ€™d been
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: Lennyã€‚ä»–å¯¹Everyæ˜¯ä¸€ä¸ªé‡è¦çš„çµæ„Ÿï¼Œæ‰€ä»¥çœ‹åˆ°ä»–å¯¹èŠå¤©æœºå™¨äººæ„Ÿå…´è¶£çœŸæ˜¯ä»¤äººå…´å¥‹ã€‚è¿™ä¹Ÿä¸ºæˆ‘æä¾›äº†ä¸€ä¸ªæœºä¼šï¼Œå¯ä»¥æµ‹è¯•æˆ‘ä¸€ç›´ä»¥æ¥çš„ä¸€ä¸ªç†è®º
- en: '[playing around with](https://every.to/chain-of-thought/i-trained-a-gpt-3-chatbot-on-every-episode-of-my-favorite-podcast)'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[ç©å¼„](https://every.to/chain-of-thought/i-trained-a-gpt-3-chatbot-on-every-episode-of-my-favorite-podcast)'
- en: ':'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: ï¼š
- en: '*Chatbots are a new and valuable content format for creators.*'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '*èŠå¤©æœºå™¨äººæ˜¯åˆ›ä½œè€…çš„ä¸€ç§æ–°è€Œæœ‰ä»·å€¼çš„å†…å®¹æ ¼å¼*ã€‚'
- en: 'I knew Lennyâ€™s audience would be a perfect way to test this theory:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘çŸ¥é“Lennyçš„è§‚ä¼—ä¼šæ˜¯æµ‹è¯•è¿™ä¸ªç†è®ºçš„å®Œç¾æ–¹å¼ï¼š
- en: Itâ€™s large (he has 300,000 subscribers).
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å®ƒå¾ˆå¤§ï¼ˆä»–æœ‰30ä¸‡è®¢é˜…è€…ï¼‰ã€‚
- en: Theyâ€™re highly engaged.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä»–ä»¬çš„å‚ä¸åº¦å¾ˆé«˜ã€‚
- en: All of his posts are evergreen.
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä»–çš„æ‰€æœ‰å¸–å­éƒ½æ˜¯é•¿é’çš„ã€‚
- en: Theyâ€™re often used as reference material.
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å®ƒä»¬ç»å¸¸è¢«ç”¨ä½œå‚è€ƒèµ„æ–™ã€‚
- en: For all of these reasons, making his posts available in a chatbot format made
    sense. Rather than having to scroll through his archive to answer a product question,
    any of his subscribers could ask the bot instead and get instant answers.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: å‡ºäºè¿™äº›åŸå› ï¼Œå°†ä»–çš„å¸–å­ä»¥èŠå¤©æœºå™¨äººçš„å½¢å¼æä¾›æ˜¯æœ‰æ„ä¹‰çš„ã€‚ä¸å…¶ä¸å¾—ä¸æµè§ˆä»–çš„å­˜æ¡£æ¥å›ç­”ä¸€ä¸ªäº§å“é—®é¢˜ï¼Œä»–çš„ä»»ä½•è®¢é˜…è€…éƒ½å¯ä»¥é—®æœºå™¨äººï¼Œè€Œä¸”ä¼šç«‹å³å¾—åˆ°ç­”æ¡ˆã€‚
- en: 'I knew it would be pretty easy to build one for him based on the work weâ€™d
    already doneâ€”so I offered to make it for him:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘çŸ¥é“åŸºäºæˆ‘ä»¬å·²ç»å®Œæˆçš„å·¥ä½œï¼Œä¸ºä»–æ„å»ºä¸€ä¸ªè¿™æ ·çš„æœºå™¨äººä¼šå¾ˆå®¹æ˜“â€”â€”æ‰€ä»¥æˆ‘æå‡ºäº†ä¸ºä»–åˆ¶ä½œä¸€ä¸ªçš„å»ºè®®ï¼š
- en: 'He said yes, and the next day I woke up early and delivered him a Lenny chatbot
    built to give answers from his newsletter archives:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: ä»–è¯´å¥½ï¼Œç¬¬äºŒå¤©æˆ‘ä¸€æ—©é†’æ¥å°±ç»™ä»–äº¤ä»˜äº†ä¸€ä¸ªLennyèŠå¤©æœºå™¨äººï¼Œå®ƒå¯ä»¥æ ¹æ®ä»–çš„é€šè®¯æ¡£æ¡ˆæä¾›ç­”æ¡ˆï¼š
- en: Over the next couple of weeks I also wrote an essay,
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ¥ä¸‹æ¥çš„å‡ å‘¨é‡Œï¼Œæˆ‘è¿˜å†™äº†ä¸€ç¯‡æ–‡ç« ï¼Œ
- en: '[published as a guest post on his newsletter](https://www.lennysnewsletter.com/p/39b613d6-063b-45df-9a8e-40fece9d6bde)'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '[ä»¥å®¢åº§å¸–å­çš„å½¢å¼å‘å¸ƒåœ¨ä»–çš„é€šè®¯ä¸­](https://www.lennysnewsletter.com/p/39b613d6-063b-45df-9a8e-40fece9d6bde)'
- en: ', about how I built the bot. Itâ€™s a detailed, step-by-step guide to how GPT-3
    works and how it can be used to create Q&A chatbots like this easilyâ€”no programming
    experience required. It went live on Tuesday and became Lennyâ€™s highest trafficked
    day ever:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: ï¼Œå…³äºæˆ‘å¦‚ä½•æ„å»ºæœºå™¨äººã€‚è¿™æ˜¯å¯¹GPT-3å¦‚ä½•å·¥ä½œä»¥åŠå¦‚ä½•ä½¿ç”¨å®ƒè½»æ¾åˆ›å»ºåƒè¿™æ ·çš„é—®ç­”æœºå™¨äººçš„è¯¦ç»†ã€é€æ­¥æŒ‡å—â€”â€”æ— éœ€ç¼–ç¨‹ç»éªŒã€‚å®ƒåœ¨æ˜ŸæœŸäºŒä¸Šçº¿ï¼Œæˆä¸ºLennyæœ‰å²ä»¥æ¥æµé‡æœ€é«˜çš„ä¸€å¤©ï¼š
- en: It was a wild ride, and Iâ€™m syndicating the full post below for all of you.
    There is also
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ä¸€æ¬¡ç–¯ç‹‚çš„æ—…ç¨‹ï¼Œæˆ‘æ­£åœ¨ä¸ºä½ ä»¬æ‰€æœ‰äººåŒæ­¥å…¨æ–‡ã€‚è¿˜æœ‰
- en: '**a section at the bottom exclusively for Every paying subscribers with**'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '**ä¸€ä¸ªä¸“é—¨ä¸ºæ¯ä½ä»˜è´¹è®¢é˜…è€…å‡†å¤‡çš„åº•éƒ¨éƒ¨åˆ†**ã€‚'
- en: ':'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: ï¼š
- en: A retrospective on launch day including metrics
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å‘å¸ƒæ—¥å›é¡¾ï¼ŒåŒ…æ‹¬æŒ‡æ ‡
- en: Server-side code samples
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æœåŠ¡å™¨ç«¯ä»£ç ç¤ºä¾‹ã€‚
- en: Client-side chatbot code samples
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å®¢æˆ·ç«¯èŠå¤©æœºå™¨äººä»£ç ç¤ºä¾‹ã€‚
- en: 'If you want to read the full post, including code samples, subscribe here:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ æƒ³é˜…è¯»å®Œæ•´çš„æ–‡ç« ï¼ŒåŒ…æ‹¬ä»£ç ç¤ºä¾‹ï¼Œè¯·åœ¨è¿™é‡Œè®¢é˜…ï¼š
- en: I hope you enjoy!
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: å¸Œæœ›ä½ å–œæ¬¢ï¼
- en: ''
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '* * *'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: "\uFEFF\uFEFFI Built a Lenny Chatbot Using GPT-3"
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ç”¨GPT-3æ„å»ºäº†ä¸€ä¸ªLennyèŠå¤©æœºå™¨äºº
- en: Lennyâ€™s Newsletter is great, but itâ€™s one-sided. It talks *to* you, but you
    canâ€™t talk back. Wouldnâ€™t it be awesome if you could ask Lennyâ€™s Newsletter a
    question?
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: Lennyçš„é€šè®¯å¾ˆæ£’ï¼Œä½†æ˜¯å®ƒæ˜¯å•å‘çš„ã€‚å®ƒå’Œä½ äº¤è°ˆï¼Œä½†ä½ ä¸èƒ½å›ç­”ã€‚å¦‚æœä½ èƒ½é—®Lennyçš„é€šè®¯ä¸€ä¸ªé—®é¢˜ï¼Œé‚£ä¸æ˜¯å¾ˆæ£’å—ï¼Ÿ
- en: Now thatâ€™s possible.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨è¿™æ˜¯å¯èƒ½çš„ã€‚
- en: Over the course of a week I built an AI-powered chatbot for Lenny that uses
    his entire newsletter archive to answer any question you have about product, growth,
    and startups. Itâ€™s built with GPT-3 and took a couple hours to do, end to end.
    In this post, Iâ€™ll break down exactly how the Lenny Bot works so you can learn
    to build one yourself.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä¸€ä¸ªæ˜ŸæœŸçš„æ—¶é—´é‡Œï¼Œæˆ‘ä¸ºLennyæ„å»ºäº†ä¸€ä¸ªAIé©±åŠ¨çš„èŠå¤©æœºå™¨äººï¼Œå®ƒä½¿ç”¨ä»–çš„æ•´ä¸ªé€šè®¯æ¡£æ¡ˆæ¥å›ç­”æ‚¨å…³äºäº§å“ã€å¢é•¿å’Œåˆåˆ›å…¬å¸çš„ä»»ä½•é—®é¢˜ã€‚å®ƒæ˜¯ç”¨GPT-3æ„å»ºçš„ï¼Œä»å¤´åˆ°å°¾åªç”¨äº†å‡ ä¸ªå°æ—¶ã€‚åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘å°†è¯¦ç»†è§£é‡ŠLenny
    Botçš„å·¥ä½œåŸç†ï¼Œè¿™æ ·ä½ å°±å¯ä»¥å­¦ä¼šè‡ªå·±æ„å»ºä¸€ä¸ªã€‚
- en: You can also use it right now ğŸ‘‡
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ ä¹Ÿå¯ä»¥ç«‹å³ä½¿ç”¨å®ƒğŸ‘‡
- en: AI technologies like GPT-3 are still in their infancy, but theyâ€™re going to
    be everywhere soon. Staying on top of how they work is going to be crucial to
    your career in tech, and especially in building product. The best way to prepare
    for a fast-approaching future is to dive in and get your hands dirty.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-3ç­‰AIæŠ€æœ¯ä»å¤„äºèµ·æ­¥é˜¶æ®µï¼Œä½†å®ƒä»¬å¾ˆå¿«å°±ä¼šæ— å¤„ä¸åœ¨ã€‚äº†è§£å®ƒä»¬çš„å·¥ä½œæ–¹å¼å¯¹ä½ çš„æŠ€æœ¯èŒä¸šï¼Œå°¤å…¶æ˜¯äº§å“å¼€å‘å°†è‡³å…³é‡è¦ã€‚ä¸ºäº†è¿æ¥è¿…é€Ÿåˆ°æ¥çš„æœªæ¥ï¼Œæœ€å¥½çš„å‡†å¤‡æ–¹å¼æ˜¯æŠ•å…¥å…¶ä¸­ï¼ŒåŠ¨æ‰‹å®è·µã€‚
- en: It might seem intimidating to get started, especially if you donâ€™t have a technical
    background. But Iâ€™m going to start at the very beginning. Youâ€™ll be able to understand
    what Iâ€™m talking about and begin using it yourself,*no programming required***.**
    (And if you have any questions, you can always paste them into ChatGPTâ€”itâ€™ll give
    you good responses ;)
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ æ²¡æœ‰æŠ€æœ¯èƒŒæ™¯ï¼Œå¼€å§‹å¯èƒ½ä¼šè®©äººç•æƒ§ã€‚ä½†æˆ‘å°†ä»æœ€åŸºç¡€çš„çŸ¥è¯†å¼€å§‹è®²èµ·ã€‚ä½ å°†èƒ½å¤Ÿç†è§£æˆ‘åœ¨è¯´ä»€ä¹ˆï¼Œå¹¶å¼€å§‹ä½¿ç”¨å®ƒï¼Œ*æ— éœ€ç¼–ç¨‹**ã€‚*ï¼ˆè€Œä¸”ï¼Œå¦‚æœä½ æœ‰ä»»ä½•é—®é¢˜ï¼Œå¯ä»¥éšæ—¶å°†å®ƒä»¬ç²˜è´´åˆ°ChatGPTä¸­â€”â€”å®ƒä¼šç»™ä½ è‰¯å¥½çš„å›åº”ï¼›ï¼‰
- en: 'Preamble: GPT-3 vs. ChatGPT'
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: åºè¨€ï¼šGPT-3å’ŒChatGPTçš„åŒºåˆ«
- en: Youâ€™ve probably heard of both GPT-3 and ChatGPT. Maybe you use those terms interchangeably,
    or maybe youâ€™re not really sure what the difference is. Itâ€™s worth taking a minute
    to understand how they differ.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯èƒ½å¬è¯´è¿‡GPT-3å’ŒChatGPTã€‚ä¹Ÿè®¸ä½ å°†è¿™äº›æœ¯è¯­æ··ç”¨ï¼Œæˆ–è€…ä½ å¯èƒ½å¹¶ä¸ç¡®å®šå®ƒä»¬çš„åŒºåˆ«ã€‚èŠ±ç‚¹æ—¶é—´æ¥ç†è§£å®ƒä»¬çš„åŒºåˆ«æ˜¯å€¼å¾—çš„ã€‚
- en: GPT-3 and ChatGPT are both â€œlarge language modelsâ€ (LLMs). These are machine-learning
    models that can generate natural-sounding text, code, and more. Theyâ€™re trained
    using large data sets of text, which helps them master natural-language tasks,
    like answering questions, writing marketing copy, and holding conversations. So
    whatâ€™s the difference between them? And why is it important?
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-3å’ŒChatGPTéƒ½æ˜¯â€œå¤§å‹è¯­è¨€æ¨¡å‹â€ï¼ˆLLMsï¼‰ã€‚è¿™äº›æ˜¯å¯ä»¥ç”Ÿæˆè‡ªç„¶å¬èµ·æ¥çš„æ–‡æœ¬ã€ä»£ç ç­‰çš„æœºå™¨å­¦ä¹ æ¨¡å‹ã€‚å®ƒä»¬é€šè¿‡å¤§é‡çš„æ–‡æœ¬æ•°æ®é›†è¿›è¡Œè®­ç»ƒï¼Œæœ‰åŠ©äºå®ƒä»¬æŒæ¡è‡ªç„¶è¯­è¨€ä»»åŠ¡ï¼Œå¦‚å›ç­”é—®é¢˜ã€å†™è¥é”€æ–‡æ¡ˆå’Œè¿›è¡Œå¯¹è¯ã€‚é‚£ä¹ˆå®ƒä»¬ä¹‹é—´çš„åŒºåˆ«æ˜¯ä»€ä¹ˆï¼Ÿä¸ºä»€ä¹ˆè¿™å¾ˆé‡è¦ï¼Ÿ
- en: 'GPT-3 is a general-purpose language model: it can hold conversations, write
    code, complete a blog post, do translation tasks, and more. You can think of it
    like a flexible know-it-all that can expound on any topic you want.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-3æ˜¯ä¸€ä¸ªé€šç”¨è¯­è¨€æ¨¡å‹ï¼šå®ƒå¯ä»¥è¿›è¡Œå¯¹è¯ï¼Œç¼–å†™ä»£ç ï¼Œå®Œæˆåšå®¢æ–‡ç« ï¼Œè¿›è¡Œç¿»è¯‘ä»»åŠ¡ç­‰ã€‚ä½ å¯ä»¥æŠŠå®ƒæƒ³è±¡æˆä¸€ä¸ªçµæ´»çš„å…¨èƒ½å‹äººç‰©ï¼Œå¯ä»¥åœ¨ä½ æƒ³è¦çš„ä»»ä½•è¯é¢˜ä¸Šé˜è¿°ã€‚
- en: ChatGPT is a version of GPT-3 thatâ€™s been turned into a friendly, inoffensive
    extrovert. Basically, itâ€™s been trained to be good at holding conversations. Its
    creator OpenAI does this by repeatedly holding conversations with the model, and
    rewarding it for good responses and punishing it for bad onesâ€”a process called
    [Reinforcement Learning from Human Feedback](https://huggingface.co/blog/rlhf).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPTæ˜¯GPT-3çš„ä¸€ä¸ªç‰ˆæœ¬ï¼Œå®ƒè¢«æ‰“é€ æˆäº†ä¸€ä¸ªå‹å¥½ã€æ— æ”»å‡»æ€§çš„å¤–å‘å‹ä¸ªä½“ã€‚åŸºæœ¬ä¸Šï¼Œå®ƒç»è¿‡è®­ç»ƒæ“…é•¿è¿›è¡Œå¯¹è¯ã€‚å…¶åˆ›é€ è€…OpenAIé€šè¿‡ä¸æ–­åœ°ä¸æ¨¡å‹è¿›è¡Œå¯¹è¯ï¼Œå¯¹å¥½çš„å›åº”è¿›è¡Œå¥–åŠ±ï¼Œå¯¹ä¸å¥½çš„å›åº”è¿›è¡Œæƒ©ç½šâ€”â€”è¿™ä¸ªè¿‡ç¨‹è¢«ç§°ä¸º[äººç±»åé¦ˆçš„å¼ºåŒ–å­¦ä¹ ](https://huggingface.co/blog/rlhf)ã€‚
- en: Youâ€™d think since weâ€™re building a chatbot, weâ€™d use ChatGPT, right? Unfortunately
    not. OpenAI hasnâ€™t created a way for us to interact with the ChatGPT model directlyâ€”you
    can only use it through the ChatGPT web app. So itâ€™s not suitable for our purposes.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯èƒ½ä¼šè®¤ä¸ºæ—¢ç„¶æˆ‘ä»¬æ­£åœ¨æ„å»ºä¸€ä¸ªèŠå¤©æœºå™¨äººï¼Œæˆ‘ä»¬ä¼šä½¿ç”¨ChatGPTï¼Œå¯¹å§ï¼Ÿä¸å¹¸çš„æ˜¯ï¼ŒOpenAIå¹¶æ²¡æœ‰ä¸ºæˆ‘ä»¬åˆ›å»ºä¸€ç§æ–¹å¼æ¥ç›´æ¥ä¸ChatGPTæ¨¡å‹äº’åŠ¨â€”â€”ä½ åªèƒ½é€šè¿‡ChatGPT
    Webåº”ç”¨ç¨‹åºä½¿ç”¨å®ƒã€‚æ‰€ä»¥å®ƒä¸é€‚åˆæˆ‘ä»¬çš„ç›®çš„ã€‚
- en: We want to be able to interact with the model directly, not through an intervening
    app. So instead weâ€™ll use GPT-3 for our explorations. Itâ€™ll give us all the power
    and flexibility we need to build a chatbot.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¸Œæœ›èƒ½å¤Ÿç›´æ¥ä¸æ¨¡å‹äº’åŠ¨ï¼Œè€Œä¸æ˜¯é€šè¿‡ä¸€ä¸ªä¸­ä»‹åº”ç”¨ã€‚æ‰€ä»¥æˆ‘ä»¬å°†ä½¿ç”¨GPT-3è¿›è¡Œæ¢ç´¢ã€‚å®ƒå°†ä¸ºæˆ‘ä»¬æä¾›æ„å»ºèŠå¤©æœºå™¨äººæ‰€éœ€çš„æ‰€æœ‰åŠ›é‡å’Œçµæ´»æ€§ã€‚
- en: 'Weâ€™ll do it in two ways: using [OpenAIâ€™s Playground](https://platform.openai.com/playground)
    to start, and with a little bit of code after that. The Playground is a web app
    that lets you prompt GPT-3 and get responses back, making it a great place for
    us to experiment.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†ä»¥ä¸¤ç§æ–¹å¼æ¥è¿›è¡Œï¼šé¦–å…ˆä½¿ç”¨[OpenAIçš„Playground](https://platform.openai.com/playground)èµ·æ­¥ï¼Œä¹‹åå†åŠ ä¸Šä¸€ç‚¹ä»£ç ã€‚Playgroundæ˜¯ä¸€ä¸ªWebåº”ç”¨ç¨‹åºï¼Œè®©ä½ æç¤ºGPT-3å¹¶å¾—åˆ°å›åº”ï¼Œè®©æˆ‘ä»¬æ¥å®éªŒçš„ç»ä½³åœ°æ–¹ã€‚
- en: Letâ€™s start there and see how things go.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ä»è¿™é‡Œå¼€å§‹ï¼Œçœ‹çœ‹äº‹æƒ…çš„å‘å±•æƒ…å†µã€‚
- en: The basics of GPT-3
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GPT-3çš„åŸºç¡€çŸ¥è¯†
- en: The basic way to explain GPT-3 is that it likes to finish your sentences for
    you. You provide it with a starting set of words, and it tries to figure out the
    most likely set of words that follow from your input. You can provide any string
    of words. Itâ€™s very flexible and can talk about anything you want, from product
    management to astrophysics.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: è§£é‡Š GPT-3 çš„åŸºæœ¬æ–¹å¼æ˜¯å®ƒå–œæ¬¢å¸®ä½ å®Œæˆå¥å­ã€‚ä½ æä¾›ä¸€ç»„èµ·å§‹è¯ï¼Œå®ƒä¼šå°è¯•æ‰¾å‡ºä»ä½ çš„è¾“å…¥ä¸­æœ€å¯èƒ½è·Ÿéšçš„è¯ç»„ã€‚ä½ å¯ä»¥æä¾›ä»»ä½•ä¸€ç»„è¯ã€‚å®ƒéå¸¸çµæ´»ï¼Œå¯ä»¥è°ˆè®ºä»»ä½•ä½ æƒ³è¦çš„è¯é¢˜ï¼Œä»äº§å“ç®¡ç†åˆ°å¤©ä½“ç‰©ç†å­¦ã€‚
- en: The set of words you provide is called a *prompt*, and the answer you get back
    from GPT-3 is called a *completion*.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ æä¾›çš„è¯ç»„ç§°ä¸º*æç¤º*ï¼Œè€Œä½ ä» GPT-3 å¾—åˆ°çš„ç­”æ¡ˆç§°ä¸º*å®Œæˆ*ã€‚
- en: 'Below is a simple example in the [GPT-3 Playground](https://platform.openai.com/playground?model=text-davinci-003).
    The non-green text is what I typed in as a prompt, and the green text is what
    GPT-3 returned as the completion:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸‹é¢æ˜¯ [GPT-3 æ¸¸ä¹åœº](https://platform.openai.com/playground?model=text-davinci-003)
    ä¸­çš„ä¸€ä¸ªç®€å•ç¤ºä¾‹ã€‚éç»¿è‰²æ–‡æœ¬æ˜¯æˆ‘è¾“å…¥çš„æç¤ºï¼Œç»¿è‰²æ–‡æœ¬æ˜¯ GPT-3 è¿”å›çš„å®Œæˆï¼š
- en: You can see that GPT-3 performs well on a simple completion like this. But it
    performs well even when the prompts get more complicated.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯ä»¥çœ‹åˆ°ï¼ŒGPT-3 åœ¨åƒè¿™æ ·ç®€å•çš„å®Œæˆä¸Šè¡¨ç°å¾—å¾ˆå¥½ã€‚ä½†æ˜¯å³ä½¿æç¤ºå˜å¾—æ›´åŠ å¤æ‚ï¼Œå®ƒä¹Ÿä¼šè¡¨ç°å¾—å¾ˆå¥½ã€‚
- en: 'You can, for example, prompt it to define product-market fit:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œä½ å¯ä»¥è¦æ±‚å®ƒå®šä¹‰äº§å“å¸‚åœºåŒ¹é…ï¼š
- en: Thatâ€™s not bad! Since it can already answer product questions, this looks like
    it will be useful for our Lenny Chatbot out of the box.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™è¿˜ä¸é”™ï¼å› ä¸ºå®ƒå·²ç»èƒ½å¤Ÿå›ç­”äº§å“é—®é¢˜ï¼Œæ‰€ä»¥çœ‹èµ·æ¥å®ƒå¯¹æˆ‘ä»¬çš„è±å°¼èŠå¤©æœºå™¨äººæ¥è¯´å°†ä¼šå¾ˆæœ‰ç”¨ã€‚
- en: You might assume that on the back end, GPT-3 has a compendium of concepts that
    itâ€™s using to understand your sentence and generate the right completion. But
    in reality, itâ€™s a probability engineâ€”one thatâ€™s very good at, given a prompt,
    finding the words that are most likely to follow it.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯èƒ½ä¼šè®¤ä¸ºï¼Œåœ¨åå°ï¼ŒGPT-3 æœ‰ä¸€ä¸ªæ¦‚å¿µæ‰‹å†Œï¼Œå®ƒç”¨æ¥ç†è§£ä½ çš„å¥å­å¹¶ç”Ÿæˆæ­£ç¡®çš„å®Œæˆã€‚ä½†å®é™…ä¸Šï¼Œå®ƒæ˜¯ä¸€ä¸ªæ¦‚ç‡å¼•æ“â€”â€”ä¸€ä¸ªéå¸¸æ“…é•¿çš„æ¦‚ç‡å¼•æ“ï¼Œåœ¨ç»™å®šæç¤ºçš„æƒ…å†µä¸‹ï¼Œæ‰¾åˆ°æœ€æœ‰å¯èƒ½è·Ÿéšå®ƒçš„è¯è¯­ã€‚
- en: It can do this because itâ€™s been [trained by analyzing](https://en.wikipedia.org/wiki/GPT-3#Training_and_capabilities)
    the statistical probabilities of sentences from basically the entire internet,
    so it has a lot of data to learn from. (All those Medium posts about product-market
    fit are good for something!)
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒä¹‹æ‰€ä»¥èƒ½åšåˆ°è¿™ä¸€ç‚¹ï¼Œæ˜¯å› ä¸ºå®ƒé€šè¿‡åˆ†ææ•´ä¸ªäº’è”ç½‘ä¸Šçš„å¥å­çš„ç»Ÿè®¡æ¦‚ç‡æ¥è¿›è¡Œè®­ç»ƒï¼Œæ‰€ä»¥å®ƒæœ‰å¾ˆå¤šæ•°æ®å¯ä»¥å­¦ä¹ ã€‚ï¼ˆæ‰€æœ‰å…³äºäº§å“å¸‚åœºåŒ¹é…çš„ Medium æ–‡ç« éƒ½æ˜¯æœ‰ç”¨çš„ï¼ï¼‰
- en: If you want to learn more about how this works from a technical perspective,
    I recommend checking out Andrej Karpathyâ€™s [videos](https://www.youtube.com/@AndrejKarpathy).
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ æƒ³ä»æŠ€æœ¯è§’åº¦äº†è§£æ›´å¤šå…³äºè¿™ä¸ªå·¥ä½œåŸç†çš„ä¿¡æ¯ï¼Œæˆ‘å»ºè®®æŸ¥çœ‹å®‰å¾·çƒˆÂ·å¡å°”å¸•è¥¿çš„ [è§†é¢‘](https://www.youtube.com/@AndrejKarpathy)ã€‚
- en: Turning GPT-3 into a chatbot
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å°† GPT-3 è½¬å˜æˆèŠå¤©
- en: Now we have the bot answering questions, but how can we get it to actually chat
    with us?
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬è®©æœºå™¨äººå›ç­”é—®é¢˜äº†ï¼Œä½†æ˜¯æˆ‘ä»¬å¦‚ä½•è®©å®ƒçœŸæ­£ä¸æˆ‘ä»¬äº¤æµå‘¢ï¼Ÿ
- en: Ideally we want it to get messages from the user and give responses back. And
    we want to give it a little bit of personality. It would be great if it sounded
    like Lenny himselfâ€”warm, friendly, and smart.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: ç†æƒ³æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¸Œæœ›å®ƒèƒ½æ¥æ”¶ç”¨æˆ·çš„æ¶ˆæ¯å¹¶åšå‡ºå›åº”ã€‚æˆ‘ä»¬è¿˜å¸Œæœ›ç»™å®ƒä¸€ç‚¹ä¸ªæ€§ã€‚å¦‚æœå®ƒå¬èµ·æ¥åƒè±å°¼æœ¬äººä¸€æ ·â€”â€”æ¸©æš–ã€å‹å¥½å’Œèªæ˜ï¼Œé‚£å°±å¤ªæ£’äº†ã€‚
- en: 'Thatâ€™s pretty simple to do with GPT-3 as well. We can ask it to behave in this
    way in our prompt:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ GPT-3 åšåˆ°è¿™ä¸€ç‚¹ä¹Ÿç›¸å½“ç®€å•ã€‚æˆ‘ä»¬å¯ä»¥åœ¨æç¤ºä¸­è¦æ±‚å®ƒä»¥è¿™ç§æ–¹å¼è¡Œäº‹ï¼š
- en: As you can see, GPT-3 has read enough chatbot transcripts and product management
    posts to be able to start a conversation with us based on this kind of prompt.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: æ­£å¦‚ä½ æ‰€è§ï¼ŒGPT-3 å·²ç»é˜…è¯»äº†è¶³å¤Ÿå¤šçš„èŠå¤©æœºå™¨äººå¯¹è¯å’Œäº§å“ç®¡ç†æ–‡ç« ï¼Œä»¥ä¾¿æ ¹æ®è¿™ç§ç±»å‹çš„æç¤ºå¼€å§‹ä¸æˆ‘ä»¬å¯¹è¯ã€‚
- en: 'We can continue our conversation with it by writing more of the transcript:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥é€šè¿‡å†™æ›´å¤šçš„è®°å½•æ¥ç»§ç»­ä¸å®ƒå¯¹è¯ï¼š
- en: 'Notice what weâ€™re doing: every time we run the model, we have to feed it the
    entire transcript of what came before in the conversation. That guides its responses:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„æˆ‘ä»¬æ­£åœ¨åšä»€ä¹ˆï¼šæ¯æ¬¡è¿è¡Œæ¨¡å‹æ—¶ï¼Œæˆ‘ä»¬éƒ½å¿…é¡»å‘å…¶æä¾›å…ˆå‰å¯¹è¯ä¸­çš„æ•´ä¸ªè®°å½•ã€‚è¿™æŒ‡å¯¼äº†å®ƒçš„å›å¤ï¼š
- en: Success! Itâ€™s chatting with us at a high level about product management questions,
    like how to build a roadmap.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: æˆåŠŸï¼å®ƒæ­£åœ¨ä¸æˆ‘ä»¬å°±äº§å“ç®¡ç†ç­‰é—®é¢˜è¿›è¡Œé«˜æ°´å¹³çš„äº¤æµï¼Œæ¯”å¦‚å¦‚ä½•åˆ¶å®šè·¯çº¿å›¾ã€‚
- en: But what if we want to get responses to questions that are harder to answer?
    For example, one of the biggest values of Lennyâ€™s Newsletter is the amount of
    benchmark data he provides so that you can measure how well youâ€™re doing against
    the best in the business.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æ˜¯å¦‚æœæˆ‘ä»¬æƒ³è¦å›ç­”æ›´éš¾çš„é—®é¢˜å‘¢ï¼Ÿä¾‹å¦‚ï¼Œè±å°¼çš„æ–°é—»é€šè®¯çš„æœ€å¤§ä»·å€¼ä¹‹ä¸€æ˜¯ä»–æä¾›äº†å¤§é‡åŸºå‡†æ•°æ®ï¼Œè¿™æ ·ä½ å°±å¯ä»¥è¡¡é‡è‡ªå·±åœ¨ä¸šç•Œçš„è¡¨ç°å¦‚ä½•ã€‚
- en: If we go back through Lennyâ€™s archive, we find in his post about [activation
    rates](https://www.lennysnewsletter.com/p/what-is-a-good-activation-rate) that
    the average one across different kinds of products is about 34% and the median
    is 25%.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæˆ‘ä»¬å›é¡¾ä¸€ä¸‹ Lenny çš„å­˜æ¡£ï¼Œæˆ‘ä»¬ä¼šå‘ç°åœ¨ä»–å…³äº[æ¿€æ´»ç‡](https://www.lennysnewsletter.com/p/what-is-a-good-activation-rate)çš„æ–‡ç« ä¸­ï¼Œä¸åŒç±»å‹äº§å“çš„å¹³å‡æ¿€æ´»ç‡çº¦ä¸º
    34%ï¼Œä¸­ä½æ•°ä¸º 25%ã€‚
- en: 'Letâ€™s ask GPT-3 and see whether it knows this:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬é—®é—® GPT-3ï¼Œçœ‹çœ‹å®ƒæ˜¯å¦çŸ¥é“è¿™ä¸ªï¼š
- en: Not bad! Itâ€™s in the right ballpark, but its estimate for a good activation
    rate is a little lower than Lennyâ€™s data says is the average. Ideally, since itâ€™s
    a Lenny chatbot, we want it to return the benchmark he provides in his article.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸é”™ï¼å®ƒçš„ç­”æ¡ˆå·®ä¸å¤šï¼Œä½†æ˜¯å®ƒå¯¹è‰¯å¥½æ¿€æ´»ç‡çš„ä¼°è®¡ç•¥ä½äº Lenny æ•°æ®æ˜¾ç¤ºçš„å¹³å‡å€¼ã€‚ç†æƒ³æƒ…å†µä¸‹ï¼Œç”±äºå®ƒæ˜¯ Lenny çš„èŠå¤©æœºå™¨äººï¼Œæˆ‘ä»¬å¸Œæœ›å®ƒè¿”å›ä»–åœ¨æ–‡ç« ä¸­æä¾›çš„åŸºå‡†å€¼ã€‚
- en: 'Once we start really probing the bot, this kind of problem only gets bigger.
    For example, if we ask it who Substackâ€™s first publisher wasâ€”a [topic Lenny covered](https://www.lennysnewsletter.com/p/consumer-business-find-first-users)â€”it
    will say it was Andrew Sullivan:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€æ—¦æˆ‘ä»¬å¼€å§‹çœŸæ­£å®¡è§†è¿™ä¸ªæœºå™¨äººï¼Œè¿™ç§é—®é¢˜å°±ä¼šå˜å¾—æ›´åŠ ä¸¥é‡ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬é—®å®ƒ Substack çš„ç¬¬ä¸€ä¸ªå‡ºç‰ˆå•†æ˜¯è°â€”â€”Lenny åœ¨ä»–çš„æ–‡ç« ä¸­æåˆ°çš„ä¸€ä¸ª[è¯é¢˜](https://www.lennysnewsletter.com/p/consumer-business-find-first-users)â€”â€”å®ƒä¼šè¯´æ˜¯
    Andrew Sullivanï¼š
- en: 'This answer sounds confident, but it is incorrect. (The correct answer is [Bill
    Bishop](https://sinocism.com/).) This isnâ€™t an isolated incident. For example,
    if I ask, â€œIs it best for consumer startup ideas to come from founders who are
    trying to solve their own problems?â€ it replies:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªç­”æ¡ˆå¬èµ·æ¥å¾ˆè‡ªä¿¡ï¼Œä½†æ˜¯æ˜¯é”™è¯¯çš„ã€‚ï¼ˆæ­£ç¡®ç­”æ¡ˆæ˜¯ [Bill Bishop](https://sinocism.com/)ã€‚ï¼‰è¿™ä¸æ˜¯ä¸€ä¸ªå­¤ç«‹äº‹ä»¶ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘é—®ï¼šâ€œæ¶ˆè´¹è€…åˆåˆ›ä¼ä¸šçš„æœ€ä½³åˆ›æ„æ˜¯å¦åº”è¯¥æ¥è‡ªè¯•å›¾è§£å†³è‡ªå·±é—®é¢˜çš„åˆ›å§‹äººï¼Ÿâ€å®ƒå›ç­”é“ï¼š
- en: This is confidentâ€”and also wrong. As Lenny covered in his post on
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯è‡ªä¿¡çš„â€”â€”ä¹Ÿæ˜¯é”™è¯¯çš„ã€‚æ­£å¦‚ Lenny åœ¨ä»–çš„æ–‡ç« ä¸­æ‰€è¯´çš„é‚£æ ·
- en: '[starting and scaling consumer businesses](https://www.lennysnewsletter.com/p/kickstarting-and-scaling-a-consumer)'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '[å¯åŠ¨å’Œæ‰©å±•æ¶ˆè´¹å‹ä¼ä¸š](https://www.lennysnewsletter.com/p/kickstarting-and-scaling-a-consumer)'
- en: ', less than a third of consumer startup ideas came from founders solving their
    own problems. So itâ€™s not â€œabsolutelyâ€ a best practice.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: ï¼Œä¸åˆ°ä¸‰åˆ†ä¹‹ä¸€çš„æ¶ˆè´¹è€…åˆåˆ›ä¼ä¸šåˆ›æ„æ¥è‡ªè§£å†³è‡ªå·±é—®é¢˜çš„åˆ›å§‹äººã€‚æ‰€ä»¥è¿™ä¸æ˜¯â€œç»å¯¹â€æ˜¯æœ€ä½³å®è·µã€‚
- en: 'Whatâ€™s going on here? There are two intertwined problems:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: å‘ç”Ÿäº†ä»€ä¹ˆï¼Ÿæœ‰ä¸¤ä¸ªç›¸äº’äº¤ç»‡çš„é—®é¢˜ï¼š
- en: '**GPT-3 tends to â€œhallucinate.â€** [Hallucination](https://en.wikipedia.org/wiki/Hallucination_(artificial_intelligence))
    is a technical term that refers to the modelâ€™s propensity to return nonsensical
    or false completions depending on whatâ€™s asked of it. The model is like a smart
    and overeager 6-year-old. It will try its best to give you a good answer even
    if it doesnâ€™t know what itâ€™s talking about. OpenAI and other foundational-model
    companies are actively working on this problem, but itâ€™s still common. Itâ€™s compounded
    by the second problem.'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**GPT-3 å€¾å‘äºâ€œå¹»è§‰â€**ã€‚[å¹»è§‰](https://en.wikipedia.org/wiki/Hallucination_(artificial_intelligence))æ˜¯ä¸€ä¸ªæŠ€æœ¯æœ¯è¯­ï¼ŒæŒ‡çš„æ˜¯æ¨¡å‹å€¾å‘äºæ ¹æ®æ‰€è¯¢é—®çš„å†…å®¹è¿”å›è’è°¬æˆ–é”™è¯¯çš„è¡¥å…¨ã€‚è¯¥æ¨¡å‹å°±åƒä¸€ä¸ªèªæ˜è€Œçƒ­å¿ƒçš„å…­å²å­©å­ã€‚å³ä½¿å®ƒä¸çŸ¥é“è‡ªå·±åœ¨è¯´ä»€ä¹ˆï¼Œä¹Ÿä¼šå°½åŠ›ç»™å‡ºä¸€ä¸ªå¥½ç­”æ¡ˆã€‚OpenAI
    å’Œå…¶ä»–åŸºç¡€æ¨¡å‹å…¬å¸æ­£åœ¨ç§¯æè§£å†³è¿™ä¸ªé—®é¢˜ï¼Œä½†è¿™ä»ç„¶å¾ˆå¸¸è§ã€‚ç¬¬äºŒä¸ªé—®é¢˜åŠ å‰§äº†è¿™ä¸ªé—®é¢˜ã€‚'
- en: '**GPT-3 might not have the right data.** GPT-3 has a knowledge cutoffâ€”meaning
    all of the information it uses to produce its responses is frozen in 2021\. Also,
    much of Lennyâ€™s writing is behind a paywall. That means that even though GPT-3
    has read the whole internet, it wonâ€™t have the material from his newsletter available
    to construct answers.'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**GPT-3 å¯èƒ½æ²¡æœ‰æ­£ç¡®çš„æ•°æ®ã€‚** GPT-3 æœ‰ä¸€ä¸ªçŸ¥è¯†æˆªæ­¢ç‚¹â€”â€”è¿™æ„å‘³ç€å®ƒç”¨äºç”Ÿæˆå“åº”çš„æ‰€æœ‰ä¿¡æ¯éƒ½åœ¨ 2021 å¹´å†»ç»“ã€‚æ­¤å¤–ï¼ŒLenny çš„è®¸å¤šå†™ä½œéƒ½åœ¨ä»˜è´¹å¢™åé¢ã€‚è¿™æ„å‘³ç€å³ä½¿
    GPT-3 å·²ç»é˜…è¯»äº†æ•´ä¸ªäº’è”ç½‘ï¼Œå®ƒä¹Ÿæ— æ³•ä½¿ç”¨ä»–çš„æ–°é—»ç®€æŠ¥ææ–™æ¥æ„å»ºç­”æ¡ˆã€‚'
- en: So how could we construct a chatbot with GPT-3 that solves these problems? Ideally
    we want to feed GPT-3 the information it needs to answer questions spontaneously.
    That way it will have the right information available and be less likely to make
    things up.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: é‚£ä¹ˆæˆ‘ä»¬å¦‚ä½•æ„å»ºä¸€ä¸ªèƒ½è§£å†³è¿™äº›é—®é¢˜çš„ GPT-3 èŠå¤©æœºå™¨äººå‘¢ï¼Ÿç†æƒ³æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¸Œæœ›å‘ GPT-3 æä¾›å®ƒå›ç­”é—®é¢˜æ‰€éœ€çš„ä¿¡æ¯ã€‚è¿™æ ·å®ƒå°±ä¼šæœ‰æ­£ç¡®çš„ä¿¡æ¯å¯ç”¨ï¼Œå¹¶ä¸”æ›´ä¸å¯èƒ½èƒ¡è¨€ä¹±è¯­ã€‚
- en: Thereâ€™s an easy way to do that.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰ä¸€ä¸ªç®€å•çš„æ–¹æ³•å¯ä»¥åšåˆ°è¿™ä¸€ç‚¹ã€‚
- en: Stuffing context into the prompt
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å°†ä¸Šä¸‹æ–‡è£…å…¥æç¤º
- en: When I was in high school, I had a physics teacher who allowed open-book tests.
    He would allow you to bring a single index card to the test with any of the formulas
    that you thought you needed to answer the questions.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: å½“æˆ‘ä¸Šé«˜ä¸­çš„æ—¶å€™ï¼Œæœ‰ä¸€ä½ç‰©ç†è€å¸ˆå…è®¸å¼€å·è€ƒè¯•ã€‚ä»–å…è®¸ä½ å¸¦ä¸€å¼ ç´¢å¼•å¡å»è€ƒè¯•ï¼Œä¸Šé¢å†™ä¸Šä½ è®¤ä¸ºéœ€è¦å›ç­”é—®é¢˜æ‰€éœ€çš„ä»»ä½•å…¬å¼ã€‚
- en: Memorizing the formulas didnâ€™t matter so much, but what did was using your reasoning
    abilities to turn the formulas into the correct answer.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: è®°ä½å…¬å¼å¹¶ä¸é‡è¦ï¼Œé‡è¦çš„æ˜¯ä½¿ç”¨æ‚¨çš„æ¨ç†èƒ½åŠ›å°†å…¬å¼è½¬åŒ–ä¸ºæ­£ç¡®çš„ç­”æ¡ˆã€‚
- en: People would come to the test with microscopic handwriting covering every inch
    of their notecard, which was a helpful strategy. The formulas gave you the context
    you needed to think through the answers to the questions on the tests, so the
    tests became less about your memory and more about how well you understood the
    topic. (I got a B in that class, so my understanding was pretty average.)
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: äººä»¬ä¼šå¸¦ç€æ»¡æ»¡ä¸€é¡µå¾®å°å­—è¿¹æ¥å‚åŠ è€ƒè¯•ï¼Œè¿™æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„ç­–ç•¥ã€‚è¿™äº›å…¬å¼ä¸ºæ‚¨æä¾›äº†æ‚¨éœ€è¦æ€è€ƒæµ‹è¯•é—®é¢˜ç­”æ¡ˆçš„ä¸Šä¸‹æ–‡ï¼Œå› æ­¤æµ‹è¯•å˜å¾—ä¸å†æ˜¯å…³äºæ‚¨çš„è®°å¿†ï¼Œè€Œæ˜¯å…³äºæ‚¨å¯¹ä¸»é¢˜çš„ç†è§£æœ‰å¤šå¥½ã€‚ï¼ˆæˆ‘åœ¨é‚£é—¨è¯¾ä¸Šå¾—äº†
    Bï¼Œæ‰€ä»¥æˆ‘çš„ç†è§£è¿˜ç®—å¹³å‡ã€‚ï¼‰
- en: You can work with GPT-3 in a similar way. If, in your prompt, you include the
    equivalent of a notecard with context to help it answer the question, it will
    often get it right. (Its reasoning capabilities are better than mine.)
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨å¯ä»¥ä»¥ç±»ä¼¼çš„æ–¹å¼ä¸ GPT-3 åˆä½œã€‚å¦‚æœåœ¨æ‚¨çš„æç¤ºä¸­åŒ…å«ç­‰æ•ˆäºä¾¿æ¡çš„å†…å®¹ä»¥å¸®åŠ©å…¶å›ç­”é—®é¢˜ï¼Œå®ƒé€šå¸¸ä¼šå›ç­”æ­£ç¡®ã€‚ï¼ˆå®ƒçš„æ¨ç†èƒ½åŠ›æ¯”æˆ‘çš„å¥½ã€‚ï¼‰
- en: Letâ€™s go back to an example GPT-3 failed on earlier and see if we can correct
    it with this technique.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬å›åˆ°ä¹‹å‰ GPT-3 å¤±è´¥çš„ä¸€ä¸ªç¤ºä¾‹ï¼Œçœ‹çœ‹æˆ‘ä»¬æ˜¯å¦å¯ä»¥ç”¨è¿™ç§æŠ€æœ¯çº æ­£å®ƒã€‚
- en: 'As I mentioned above, in his post on consumer businesses, Lenny notes that
    less than a third of the founders got their idea from trying to solve their own
    problem:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: æ­£å¦‚æˆ‘ä¸Šé¢æåˆ°çš„ï¼Œåœ¨ä»–å…³äºæ¶ˆè´¹å‹ä¼ä¸šçš„å¸–å­ä¸­ï¼ŒLenny æŒ‡å‡ºä¸åˆ°ä¸‰åˆ†ä¹‹ä¸€çš„åˆ›å§‹äººä»å°è¯•è§£å†³è‡ªå·±çš„é—®é¢˜ä¸­è·å¾—äº†æƒ³æ³•ï¼š
- en: Last time, when we asked GPT-3 if it was best for consumer business founders
    to try to solve their own problem, it responded, â€œAbsolutely!â€ Given whatâ€™s in
    Lennyâ€™s article, thatâ€™s wrong.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸Šæ¬¡ï¼Œå½“æˆ‘ä»¬é—® GPT-3 æ¶ˆè´¹å‹ä¼ä¸šåˆ›å§‹äººæ˜¯å¦æœ€å¥½å°è¯•è§£å†³è‡ªå·±çš„é—®é¢˜æ—¶ï¼Œå®ƒå›ç­”è¯´ï¼šâ€œç»å¯¹æ˜¯ï¼â€è€ƒè™‘åˆ° Lenny çš„æ–‡ç« å†…å®¹ï¼Œè¿™æ˜¯é”™è¯¯çš„ã€‚
- en: Letâ€™s ask GPT-3 this question againâ€”but with a little help. Weâ€™ll feed it the
    equivalent of a notecard that has written on it the section of Lennyâ€™s article
    with the answer. Then weâ€™ll see if it can get it right.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬å†æ¬¡å‘ GPT-3 æå‡ºè¿™ä¸ªé—®é¢˜â€”â€”ä½†ç¨å¾®å¸®åŠ©ä¸€ä¸‹ã€‚æˆ‘ä»¬å°†å‘å…¶æä¾›ç›¸å½“äºä¸€å¼ ä¾¿æ¡çš„å†…å®¹ï¼Œä¸Šé¢å†™ç€ Lenny æ–‡ç« ä¸­å«æœ‰ç­”æ¡ˆçš„éƒ¨åˆ†ã€‚ç„¶åæˆ‘ä»¬çœ‹çœ‹å®ƒæ˜¯å¦èƒ½å›ç­”æ­£ç¡®ã€‚
- en: 'To make this fair, we wonâ€™t give it just the text containing the answer. Weâ€™ll
    give it some of the surrounding text in the article as well to see how it does.
    Letâ€™s see if it works:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†å…¬å¹³èµ·è§ï¼Œæˆ‘ä»¬ä¸åªæ˜¯æä¾›åŒ…å«ç­”æ¡ˆçš„æ–‡æœ¬ã€‚æˆ‘ä»¬è¿˜ä¼šæä¾›æ–‡ç« ä¸­çš„ä¸€äº›å‘¨å›´æ–‡æœ¬ï¼Œä»¥æŸ¥çœ‹å®ƒçš„è¡¨ç°å¦‚ä½•ã€‚è®©æˆ‘ä»¬çœ‹çœ‹å®ƒæ˜¯å¦æœ‰æ•ˆï¼š
- en: Success! Now it tells us that less than a third of founders were trying to solve
    their own problem. All we have to do is write all of Lennyâ€™s posts on a notecard
    and feed it into the model along with any question we have, and it will answer
    based on what heâ€™s written.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: æˆåŠŸï¼ç°åœ¨å®ƒå‘Šè¯‰æˆ‘ä»¬ï¼Œä¸åˆ°ä¸‰åˆ†ä¹‹ä¸€çš„åˆ›å§‹äººè¯•å›¾è§£å†³è‡ªå·±çš„é—®é¢˜ã€‚æˆ‘ä»¬åªéœ€æŠŠ Lenny çš„æ‰€æœ‰æ–‡ç« å†™åœ¨ä¸€å¼ ä¾¿æ¡ä¸Šï¼Œä¸ä»»ä½•é—®é¢˜ä¸€èµ·è¾“å…¥æ¨¡å‹ï¼Œå®ƒå°±ä¼šæ ¹æ®ä»–æ‰€å†™çš„å†…å®¹å›ç­”ã€‚
- en: 'But this introduces another problem: space limitations.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†è¿™å¸¦æ¥äº†å¦ä¸€ä¸ªé—®é¢˜ï¼šç©ºé—´é™åˆ¶ã€‚
- en: The notecard analogy is apt because thereâ€™s limited space in the promptâ€”right
    now, about 4,000 tokens (each token is the equivalent of three-quarters of a word).
    So we canâ€™t feed in Lennyâ€™s entire archive on every question. We have to be choosy
    about what we select.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾¿æ¡çš„ç±»æ¯”å¾ˆè´´åˆ‡ï¼Œå› ä¸ºæç¤ºä¸­çš„ç©ºé—´æœ‰é™â€”â€”ç›®å‰çº¦ä¸º 4,000 ä¸ªæ ‡è®°ï¼ˆæ¯ä¸ªæ ‡è®°ç›¸å½“äºä¸‰åˆ†ä¹‹å››ä¸ªå•è¯ï¼‰ã€‚å› æ­¤ï¼Œæˆ‘ä»¬ä¸èƒ½åœ¨æ¯ä¸ªé—®é¢˜ä¸Šéƒ½æä¾› Lenny çš„æ•´ä¸ªå­˜æ¡£ã€‚æˆ‘ä»¬å¿…é¡»è°¨æ…é€‰æ‹©ã€‚
- en: Letâ€™s talk about how to solve this.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬è°ˆè°ˆå¦‚ä½•è§£å†³è¿™ä¸ªé—®é¢˜ã€‚
- en: Embedding Lennyâ€™s archive
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: åµŒå…¥ Lenny çš„å­˜æ¡£
- en: 'At this point weâ€™re going to have to move out of manual interactions with GPT-3â€™s
    Playground and start using chunks of code that work directly with the GPT-3 API.
    The code weâ€™re building is going to do the following tasks:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬å°†ä¸å¾—ä¸é€€å‡ºä¸ GPT-3 Playground çš„æ‰‹åŠ¨äº¤äº’ï¼Œå¼€å§‹ä½¿ç”¨ç›´æ¥ä¸ GPT-3 API ä¸€èµ·å·¥ä½œçš„ä»£ç å—ã€‚æˆ‘ä»¬æ­£åœ¨æ„å»ºçš„ä»£ç å°†æ‰§è¡Œä»¥ä¸‹ä»»åŠ¡ï¼š
- en: We need to download and store Lennyâ€™s archive in a way that makes it easily
    searchable for our bot.
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬éœ€è¦ä»¥ä¸€ç§ä¾¿äºæˆ‘ä»¬çš„æœºå™¨äººè¿›è¡Œè½»æ¾æœç´¢çš„æ–¹å¼ä¸‹è½½å’Œå­˜å‚¨ Lenny çš„å­˜æ¡£ã€‚
- en: We need some code that will help find relevant chunks of text from the archive
    of Lennyâ€™s content that we created in the previous step.
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬éœ€è¦ä¸€äº›ä»£ç æ¥å¸®åŠ©ä»æˆ‘ä»¬åœ¨ä¸Šä¸€æ­¥åˆ›å»ºçš„ Lenny å†…å®¹çš„å­˜æ¡£ä¸­æ‰¾åˆ°ç›¸å…³æ–‡æœ¬ç‰‡æ®µã€‚
- en: When a user asks a question, we want to use the code from the last step to get
    the chunks of text that are most likely to answer the question, and put them into
    the prompt that we send to GPT-3.
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å½“ç”¨æˆ·æé—®æ—¶ï¼Œæˆ‘ä»¬å¸Œæœ›ä½¿ç”¨ä¸Šä¸€æ­¥çš„ä»£ç æ¥è·å–æœ€æœ‰å¯èƒ½å›ç­”é—®é¢˜çš„æ–‡æœ¬ç‰‡æ®µï¼Œå¹¶å°†å®ƒä»¬æ”¾å…¥æˆ‘ä»¬å‘é€ç»™ GPT-3 çš„æç¤ºä¸­ã€‚
- en: Weâ€™ll display the resulting answer to the user.
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†å‘ç”¨æˆ·æ˜¾ç¤ºç”Ÿæˆçš„ç­”æ¡ˆã€‚
- en: 'This is simple to do with a library called [GPT Index](https://gpt-index.readthedocs.io/en/latest/),
    an open-source library created by [Jerry Liu](https://twitter.com/jerryjliu0).
    Itâ€™s separate from OpenAI but built to help with tasks like this. Hereâ€™s how it
    works:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å¯ä»¥é€šè¿‡ä¸€ä¸ªåä¸º[GPT Index](https://gpt-index.readthedocs.io/en/latest/)çš„åº“æ¥å®Œæˆï¼Œè¿™æ˜¯ä¸€ä¸ªç”±[Jerry
    Liu](https://twitter.com/jerryjliu0)åˆ›å»ºçš„å¼€æºåº“ã€‚å®ƒä¸ OpenAI åˆ†å¼€ï¼Œä½†æ˜¯æ„å»ºå®ƒä»¥å¸®åŠ©å®Œæˆè¿™æ ·çš„ä»»åŠ¡ã€‚å®ƒçš„å·¥ä½œåŸç†å¦‚ä¸‹ï¼š
- en: Create an index of article chunks.
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åˆ›å»ºä¸€ç»„æ–‡ç« ç‰‡æ®µçš„ç´¢å¼•ã€‚
- en: Find the most relevant chunks.
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ‰¾åˆ°æœ€ç›¸å…³çš„ç‰‡æ®µã€‚
- en: Ask our question to GPT-3 using the most relevant chunk.
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨æœ€ç›¸å…³çš„ç‰‡æ®µå‘ GPT-3 æé—®ã€‚
- en: '*Note:* This is about to get a little bit more complicated and technical. If
    youâ€™re interested in that, read on for an explanation.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '*æ³¨æ„ï¼š* è¿™å°†å˜å¾—æœ‰ç‚¹å¤æ‚å’ŒæŠ€æœ¯æ€§ã€‚å¦‚æœä½ å¯¹æ­¤æ„Ÿå…´è¶£ï¼Œè¯·ç»§ç»­é˜…è¯»è§£é‡Šã€‚'
- en: You can access and run the code from this article in a [Google Colab file](https://colab.research.google.com/drive/1p2AablavDkSXly6H-XNLoSylMtoz7NDG?usp=sharing).
    Colab is a cloud-based programming environment that will let you run everything
    from your browser. (If you have questions about any of this, reach out to me on
    [Twitter](https://www.twitter.com/danshipper).)
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨å¯ä»¥åœ¨[Google Colab æ–‡ä»¶](https://colab.research.google.com/drive/1p2AablavDkSXly6H-XNLoSylMtoz7NDG?usp=sharing)ä¸­è®¿é—®å¹¶è¿è¡Œæœ¬æ–‡ä¸­çš„ä»£ç ã€‚Colab
    æ˜¯ä¸€ä¸ªåŸºäºäº‘çš„ç¼–ç¨‹ç¯å¢ƒï¼Œè®©æ‚¨å¯ä»¥ä»æµè§ˆå™¨ä¸­è¿è¡Œæ‰€æœ‰å†…å®¹ã€‚ï¼ˆå¦‚æœæ‚¨å¯¹æ­¤æœ‰ä»»ä½•ç–‘é—®ï¼Œè¯·åœ¨[Twitter](https://www.twitter.com/danshipper)ä¸Šè”ç³»æˆ‘ã€‚ï¼‰
- en: If youâ€™re not interested in the technical details, skip to the end to try out
    the chatbot for yourself.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ‚¨å¯¹æŠ€æœ¯ç»†èŠ‚ä¸æ„Ÿå…´è¶£ï¼Œè¯·è·³åˆ°æœ€åå°è¯•èŠå¤©æœºå™¨äººã€‚
- en: Still here? Great. Letâ€™s start with index construction.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: ä»ç„¶åœ¨è¿™é‡Œå—ï¼Ÿå¤ªå¥½äº†ã€‚è®©æˆ‘ä»¬ä»æ„å»ºç´¢å¼•å¼€å§‹ã€‚
- en: Constructing our index
  id: totrans-110
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: æ„å»ºæˆ‘ä»¬çš„ç´¢å¼•
- en: 'The first thing we need to do is construct our index. You can think of an index
    as a database: it stores a collection of pieces of text in a way that makes them
    easily searchable.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬éœ€è¦åšçš„ç¬¬ä¸€ä»¶äº‹æ˜¯æ„å»ºæˆ‘ä»¬çš„ç´¢å¼•ã€‚ä½ å¯ä»¥æŠŠç´¢å¼•æƒ³è±¡æˆä¸€ä¸ªæ•°æ®åº“ï¼šå®ƒä»¥ä¸€ç§ä½¿å®ƒä»¬æ˜“äºæœç´¢çš„æ–¹å¼å­˜å‚¨ä¸€ç³»åˆ—æ–‡æœ¬ç‰‡æ®µã€‚
- en: First we collect Lennyâ€™s newsletter archive into a folder. Then we ask GPT Index
    to take all of the files in the folder and break each one into small, sequential
    pieces. Then we store those pieces in a searchable format.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼Œæˆ‘ä»¬å°† Lenny çš„æ–°é—»é€šè®¯å­˜æ¡£æ”¶é›†åˆ°ä¸€ä¸ªæ–‡ä»¶å¤¹ä¸­ã€‚ç„¶åæˆ‘ä»¬è¦æ±‚ GPT Index è·å–æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰æ–‡ä»¶ï¼Œå¹¶å°†æ¯ä¸ªæ–‡ä»¶åˆ†è§£æˆå°çš„ã€è¿ç»­çš„ç‰‡æ®µã€‚ç„¶åæˆ‘ä»¬ä»¥å¯æœç´¢çš„æ ¼å¼å­˜å‚¨è¿™äº›ç‰‡æ®µã€‚
- en: 'The code looks like this:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: ä»£ç çœ‹èµ·æ¥åƒè¿™æ ·ï¼š
- en: When we run this function, weâ€™ll have created a file called index.json that
    contains chunks of Lennyâ€™s articles converted into a searchable format. These
    are called
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: å½“æˆ‘ä»¬è¿è¡Œè¿™ä¸ªå‡½æ•°æ—¶ï¼Œæˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ªåä¸º index.json çš„æ–‡ä»¶ï¼Œå…¶ä¸­åŒ…å«å°† Lenny çš„æ–‡ç« è½¬æ¢ä¸ºå¯æœç´¢æ ¼å¼çš„ç‰‡æ®µã€‚è¿™äº›è¢«ç§°ä¸º
- en: '[embeddings](https://platform.openai.com/docs/guides/embeddings)'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '[åµŒå…¥](https://platform.openai.com/docs/guides/embeddings)'
- en: â€”a condensed mathematical representation of each chunk of text.Â Just like latitude
    and longitude can help you tell how close two cities are on a map, embeddings
    do the same kind of thing for text chunks. If you want to know if two pieces of
    text are similar, calculate the embeddings for them and compare. Text chunks with
    embeddings that are â€œcloserâ€ together are similar.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: â€”æ¯ä¸ªæ–‡æœ¬ç‰‡æ®µçš„ç®€åŒ–æ•°å­¦è¡¨ç¤ºã€‚å°±åƒç»åº¦å’Œçº¬åº¦å¯ä»¥å¸®åŠ©æ‚¨åˆ¤æ–­åœ°å›¾ä¸Šä¸¤ä¸ªåŸå¸‚ä¹‹é—´æœ‰å¤šè¿‘ä¸€æ ·ï¼ŒåµŒå…¥ä¹Ÿå¯ä»¥ä¸ºæ–‡æœ¬ç‰‡æ®µåšåŒæ ·çš„äº‹æƒ…ã€‚å¦‚æœä½ æƒ³çŸ¥é“ä¸¤ä¸ªæ–‡æœ¬ç‰‡æ®µæ˜¯å¦ç›¸ä¼¼ï¼Œå°±è®¡ç®—å®ƒä»¬çš„åµŒå…¥å¹¶è¿›è¡Œæ¯”è¾ƒã€‚åµŒå…¥â€œæ›´æ¥è¿‘â€çš„æ–‡æœ¬ç‰‡æ®µæ˜¯ç›¸ä¼¼çš„ã€‚
- en: Embeddings are handy because when a user asks a question, theyâ€™ll make it easy
    to search Lennyâ€™s archive and find articles that are most likely to answer our
    question.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: åµŒå…¥å¾ˆæ–¹ä¾¿ï¼Œå› ä¸ºå½“ç”¨æˆ·æé—®æ—¶ï¼Œå®ƒä»¬å°†ä½¿æœç´¢ Lenny çš„å­˜æ¡£å¹¶æ‰¾åˆ°æœ€æœ‰å¯èƒ½å›ç­”æˆ‘ä»¬é—®é¢˜çš„æ–‡ç« å˜å¾—å®¹æ˜“ã€‚
- en: With that in mind, letâ€™s run the code and see what happens.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰äº†è¿™ä¸ªæƒ³æ³•ï¼Œè®©æˆ‘ä»¬è¿è¡Œä»£ç ï¼Œçœ‹çœ‹ä¼šå‘ç”Ÿä»€ä¹ˆã€‚
- en: Success! The Lennyâ€™s archive is fully indexed, and we can query it to find relevant
    chunks of documents and use those chunks to answer our questions. (Be careful
    if you do this with big documents, as embeddings cost $0.0004 for every 1,000
    tokens.)Asking our question
  id: totrans-119
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: æˆåŠŸï¼ Lenny çš„å­˜æ¡£å·²å®Œå…¨ç´¢å¼•ï¼Œæˆ‘ä»¬å¯ä»¥æŸ¥è¯¢å®ƒä»¥æ‰¾åˆ°ç›¸å…³çš„æ–‡æ¡£ç‰‡æ®µï¼Œå¹¶ä½¿ç”¨è¿™äº›ç‰‡æ®µå›ç­”æˆ‘ä»¬çš„é—®é¢˜ã€‚ï¼ˆå¦‚æœæ‚¨ç”¨å¤§æ–‡æ¡£åšè¿™ä¸ªï¼Œè¦å°å¿ƒï¼Œå› ä¸ºæ¯ 1,000
    ä¸ªæ ‡è®°çš„åµŒå…¥æˆæœ¬æ˜¯ 0.0004 ç¾å…ƒã€‚ï¼‰é—®æˆ‘ä»¬çš„é—®é¢˜
- en: 'To query the index we created in the last section, all we have to do is paste
    a question into GPT Index. It will then:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: è¦æŸ¥è¯¢æˆ‘ä»¬åœ¨ä¸Šä¸€èŠ‚ä¸­åˆ›å»ºçš„ç´¢å¼•ï¼Œæˆ‘ä»¬æ‰€è¦åšçš„å°±æ˜¯å°†ä¸€ä¸ªé—®é¢˜ç²˜è´´åˆ° GPT Index ä¸­ã€‚ç„¶åå®ƒå°†ï¼š
- en: Find the chunks of our index that are most relevant to the question.
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ‰¾åˆ°ä¸æˆ‘ä»¬é—®é¢˜æœ€ç›¸å…³çš„ç´¢å¼•ç‰‡æ®µã€‚
- en: Combine those chunks and our question into a prompt that it sends to GPT-3.
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å°†è¿™äº›ç‰‡æ®µå’Œæˆ‘ä»¬çš„é—®é¢˜åˆå¹¶æˆä¸€ä¸ªæç¤ºï¼Œç„¶åå‘é€ç»™ GPT-3ã€‚
- en: Print the output.
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ‰“å°è¾“å‡ºã€‚
- en: 'Hereâ€™s what the code looks like:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ä»£ç çš„æ ·å­ï¼š
- en: 'If I ask it, â€œWhat is good retention for a consumer social product?â€ it says:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæˆ‘é—®å®ƒï¼Œâ€œæ¶ˆè´¹è€…ç¤¾äº¤äº§å“çš„è‰¯å¥½ç•™å­˜ç‡æ˜¯å¤šå°‘ï¼Ÿâ€å®ƒä¼šè¯´ï¼š
- en: â€œ25% is good.â€
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: â€œ25% æ˜¯å¥½çš„ã€‚â€
- en: 'If I query it, â€œIs it best for consumer startup ideas to come from founders
    who are trying to solve their own problem?â€ it returns the right answer:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæˆ‘æŸ¥è¯¢ï¼šâ€œæ¶ˆè´¹è€…åˆåˆ›å…¬å¸çš„æœ€ä½³åˆ›æ„æ˜¯æ¥è‡ªè¯•å›¾è§£å†³è‡ªå·±é—®é¢˜çš„åˆ›å§‹äººå—ï¼Ÿâ€å®ƒä¼šè¿”å›æ­£ç¡®çš„ç­”æ¡ˆï¼š
- en: '*â€œBased on the research, it appears that it is a good idea for consumer startup
    ideas to come from founders who are trying to solve their own problem, as this
    was the strategy used by around 30% of the most successful consumer companies.Â *'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '*â€œæ ¹æ®ç ”ç©¶ï¼Œä¼¼ä¹æ¶ˆè´¹è€…åˆåˆ›å…¬å¸çš„æœ€ä½³åˆ›æ„æ¥è‡ªè¯•å›¾è§£å†³è‡ªå·±é—®é¢˜çš„åˆ›å§‹äººï¼Œå› ä¸ºè¿™æ˜¯çº¦ 30% æœ€æˆåŠŸçš„æ¶ˆè´¹è€…å…¬å¸ä½¿ç”¨çš„ç­–ç•¥ã€‚â€*'
- en: '*However, it is not necessarily the best strategy, as other strategies such
    as paying attention to curiosity, whatâ€™s already working, and paradigm shifts
    were also used by a significant number of successful companies.â€*'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '*ç„¶è€Œï¼Œå¹¶éä¸€å®šæ˜¯æœ€ä½³ç­–ç•¥ï¼Œå› ä¸ºå…¶ä»–ç­–ç•¥ï¼Œå¦‚å…³æ³¨å¥½å¥‡å¿ƒã€å·²ç»å¥æ•ˆçš„äº‹ç‰©å’ŒèŒƒå¼è½¬å˜ï¼Œä¹Ÿè¢«è®¸å¤šæˆåŠŸå…¬å¸é‡‡ç”¨è¿‡ã€‚â€*'
- en: We now have an end-to-end solution to turn questions into answers that are based
    on Lennyâ€™s archive. And it only took a few lines of code!
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ç°åœ¨æœ‰äº†ä¸€ä¸ªç«¯åˆ°ç«¯çš„è§£å†³æ–¹æ¡ˆï¼Œå¯ä»¥å°†é—®é¢˜è½¬åŒ–ä¸ºåŸºäº Lenny å­˜æ¡£çš„ç­”æ¡ˆã€‚è€Œä¸”è¿™åªéœ€è¦å‡ è¡Œä»£ç ï¼
- en: 'If you want to see the results in action, check out the bot:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ‚¨æƒ³çœ‹åˆ°ç»“æœï¼Œå¯ä»¥æŸ¥çœ‹è¿™ä¸ªæœºå™¨äººï¼š
- en: You can also access the
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨è¿˜å¯ä»¥è®¿é—®
- en: '[full source code](https://colab.research.google.com/drive/1p2AablavDkSXly6H-XNLoSylMtoz7NDG#scrollTo=4gHdfdtsSGEW)'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '[å®Œæ•´æºä»£ç ](https://colab.research.google.com/drive/1p2AablavDkSXly6H-XNLoSylMtoz7NDG#scrollTo=4gHdfdtsSGEW)'
- en: for this article in this Colab notebook. More details exclusively for Every
    subscribers are at the bottom of this post.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†è¿™ç¯‡æ–‡ç« åœ¨æ­¤ Colab ç¬”è®°æœ¬ä¸­ã€‚æ›´å¤šçš„ç»†èŠ‚ä¸“é—¨ä¸ºæ¯ä½è®¢é˜…è€…åœ¨æœ¬æ–‡çš„åº•éƒ¨ã€‚
- en: What all of this means
  id: totrans-135
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ‰€æœ‰è¿™ä¸€åˆ‡æ„å‘³ç€ä»€ä¹ˆ
- en: This is just the beginning. The horizon of possibility is shifting almost every
    day with these technologies. Whatâ€™s hard to do today will be easy in a matter
    of months.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™åªæ˜¯ä¸€ä¸ªå¼€å§‹ã€‚éšç€è¿™äº›æŠ€æœ¯çš„å‘å±•ï¼Œå¯èƒ½æ€§çš„åœ°å¹³çº¿å‡ ä¹æ¯å¤©éƒ½åœ¨å˜åŒ–ã€‚ä»Šå¤©éš¾ä»¥å®ç°çš„äº‹æƒ…å°†åœ¨å‡ ä¸ªæœˆå†…å˜å¾—å®¹æ˜“ã€‚
- en: Every newsletter, book, blog, and podcast thatâ€™s used as evergreen reference
    information by its audience can now be repackaged as a chatbot.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: æ¯ä¸ªæ–°é—»é€šè®¯ã€ä¹¦ç±ã€åšå®¢å’Œæ’­å®¢ï¼Œä½œä¸ºå—ä¼—æ°¸ä¹…å‚è€ƒä¿¡æ¯ä½¿ç”¨ï¼Œç°åœ¨éƒ½å¯ä»¥é‡æ–°æ‰“åŒ…æˆä¸€ä¸ªèŠå¤©æœºå™¨äººã€‚
- en: This is great for audiences because it means that any time you want to know
    what Lenny (or any other creator) says about a topic, youâ€™re not going to have
    to sort through an archive of articles or podcast episodes in order to get their
    answer to your question. Instead, youâ€™ll just be able to use Lennyâ€™s chatbot to
    get his answer instantlyâ€”and then maybe later read the article in full if you
    want more details.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å¯¹è§‚ä¼—æ¥è¯´æ˜¯å¾ˆæ£’çš„ï¼Œå› ä¸ºè¿™æ„å‘³ç€æ— è®ºä½•æ—¶æ‚¨æƒ³çŸ¥é“ Lennyï¼ˆæˆ–ä»»ä½•å…¶ä»–åˆ›ä½œè€…ï¼‰å¯¹æŸä¸ªè¯é¢˜çš„çœ‹æ³•ï¼Œæ‚¨éƒ½ä¸å¿…æ•´ç†ä¸€å †æ–‡ç« æˆ–æ’­å®¢é›†æ•°çš„å­˜æ¡£ï¼Œä»¥è·å–ä»–ä»¬å¯¹æ‚¨é—®é¢˜çš„ç­”æ¡ˆã€‚ç›¸åï¼Œæ‚¨åªéœ€ä½¿ç”¨
    Lenny çš„èŠå¤©æœºå™¨äººå³å¯ç«‹å³è·å¾—ä»–çš„ç­”æ¡ˆï¼Œç„¶åå¦‚æœæ‚¨æƒ³è¦æ›´å¤šç»†èŠ‚ï¼Œå¯ä»¥ç¨åé˜…è¯»å®Œæ•´æ–‡ç« ã€‚
- en: This is also great for content creators. They now get the ability to monetize
    the content theyâ€™ve already created in new ways, and lessen the amount of repetitive
    questions they have to answer. This will (hopefully) give them more time and money
    to create great content.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å¯¹å†…å®¹åˆ›ä½œè€…ä¹Ÿæ˜¯å¥½äº‹ã€‚ä»–ä»¬ç°åœ¨æœ‰èƒ½åŠ›ä»¥æ–°çš„æ–¹å¼å˜ç°ä»–ä»¬å·²ç»åˆ›ä½œçš„å†…å®¹ï¼Œå¹¶å‡å°‘ä»–ä»¬éœ€è¦å›ç­”çš„é‡å¤é—®é¢˜çš„æ•°é‡ã€‚è¿™å°†ï¼ˆå¸Œæœ›ï¼‰ç»™ä»–ä»¬æ›´å¤šçš„æ—¶é—´å’Œé‡‘é’±å»åˆ›é€ ä¼˜ç§€çš„å†…å®¹ã€‚
- en: A new class of content creators will learn to create compelling chatbot experiences
    that combine their personality and worldview for their niche audience in the same
    way that some creators learned to create compelling YouTube videos, newsletter
    articles, or TikTok clips.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ç±»æ–°çš„å†…å®¹åˆ›ä½œè€…å°†å­¦ä¼šåˆ›å»ºå¼•äººæ³¨ç›®çš„èŠå¤©æœºå™¨äººä½“éªŒï¼Œå°†å…¶ä¸ªæ€§å’Œä¸–ç•Œè§‚ä¸å…¶ç‰¹å®šå—ä¼—ç»“åˆèµ·æ¥ï¼Œå°±åƒæŸäº›åˆ›ä½œè€…å­¦ä¼šåˆ›å»ºå¼•äººæ³¨ç›®çš„ YouTube è§†é¢‘ã€é€šè®¯æ–‡ç« æˆ–
    TikTok çŸ­ç‰‡ä¸€æ ·ã€‚
- en: If you use Lennyâ€™s chatbot or follow the code samples, youâ€™ll see that itâ€™s
    promising but not yet perfect. There are tremendous returns available to the individuals
    or groups who learn to make these types of experiences incredible for users.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ‚¨ä½¿ç”¨ Lenny çš„èŠå¤©æœºå™¨äººæˆ–è€…å…³æ³¨ä»£ç ç¤ºä¾‹ï¼Œæ‚¨ä¼šå‘ç°å®ƒå¾ˆæœ‰å‰æ™¯ï¼Œä½†è¿˜ä¸å®Œç¾ã€‚å¯¹äºé‚£äº›å­¦ä¼šå¦‚ä½•è®©è¿™äº›ç±»å‹çš„ä½“éªŒå¯¹ç”¨æˆ·æ¥è¯´ä»¤äººéš¾ä»¥ç½®ä¿¡çš„ä¸ªäººæˆ–å›¢ä½“æ¥è¯´ï¼Œå°†è·å¾—å·¨å¤§çš„å›æŠ¥ã€‚
- en: I hope this inspires you to embark on that journey.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å¸Œæœ›è¿™èƒ½æ¿€åŠ±æ‚¨è¸ä¸Šè¿™æ®µæ—…ç¨‹ã€‚
- en: ''
  id: totrans-143
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '* * *'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: "\uFEFF\uFEFFMore details for Every subscribers"
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: "\uFEFF\uFEFFæ¯ä½è®¢é˜…è€…çš„æ›´å¤šç»†èŠ‚"
- en: 'In this section, Iâ€™ll give an update for Every paying subscribers on:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸€éƒ¨åˆ†ä¸­ï¼Œæˆ‘å°†ç»™æ¯ä½ä»˜è´¹è®¢é˜…è€…æ›´æ–°ä»¥ä¸‹å†…å®¹ï¼š
- en: How launch day went
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å‘å¸ƒæ—¥çš„æƒ…å†µ
- en: Server-side code samples
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æœåŠ¡å™¨ç«¯ä»£ç ç¤ºä¾‹
- en: Client-side code samples including React code and CSS
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åŒ…æ‹¬ React ä»£ç å’Œ CSS çš„å®¢æˆ·ç«¯ä»£ç ç¤ºä¾‹
- en: Letâ€™s dive in!
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬å¼€å§‹å§ï¼
- en: '[Learn more](/)'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '[äº†è§£æ›´å¤š](/)'
- en: This post is for
  id: totrans-152
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: è¿™ç¯‡æ–‡ç« æ˜¯
- en: paying subscribers
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: ä»˜è´¹è®¢é˜…è€…
- en: '[Subscribe â†’](/subscribe?publication=chain-of-thought)'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '[è®¢é˜… â†’](/subscribe?publication=chain-of-thought)'
- en: Or, [login](/login).
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ–è€…ï¼Œ[ç™»å½•](/login)ã€‚
