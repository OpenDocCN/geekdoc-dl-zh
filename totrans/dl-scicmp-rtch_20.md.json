["```r\n0,0,1,1,1,-1,0,-1,-1,1,1,1,-1,0\n1,1,1\n\n0,0,1,1,1,-1,0,-1,-1,1,1,1,-1,0\n   1,1,1\n\n0,0,1,1,1,-1,0,-1,-1,1,1,1,-1,0\n      1,1, 1\n```", "```r\n 0 0 0\n-1 1 0\n 0 0 0\n```", "```r\nlibrary(torch)\n\nconvnet <- nn_module(\n \"convnet\",\n\n initialize = function() {\n\n # nn_conv2d(in_channels, out_channels, kernel_size)\n self$conv1 <- nn_conv2d(1, 16, 3)\n self$conv2 <- nn_conv2d(16, 32, 3)\n self$conv3 <- nn_conv2d(32, 64, 3)\n\n self$output <- nn_linear(2304, 3)\n\n },\n\n forward = function(x) {\n\n x %>% \n self$conv1() %>% \n nnf_relu() %>%\n nnf_max_pool2d(2) %>%\n self$conv2() %>% \n nnf_relu() %>%\n nnf_max_pool2d(2) %>%\n self$conv3() %>% \n nnf_relu() %>%\n nnf_max_pool2d(2) %>%\n torch_flatten(start_dim = 2) %>%\n self$output()\n\n }\n)\n\nmodel <- convnet()\n```", "```r\nimg <- torch_randn(1, 1, 64, 64)\n```", "```r\nmodel(img)\n```", "```r\ntorch_tensor\n0.01 *\n 6.4821  3.4166 -5.6050\n[ CPUFloatType{1,3} ][ grad_fn = <AddmmBackward0> ]\n```", "```r\nself$output <- nn_linear(2304, 3)\n```", "```r\nlibrary(torch)\nlibrary(torchvision)\nlibrary(luz)\n```", "```r\nset.seed(777)\ntorch_manual_seed(777)\n\ndir <- \"~/.torch-datasets\"\n\ntrain_ds <- tiny_imagenet_dataset(\n dir,\n download = TRUE,\n transform = function(x) {\n x %>%\n transform_to_tensor() \n }\n)\n\nvalid_ds <- tiny_imagenet_dataset(\n dir,\n split = \"val\",\n transform = function(x) {\n x %>%\n transform_to_tensor()\n }\n)\n```", "```r\ntrain_dl <- dataloader(train_ds,\n batch_size = 128,\n shuffle = TRUE\n)\nvalid_dl <- dataloader(valid_ds, batch_size = 128)\n```", "```r\nbatch <- train_dl %>%\n dataloader_make_iter() %>%\n dataloader_next()\n\ndim(batch$x)\n```", "```r\n[1] 128   3  64  64\n```", "```r\nbatch$y\n```", "```r\ntorch_tensor\n 172\n  17\n  76\n  78\n 111\n  57\n   8\n 166\n 146\n 114\n  41\n  28\n 138\n  98\n  57\n  98\n  25\n 148\n 166\n 135\n  31\n 182\n  48\n 184\n 160\n 166\n  40\n 115\n 161\n  21\n... [the output was truncated (use n=-1 to disable)]\n[ CPULongType{128} ]\n```", "```r\nconvnet <- nn_module(\n \"convnet\",\n initialize = function() {\n self$features <- nn_sequential(\n nn_conv2d(3, 64, kernel_size = 3, padding = 1),\n nn_relu(),\n nn_max_pool2d(kernel_size = 2),\n nn_conv2d(64, 128, kernel_size = 3, padding = 1),\n nn_relu(),\n nn_max_pool2d(kernel_size = 2),\n nn_conv2d(128, 256, kernel_size = 3, padding = 1),\n nn_relu(),\n nn_max_pool2d(kernel_size = 2),\n nn_conv2d(256, 512, kernel_size = 3, padding = 1),\n nn_relu(),\n nn_max_pool2d(kernel_size = 2),\n nn_conv2d(512, 1024, kernel_size = 3, padding = 1),\n nn_relu(),\n nn_adaptive_avg_pool2d(c(1, 1))\n )\n self$classifier <- nn_sequential(\n nn_linear(1024, 1024),\n nn_relu(),\n nn_linear(1024, 1024),\n nn_relu(),\n nn_linear(1024, 200)\n )\n },\n forward = function(x) {\n x <- self$features(x)$squeeze()\n x <- self$classifier(x)\n x\n }\n)\n```", "```r\nfitted <- convnet %>%\n setup(\n loss = nn_cross_entropy_loss(),\n optimizer = optim_adam,\n metrics = list(\n luz_metric_accuracy()\n )\n ) %>%\n fit(train_dl,\n epochs = 50,\n valid_data = valid_dl,\n verbose = TRUE\n )\n```", "```r\nEpoch 1/50\nTrain metrics: Loss: 5.0822 - Acc: 0.0146                                     \nValid metrics: Loss: 4.8564 - Acc: 0.0269\nEpoch 2/50\nTrain metrics: Loss: 4.5545 - Acc: 0.0571                                     \nValid metrics: Loss: 4.2592 - Acc: 0.0904\nEpoch 3/50\nTrain metrics: Loss: 4.0727 - Acc: 0.1122                                     \nValid metrics: Loss: 3.9097 - Acc: 0.1381\n...\n...\nEpoch 48/50\nTrain metrics: Loss: 0.3033 - Acc: 0.9064                                     \nValid metrics: Loss: 10.2999 - Acc: 0.2188\nEpoch 49/50\nTrain metrics: Loss: 0.2932 - Acc: 0.9098                                     \nValid metrics: Loss: 10.7348 - Acc: 0.222\nEpoch 50/50\nTrain metrics: Loss: 0.2733 - Acc: 0.9152                                     \nValid metrics: Loss: 10.641 - Acc: 0.2204\n```", "```r\npreds <- last %>% predict(valid_dl)\n```", "```r\npreds <- nnf_softmax(preds, dim = 2)\n```", "```r\ntorch_argmax(preds, dim = 2)\n```", "```r\ntorch_tensor\n  55\n   1\n   1\n   1\n   1\n   1\n   1\n  89\n  45\n   1\n   1\n  19\n   1\n 190\n  14\n   1\n 185\n   1\n   1\n 150\n  77\n  37\n 131\n 193\n  80\n   1\n   1\n  45\n   1\n 131\n... [the output was truncated (use n=-1 to disable)]\n[ CUDALongType{10000} ]\n```"]