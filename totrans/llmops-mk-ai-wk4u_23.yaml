- en: 3.3 AI Quiz Generation Mechanism
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3.3 AI 问答生成机制
- en: 原文：[https://boramorka.github.io/LLM-Book/en/CHAPTER-3/3.3%20AI%20Quiz%20Generation%20Mechanism/](https://boramorka.github.io/LLM-Book/en/CHAPTER-3/3.3%20AI%20Quiz%20Generation%20Mechanism/)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://boramorka.github.io/LLM-Book/en/CHAPTER-3/3.3%20AI%20Quiz%20Generation%20Mechanism/](https://boramorka.github.io/LLM-Book/en/CHAPTER-3/3.3%20AI%20Quiz%20Generation%20Mechanism/)
- en: 'This chapter assembles a working AI‑powered quiz generator end to end: we set
    up the environment and access to external services, prepare a compact dataset
    of subjects/categories/facts, design a prompt so questions strictly match the
    chosen category, and wire it all into a LangChain pipeline. We start with environment
    setup and keys; to keep output clean you can suppress non‑essential warnings.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章从头到尾组装了一个工作的人工智能问答生成器：我们设置环境并访问外部服务，准备主题/类别/事实的紧凑数据集，设计一个提示，以确保问题严格匹配所选类别，并将其所有内容连接到LangChain管道中。我们首先设置环境并获取密钥；为了保持输出整洁，您可以抑制非必要的警告。
- en: '[PRE0]'
  id: totrans-3
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Next, we form the app’s backbone — a compact dataset from which questions will
    be composed: we fix subjects, categories, and facts that quizzes will be built
    from.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们构建应用程序的核心——一个紧凑的数据集，从中将组成问题：我们固定主题、类别和事实，这些将用于构建问答。
- en: '[PRE1]'
  id: totrans-5
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'To ensure questions are relevant to the user’s selected category, we design
    a detailed prompt template: from category selection via the quiz bank to formulating
    questions in the prescribed format.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确保问题与用户选择的类别相关，我们设计了一个详细的提示模板：从类别选择通过问答库到以规定的格式制定问题。
- en: '[PRE2]'
  id: totrans-7
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'With this template, we move to LangChain: form a ChatPrompt, select a model,
    and a parser to normalize the response into a readable form.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 使用此模板，我们转向LangChain：形成一个ChatPrompt，选择一个模型和一个解析器，将响应标准化为可读形式。
- en: '[PRE3]'
  id: totrans-9
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Now we connect everything using the LangChain Expression Language into a single
    pipeline for reproducible generation.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们使用LangChain表达式语言将所有内容连接起来，形成一个可重复生成的单一管道。
- en: '[PRE4]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Next, encapsulate the setup and execution of quiz generation into a single reusable
    function. This increases modularity and simplifies maintenance. `generate_quiz_assistant_pipeline`
    bundles prompt creation, model selection, and parsing into one workflow.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，将问答生成的设置和执行封装成一个可重用的函数。这增加了模块化并简化了维护。`generate_quiz_assistant_pipeline`将提示创建、模型选择和解析捆绑到一个工作流程中。
- en: 'Quick overview: `generate_quiz_assistant_pipeline` is flexible and allows plugging
    in different templates and configurations (models/parsers). Function definition:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 快速概述：`generate_quiz_assistant_pipeline`灵活，允许插入不同的模板和配置（模型/解析器）。函数定义：
- en: '[PRE5]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Practical usage. The function hides the complexity of composing components:
    simply call `generate_quiz_assistant_pipeline` with the required arguments to
    generate topic/category quizzes and easily integrate into larger systems. A few
    practical tips:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 实际应用。该函数隐藏了组件组合的复杂性：只需用所需的参数调用`generate_quiz_assistant_pipeline`以生成主题/类别问答，并轻松集成到更大的系统中。一些实用提示：
- en: '**Configuration**: use parameters to flexibly tune the process.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**配置**：使用参数灵活调整过程。'
- en: '**Model choice**: experiment with models for quality/creativity trade‑offs.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型选择**：在质量/创意权衡中尝试不同的模型。'
- en: '**Prompt design**: plan `user_question_template` and `system_prompt_message`
    thoughtfully.'
  id: totrans-18
  prefs:
  - PREF_UL
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**提示设计**：仔细规划`user_question_template`和`system_prompt_message`。'
- en: '**Error handling**: account for API limits and unexpected responses.'
  id: totrans-19
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**错误处理**：考虑API限制和意外响应。'
- en: Including this function in your project simplifies creating AI‑driven quizzes,
    enabling innovative educational tools and interactive content.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 将此函数包含到您的项目中可以简化创建AI驱动的问答，使创新的教育工具和互动内容成为可能。
- en: 'To add quality checks, introduce `evaluate_quiz_content`: it verifies that
    the generated quiz contains the expected topic keywords — essential for relevance
    and correctness in learning scenarios.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 为了添加质量检查，引入`evaluate_quiz_content`：它验证生成的问答包含预期的主题关键词——这对于学习场景中的相关性和正确性至关重要。
- en: 'Now about content evaluation. The function integrates with the generation pipeline:
    it accepts the system message (instructions/context), a specific request (e.g.,
    a topic for the quiz), and a list of expected words/phrases that should appear
    in the result. Function definition:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 现在关于内容评估。该函数与生成管道集成：它接受系统消息（指令/上下文）、一个特定的请求（例如，问答的主题）以及应在结果中出现的预期单词/短语列表。函数定义：
- en: '[PRE6]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Consider an example: generate and evaluate a science quiz.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一个例子：生成并评估一个科学问答。
- en: '[PRE7]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'This example shows how `evaluate_quiz_content` can confirm that a science quiz
    includes relevant themes (figures, instruments, concepts). Good practices:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 此示例展示了`evaluate_quiz_content`如何确认科学测验包含相关的主题（图表、仪器、概念）。良好实践：
- en: '**Keyword selection** — make them specific enough but leave room for variation.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**关键词选择** — 使其足够具体，但留有变通的空间。'
- en: '**Broad checks** — use multiple keyword sets for different topics.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**广泛检查** — 使用多个关键词集针对不同主题。'
- en: '**Iterative approach** — refine template/parameters/dataset based on evaluation
    results.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**迭代方法** — 根据评估结果精炼模板/参数/数据集。'
- en: Structured testing helps maintain quality and uncover opportunities to improve
    relevance and engagement.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 结构化测试有助于保持质量并揭示提高相关性和参与度的机会。
- en: 'To handle out‑of‑scope requests, introduce `evaluate_request_refusal`, which
    tests proper refusal in inappropriate scenarios. This matters for trust and user
    experience (UX): the function simulates cases where the system should refuse (based
    on relevance/constraints) and verifies that the expected refusal message is returned.
    Function definition:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 为了处理超出范围请求，引入`evaluate_request_refusal`，它测试在不适当的场景中的适当拒绝。这对信任和用户体验（UX）很重要：该函数模拟系统应该拒绝的情况（基于相关性/限制）并验证是否返回了预期的拒绝消息。函数定义：
- en: '[PRE8]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: To illustrate `evaluate_request_refusal`, consider a scenario where the quiz
    generator should refuse to create a quiz because the request is outside its scope
    or unsupported by the current configuration.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明`evaluate_request_refusal`，考虑一个场景，其中测验生成器应拒绝创建测验，因为请求超出了其范围或不受当前配置支持。
- en: '[PRE9]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'This example demonstrates how to test the quiz generator’s response to a request
    that should be declined: by checking for the expected refusal message, we ensure
    the system behaves correctly when facing requests it cannot fulfill. Tips and
    suggestions:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 此示例演示了如何测试测验生成器对应该拒绝的请求的反应：通过检查预期的拒绝消息，我们确保系统在面临无法满足的请求时表现正确。提示和建议：
- en: '**Clear refusal messages**: make them informative so users understand why the
    request cannot be completed.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**清晰的拒绝消息**：使其信息丰富，以便用户了解为什么请求无法完成。'
- en: '**Comprehensive testing**: use diverse scenarios, including unsupported topics
    or formats, to thoroughly evaluate refusal logic.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**全面测试**：使用各种场景，包括不支持的主题或格式，以彻底评估拒绝逻辑。'
- en: '**Refinement and feedback**: iterate on refusal logic and messaging to improve
    user understanding and satisfaction.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**精炼和反馈**：迭代拒绝逻辑和消息以改善用户理解和满意度。'
- en: '**Consider UX**: where possible, offer alternatives or suggestions to maintain
    a positive interaction.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**考虑用户体验**：在可能的情况下，提供替代方案或建议以保持积极的互动。'
- en: Implementing and testing refusal scenarios ensures the quiz generator can reliably
    handle a wide range of requests, maintaining robustness and user trust even when
    it cannot provide the requested content.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 实施和测试拒绝场景确保测验生成器可以可靠地处理各种请求，即使在无法提供请求内容的情况下也能保持稳健性和用户信任。
- en: To adapt the provided template to a practical test scenario focused on a science‑themed
    quiz, we add a `test_science_quiz` function. It evaluates whether AI‑generated
    quiz questions truly center on expected scientific topics or subjects. By integrating
    `evaluate_quiz_content`, we can ensure the quiz includes specific keywords or
    themes characteristic of the science category.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将提供的模板适应于一个以科学主题测验为重点的实际测试场景，我们添加了一个`test_science_quiz`函数。它评估AI生成的测验问题是否真正集中在预期的科学主题或科目上。通过集成`evaluate_quiz_content`，我们可以确保测验包含科学类别特有的特定关键词或主题。
- en: 'Finally, we tailor `evaluate_quiz_content` for a science test case: the function
    checks whether the generated content aligns with expected scientific themes. Function
    definition for testing a science quiz:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们为科学测试案例定制`evaluate_quiz_content`函数：该函数检查生成的内容是否符合预期的科学主题。测试科学测验的函数定义：
- en: '[PRE10]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'This function encapsulates the validation logic: for a science request, content
    must contain expected science themes/keywords. Calling `test_science_quiz` simulates
    the request and checks for scientific themes — a key indicator of correct generation.
    Refine the keyword list for your domain and coverage, expand tests for other categories
    (history/geography/art), and analyze failures: compare expectations with results
    to improve prompt logic/dataset. Structured testing helps maintain quality and
    discover opportunities to improve relevance and engagement.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 此函数封装了验证逻辑：对于科学请求，内容必须包含预期的科学主题/关键词。调用`test_science_quiz`模拟请求并检查科学主题 — 这是正确生成的关键指标。根据你的领域和覆盖范围细化关键词列表，扩展其他类别（历史/地理/艺术）的测试，并分析失败：比较预期与结果以改进提示逻辑/数据集。结构化测试有助于保持质量并发现改进相关性和参与度的机会。
- en: 'Lastly — a quick look at CI/CD: the `.circleci/config.yml` file in the repository
    root describes a YAML‑based pipeline (build/test/deploy). Below is a sketch for
    a Python project with automated tests:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 最后 — 快速了解CI/CD：存储库根目录中的`.circleci/config.yml`文件描述了一个基于YAML的管道（构建/测试/部署）。以下是Python项目自动测试的草图：
- en: '[PRE11]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Key elements: `version` — the config version (commonly 2.1); `orbs` — reusable
    blocks, here the `python` orb helps with environment setup; `jobs` — a set of
    tasks, here a single `build-and-test`; `docker` — the image to run (e.g., `cimg/python:3.8`);
    `steps` — the sequence (checkout, cache, dependencies, tests); `workflows` — ties
    jobs into a process and triggers them by rule.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 关键元素：`version` — 配置版本（通常是2.1）；`orbs` — 可重用块，这里`python` orb帮助设置环境；`jobs` — 一组任务，这里是一个单一的`build-and-test`；`docker`
    — 运行的镜像（例如，`cimg/python:3.8`）；`steps` — 序列（检出、缓存、依赖、测试）；`workflows` — 将作业与流程绑定并按规则触发它们。
- en: 'To customize: pick your Python version under `docker`, replace `pytest` with
    your test command, and add extra steps (DB, env vars, etc.) as additional `- run:`
    blocks. After committing `.circleci/config.yml`, CircleCI detects the configuration
    and will run the pipeline on each commit per your rules.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 要定制：在`docker`下选择你的Python版本，将`pytest`替换为你的测试命令，并添加额外的步骤（数据库、环境变量等）作为额外的`- run:`块。提交`.circleci/config.yml`后，CircleCI将检测配置并在每次提交时根据你的规则运行管道。
- en: Theoretical Questions
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理论问题
- en: What components are necessary to set up the environment for an AI‑based quiz
    generator?
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置基于AI的测验生成器环境需要哪些组件？
- en: How do you structure a dataset for generating quiz questions? Include examples
    of categories and facts.
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你如何构建用于生成测验问题的数据集？包括类别和事实的示例。
- en: How does prompt engineering influence customized quiz generation? Provide a
    sample prompt template.
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提示工程如何影响定制化测验生成？提供示例提示模板。
- en: Explain LangChain’s role in structuring prompts for LLM processing.
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 解释LangChain在为LLM处理构建提示中的作用。
- en: What constitutes the quiz generation pipeline when using the LangChain Expression
    Language?
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用LangChain表达式语言时，测验生成管道由哪些构成？
- en: How can functions for evaluation ensure the relevance and accuracy of generated
    quiz content?
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如何确保评估函数能够保证生成测验内容的相关性和准确性？
- en: Describe a method for testing the system’s ability to refuse quiz generation
    under certain conditions.
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 描述一种测试系统在特定条件下拒绝生成测验的能力的方法。
- en: How can you test LLM‑generated quiz questions for alignment with expected science
    topics or subjects?
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如何测试LLM生成的测验问题是否符合预期的科学主题或科目？
- en: Describe the key components of a CircleCI configuration file for a Python project,
    including automated test execution.
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 描述Python项目的CircleCI配置文件的关键组件，包括自动测试执行。
- en: Discuss the importance of customizing the CircleCI config to match a project’s
    specific needs.
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 讨论定制CircleCI配置以匹配项目特定需求的重要性。
- en: Practical Assignments
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实践作业
- en: 'Create a quiz dataset: Define a Python dictionary named `quiz_bank` representing
    a collection of quiz entries, each containing subjects, categories, and facts
    similar to the example. Ensure your dictionary supports easy access to subjects,
    categories, and facts.'
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建测验数据集：定义一个名为`quiz_bank`的Python字典，表示一组测验条目，每个条目包含与示例类似的科目、类别和事实。确保你的字典支持对科目、类别和事实的轻松访问。
- en: 'Generate quiz questions using prompts: Implement a function `generate_quiz_questions(category)`
    that accepts a category (e.g., "History", "Technology") as input and returns a
    list of generated quiz questions based on subjects and facts from `quiz_bank`.
    Use string operations or templates to construct the questions.'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用提示生成试题：实现一个名为 `generate_quiz_questions(category)` 的函数，该函数接受一个类别（例如，“历史”，“技术”）作为输入，并返回基于
    `quiz_bank` 中的主题和事实生成的试题列表。使用字符串操作或模板构建问题。
- en: 'Implement LangChain‑style prompt structuring: Simulate using LangChain’s capabilities
    by writing a function `structure_quiz_prompt(quiz_questions)` that accepts a list
    of quiz questions and returns a structured chat prompt in a format similar to
    the one described, without actually integrating LangChain.'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实现LangChain风格的提示结构：通过编写一个名为 `structure_quiz_prompt(quiz_questions)` 的函数来模拟使用
    LangChain 的功能，该函数接受一个试题问题列表，并返回一个类似描述的结构化聊天提示，而不实际集成 LangChain。
- en: 'Quiz generation pipeline: Create a Python function `generate_quiz_pipeline()`
    that simulates creating and running a quiz generation pipeline using placeholders
    for LangChain components. The function should print a message emulating pipeline
    execution.'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 试题生成管道：创建一个名为 `generate_quiz_pipeline()` 的 Python 函数，该函数模拟使用 LangChain 组件创建和运行试题生成管道，并使用占位符。该函数应打印一条模拟管道执行的消息。
- en: 'Reusable quiz generation function: Implement a Python function `generate_quiz_assistant_pipeline(system_prompt_message,
    user_question_template="{question}")` that simulates assembling the components
    needed for quiz generation. Use string formatting to construct the detailed prompt
    from inputs.'
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可重用试题生成函数：实现一个名为 `generate_quiz_assistant_pipeline(system_prompt_message, user_question_template="{question}")`
    的 Python 函数，该函数模拟组装试题生成所需的组件。使用字符串格式化从输入构建详细的提示。
- en: 'Evaluate generated quiz content: Write a function `evaluate_quiz_content(generated_content,
    expected_keywords)` that accepts generated quiz content and a list of expected
    keywords, and checks whether the content contains any of the keywords. Raise an
    assertion error with a custom message if none are found.'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 评估生成的试题内容：编写一个名为 `evaluate_quiz_content(generated_content, expected_keywords)`
    的函数，该函数接受生成的试题内容和预期关键词列表，并检查内容是否包含任何关键词。如果没有找到任何关键词，则引发一个带有自定义消息的断言错误。
- en: 'Handle invalid quiz requests: Develop a function `evaluate_request_refusal(invalid_request,
    expected_response)` that simulates evaluating the system’s response to an invalid
    quiz request. The function should verify whether the refusal text matches the
    expected refusal response.'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 处理无效的试题请求：开发一个名为 `evaluate_request_refusal(invalid_request, expected_response)`
    的函数，该函数模拟评估系统对无效试题请求的响应。该函数应验证拒绝文本是否与预期的拒绝响应匹配。
- en: 'Science Quiz Evaluation Test: Develop a Python function `test_science_quiz()`
    that uses the `evaluate_quiz_content` function to test if a generated science
    quiz includes questions related to expected scientific topics, such as "physics"
    or "chemistry".'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 科学试题评估测试：开发一个名为 `test_science_quiz()` 的 Python 函数，该函数使用 `evaluate_quiz_content`
    函数来测试生成的科学试题是否包含与预期科学主题相关的题目，例如“物理”或“化学”。
