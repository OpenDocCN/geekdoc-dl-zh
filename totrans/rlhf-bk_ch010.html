<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops" xml:lang="en-US">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <title>ch010.xhtml</title>
  <style>
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
/*
 * Custom CSS file. Override it as you like.
 *
 * Credits to @killercup (https://gist.github.com/killercup); Extracted from this Gist:
 *   https://gist.github.com/killercup/5917178
 * Substantial modifications made by natolambert
 */

html {
    font-size: 100%;
    overflow-y: scroll;
    -webkit-text-size-adjust: 100%;
    -ms-text-size-adjust: 100%;
}

body {
    color: #444;
    font-family: Georgia, Palatino, 'Palatino Linotype', Times, 'Times New Roman', serif;
    font-size: 12px;
    line-height: 1.7;
    padding: 1em;
    margin: auto;
    max-width: 42em;
    background: #fefefe;
}

a {
    color: #0645ad;
    text-decoration: none;
}

a:visited {
    color: #0b0080;
}

a:hover {
    color: #06e;
}

a:active {
    color: #faa700;
}

a:focus {
    outline: thin dotted;
}

*::-moz-selection {
    background: rgba(255, 255, 0, 0.3);
    color: #000;
}

*::selection {
    background: rgba(255, 255, 0, 0.3);
    color: #000;
}

a::-moz-selection {
    background: rgba(255, 255, 0, 0.3);
    color: #0645ad;
}

a::selection {
    background: rgba(255, 255, 0, 0.3);
    color: #0645ad;
}

p {
    margin: 1em 0;
}

img {
    max-width: 100%;
}

h1,
h2,
h3,
h4,
h5,
h6 {
    color: #111;
    line-height: 125%;
    margin-top: 2em;
    font-weight: normal;
    position: relative;
}

/* Heading anchor link styles */
.header-anchor {
    opacity: 0;
    font-size: 0.8em;
    vertical-align: middle;
    position: absolute;
    margin-left: 0.3em;
    transition: opacity 0.2s ease-in-out;
}

h2:hover .header-anchor,
h3:hover .header-anchor,
h4:hover .header-anchor,
h5:hover .header-anchor,
h6:hover .header-anchor {
    opacity: 1;
}

h4,
h5,
h6 {
    font-weight: bold;
}

h1 {
    font-size: 2.5em;
}

h1.title {
    hyphens: none;
    -webkit-hyphens: none;
    -moz-hyphens: none;
    -ms-hyphens: none;
    word-break: keep-all;
}

h2 {
    font-size: 2em;
}

h3 {
    font-size: 1.5em;
}

h4 {
    font-size: 1.2em;
}

h5 {
    font-size: 1em;
}

h6 {
    font-size: 0.9em;
}

blockquote {
    color: #666666;
    margin: 0;
    padding-left: 3em;
    border-left: 0.5em #EEE solid;
}

hr {
    display: block;
    height: 2px;
    border: 0;
    border-top: 1px solid #aaa;
    border-bottom: 1px solid #eee;
    margin: 1em 0;
    padding: 0;
}

pre,
code,
kbd,
samp {
    color: #000;
    font-family: monospace, monospace;
    _font-family: 'courier new', monospace;
    font-size: 0.98em;
}

pre {
    white-space: pre;
    white-space: pre-wrap;
    word-wrap: break-word;
}


b,
strong {
    font-weight: bold;
}

dfn {
    font-style: italic;
}

ins {
    background: #ff9;
    color: #000;
    text-decoration: none;
}

mark {
    background: #ff0;
    color: #000;
    font-style: italic;
    font-weight: bold;
}

sub,
sup {
    font-size: 75%;
    line-height: 0;
    position: relative;
    vertical-align: baseline;
}

sup {
    top: -0.5em;
}

sub {
    bottom: -0.25em;
}

ul,
ol {
    margin: 1em 0;
    padding: 0 0 0 2em;
}

li p:last-child {
    margin-bottom: 0;
}

ul ul,
ol ol {
    margin: .3em 0;
}

dl {
    margin-bottom: 1em;
}

dt {
    font-weight: bold;
    margin-bottom: .8em;
}

dd {
    margin: 0 0 .8em 2em;
}

dd:last-child {
    margin-bottom: 0;
}

img {
    border: 0;
    -ms-interpolation-mode: bicubic;
    vertical-align: middle;
}

figure {
    display: block;
    text-align: center;
    margin: 1em 0;
}

figure img {
    border: none;
    margin: 0 auto;
}

figcaption {
    font-size: 0.8em;
    font-style: italic;
    margin: 0 0 .8em;
}

/* for html tables */
table {
    margin-bottom: 2em;
    border-bottom: 1px solid #ddd;
    border-right: 1px solid #ddd;
    border-spacing: 0;
    box-shadow: none;
    border: none;
    border-collapse: collapse;
    margin-left: auto;
    margin-right: auto;
    width: auto; /* Keeps natural width; wrapper handles overflow */
    display: table;
}

th {
    padding: 12px;
    text-align: center;
    background-color: #eee;
    border: 1px solid #ddd;
}

td {
    padding: 12px;
    text-align: left; /* Keeps data cells left-aligned */
    border: 1px solid #ddd;
    vertical-align: top;
}

.table-scroll {
    max-width: 100%;
    overflow-x: auto;
    -webkit-overflow-scrolling: touch;
    margin: 1.5em auto 2em;
}

.table-scroll table {
    margin: 0 auto;
    display: table;
    width: auto;
    width: fit-content;
    width: max-content;
}

.table-wrap {
    margin: 1.5em auto 2em;
}

.table-wrap table {
    margin: 0 auto;
}

.table-scroll::-webkit-scrollbar {
    height: 8px;
}

.table-scroll::-webkit-scrollbar-thumb {
    background-color: rgba(0, 0, 0, 0.2);
    border-radius: 4px;
}

.table-scroll::-webkit-scrollbar-track {
    background: rgba(0, 0, 0, 0.05);
}

.author {
    font-size: 1.2em;
    text-align: center;
}

/* Target only mobile screens */
@media only screen and (max-width: 479px) {
    body {
        font-size: 14px;
    }
}

@media only screen and (min-width: 480px) {
    body {
        font-size: 15px;
    }
}

@media only screen and (min-width: 768px) {
    body {
        font-size: 16px;
    }
}

@media print {
    * {
        background: transparent !important;
        color: black !important;
        filter: none !important;
        -ms-filter: none !important;
    }
    body {
        font-size: 12pt;
        max-width: 100%;
    }
    a,
    a:visited {
        text-decoration: underline;
    }
    hr {
        height: 1px;
        border: 0;
        border-bottom: 1px solid black;
    }
    a[href]:after {
        content: " (" attr(href) ")";
    }
    abbr[title]:after {
        content: " (" attr(title) ")";
    }
    .ir a:after,
    a[href^="javascript:"]:after,
    a[href^="#"]:after {
        content: "";
    }
    pre,
    blockquote {
        border: 1px solid #999;
        padding-right: 1em;
        page-break-inside: avoid;
    }
    tr,
    img {
        page-break-inside: avoid;
    }
    img {
        max-width: 100% !important;
    }
    @page :left {
        margin: 15mm 20mm 15mm 10mm;
    }
    @page :right {
        margin: 15mm 10mm 15mm 20mm;
    }
    p,
    h2,
    h3 {
        orphans: 3;
        widows: 3;
    }
    h2,
    h3 {
        page-break-after: avoid;
    }
}

.dropdown-content {
  display: none;
}



thead {
    background-color: #f5f5f5;
}


.dropdown-content.open {
  display: block;
  max-height: 2000px;
}
/* Header Nav Block */
    .chapter-nav {
        display: grid;
        grid-template-columns: repeat(3, 1fr);
        /* grid-template-rows: auto auto;  */
        gap: 0.5rem;
        padding: 0.5rem;
        max-width: 1200px;
        text-align: left;
    }  
    .section {
        background-color: #ffffff;
        padding-top: 5px;
        padding-right: 12px;
        padding-bottom: 8px;
        padding-left: 12px;
        border-radius: 5px;
        text-align: left;
    }
  .dropdown-content {
    max-height: 0;
    overflow: hidden;
    transition: max-height 0.3s ease-out;
    background: #f8f8f8;  /* Unified with section background */
  }
  /* dropdown row */
  .dropdown-button {
    width: 100%;
    text-align: left;
    padding: 0.5rem;
    background: #f8f8f8;
    display: flex;
    align-items: center;
    gap: 0.5rem;
    cursor: pointer;
    border: none;
    font-size: 0.9rem;
  }
  /* carrot button */
  .dropdown-button .chevron {
    width: 14px;
    height: 14px;
    transition: transform 0.2s;
  }
  /* dropdown animation */
  .dropdown-button[aria-expanded="true"] .chevron {
    transform: rotate(180deg);
  }
  .section h3 {
    font-weight: bold;
    font-size: 0.8rem;
    margin-top: 5px;
    margin-bottom: 5px;  /* or whatever bottom spacing you prefer */
  }
  .section ol, .section ul {
    margin: 0;
    padding-left: 20px;
    text-align: left;
  }
  .section li {
    font-size: 12px;
    line-height: 1.3;
    margin-bottom: 3px;
    text-align: left;
  }
  .section a {
    color: #0066cc;
    text-decoration: none;
  }
  .section a:hover {
    text-decoration: underline;
  }

  /* Mobile Responsiveness */
  @media screen and (max-width: 768px) {
    .chapter-nav {
      grid-template-columns: 1fr;
    }
    .section {
      margin-bottom: 10px;
    }
    .section p {
      font-size: 16px;
    }
    .section li {
      font-size: 14px;
    }
  }  </style>
  <link rel="stylesheet" type="text/css" href="../styles/stylesheet1.css" />
</head>
<body epub:type="bodymatter">
<section id="rejection-sampling" class="level1">
<h1>Rejection Sampling</h1>
<p>Rejection Sampling (RS) is a popular and simple baseline for performing preference fine-tuning. This makes it one of a handful of methods that are used after a first round of instruction tuning in order to further refine the model to human preferences. Rejection sampling operates by curating new candidate completions, filtering them based on a trained reward model, and then instruction finetuning the original model only on the top completions (same loss function as when doing a dedicated training stage for learning to follow instructions).</p>
<p>The name originates from computational statistics <span class="citation" data-cites="gilks1992adaptive"><a href="ch021.xhtml#ref-gilks1992adaptive">[175]</a></span>, where one wishes to sample from a complex distribution, but does not have a direct method to do so. To alleviate this, one samples from a simpler distribution to model and uses a heuristic to check if the sample is permissible. With language models, the target distribution is high-quality completions to prompts, the filter is a reward model, and the sampling distribution is the current model.</p>
<p>Many prominent RLHF and preference fine-tuning papers have used rejection sampling as a baseline, but a canonical implementation and documentation does not exist.</p>
<p>WebGPT <span class="citation" data-cites="nakano2021webgpt"><a href="ch021.xhtml#ref-nakano2021webgpt">[4]</a></span>, Anthropic‚Äôs Helpful and Harmless agent <span class="citation" data-cites="bai2022training"><a href="ch021.xhtml#ref-bai2022training">[5]</a></span>, OpenAI‚Äôs popular paper on process reward models <span class="citation" data-cites="lightman2023let"><a href="ch021.xhtml#ref-lightman2023let">[45]</a></span>, Llama 2 Chat models <span class="citation" data-cites="touvron2023llama"><a href="ch021.xhtml#ref-touvron2023llama">[44]</a></span>, and other seminal works all use this baseline; more recent work has formalized it directly (e.g., RAFT <span class="citation" data-cites="dong2023raft"><a href="ch021.xhtml#ref-dong2023raft">[176]</a></span> for applying it to alignment in multiple modalities and Statistical Rejection Sampling Optimization (RSO) <span class="citation" data-cites="liu2023statistical"><a href="ch021.xhtml#ref-liu2023statistical">[177]</a></span> that gives a principled overview on how rejection sampling relates to other preference learning objectives).</p>
<p><em>Throughout this chapter, we use <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>x</mi><annotation encoding="application/x-tex">x</annotation></semantics></math> to denote prompts and <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>y</mi><annotation encoding="application/x-tex">y</annotation></semantics></math> to denote completions. This notation is common in the language model literature, where methods operate on full prompt-completion pairs rather than individual tokens.</em></p>
<section id="training-process" class="level2">
<h2>Training Process</h2>
<p>Rejection sampling overall follows a few stages.</p>
<ol start="0" type="1">
<li><strong>Prompt and reward model selection:</strong> First, you must select the prompts you want to train on, relative to other stages of training. The simplest method is to re-use every prompt from the first SFT/IFT stage, but this can cause some overfitting. Before doing rejection sampling, you must also have trained a reward model (see Chapter 7 for more information).</li>
<li><strong>Generate completions from the starting checkpoint:</strong> Next, one must generate completions to the selected prompts with the model they want to optimize. This can involve tweaking many settings, such as sampling temperature, top-p, max sequence length, number of completions per prompt, etc.</li>
<li><strong>Select top completions with a reward model</strong>: All completions are ranked by a reward model. This can include deduplication to only have one prompt per completion after this stage, or not, as a lot of the decisions become based on empirical ablation studies.</li>
<li><strong>SFT on top completions:</strong> To finish rejection sampling, one instruction finetunes the starting checkpoint on the selected completions.</li>
</ol>
<p>A visual overview of the rejection sampling process is included below in fig.¬†<a href="#fig:rs-overview">14</a>.</p>
<figure id="fig:rs-overview">
<img src="../media/file12.png" alt="Figure 14: Rejection sampling overview." />
<figcaption aria-hidden="true">Figure 14: Rejection sampling overview.</figcaption>
</figure>
<p>The actual details on which prompts to use, how to select a reward model, how to sequence rejection sampling, etc. are not well documented in the literature. This chapter provides an overview of the methods and leaves further experimentation to the reader.</p>
<section id="generating-completions" class="level3">
<h3>1. Generating Completions</h3>
<p>To generate a set of multiple candidate completions per prompt, let‚Äôs define a set of <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>M</mi><annotation encoding="application/x-tex">M</annotation></semantics></math> prompts as a vector:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi><mo>=</mo><mo stretchy="false" form="prefix">[</mo><msub><mi>x</mi><mn>1</mn></msub><mo>,</mo><msub><mi>x</mi><mn>2</mn></msub><mo>,</mo><mi>.</mi><mi>.</mi><mi>.</mi><mo>,</mo><msub><mi>x</mi><mi>M</mi></msub><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">X = [x_1, x_2, ..., x_M]</annotation></semantics></math></p>
<p>These prompts can come from many sources, but most commonly they come from the instruction training set.</p>
<p>For each prompt <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mi>i</mi></msub><annotation encoding="application/x-tex">x_i</annotation></semantics></math>, we generate <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>N</mi><annotation encoding="application/x-tex">N</annotation></semantics></math> completions. We can represent this as a matrix:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Y</mi><mo>=</mo><mrow><mo stretchy="true" form="prefix">[</mo><mtable><mtr><mtd columnalign="center" style="text-align: center"><msub><mi>y</mi><mrow><mn>1</mn><mo>,</mo><mn>1</mn></mrow></msub></mtd><mtd columnalign="center" style="text-align: center"><msub><mi>y</mi><mrow><mn>1</mn><mo>,</mo><mn>2</mn></mrow></msub></mtd><mtd columnalign="center" style="text-align: center"><mi>‚ãØ</mi></mtd><mtd columnalign="center" style="text-align: center"><msub><mi>y</mi><mrow><mn>1</mn><mo>,</mo><mi>N</mi></mrow></msub></mtd></mtr><mtr><mtd columnalign="center" style="text-align: center"><msub><mi>y</mi><mrow><mn>2</mn><mo>,</mo><mn>1</mn></mrow></msub></mtd><mtd columnalign="center" style="text-align: center"><msub><mi>y</mi><mrow><mn>2</mn><mo>,</mo><mn>2</mn></mrow></msub></mtd><mtd columnalign="center" style="text-align: center"><mi>‚ãØ</mi></mtd><mtd columnalign="center" style="text-align: center"><msub><mi>y</mi><mrow><mn>2</mn><mo>,</mo><mi>N</mi></mrow></msub></mtd></mtr><mtr><mtd columnalign="center" style="text-align: center"><mi>‚ãÆ</mi></mtd><mtd columnalign="center" style="text-align: center"><mi>‚ãÆ</mi></mtd><mtd columnalign="center" style="text-align: center"><mo>‚ã±</mo></mtd><mtd columnalign="center" style="text-align: center"><mi>‚ãÆ</mi></mtd></mtr><mtr><mtd columnalign="center" style="text-align: center"><msub><mi>y</mi><mrow><mi>M</mi><mo>,</mo><mn>1</mn></mrow></msub></mtd><mtd columnalign="center" style="text-align: center"><msub><mi>y</mi><mrow><mi>M</mi><mo>,</mo><mn>2</mn></mrow></msub></mtd><mtd columnalign="center" style="text-align: center"><mi>‚ãØ</mi></mtd><mtd columnalign="center" style="text-align: center"><msub><mi>y</mi><mrow><mi>M</mi><mo>,</mo><mi>N</mi></mrow></msub></mtd></mtr></mtable><mo stretchy="true" form="postfix">]</mo></mrow></mrow><annotation encoding="application/x-tex">Y = \begin{bmatrix}
y_{1,1} &amp; y_{1,2} &amp; \cdots &amp; y_{1,N} \\
y_{2,1} &amp; y_{2,2} &amp; \cdots &amp; y_{2,N} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
y_{M,1} &amp; y_{M,2} &amp; \cdots &amp; y_{M,N}
\end{bmatrix}</annotation></semantics></math></p>
<p>where <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub><annotation encoding="application/x-tex">y_{i,j}</annotation></semantics></math> represents the <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>j</mi><annotation encoding="application/x-tex">j</annotation></semantics></math>-th completion for the <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math>-th prompt. Each row <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math> corresponds to a single prompt <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mi>i</mi></msub><annotation encoding="application/x-tex">x_i</annotation></semantics></math> and contains its <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>N</mi><annotation encoding="application/x-tex">N</annotation></semantics></math> candidate completions; each column <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>j</mi><annotation encoding="application/x-tex">j</annotation></semantics></math> corresponds to the <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>j</mi><annotation encoding="application/x-tex">j</annotation></semantics></math>-th sampled completion across all prompts.</p>
</section>
<section id="scoring-completions" class="level3">
<h3>2. Scoring Completions</h3>
<p>Now, we pass all of these prompt-completion pairs through a reward model, to get a matrix of rewards. We‚Äôll represent the rewards as a matrix <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>R</mi><annotation encoding="application/x-tex">R</annotation></semantics></math>:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mo>=</mo><mrow><mo stretchy="true" form="prefix">[</mo><mtable><mtr><mtd columnalign="center" style="text-align: center"><msub><mi>r</mi><mrow><mn>1</mn><mo>,</mo><mn>1</mn></mrow></msub></mtd><mtd columnalign="center" style="text-align: center"><msub><mi>r</mi><mrow><mn>1</mn><mo>,</mo><mn>2</mn></mrow></msub></mtd><mtd columnalign="center" style="text-align: center"><mi>‚ãØ</mi></mtd><mtd columnalign="center" style="text-align: center"><msub><mi>r</mi><mrow><mn>1</mn><mo>,</mo><mi>N</mi></mrow></msub></mtd></mtr><mtr><mtd columnalign="center" style="text-align: center"><msub><mi>r</mi><mrow><mn>2</mn><mo>,</mo><mn>1</mn></mrow></msub></mtd><mtd columnalign="center" style="text-align: center"><msub><mi>r</mi><mrow><mn>2</mn><mo>,</mo><mn>2</mn></mrow></msub></mtd><mtd columnalign="center" style="text-align: center"><mi>‚ãØ</mi></mtd><mtd columnalign="center" style="text-align: center"><msub><mi>r</mi><mrow><mn>2</mn><mo>,</mo><mi>N</mi></mrow></msub></mtd></mtr><mtr><mtd columnalign="center" style="text-align: center"><mi>‚ãÆ</mi></mtd><mtd columnalign="center" style="text-align: center"><mi>‚ãÆ</mi></mtd><mtd columnalign="center" style="text-align: center"><mo>‚ã±</mo></mtd><mtd columnalign="center" style="text-align: center"><mi>‚ãÆ</mi></mtd></mtr><mtr><mtd columnalign="center" style="text-align: center"><msub><mi>r</mi><mrow><mi>M</mi><mo>,</mo><mn>1</mn></mrow></msub></mtd><mtd columnalign="center" style="text-align: center"><msub><mi>r</mi><mrow><mi>M</mi><mo>,</mo><mn>2</mn></mrow></msub></mtd><mtd columnalign="center" style="text-align: center"><mi>‚ãØ</mi></mtd><mtd columnalign="center" style="text-align: center"><msub><mi>r</mi><mrow><mi>M</mi><mo>,</mo><mi>N</mi></mrow></msub></mtd></mtr></mtable><mo stretchy="true" form="postfix">]</mo></mrow></mrow><annotation encoding="application/x-tex">R = \begin{bmatrix}
r_{1,1} &amp; r_{1,2} &amp; \cdots &amp; r_{1,N} \\
r_{2,1} &amp; r_{2,2} &amp; \cdots &amp; r_{2,N} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
r_{M,1} &amp; r_{M,2} &amp; \cdots &amp; r_{M,N}
\end{bmatrix}</annotation></semantics></math></p>
<p>Each reward <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>r</mi><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub><annotation encoding="application/x-tex">r_{i,j}</annotation></semantics></math> is computed by passing the completion <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub><annotation encoding="application/x-tex">y_{i,j}</annotation></semantics></math> and its corresponding prompt <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mi>i</mi></msub><annotation encoding="application/x-tex">x_i</annotation></semantics></math> through a reward model <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>‚Ñõ</mi><annotation encoding="application/x-tex">\mathcal{R}</annotation></semantics></math>:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>r</mi><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub><mo>=</mo><mi>‚Ñõ</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>y</mi><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub><mo>‚à£</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">r_{i,j} = \mathcal{R}(y_{i,j} \mid x_i)</annotation></semantics></math></p>
<p>There are multiple methods to select the top completions to train on.</p>
<p>To formalize the process of selecting the best completions based on our reward matrix, we can define a selection function <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>S</mi><annotation encoding="application/x-tex">S</annotation></semantics></math> that operates on the reward matrix <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>R</mi><annotation encoding="application/x-tex">R</annotation></semantics></math>.</p>
<section id="top-per-prompt" class="level4">
<h4>Top Per Prompt</h4>
<p>The first potential selection function takes the max reward per prompt.</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mo stretchy="false" form="prefix">(</mo><mi>R</mi><mo stretchy="false" form="postfix">)</mo><mo>=</mo><mo stretchy="false" form="prefix">[</mo><mrow><mi mathvariant="normal">arg</mi><mo>&#8289;</mo></mrow><munder><mi mathvariant="normal">max</mi><mi>j</mi></munder><msub><mi>r</mi><mrow><mn>1</mn><mo>,</mo><mi>j</mi></mrow></msub><mo>,</mo><mrow><mi mathvariant="normal">arg</mi><mo>&#8289;</mo></mrow><munder><mi mathvariant="normal">max</mi><mi>j</mi></munder><msub><mi>r</mi><mrow><mn>2</mn><mo>,</mo><mi>j</mi></mrow></msub><mo>,</mo><mi>.</mi><mi>.</mi><mi>.</mi><mo>,</mo><mrow><mi mathvariant="normal">arg</mi><mo>&#8289;</mo></mrow><munder><mi mathvariant="normal">max</mi><mi>j</mi></munder><msub><mi>r</mi><mrow><mi>M</mi><mo>,</mo><mi>j</mi></mrow></msub><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">S(R) = [\arg\max_{j} r_{1,j}, \arg\max_{j} r_{2,j}, ..., \arg\max_{j} r_{M,j}]</annotation></semantics></math></p>
<p>This function <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>S</mi><annotation encoding="application/x-tex">S</annotation></semantics></math> returns a vector of indices, where each index corresponds to the column with the maximum reward for each row in <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>R</mi><annotation encoding="application/x-tex">R</annotation></semantics></math>. We can then use these indices to select our chosen completions:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Y</mi><mrow><mi>c</mi><mi>h</mi><mi>o</mi><mi>s</mi><mi>e</mi><mi>n</mi></mrow></msub><mo>=</mo><mo stretchy="false" form="prefix">[</mo><msub><mi>y</mi><mrow><mn>1</mn><mo>,</mo><mi>S</mi><mo stretchy="false" form="prefix">(</mo><mi>R</mi><msub><mo stretchy="false" form="postfix">)</mo><mn>1</mn></msub></mrow></msub><mo>,</mo><msub><mi>y</mi><mrow><mn>2</mn><mo>,</mo><mi>S</mi><mo stretchy="false" form="prefix">(</mo><mi>R</mi><msub><mo stretchy="false" form="postfix">)</mo><mn>2</mn></msub></mrow></msub><mo>,</mo><mi>.</mi><mi>.</mi><mi>.</mi><mo>,</mo><msub><mi>y</mi><mrow><mi>M</mi><mo>,</mo><mi>S</mi><mo stretchy="false" form="prefix">(</mo><mi>R</mi><msub><mo stretchy="false" form="postfix">)</mo><mi>M</mi></msub></mrow></msub><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">Y_{chosen} = [y_{1,S(R)_1}, y_{2,S(R)_2}, ..., y_{M,S(R)_M}]</annotation></semantics></math></p>
</section>
<section id="top-overall-pairs" class="level4">
<h4>Top Overall Pairs</h4>
<p>Alternatively, we can select the top K prompt-completion pairs from the entire set. First, let‚Äôs flatten our reward matrix R into a single vector:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>R</mi><mrow><mi>f</mi><mi>l</mi><mi>a</mi><mi>t</mi></mrow></msub><mo>=</mo><mo stretchy="false" form="prefix">[</mo><msub><mi>r</mi><mrow><mn>1</mn><mo>,</mo><mn>1</mn></mrow></msub><mo>,</mo><msub><mi>r</mi><mrow><mn>1</mn><mo>,</mo><mn>2</mn></mrow></msub><mo>,</mo><mi>.</mi><mi>.</mi><mi>.</mi><mo>,</mo><msub><mi>r</mi><mrow><mn>1</mn><mo>,</mo><mi>N</mi></mrow></msub><mo>,</mo><msub><mi>r</mi><mrow><mn>2</mn><mo>,</mo><mn>1</mn></mrow></msub><mo>,</mo><msub><mi>r</mi><mrow><mn>2</mn><mo>,</mo><mn>2</mn></mrow></msub><mo>,</mo><mi>.</mi><mi>.</mi><mi>.</mi><mo>,</mo><msub><mi>r</mi><mrow><mn>2</mn><mo>,</mo><mi>N</mi></mrow></msub><mo>,</mo><mi>.</mi><mi>.</mi><mi>.</mi><mo>,</mo><msub><mi>r</mi><mrow><mi>M</mi><mo>,</mo><mn>1</mn></mrow></msub><mo>,</mo><msub><mi>r</mi><mrow><mi>M</mi><mo>,</mo><mn>2</mn></mrow></msub><mo>,</mo><mi>.</mi><mi>.</mi><mi>.</mi><mo>,</mo><msub><mi>r</mi><mrow><mi>M</mi><mo>,</mo><mi>N</mi></mrow></msub><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">R_{flat} = [r_{1,1}, r_{1,2}, ..., r_{1,N}, r_{2,1}, r_{2,2}, ..., r_{2,N}, ..., r_{M,1}, r_{M,2}, ..., r_{M,N}]</annotation></semantics></math></p>
<p>This <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>R</mi><mrow><mi>f</mi><mi>l</mi><mi>a</mi><mi>t</mi></mrow></msub><annotation encoding="application/x-tex">R_{flat}</annotation></semantics></math> vector has length <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mo>√ó</mo><mi>N</mi></mrow><annotation encoding="application/x-tex">M \times N</annotation></semantics></math>, where <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>M</mi><annotation encoding="application/x-tex">M</annotation></semantics></math> is the number of prompts and <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>N</mi><annotation encoding="application/x-tex">N</annotation></semantics></math> is the number of completions per prompt.</p>
<p>Now, we can define a selection function <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>S</mi><mi>K</mi></msub><annotation encoding="application/x-tex">S_K</annotation></semantics></math> that selects the indices of the K highest values in <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>R</mi><mrow><mi>f</mi><mi>l</mi><mi>a</mi><mi>t</mi></mrow></msub><annotation encoding="application/x-tex">R_{flat}</annotation></semantics></math>:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>S</mi><mi>K</mi></msub><mo stretchy="false" form="prefix">(</mo><msub><mi>R</mi><mrow><mi>f</mi><mi>l</mi><mi>a</mi><mi>t</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo><mo>=</mo><mtext mathvariant="normal">argsort</mtext><mo stretchy="false" form="prefix">(</mo><msub><mi>R</mi><mrow><mi>f</mi><mi>l</mi><mi>a</mi><mi>t</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo><mo stretchy="false" form="prefix">[</mo><mi>‚àí</mi><mi>K</mi><mo>:</mo><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">S_K(R_{flat}) = \text{argsort}(R_{flat})[-K:]</annotation></semantics></math></p>
<p>where <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtext mathvariant="normal">argsort</mtext><annotation encoding="application/x-tex">\text{argsort}</annotation></semantics></math> returns the indices that would sort the array in ascending order, and we take the last K indices to get the K highest values.</p>
<p>To get our selected completions, we need to map these flattened indices back to our original completion matrix <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Y</mi><annotation encoding="application/x-tex">Y</annotation></semantics></math>. To recover the corresponding (prompt, completion) pair, you can map a zero-indexed flattened index <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math> to <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false" form="prefix">(</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">(i,j)</annotation></semantics></math> via <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi><mo>=</mo><mo stretchy="false" form="prefix">‚åä</mo><mi>k</mi><mi>/</mi><mi>N</mi><mo stretchy="false" form="postfix">‚åã</mo><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">i = \lfloor k / N \rfloor + 1</annotation></semantics></math> and <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi><mo>=</mo><mo stretchy="false" form="prefix">(</mo><mi>k</mi><mrow><mspace width="0.222em"></mspace><mrow><mi mathvariant="normal">mod</mi><mo>&#8289;</mo></mrow><mspace width="0.222em"></mspace><mi>N</mi></mrow><mo stretchy="false" form="postfix">)</mo><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">j = (k \bmod N) + 1</annotation></semantics></math>.</p>
</section>
<section id="selection-example" class="level4">
<h4>Selection Example</h4>
<p>Consider the case where we have the following situation, with 5 prompts and 4 completions. We will show two ways of selecting the completions based on reward.</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mo>=</mo><mrow><mo stretchy="true" form="prefix">[</mo><mtable><mtr><mtd columnalign="center" style="text-align: center"><mn>0.7</mn></mtd><mtd columnalign="center" style="text-align: center"><mn>0.3</mn></mtd><mtd columnalign="center" style="text-align: center"><mn>0.5</mn></mtd><mtd columnalign="center" style="text-align: center"><mn>0.2</mn></mtd></mtr><mtr><mtd columnalign="center" style="text-align: center"><mn>0.4</mn></mtd><mtd columnalign="center" style="text-align: center"><mn>0.8</mn></mtd><mtd columnalign="center" style="text-align: center"><mn>0.6</mn></mtd><mtd columnalign="center" style="text-align: center"><mn>0.5</mn></mtd></mtr><mtr><mtd columnalign="center" style="text-align: center"><mn>0.9</mn></mtd><mtd columnalign="center" style="text-align: center"><mn>0.3</mn></mtd><mtd columnalign="center" style="text-align: center"><mn>0.4</mn></mtd><mtd columnalign="center" style="text-align: center"><mn>0.7</mn></mtd></mtr><mtr><mtd columnalign="center" style="text-align: center"><mn>0.2</mn></mtd><mtd columnalign="center" style="text-align: center"><mn>0.5</mn></mtd><mtd columnalign="center" style="text-align: center"><mn>0.8</mn></mtd><mtd columnalign="center" style="text-align: center"><mn>0.6</mn></mtd></mtr><mtr><mtd columnalign="center" style="text-align: center"><mn>0.5</mn></mtd><mtd columnalign="center" style="text-align: center"><mn>0.4</mn></mtd><mtd columnalign="center" style="text-align: center"><mn>0.3</mn></mtd><mtd columnalign="center" style="text-align: center"><mn>0.6</mn></mtd></mtr></mtable><mo stretchy="true" form="postfix">]</mo></mrow></mrow><annotation encoding="application/x-tex">R = \begin{bmatrix}
0.7 &amp; 0.3 &amp; 0.5 &amp; 0.2 \\
0.4 &amp; 0.8 &amp; 0.6 &amp; 0.5 \\
0.9 &amp; 0.3 &amp; 0.4 &amp; 0.7 \\
0.2 &amp; 0.5 &amp; 0.8 &amp; 0.6 \\
0.5 &amp; 0.4 &amp; 0.3 &amp; 0.6
\end{bmatrix}</annotation></semantics></math></p>
<p>First, <strong>per prompt</strong>. Intuitively, we can highlight the reward matrix as follows:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mo>=</mo><mrow><mo stretchy="true" form="prefix">[</mo><mtable><mtr><mtd columnalign="center" style="text-align: center"><mtext mathvariant="bold">ùüé.ùüï</mtext></mtd><mtd columnalign="center" style="text-align: center"><mn>0.3</mn></mtd><mtd columnalign="center" style="text-align: center"><mn>0.5</mn></mtd><mtd columnalign="center" style="text-align: center"><mn>0.2</mn></mtd></mtr><mtr><mtd columnalign="center" style="text-align: center"><mn>0.4</mn></mtd><mtd columnalign="center" style="text-align: center"><mtext mathvariant="bold">ùüé.ùüñ</mtext></mtd><mtd columnalign="center" style="text-align: center"><mn>0.6</mn></mtd><mtd columnalign="center" style="text-align: center"><mn>0.5</mn></mtd></mtr><mtr><mtd columnalign="center" style="text-align: center"><mtext mathvariant="bold">ùüé.ùüó</mtext></mtd><mtd columnalign="center" style="text-align: center"><mn>0.3</mn></mtd><mtd columnalign="center" style="text-align: center"><mn>0.4</mn></mtd><mtd columnalign="center" style="text-align: center"><mn>0.7</mn></mtd></mtr><mtr><mtd columnalign="center" style="text-align: center"><mn>0.2</mn></mtd><mtd columnalign="center" style="text-align: center"><mn>0.5</mn></mtd><mtd columnalign="center" style="text-align: center"><mtext mathvariant="bold">ùüé.ùüñ</mtext></mtd><mtd columnalign="center" style="text-align: center"><mn>0.6</mn></mtd></mtr><mtr><mtd columnalign="center" style="text-align: center"><mn>0.5</mn></mtd><mtd columnalign="center" style="text-align: center"><mn>0.4</mn></mtd><mtd columnalign="center" style="text-align: center"><mn>0.3</mn></mtd><mtd columnalign="center" style="text-align: center"><mtext mathvariant="bold">ùüé.ùüî</mtext></mtd></mtr></mtable><mo stretchy="true" form="postfix">]</mo></mrow></mrow><annotation encoding="application/x-tex">R = \begin{bmatrix}
\textbf{0.7} &amp; 0.3 &amp; 0.5 &amp; 0.2 \\
0.4 &amp; \textbf{0.8} &amp; 0.6 &amp; 0.5 \\
\textbf{0.9} &amp; 0.3 &amp; 0.4 &amp; 0.7 \\
0.2 &amp; 0.5 &amp; \textbf{0.8} &amp; 0.6 \\
0.5 &amp; 0.4 &amp; 0.3 &amp; \textbf{0.6}
\end{bmatrix}</annotation></semantics></math></p>
<p>Using the argmax method, we select the best completion for each prompt:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mo stretchy="false" form="prefix">(</mo><mi>R</mi><mo stretchy="false" form="postfix">)</mo><mo>=</mo><mo stretchy="false" form="prefix">[</mo><mrow><mi mathvariant="normal">arg</mi><mo>&#8289;</mo></mrow><munder><mi mathvariant="normal">max</mi><mi>j</mi></munder><msub><mi>r</mi><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub><mrow><mspace width="0.333em"></mspace><mtext mathvariant="normal"> for </mtext><mspace width="0.333em"></mspace></mrow><mi>i</mi><mo>‚àà</mo><mo stretchy="false" form="prefix">[</mo><mn>1</mn><mo>,</mo><mn>5</mn><mo stretchy="false" form="postfix">]</mo><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">S(R) = [\arg\max_{j} r_{i,j} \text{ for } i \in [1,5]]</annotation></semantics></math></p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mo stretchy="false" form="prefix">(</mo><mi>R</mi><mo stretchy="false" form="postfix">)</mo><mo>=</mo><mo stretchy="false" form="prefix">[</mo><mn>1</mn><mo>,</mo><mn>2</mn><mo>,</mo><mn>1</mn><mo>,</mo><mn>3</mn><mo>,</mo><mn>4</mn><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">S(R) = [1, 2, 1, 3, 4]</annotation></semantics></math></p>
<p>This means we would select:</p>
<ul>
<li>For prompt 1: completion 1 (reward 0.7)</li>
<li>For prompt 2: completion 2 (reward 0.8)</li>
<li>For prompt 3: completion 1 (reward 0.9)</li>
<li>For prompt 4: completion 3 (reward 0.8)</li>
<li>For prompt 5: completion 4 (reward 0.6)</li>
</ul>
<p>Now, <strong>best overall</strong>. Let‚Äôs highlight the top 5 overall completion pairs.</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mo>=</mo><mrow><mo stretchy="true" form="prefix">[</mo><mtable><mtr><mtd columnalign="center" style="text-align: center"><mtext mathvariant="bold">ùüé.ùüï</mtext></mtd><mtd columnalign="center" style="text-align: center"><mn>0.3</mn></mtd><mtd columnalign="center" style="text-align: center"><mn>0.5</mn></mtd><mtd columnalign="center" style="text-align: center"><mn>0.2</mn></mtd></mtr><mtr><mtd columnalign="center" style="text-align: center"><mn>0.4</mn></mtd><mtd columnalign="center" style="text-align: center"><mtext mathvariant="bold">ùüé.ùüñ</mtext></mtd><mtd columnalign="center" style="text-align: center"><mn>0.6</mn></mtd><mtd columnalign="center" style="text-align: center"><mn>0.5</mn></mtd></mtr><mtr><mtd columnalign="center" style="text-align: center"><mtext mathvariant="bold">ùüé.ùüó</mtext></mtd><mtd columnalign="center" style="text-align: center"><mn>0.3</mn></mtd><mtd columnalign="center" style="text-align: center"><mn>0.4</mn></mtd><mtd columnalign="center" style="text-align: center"><mtext mathvariant="bold">ùüé.ùüï</mtext></mtd></mtr><mtr><mtd columnalign="center" style="text-align: center"><mn>0.2</mn></mtd><mtd columnalign="center" style="text-align: center"><mn>0.5</mn></mtd><mtd columnalign="center" style="text-align: center"><mtext mathvariant="bold">ùüé.ùüñ</mtext></mtd><mtd columnalign="center" style="text-align: center"><mn>0.6</mn></mtd></mtr><mtr><mtd columnalign="center" style="text-align: center"><mn>0.5</mn></mtd><mtd columnalign="center" style="text-align: center"><mn>0.4</mn></mtd><mtd columnalign="center" style="text-align: center"><mn>0.3</mn></mtd><mtd columnalign="center" style="text-align: center"><mn>0.6</mn></mtd></mtr></mtable><mo stretchy="true" form="postfix">]</mo></mrow></mrow><annotation encoding="application/x-tex">R = \begin{bmatrix}
\textbf{0.7} &amp; 0.3 &amp; 0.5 &amp; 0.2 \\
0.4 &amp; \textbf{0.8} &amp; 0.6 &amp; 0.5 \\
\textbf{0.9} &amp; 0.3 &amp; 0.4 &amp; \textbf{0.7} \\
0.2 &amp; 0.5 &amp; \textbf{0.8} &amp; 0.6 \\
0.5 &amp; 0.4 &amp; 0.3 &amp; 0.6
\end{bmatrix}</annotation></semantics></math></p>
<p>First, we flatten the reward matrix:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>R</mi><mrow><mi>f</mi><mi>l</mi><mi>a</mi><mi>t</mi></mrow></msub><mo>=</mo><mo stretchy="false" form="prefix">[</mo><mn>0.7</mn><mo>,</mo><mn>0.3</mn><mo>,</mo><mn>0.5</mn><mo>,</mo><mn>0.2</mn><mo>,</mo><mn>0.4</mn><mo>,</mo><mn>0.8</mn><mo>,</mo><mn>0.6</mn><mo>,</mo><mn>0.5</mn><mo>,</mo><mn>0.9</mn><mo>,</mo><mn>0.3</mn><mo>,</mo><mn>0.4</mn><mo>,</mo><mn>0.7</mn><mo>,</mo><mn>0.2</mn><mo>,</mo><mn>0.5</mn><mo>,</mo><mn>0.8</mn><mo>,</mo><mn>0.6</mn><mo>,</mo><mn>0.5</mn><mo>,</mo><mn>0.4</mn><mo>,</mo><mn>0.3</mn><mo>,</mo><mn>0.6</mn><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">R_{flat} = [0.7, 0.3, 0.5, 0.2, 0.4, 0.8, 0.6, 0.5, 0.9, 0.3, 0.4, 0.7, 0.2, 0.5, 0.8, 0.6, 0.5, 0.4, 0.3, 0.6]</annotation></semantics></math></p>
<p>Now, we select the indices of the 5 highest values: <math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>S</mi><mn>5</mn></msub><mo stretchy="false" form="prefix">(</mo><msub><mi>R</mi><mrow><mi>f</mi><mi>l</mi><mi>a</mi><mi>t</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo><mo>=</mo><mo stretchy="false" form="prefix">[</mo><mn>8</mn><mo>,</mo><mn>5</mn><mo>,</mo><mn>14</mn><mo>,</mo><mn>0</mn><mo>,</mo><mn>11</mn><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">S_5(R_{flat}) = [8, 5, 14, 0, 11]</annotation></semantics></math></p>
<p>Mapping these back to our original matrix:</p>
<ul>
<li>Index 8 ‚Üí prompt 3, completion 1 (reward 0.9)</li>
<li>Index 5 ‚Üí prompt 2, completion 2 (reward 0.8)</li>
<li>Index 14 ‚Üí prompt 4, completion 3 (reward 0.8)</li>
<li>Index 0 ‚Üí prompt 1, completion 1 (reward 0.7)</li>
<li>Index 11 ‚Üí prompt 3, completion 4 (reward 0.7)</li>
</ul>
</section>
<section id="implementation-example-2" class="level4">
<h4>Implementation Example</h4>
<p>Here is a code snippet showing how the selection methods could be implemented.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.random.randint(<span class="dv">10</span>, size<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;</span><span class="sc">{</span>x<span class="op">=</span><span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>sorted_indices <span class="op">=</span> np.argsort(x)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>x_sorted <span class="op">=</span> x[sorted_indices]</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;</span><span class="sc">{</span>x_sorted<span class="op">=</span><span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="co"># first way to recover the original array</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>i_rev <span class="op">=</span> np.zeros(<span class="dv">10</span>, dtype<span class="op">=</span><span class="bu">int</span>)</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>i_rev[sorted_indices] <span class="op">=</span> np.arange(<span class="dv">10</span>)</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>np.allclose(x, x_sorted[i_rev])</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="co"># second way to recover the original array</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>np.allclose(x, x_sorted[np.argsort(sorted_indices)])</span></code></pre></div>
</section>
</section>
<section id="fine-tuning" class="level3">
<h3>3. Fine-tuning</h3>
<p>With the selected completions, you then perform standard instruction fine-tuning on the current rendition of the model. More details can be found in the <a href="https://rlhfbook.com/c/instructions">chapter on instruction tuning</a>.</p>
</section>
</section>
<section id="implementation-details" class="level2">
<h2>Implementation Details</h2>
<p>The core hyperparameters for performing this training are very intuitive:</p>
<ul>
<li><strong>Sampling parameters</strong>: Rejection sampling is directly dependent on the completions received from the model. Common settings for rejection sampling include temperatures above zero, e.g.¬†between 0.7 and 1.0, with other modifications to parameters such as top-p or top-k sampling.</li>
<li><strong>Completions per prompt</strong>: Successful implementations of rejection sampling have included 10 to 30 or more completions for each prompt. Using too few completions will make training biased and/or noisy.</li>
<li><strong>Instruction tuning details</strong>: No clear training details for the instruction tuning during rejection sampling have been released. It is likely that they use slightly different settings than the initial instruction tuning phase of the model.</li>
<li><strong>Heterogeneous model generations</strong>: Some implementations of rejection sampling include generations from multiple models rather than just the current model that is going to be trained. Best practices on how to do this are not established.</li>
<li><strong>Reward model training</strong>: The reward model used will heavily impact the final result. For more resources on reward model training, see the <a href="https://rlhfbook.com/c/07-reward-models">relevant chapter</a>.</li>
</ul>
<p>When doing batch reward model inference, you can sort the tokenized completions by length so that the batches are of similar lengths. This eliminates the need to run inference on as many padding tokens and will improve throughput in exchange for minor implementation complexity.</p>
</section>
<section id="related-best-of-n-sampling" class="level2">
<h2>Related: Best-of-N Sampling</h2>
<p>Best-of-N (BoN) is a close relative of rejection sampling, where the same generate-and-score procedure is followed, but you do <strong>not</strong> fine-tune the model on the selected completions. Instead, BoN is a way of computing a best possible completion to a static prompt (or set of prompts) at inference time, and related techniques are often used in ‚ÄúPro‚Äù tiers of chat models that spend extra compute to get an answer to your query.</p>
<p>Best-of-N sampling is often included as a baseline relative to RLHF training methods. It is important to remember that BoN <em>does not</em> modify the underlying model, but is a sampling technique. For this reason, comparisons for BoN sampling to online training methods, such as PPO, are still valid in some contexts. For example, you can still measure the KL distance when running BoN sampling relative to any other policy.</p>
<p>Here, we will show that when using simple BoN sampling over one prompt, both selection criteria shown above are equivalent.</p>
<p>Let R be a reward vector for our single prompt with N completions:</p>
<p><span id="eq:rewards_vector"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mo>=</mo><mo stretchy="false" form="prefix">[</mo><msub><mi>r</mi><mn>1</mn></msub><mo>,</mo><msub><mi>r</mi><mn>2</mn></msub><mo>,</mo><mi>.</mi><mi>.</mi><mi>.</mi><mo>,</mo><msub><mi>r</mi><mi>N</mi></msub><mo stretchy="false" form="postfix">]</mo><mspace width="2.0em"></mspace><mrow><mo stretchy="false" form="prefix">(</mo><mn>31</mn><mo stretchy="false" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">R = [r_1, r_2, ..., r_N]\qquad{(31)}</annotation></semantics></math></span></p>
<p>Where <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>r</mi><mi>j</mi></msub><annotation encoding="application/x-tex">r_j</annotation></semantics></math> represents the reward for the j-th completion.</p>
<p>Using the argmax method, we select the best completion for the prompt:</p>
<p><span id="eq:selection_function"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mo stretchy="false" form="prefix">(</mo><mi>R</mi><mo stretchy="false" form="postfix">)</mo><mo>=</mo><mrow><mi mathvariant="normal">arg</mi><mo>&#8289;</mo></mrow><munder><mi mathvariant="normal">max</mi><mrow><mi>j</mi><mo>‚àà</mo><mo stretchy="false" form="prefix">[</mo><mn>1</mn><mo>,</mo><mi>N</mi><mo stretchy="false" form="postfix">]</mo></mrow></munder><msub><mi>r</mi><mi>j</mi></msub><mspace width="2.0em"></mspace><mrow><mo stretchy="false" form="prefix">(</mo><mn>32</mn><mo stretchy="false" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">S(R) = \arg\max_{j \in [1,N]} r_j\qquad{(32)}</annotation></semantics></math></span></p>
<p>Using the Top-K method with <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">K=1</annotation></semantics></math> reduces to the same method, which is common practice.</p>
</section>
</section>
</body>
</html>
