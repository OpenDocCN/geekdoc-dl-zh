<?xml version="1.0" encoding="utf-8"?><!DOCTYPE html []>
<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops" xml:lang="en" lang="en">
<head>
<title>6 Technology Behind GenAI</title>
<link rel="stylesheet" type="text/css" href="template.css"/></head>
<body epub:type="bodymatter">
<section epub:type="chapter" role="doc-chapter">
<header>
<h1 id="h1"><span epub:type="pagebreak" id="p166" aria-label=" page 166. " role="doc-pagebreak"/><span class="chnum" epub:type="ordinal">6 </span><span class="chtitle">Technology Behind GenAI</span></h1>
<p class="doi">DOI: <a href="https://dx.doi.org/10.4324/9781003459026-6" aria-label="D.O.I. link to this document.">10.4324/9781003459026-6</a></p></header>
<blockquote epub:type="epigraph" role="doc-epigraph">
<p>Big centralised AI models have amazed people. Personal, portable, and secure AI will make everyone amazing.</p>
<p class="byLine"><span epub:type="credit" role="doc-credit">Tom Colloton</span></p></blockquote>
<section epub:type="introduction" role="doc-introduction">
<h2 id="sec6_1"><span epub:type="ordinal">6.1 </span>Introduction</h2>
<p>The aim of this chapter is to equip the reader with a clearer understanding of the technology behind generative Artificial Intelligence (GenAI). While the book primarily focuses on GenAI in higher education, we recognise that some readers may be curious to learn more about the &#x201C;black box&#x201D; of GenAI. Thus, we will delve into its history, processes, methods, and the foundational technology of GenAI. In this exploration, the reader will encounter terminology commonly used in the Artificial Intelligence (AI) field.</p>
<p>In this chapter, we will discuss GenAI models, henceforth referred to simply as &#x2018;models&#x2019; for brevity. It is crucial not to confuse these with other types of models mentioned in the book, such as assessment models. Contemporary GenAI systems predominantly employ deep neural networks (DNN) as the foundational approach for their models. As illustrated in <a href="#fig6_1" id="R_fig6_1">Figure 6.1</a>, DNNs are a type of artificial neural network (ANN). The concept of using artificial neural networks (ANNs) has deep roots in AI, drawing inspiration from studies on the biological brain&#x2019;s functionality. We will delve deeper into this history, providing context leading up to the present-day state-of-the-art models. As illustrated in <a href="#fig6_1">Figure 6.1</a>, GenAI and its various model types, including large language models (LLMs) and text-to-image models like diffusion models, reside within the realm of deep learning ANNs.</p>
<figure id="fig6_1"><img src="images/fig6_1_B.jpg" alt="A I categories include Artificial intelligence, machine learning, artificial neural networks, deep learning, and gen A I which include L L M and text to image."/>
<figcaption><a href="#R_fig6_1" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. "><span epub:type="label">Figure</span> <span epub:type="ordinal">6.1 </span>AI Categorisation.</a></figcaption></figure>
<p><b>Artificial neural networks (ANNs)</b> are computational models inspired by the human brain&#x2019;s structure and function. They consist of interconnected nodes, called neurons, which process and transmit information through weighted connections. ANNs are designed to learn and recognise patterns from input data, making them useful for tasks such as classification, prediction, and decision-making in various fields like computer vision, natural language processing, and robotics. This chapter will delve into the processes and techniques that underpin these capabilities.</p>
<p>The precise mechanisms by which neural networks store experiences and utilise them for predictions remain somewhat enigmatic. This elusive nature has led some to describe their operation as &#x201C;magic&#x201D;, given that the complete intricacies and potential limitations are not yet fully understood. This chapter will try to share what is known and what is not yet understood about how these models work.</p>
<p>This chapter involves examining specific GenAI solutions that are currently popular and widely used. It will delve into these specific examples in detail, while also referencing broader <span epub:type="pagebreak" id="p167" aria-label=" page 167. " role="doc-pagebreak"/>methods. By juxtaposing specific examples with general concepts, we aim to offer non-experts a more insightful perspective than if we merely discussed the topic in general terms.</p>
<p>The chapter is structured in a manner that facilitates a gradual understanding, building later concepts on top of earlier concepts as much as possible. However, some topics are interrelated and require more of an iterative approach rather than a pure serial reading of the information, thus it is advised to read the chapter end to end and then re-read to get a deeper understanding of these concepts that required a more iterative approach.</p>
<p>The structure of the chapter is outlined below:</p>
<ul class="disc">
<li><b>The history</b>. This section looks at the history of artificial neural networks (ANNs), the early work that was done and some of the recent advancements.</li>
<li><b>Creating a model</b>. This section aims to furnish a comprehensive understanding of how a model operates and the processes involved in its creation. It examines the various stages of model creation: from gathering vast quantities of data to considerations in design and structure; the training phase; and testing the model for quality, performance, and safety.</li>
<li><b>Models and ecosystems</b>. This section looks at how models are being used and the ecosystems that have built up around them to allow people to interact with models in different ways and allow the models to interact with their environments.</li>
<li><b>State-of-the-art models</b>. This section aims to provide an overview of some currently popular models considered state-of-the-art. It examines the applications of these models, discusses their design approaches, and comments on their strengths and weaknesses.</li>
<li><b>Conclusions</b>. This section recaps the key points of GenAI and reflects on the current boundaries of its application.</li></ul></section>
<section aria-labelledby="sec6_2">
<h2 id="sec6_2"><span epub:type="ordinal">6.2 </span>The History</h2>
<p>The subsequent sections present the history of artificial neural networks (ANNs) in chronological order. You might encounter terms that have not yet been discussed or elaborated upon, such as the specifics of an artificial neuron or cell, the connectivity within artificial neural networks, the concept of a layer, and the roles of weights and biases. However, these intricacies will be addressed in due course. Initially, our focus will be on providing a <span epub:type="pagebreak" id="p168" aria-label=" page 168. " role="doc-pagebreak"/>chronological overview of how these concepts evolved. Later, we will delve into the particulars, emphasising those aspects that remain pertinent today, all while employing contemporary terminology.</p>
<p>The history of AI research can be understood as an evolving interplay of several distinct approaches or &#x201C;camps&#x201D;. These different approaches often reflected the diverse intellectual backgrounds of AI&#x2019;s founding figures and were influenced by the available technology, prevailing scientific paradigms, and broader societal trends. Two of these camps were the Symbolists and the Connectionists.</p>
<p>The <b>Symbolists</b> believed that intelligence could be attained through the manipulation of symbols and rules. Their methodologies encompassed logic-based systems, rule-based expert systems, and semantic networks. Key figures within this camp included John McCarthy, Marvin Minsky, and Herbert Simon. Their primary focus was on determining how the essential rules of understanding, logic, and reason could be represented within a machine and discerning what these fundamental rules encompassed.</p>
<p>The <b>Connectionists</b> believed that intelligence emerges from interconnected networks of simple units, often referred to as cells or neurons. Their methodologies are exemplified by neural networks and deep neural networks, which include diverse architectures such as RNNs (recurrent neural networks), CNNs (convolutional neural networks), and Transformers. Notable figures within this camp included Frank Rosenblatt, Geoffrey Hinton, Yann LeCun, James Rumelhart, and James McClelland. Their primary focus was on determining how a machine could learn the necessary rules, how to train the said machine, and how to structure its architecture to facilitate learning in a manner as comprehensive as a human.</p>
<p>We discuss these two camps in more detail later.</p>
<p>It is important to recognise that advancements have been made in other areas of AI beyond the scope of this discussion. <a href="#fig6_2" id="R_fig6_2">Figure 6.2</a> illustrates AI&#x2019;s application in gaming; notably, many of these milestones didn&#x2019;t employ ANNs until more recent times. In specific instances, such as checkers, there is debate as to whether an ANN could even match a rule-based approach, especially given that it is considered a &#x2018;solved&#x2019; game. Our primary focus in this context is on ANNs and, consequently, on the types of challenges where ANNs excel, including natural language processing (NLP), image recognition and generation, and certain gaming scenarios. Nonetheless, AI encompasses a vast range of areas, many of which are crucial; however, not all will be discussed here.</p>
<figure id="fig6_2"><img src="images/fig6_2_B.jpg" alt="A timeline from 1947 to 2023 that shows the advances of A I and gaming."/>
<figcaption><a href="#R_fig6_2" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. "><span epub:type="label">Figure</span> <span epub:type="ordinal">6.2 </span>AI and Gaming Timeline.</a></figcaption></figure>
<p>As we embark on a journey through the rich history of Artificial Intelligence (AI), with a keen focus on ANNs, it is important to grasp the evolution of this field in stages. This journey not only simplifies our understanding but also provides a structured lens through which we can appreciate the milestones, challenges, and rapid innovations that AI has undergone. Thus, the history has been broken into three phases.</p>
<ul class="disc">
<li><b>The Genesis Phase (1940s&#x2013;1980s)</b>: This was the birth of AI. During this period, the foundational ideas were laid down. Think of these as the foundational years of AI, where pioneers set the stage, developing the very first algorithms and concepts. Many of the ideas from this era served as the bedrock upon which later innovations were built. See <a href="#fig6_4" id="R_fig6_4">Figure 6.4</a> for key milestones in the Genesis Phase.
<figure id="fig6_3"><img src="images/fig6_3_B.jpg" alt="A timeline from 1947 to 2023 that shows the advances of hardware and another timeline from 1947 to 2033 for A I periods."/>
<figcaption><a href="#R_fig6_3" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. "><span epub:type="label">Figure</span> <span epub:type="ordinal">6.3 </span>AI Periods and Hardware Advances.</a></figcaption></figure>
<figure id="fig6_4"><img src="images/fig6_4_B.jpg" alt="A timeline from 1947 to 1994 about the genesis phase and publications and models."/>
<figcaption><a href="#R_fig6_4" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. "><span epub:type="label">Figure</span> <span epub:type="ordinal">6.4 </span>The Genesis Phase (1940s to1980s) &#x2013; Publications and Models.</a></figcaption></figure></li>
<li><b>The Maturing Phase (1980s&#x2013;2010s)</b>: After its birth, AI went through a phase of growth and maturation. During this period, the foundational ideas from the genesis phase were refined, expanded, and implemented in various applications. The concepts became <span epub:type="pagebreak" id="p169" aria-label=" page 169. Figure on this page. " role="doc-pagebreak"/><span epub:type="pagebreak" id="p170" aria-label=" page 170. " role="doc-pagebreak"/>clearer, and the tools more sophisticated. It was a time of exploration, consolidation, and practical application. See <a href="#fig6_5" id="R_fig6_5">Figure 6.5</a> for key milestones in the Maturing Phase.
<figure id="fig6_5"><img src="images/fig6_5_B.jpg" alt="A timeline from 1980 to 2010 about the maturing phase and publications and models."/>
<figcaption><a href="#R_fig6_5" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. "><span epub:type="label">Figure</span> <span epub:type="ordinal">6.5 </span>The Maturing Phase (1980s to 2010s) &#x2013; Publications and Models.</a></figcaption></figure></li>
<li><b>The Acceleration Phase (2010s&#x2013;2030s)</b>: Entering the current era, we see an explosion in AI capabilities and applications. Thanks to advances in computational power, data availability, and refined algorithms, AI, especially ANNs, is now evolving at an unprecedented rate and we expect this to continue for some considerable time. This phase captures the whirlwind of innovation, and the transformative impact AI is having on nearly every facet of our lives. At the end of this phase, we expect that AI will have been integrated and adopted into society. It is not clear what that picture will look like, but the anticipation of this future drives current research and application efforts. For more on what the future may look like, we invite you to read <a href="ch7.xhtml">Chapter 7</a> on some of our predictions. See <a href="#fig6_6" id="R_fig6_6">Figure 6.6</a> for key milestones in the Acceleration Phase.
<figure id="fig6_6"><img src="images/fig6_6_B.jpg" alt="A timeline from 2010 to 2023 about the acceleration phase and publications and models."/>
<figcaption><a href="#R_fig6_6" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. "><span epub:type="label">Figure</span> <span epub:type="ordinal">6.6 </span>The Acceleration Phase (2010s to 2030s) &#x2013; Publications and Models.</a></figcaption></figure></li></ul>
<p>By breaking down the history of AI and ANNs into these three distinct phases, readers will find it easier to digest the information, understand the context of current AI developments, and quickly reference the most recent and relevant advancements that shape our daily interactions with technology.</p>
<p><a href="#fig6_3" id="R_fig6_3">Figure 6.3</a> helps depict these phases and how they relate to commonly referred to periods in AI history such as the AI winters and AI boom periods. It also highlights some of the key hardware advancements that have facilitated progress in the field. These phases will be discussed in the respective sections below.</p>
<p>As we delve deeper into each phase, we will uncover the stories, the challenges, the breakthroughs, and the visionaries that have made AI the formidable force it is today.</p>
<section aria-labelledby="sec6_2_1">
<h3 id="sec6_2_1"><span epub:type="ordinal">6.2.1 </span>The Genesis Phase (1940s&#x2013;1980s)</h3>
<section aria-labelledby="sec6_2_1_1">
<h4 id="sec6_2_1_1"><span epub:type="ordinal">6.2.1.1 </span>New Fields of Study</h4>
<p>In the earliest days of AI, there was a desire to build machines that could solve problems by learning, similar to how the brain works. This approach was fundamentally different from explicitly programming a machine to solve a specific problem. To build these machines, scientists studied animal brains to understand their biological models. This can be seen in the work by <a href="#ref6_42" id="R_ref6_42" epub:type="biblioref" role="doc-biblioref">McCulloch and Pitts (1943)</a> on modelling a neuron, and in the work by <a href="#ref6_24" id="R_ref6_24" epub:type="biblioref" role="doc-biblioref">Hebb (1949)</a> on Hebbian Learning. These works, along with contributions from others in the fields of neurophysiology and psychology, were used by those in the fields of Mathematics, Statistical Theory, Information Science, and Computer Science (both Information Science and Computer Science were in their infancy at this point).</p>
<p>Given the availability of these biological models and the extensive research conducted in these areas, it might have seemed reasonable to anticipate swift solutions to problems that explicit programming struggled with, such as pattern recognition, reasoning, and the understanding and use of language.</p></section>
<section aria-labelledby="sec6_2_1_2">
<h4 id="sec6_2_1_2"><span epub:type="ordinal">6.2.1.2 </span>The Symbolists</h4>
<p>In 1955, McCarthy, along with Marvin Minsky, Nathaniel Rochester, and Claude Shannon, penned a proposal for a workshop to be held at Dartmouth College in the summer of 1956. The primary objective of this workshop was as follows<span epub:type="pagebreak" id="p171" aria-label=" page 171. Figure on this page. " role="doc-pagebreak"/>:</p>
<blockquote>
<p><span epub:type="pagebreak" id="p172" aria-label=" page 172. " role="doc-pagebreak"/>An attempt will be made to find how to make machines use language, form abstractions, and concepts, solve kinds of problems now reserved for humans, and improve themselves.</p>
<p class="byLine"><span epub:type="credit" role="doc-credit">(<a href="#ref6_40" id="R_ref6_40" epub:type="biblioref" role="doc-biblioref">McCarthy et al., 1955</a>, p. 1)</span></p></blockquote>
<p>This workshop is widely regarded as the birth of AI as a formal academic discipline. The Dartmouth workshop was the first occasion where the term &#x201C;artificial intelligence&#x201D; was used, a term coined by McCarthy himself.</p>
<p>The optimism of the Dartmouth attendees was high. They genuinely believed that with a dedicated effort over the summer, they could make significant inroads into achieving machine intelligence. This is partly a reflection of the overall optimism about technology and computing that pervaded the 1950s. They thought that the available computational capacity should be sufficient for their tasks. Their main challenge, as they saw it, was the need to develop appropriate algorithms and program instructions to guide the machines.</p>
<p>The group was heavily influenced by what later became known as the &#x201C;Symbolist&#x201D; school of AI. As mentioned, Symbolists believed that intelligence arises from the manipulation of symbols and that it can be achieved through rule-based systems and formal reasoning. This was in stark contrast to other paradigms, such as the Connectionist approach that sought to replicate neural networks and the evolutionary approach that took inspiration from Darwinian processes.</p>
<p>This Symbolist approach is reflected in early AI projects like the Logic Theorist and General Problem Solver, which aimed to simulate human problem-solving capabilities through symbolic manipulations.</p>
<p><span epub:type="pagebreak" id="p173" aria-label=" page 173. " role="doc-pagebreak"/>In hindsight, while the Dartmouth workshop didn&#x2019;t achieve its lofty goals within a single summer, it marked the beginning of a new and transformative field. The event catalysed research and set the direction for AI for many years. Even though we now recognise the challenges in achieving human-like AI are more complex than McCarthy and his colleagues initially imagined, their vision, ambition, and foundational work laid the groundwork for the field of AI.</p></section>
<section aria-labelledby="sec6_2_1_3">
<h4 id="sec6_2_1_3"><span epub:type="ordinal">6.2.1.3 </span>The Connectionists</h4>
<p>Connectionists of AI, often associated with the development and study of Artificial Neural Networks (ANNs), take inspiration from the human brain&#x2019;s intricate web of neurons to design computational models. These models aim to emulate the brain&#x2019;s ability to recognise patterns, process information, and learn from experiences. Unlike traditional symbolic AI, which relies on explicit rules to make decisions, Connectionism adopts a bottom-up approach. By adjusting the connections (or weights) between a myriad of simple processing nodes (akin to neurons), Connectionists believe that complex cognition can emerge organically. Since their inception, ANNs and the Connectionist paradigm have faced waves of both enthusiasm and skepticism. However, with advancements in computational power and algorithmic techniques in recent decades, Connectionism has become central to many of AI&#x2019;s most groundbreaking achievements, particularly in deep learning and areas such as image and speech recognition.</p>
<p>In the early days of Artificial Intelligence, there was a promising glimmer on the horizon, a belief that &#x2018;neuron nets&#x2019; might just hold the answer to some of AI&#x2019;s most perplexing questions. Among these was the intriguing query, &#x201C;How can a set of hypothetical neurons be arranged to form concepts?&#x201D; Scholars like Uttley, Rashevsky and his ensemble, the duo Farley and Clark, and pioneers like Pitts, McCulloch, Minsky, Rochester, and Holland, were all engrossed in deciphering this enigma. Despite their vast and varied contributions, the consensus remained: the field desperately needed more theoretical depth (<a href="#ref6_40" epub:type="biblioref" role="doc-biblioref">McCarthy et al., 1955</a>).</p>
<p>The legacy of artificial neural networks (ANNs) is deeply intertwined with AI&#x2019;s history. These networks, which might seem contemporary, have been the bedrock of AI research since its inception. The landmark Dartmouth summer project was indeed a milestone, but even before this event, McCulloch and his colleagues had ventured into the neural realms. Their 1943 publication, &#x2018;A logical calculus of the ideas immanent in nervous activity&#x2019; (<a href="#ref6_42" epub:type="biblioref" role="doc-biblioref">McCulloch et al., 1943</a>), presented an avant-garde notion: neurons could be emulated using simplistic switches, which when networked in unique arrangements, could replicate the logic of a Turing machine.</p>
<p>However, it wasn&#x2019;t until 1958 that the perceptron, a term now synonymous with AI, was born. In 1958, Frank Rosenblatt wrote about it in his paper (<a href="#ref6_58" id="R_ref6_58" epub:type="biblioref" role="doc-biblioref">Rosenblatt, 1958</a>). Think of it like a mini-brain with different parts working together, similar to modern ANNs. This mini-brain had different types of units, known as S-units, A-units, and R-units, which formed a basic two-layer network. Though at the time, people saw it as a &#x2018;three-layered network&#x2019;. Rosenblatt called it &#x2018;photoperceptron&#x2019;, and it was designed to recognise objects in photos, like circles and rectangles (<a href="#ref6_57" id="R_ref6_57" epub:type="biblioref" role="doc-biblioref">Rosenblatt, 1957</a>).</p>
<p>The 1960s saw the perceptron&#x2019;s blueprint being taken and expanded upon. Widrow and Hoff birthed ADALINE (<a href="#ref6_81" id="R_ref6_81" epub:type="biblioref" role="doc-biblioref">Widrow, 1960</a>) and MADALINE (<a href="#ref6_82" id="R_ref6_82" epub:type="biblioref" role="doc-biblioref">Widrow, 1962</a>), employing novel algorithms to fine-tune weights and biases, laying the foundation for modern feed forward networks. Block and team (<a href="#ref6_8" id="R_ref6_8" epub:type="biblioref" role="doc-biblioref">Block et al., 1962</a>) added a layer to the perceptron <span epub:type="pagebreak" id="p174" aria-label=" page 174. " role="doc-pagebreak"/>model, propelling it into the realm of deep neural networks. Their model aimed for more extensive image classification, however, training this improved network was tough because there weren&#x2019;t yet good methods to correct errors in multi-layer networks.</p>
<p>In 1969, however, a cautionary tale emerged. Minsky and others published &#x201C;Perceptrons: An introduction to computational geometry&#x201D; (<a href="#ref6_45" id="R_ref6_45" epub:type="biblioref" role="doc-biblioref">Minsky &#x0026; Papert, 1988</a>), highlighting the perceptron&#x2019;s mathematical limitations. The book particularly scrutinised the single-layer perceptron and expressed skepticism about its potential in resolving intricate challenges.</p>
<p>In 1985, Rumelhart and his team introduced a new technique that helped teach multi-layered machines. This method, which corrected mistakes as it learned, opened the door for what we call deep learning. Still, we didn&#x2019;t have the powerful computers needed to fully use this new technique. It is worth noting that Paul Werbos&#x2019; earlier doctoral dissertation (<a href="#ref6_80" id="R_ref6_80" epub:type="biblioref" role="doc-biblioref">Werbos, 1974</a>) had pre-empted Rumelhart&#x2019;s work, laying the groundwork for backpropagation.</p>
<p>Intriguingly, Minsky and Papert, in an extended edition of their earlier book (<a href="#ref6_45" epub:type="biblioref" role="doc-biblioref">Minsky &#x0026; Papert, 1988</a>), critically reviewed advances like those made by Rumelhart and McClelland. Despite acknowledging progress, they felt the claims, especially those surrounding the efficiency of gradient descent and the generalised delta rule, were overstated. The debates and differences of opinion serve as reminders of the cautious notes sounded by thinkers like Weizenbaum in the 1970s (see the next section on philosophical concerns), warning against getting too excited too soon.</p>
<p>Over time, even with advances like this new teaching method, backpropagation, the big hopes for ANNs started to fade. This led to periods known as &#x2018;AI winters&#x2019; where people lost interest and didn&#x2019;t invest much in AI. But, as always, after a cold period of winter, things tend to warm up again in spring.</p></section>
<section aria-labelledby="sec6_2_1_4">
<h4 id="sec6_2_1_4"><span epub:type="ordinal">6.2.1.4 </span>Philosophical and Ethical Considerations</h4>
<section aria-labelledby="sec6_2_1_4_1">
<h5 id="sec6_2_1_4_1"><span epub:type="ordinal">6.2.1.4.1 </span>The Turing Test &#x2013; Alan Turing</h5>
<p>Philosophical questions concerning the ability of machines to think emerged in these early days. In 1950, Alan Turing addressed this in his paper, &#x201C;Computing Machinery and Intelligence&#x201D; (<a href="#ref6_73" id="R_ref6_73" epub:type="biblioref" role="doc-biblioref">Turing, 1950</a>). Instead of directly asking &#x201C;can machines think?&#x201D;, Turing proposed an alternative method. He suggested a game, which he named &#x201C;The Imitation Game&#x201D;. This game measured the likelihood of a machine deceiving an interrogator against the probability of a real person doing the same, relying solely on written communications in a question-and-answer format. This challenge subsequently became renowned as the Turing test.</p></section>
<section aria-labelledby="sec6_2_1_4_2">
<h5 id="sec6_2_1_4_2"><span epub:type="ordinal">6.2.1.4.2 </span>Three Laws of Robotics &#x2013; Isaac Asimov</h5>
<p>In a related development around the ethical considerations regarding machine intelligence, Isaac Asimov &#x2013; a science fiction writer and professor of biochemistry &#x2013; developed the &#x201C;Three Laws of Robotics&#x201D; in 1942. These were featured in his short story &#x201C;Runaround&#x201D;, which formed part of the &#x201C;I, Robot&#x201D; series (<a href="#ref6_4" id="R_ref6_4" epub:type="biblioref" role="doc-biblioref">Asimov, 1950</a>), as mentioned in <a href="ch5.xhtml">Chapter 5</a>.</p>
<ol type="1">
<li>A robot may not injure a human being, or, through inaction, allow a human being to come to harm.</li>
<li>A robot must obey the orders given it by human beings except where such orders would conflict with the First Law.</li>
<li><span epub:type="pagebreak" id="p175" aria-label=" page 175. " role="doc-pagebreak"/>A robot must protect its own existence as long as such protection does not conflict with the First or Second Laws.</li></ol></section>
<section aria-labelledby="sec6_2_1_4_3">
<h5 id="sec6_2_1_4_3"><span epub:type="ordinal">6.2.1.4.3 </span>Computer Power and Human Reason &#x2013; Joseph Weizenbaum</h5>
<p>Joseph Weizenbaum, the creator of the ELIZA chatbot and author of <i>Computer Power and Human Reason: From Judgment to Calculation</i> (<a href="#ref6_78" id="R_ref6_78" epub:type="biblioref" role="doc-biblioref">1976</a>), grew increasingly wary of the expanding influence of computer technology. He argued that machines shouldn&#x2019;t handle tasks needing genuine compassion, emphasising their inability to exercise human judgement and distinguishing between mere decision-making and genuine choice.</p>
<p>During the 1970s, skepticism about computers replicating human thought was prevalent. Many felt that the AI community had made overly ambitious promises. In his book, Weizenbaum delved into the overhyped expectations of AI and the unsettling emotional bonds people formed with AI systems. He also expressed concerns about society&#x2019;s growing dependency on technology. As we will see, these ambitious claims would continue to be a major topic of debate in the AI world.</p></section>
<section aria-labelledby="sec6_2_1_4_4">
<h5 id="sec6_2_1_4_4"><span epub:type="ordinal">6.2.1.4.4 </span>Father of Cybernetics &#x2013; Norbert Wiener</h5>
<p>Furthermore, Norbert Wiener, often referred to as the &#x201C;father of cybernetics&#x201D;, expressed concerns about the potential for automation to lead to unintended consequences in his work &#x201C;God &#x0026; Golem, Inc.: A Comment on Certain Points where Cybernetics Impinges on Religion&#x201D; (<a href="#ref6_83" id="R_ref6_83" epub:type="biblioref" role="doc-biblioref">Wiener, 1966</a>) He posited that once we can effectively replicate human decision-making processes, extreme caution is imperative in managing these innovations. To illustrate, he drew upon the tale of &#x2018;The Monkey&#x2019;s Paw&#x2019;, highlighting how wielding power without full comprehension could result in catastrophic outcomes.</p>
<p>From the 1940s to the 1980s, the field of AI embarked on an exhilarating journey, laying the bedrock upon which future innovations would thrive. The essence of ANNs drew inspiration from the intricate webs of neurons in our brains, thanks to the pioneering work of individuals like McCulloch and Pitts. As the decades progressed, this biological inspiration was interwoven with a fabric of mathematical and statistical rigour, establishing proofs and formulas that defined how artificial neurons would interact and collaborate within networks. By the 1980s, this foundational work bore fruit in the form of breakthrough learning techniques like backpropagation and gradient descent. These mechanisms optimised the training of ANNs, equipping them with the capability to refine their performance and solve complex problems. Alongside these technical advancements, the era was also marked by deep philosophical introspection, questioning the boundaries of AI, its relation to consciousness, and the ethics surrounding its potential. By the close of the 1980s, the AI landscape had been primed with the necessary fundamentals, ready for the transformations that would follow including the concept of the quantum computer such as those discussed by Richard Feynman (<a href="#ref6_17" id="R_ref6_17" epub:type="biblioref" role="doc-biblioref">Feynman, 1982</a>) that are perhaps a still long way off from delivering their benefits to AI.</p></section></section></section>
<section aria-labelledby="sec6_2_2">
<h3 id="sec6_2_2"><span epub:type="ordinal">6.2.2 </span>The Maturing Phase (1980s to 2010s)</h3>
<p>In the span between the 1980s and 2010s, ANNs experienced both challenges and pivotal advancements. Initial enthusiasm for ANNs had diminished due to persistent issues like the vanishing gradient problem, but the 1980s brought about key innovations that would later be instrumental for the field&#x2019;s revival.<span epub:type="pagebreak" id="p176" aria-label=" page 176. Figure on this page. " role="doc-pagebreak"/></p>
<p><span epub:type="pagebreak" id="p177" aria-label=" page 177. " role="doc-pagebreak"/>The introduction of the backpropagation algorithm by Rumelhart, Hinton, and Williams in 1986 was a seminal moment (Rumelhart et al., <a href="#ref6_61" id="R_ref6_61" epub:type="biblioref" role="doc-biblioref">1986a</a>, <a href="#ref6_62" id="R_ref6_62" epub:type="biblioref" role="doc-biblioref">1986b</a>, <a href="#ref6_63" id="R_ref6_63" epub:type="biblioref" role="doc-biblioref">1986c</a>). This algorithm optimised the weights in multi-layer perceptrons, sparking renewed interest and research in ANNs. Following this, the torchbearers of the field, namely LeCun, Bengio, and Hinton, made significant contributions. Their efforts during this phase laid the foundation for deep learning and the transformative changes of the next era (<a href="#ref6_22" id="R_ref6_22" epub:type="biblioref" role="doc-biblioref">Goodfellow et al., 2016</a>).</p>
<p>In the 1990s, there were important developments in using neural networks. Researchers found ways to use them for complex data analysis (<a href="#ref6_9" id="R_ref6_9" epub:type="biblioref" role="doc-biblioref">Breiman, 2001</a>), to simplify data by reducing its complexity (<a href="#ref6_27" id="R_ref6_27" epub:type="biblioref" role="doc-biblioref">Hinton et al., 2006</a>), and to improve algorithms for better performance (<a href="#ref6_18" id="R_ref6_18" epub:type="biblioref" role="doc-biblioref">Friedman, 2002</a>). They also developed new techniques for training and managing neural networks, like energy-based models (<a href="#ref6_1" id="R_ref6_1" epub:type="biblioref" role="doc-biblioref">Ackley et al., 1985</a>), and introduced new types of neural cells, such as long short-term memory (LSTM), to solve problems with gradients (<a href="#ref6_28" id="R_ref6_28" epub:type="biblioref" role="doc-biblioref">Hochreiter &#x0026; Schmidhuber, 1997</a>). Additionally, researchers gained a better understanding of Support Vector Machines (SVM) and kernel methods, which improved the creation of robust predictive models (<a href="#ref6_75" id="R_ref6_75" epub:type="biblioref" role="doc-biblioref">Wahba et al., 2002</a>). With innovations like LeCun&#x2019;s convolutional neural networks (CNNs) for image recognition (<a href="#ref6_37" id="R_ref6_37" epub:type="biblioref" role="doc-biblioref">LeCun et al., 1989</a>) and the advent of recurrent neural networks (RNNs) for sequential data (<a href="#ref6_28" epub:type="biblioref" role="doc-biblioref">Hochreiter &#x0026; Schmidhuber, 1997</a>), the vast potential of ANNs was increasingly realised.</p>
<p>However, the full potential of deep ANNs was hampered by computational restraints and the scarcity of comprehensive labelled datasets. Despite these hurdles, the maturing phase was crucial in embedding the importance of ANNs and setting the groundwork for the momentous progress of the acceleration phase that would follow.</p></section>
<section aria-labelledby="sec6_2_3">
<h3 id="sec6_2_3"><span epub:type="ordinal">6.2.3 </span>The Acceleration Phase (2010s to 2030s)</h3>
<p>The early 2010s marked a monumental shift for ANNs with developments powered by larger datasets, increased computational capabilities - particularly from GPUs, and innovative algorithms. One notable paper in this regard was &#x201C;Building High-level Features Using Large Scale Unsupervised Learning&#x201D; by Le et al., which showcased the strength of refined algorithms in propelling ANNs&#x2019; capabilities (<a href="#ref6_36" id="R_ref6_36" epub:type="biblioref" role="doc-biblioref">Le et al., 2011</a>).</p>
<p>The subfield of deep learning, an advanced application of ANNs, took centre stage during this period. Esteemed figures like Geoffrey Hinton, Yann LeCun, and Yoshua Bengio were instrumental in these evolutions (<a href="#ref6_22" epub:type="biblioref" role="doc-biblioref">Goodfellow et al., 2016</a>). A groundbreaking moment occurred with the creation of AlexNet, a convolutional neural network (CNN) designed by Alex Krizhevsky under Geoffrey Hinton&#x2019;s guidance. In 2012, AlexNet achieved unmatched performance in the ImageNet competition, a benchmark in image recognition, marking what many called the &#x201C;ImageNet moment&#x201D; (<a href="#ref6_33" id="R_ref6_33" epub:type="biblioref" role="doc-biblioref">Krizhevsky et al., 2012</a>).</p>
<p>Such triumphs galvanised the broader tech industry. Companies like Google and Facebook not only adopted but also significantly contributed to ANN research. For instance, Google&#x2019;s approach to recommendation systems was articulated in &#x201C;Wide &#x0026; Deep Learning for Recommender Systems&#x201D; (<a href="#ref6_12" id="R_ref6_12" epub:type="biblioref" role="doc-biblioref">Cheng et al., 2016</a>), while Facebook advanced text understanding and user modelling through ANNs, as evidenced by their studies (<a href="#ref6_31" id="R_ref6_31" epub:type="biblioref" role="doc-biblioref">Joulin et al., 2016</a>; <a href="#ref6_32" id="R_ref6_32" epub:type="biblioref" role="doc-biblioref">Kaur et al., 2021</a>).</p>
<p>As the decade progressed, ANNs&#x2019; applications diversified. Recurrent neural networks (RNNs), and particularly their evolved form, long short-term memory networks (LSTMs), became the go-to for handling sequential data, finding applications in natural language processing and time-series analysis (<a href="#ref6_28" epub:type="biblioref" role="doc-biblioref">Hochreiter et al., 1997</a>). In parallel, generative <span epub:type="pagebreak" id="p178" aria-label=" page 178. Figure on this page. " role="doc-pagebreak"/><span epub:type="pagebreak" id="p179" aria-label=" page 179. " role="doc-pagebreak"/>adversarial networks (GANs), introduced by Ian Goodfellow, transformed generative models, enabling feats like image synthesis and style transfer (<a href="#ref6_23" id="R_ref6_23" epub:type="biblioref" role="doc-biblioref">Goodfellow et al., 2014</a>).</p>
<p>By the late 2010s, the introduction of transformer architectures, like the one described in the &#x201C;Attention Is All You Need&#x201D; paper, signalled another paradigm shift, especially in NLP. This paper served as a bedrock for models such as BERT and GPT variants, including OpenAI&#x2019;s ChatGPT-3.5 and GPT 4.0, redefining text comprehension and generation (<a href="#ref6_74" id="R_ref6_74" epub:type="biblioref" role="doc-biblioref">Vaswani et al., 2017</a>).</p>
<p>With the dawn of the 2020s, the drive behind ANNs only intensified. Breakthroughs in areas like few-shot learning and self-supervised learning signalled the continuous advancement of the field. Yet, as AI capabilities surged, so did ethical and societal concerns. These concerns were highlighted in March 2023 open letter from the Future of Life Institute, urging a pause on the development of models more advanced than GPT-4, underlining the need for a more reflective approach to AI&#x2019;s rapid advancement (Future of Life Institute, <a href="#ref6_19" id="R_ref6_19" epub:type="biblioref" role="doc-biblioref">2023a</a>, <a href="#ref6_20" id="R_ref6_20" epub:type="biblioref" role="doc-biblioref">2023b</a>).</p>
<p>While the path towards artificial general intelligence (AGI) or even artificial super intelligence (ASI) remains debated, what is unequivocal is the transformative role of AI will have on society and humanity. In addition, this transformative role is likely to be further compounded by future advancements. Echoing Richard Feynman&#x2019;s proposition, quantum computers might surpass classical computers in simulating complex systems (<a href="#ref6_17" epub:type="biblioref" role="doc-biblioref">Feynman, 1982</a>), potentially steering AI into its next epoch. Indeed, milestones like achieving quantum supremacy, where quantum devices outpace their classical counterparts, hint at a future where the bounds of AI&#x2019;s potential could be redefined (<a href="#ref6_3" id="R_ref6_3" epub:type="biblioref" role="doc-biblioref">Arute et al., 2019</a>).</p></section></section>
<section aria-labelledby="sec6_3">
<h2 id="sec6_3"><span epub:type="ordinal">6.3 </span>Creating a Model</h2>
<p>Now that we have covered the history of ANNs in some detail, we will turn our attention to the process of creating a GenAI model. This discussion will focus on recent approaches and will delve deeper into the terminology and advances previously outlined in the historical overview. As we delve into the creation and comprehension of models, you will recognise some of the key people and advances mentioned in the earlier history section.</p>
<p><a href="#fig6_7" id="R_fig6_7">Figure 6.7</a> illustrates the essential steps in creating a model. This process encompasses both the training and the testing of a foundational model, followed by its fine-tuning. A foundational model is an initial, untrained model with a generic purpose (i.e.) to learn from data. Many foundational models undergo fine-tuning for specific applications. For instance, the LLaMA-2 (Large Language Model Meta AI) foundational model was fine-tuned for chat functionality, resulting in the finely-tuned model known as LLaMA-2-chat. This fine-tuning involves further training of the foundational model on specific data to serve a more specialised purpose, such as functioning as a chatbot to answer user queries or engage in conversations with users.</p>
<figure id="fig6_7"><img src="images/fig6_7_B.jpg" alt="A model which shows the larger picture about creating a model."/>
<figcaption><a href="#R_fig6_7" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. "><span epub:type="label">Figure</span> <span epub:type="ordinal">6.7 </span>Creating a Model &#x2013; The Big Picture.</a></figcaption></figure>
<p>The steps involved in creating a model are:</p>
<ol class="decimal">
<li>
<p>The Training Data</p>
<ol class="lower-alpha">
<li>Data Gathering and Preparation</li>
<li>Dataset Customisation</li></ol></li>
<li>
<p>The Foundation Model</p>
<ol class="lower-alpha">
<li>Model Design and Structuring</li>
<li>Model Training</li>
<li>Model Testing<span epub:type="pagebreak" id="p180" aria-label=" page 180. Figure on this page. " role="doc-pagebreak"/></li></ol></li>
<li><span epub:type="pagebreak" id="p181" aria-label=" page 181. " role="doc-pagebreak"/>
<p>The Fine-Tuning</p>
<ol class="lower-alpha">
<li>Fine-Tuning Data Set Customisation</li>
<li>Model Fine-Tuning Training</li>
<li>Model Testing</li></ol></li>
<li>
<p>The Deployment and Use</p>
<ol class="lower-alpha">
<li>Model Deployment</li>
<li>Model Monitoring</li>
<li>Model Use (aka inference)</li></ol></li></ol>
<p>Fine-tuning can employ a variety of training techniques, including reinforcement learning with human feedback (RLHF), which will be discussed below. The following sections will cover each of these areas to provide an understanding of what is involved.</p>
<section aria-labelledby="sec6_3_1">
<h3 id="sec6_3_1"><span epub:type="ordinal">6.3.1 </span>The Training Data</h3>
<p>The initial step in the comprehensive model creation process is data gathering and preparation. Modern deep neural networks (DNNs), especially large language models (LLMs), require vast amounts of training data. While several well-known data sources are available, some companies maintain their own unique repositories. Prominent entities such as Meta, Google, and Microsoft possess vast amounts of data, owing to the diverse services they offer. Meanwhile, companies like OpenAI have ventured into developing their own data-sourcing solutions, such as the web crawling tool, GPTbot, which gathers publicly accessible data from the web for OpenAI.</p>
<p>After the initial acquisition, the dataset might be further refined to improve quality or to better align with the desired outcomes of a particular model. The processes of gathering and preparation often intertwine with dataset customisation, especially when an organisation sources its data directly, rather than relying on externally provided datasets.</p>
<p>It is crucial to acknowledge the complexity and sophistication inherent in the data gathering, preparation, and customisation phases. To provide a clearer understanding of these processes, they will be explored in more depth using several widely utilised data sources as examples.</p>
<section aria-labelledby="sec6_3_1_1">
<h4 id="sec6_3_1_1"><span epub:type="ordinal">6.3.1.1 </span>Text Data &#x2013; Common Crawl</h4>
<p>Common Crawl (see <a href="https://commoncrawl.org">https://commoncrawl.org/</a>) (<a href="#ref6_49" id="R_ref6_49" epub:type="biblioref" role="doc-biblioref">Patel, 2020</a>) is an organisation that offers data dumps from billions of web pages on a regular basis, typically 6 to 12 times per year. While it has some data from as far back as 2008, there have been more consistent outputs since 2011. Common Crawl employs a tool known as a spider bot to access the content of web pages. A spider bot starts with a list of URLs and retrieves the content of these web pages. Additionally, it can identify other URLs within a web page (i.e., links to different sites) and pursue these links to access those pages. For each page accessed, the spider bot saves the content and recognises other links to pursue, expanding outwards much like a spider&#x2019;s web to encompass other URLs.</p>
<p>The CCBot, commonly referred to as the Common Crawl spider bot, processes a candidate database of URLs for each iteration. It updates this database with new URLs based on its findings during the crawl. While the set of URLs is expansive, they are not rigorously reviewed, organised, or managed. As a result, the quality of the data obtained can vary <span epub:type="pagebreak" id="p182" aria-label=" page 182. " role="doc-pagebreak"/>significantly, encompassing content in multiple languages. Surprisingly, there is a minimal overlap between the outputs of one crawl and the next. For instance, the overlap between the data dumps from February 2023 and June 2023 is only around 1% (see <a href="https://commoncrawl.github.io">https://commoncrawl.github.io/cc-crawl-statistics/plots/crawloverlap</a>).</p>
<p>The volume of data provided in each release is indeed staggering. For example, the June 2023 release (CC-MAIN-2023-23) comprises 100 segments. Each segment contains 800 files for WARC (approximately 1.1 GB compressed), WAT (around 285 MB compressed), and WET (roughly 115 MB compressed) formats. Including various metadata, the total size of the June 2023 release is about 120 TB when compressed. The compression ratio for text data is favourable, ranging from 3 to 5 times, which results in an uncompressed size of approximately 580 TB. However, not all users will need every format. Some might focus only on the WET format (plaintext), which alone amounts to about 26 TB when uncompressed.</p>
<p>The output from Common Crawl varies in both content and quality. When training a large language model (LLM), this data undergoes further processing and cleaning to enhance its quality. Specialised tools, such as CCNet (<a href="#ref6_79" id="R_ref6_79" epub:type="biblioref" role="doc-biblioref">Wenzek et al., 2019</a>), have been designed to help with this, especially when dealing with outputs like those from Common Crawl. For instance, these tools can restructure the files, decompress them, and divide them into shards. Each web page entry is then housed in a specifically formatted &#x2018;json&#x2019; file. Data deduplication occurs at the paragraph level, and language detection is performed, enabling the sorting of different languages into separate datasets. Some of these steps are complex. Take the language detection feature as an example: it uses another language model, fastText (<a href="https://fasttext.cc">https://fasttext.cc/</a>), which is pre-trained on alternative data sources like Wikipedia, Tatoeba, and SETimes, to identify the language of the Common Crawl output. <a href="#fig6_8" id="R_fig6_8">Figure 6.8</a> showcases the intricacy of the data gathering and post-processing stages.</p>
<figure id="fig6_8"><img src="images/fig6_8_B.jpg" alt="A flowchart like diagram that shows the processes in the data gathering and customisation pipeline."/>
<figcaption><a href="#R_fig6_8" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. "><span epub:type="label">Figure</span> <span epub:type="ordinal">6.8 </span>Data Gathering and Customisation Pipeline.</a></figcaption></figure>
<p>It does not end there; further processing by other models is also possible. For instance, data quality can be assessed, and, based on the quality score, specific data can either be retained or removed from the dataset. One model employed in this manner is the 5-gram Kneser-Ney model, which utilises a perplexity measure to compare the input from Common Crawl with another source deemed of higher quality, such as Wikipedia.</p>
<p>The perplexity is a measure of the predictability of the text within a specific paragraph. The higher the perplexity, the more surprised (or perplexed) the model becomes, suggesting a lower quality in this data customisation pipeline. If the perplexity surpasses a certain threshold for a given paragraph, that paragraph may be removed from the dataset with the aim of enhancing the overall quality of the dataset. You may recall that Perplexity is also used for GenAI text detection in <a href="ch4.xhtml#sec4_7">Section 4.7</a>.</p>
<p>Given the vast volume of data involved, the necessity to execute complex tasks like these pre-processing models, and the fact that the customisation processes operate on specialised data processing environments requiring significant expertise to build and manage, the cost of undertaking this task is considerable.</p></section>
<section aria-labelledby="sec6_3_1_2">
<h4 id="sec6_3_1_2"><span epub:type="ordinal">6.3.1.2 </span>Text Data &#x2013; Colossal Clean Crawled Corpus (C4)</h4>
<p>The Colossal Clean Crawled Corpus (C4) dataset is derived from dumps provided by Common Crawl (<a href="#ref6_54" id="R_ref6_54" epub:type="biblioref" role="doc-biblioref">Raffel et al., 2023</a>). This dataset undergoes various filtering and formatting processes to produce a version compatible with models developed using the TensorFlow runtime. TensorFlow is an important widely used tool for those building and training <span epub:type="pagebreak" id="p183" aria-label=" page 183. Figure on this page. " role="doc-pagebreak"/><span epub:type="pagebreak" id="p184" aria-label=" page 184. " role="doc-pagebreak"/>models. The filtering process includes tasks such as deduplication and the removal of sensitive words.</p>
<p>Initially, Google created the C4 data set for their own use. While they provided a description and some tools to generate the dataset from the Common Crawl inputs, they did not release the actual dataset. Recognising the value of this dataset, another organisation, the Allen Institute for AI (see <a href="https://allenai.org">https://allenai.org/</a>; founded by the late Paul G. Allen, co-founder of Microsoft), reproduced the C4 dataset. They collaborated with a company called Hugging Face (see <a href="https://huggingface.co">https://huggingface.co/</a>) to host and make this dataset accessible to all.</p>
<p>Recreating the C4 dataset is not only costly (with expenses estimated between US$100s and US$1,000s in compute costs) but also requires significant expertise and knowledge.</p></section>
<section aria-labelledby="sec6_3_1_3">
<h4 id="sec6_3_1_3"><span epub:type="ordinal">6.3.1.3 </span>Image Data &#x2013; LAION-5B</h4>
<p>The LAION-5B image dataset (see <a href="https://laion.ai">https://laion.ai/blog/laion-5b/</a>) (<a href="#ref6_67" id="R_ref6_67" epub:type="biblioref" role="doc-biblioref">Schuhmann et al., 2022</a>) is a contemporary dataset designed for state-of-the-art (SOTA) model training. Its primary objective is to provide an open and readily accessible dataset for text-to-image model training. The dataset comprises 5.85 billion filtered image-text pairs, of which 2.32 billion are in the English language.</p>
<p>The foundation for this dataset was the Common Crawl, from which image URLs were extracted and subsequently filtered using an existing OpenAI CLIP (Contrastive Language-Image Pre-Training) model (<a href="#ref6_50" id="R_ref6_50" epub:type="biblioref" role="doc-biblioref">Radford et al., 2021</a>). This process resulted in a dataset comprising: a) 2.32 billion English image-text examples, b) 2.26 billion multilingual examples, and c) 1.27 billion examples not tied to any specific language (e.g., pertaining to places, products, etc.). Notably, this dataset is considerably more extensive than other comparable datasets. By making it publicly accessible, it promotes greater transparency, especially concerning the ethical considerations linked to large datasets of publicly sourced images.</p></section>
<section aria-labelledby="sec6_3_1_4">
<h4 id="sec6_3_1_4"><span epub:type="ordinal">6.3.1.4 </span>Image Data &#x2013; LabelMe</h4>
<p>The primary objective of the LabelMe dataset (see <a href="http://labelme.csail.mit.edu">http://labelme.csail.mit.edu/</a>) (<a href="#ref6_64" id="R_ref6_64" epub:type="biblioref" role="doc-biblioref">Russell et al., 2007</a>; <a href="#ref6_47" id="R_ref6_47" epub:type="biblioref" role="doc-biblioref">Oliva, 2001</a>) is to offer an online annotation tool to construct image datasets for computer vision research. Users could register for an account, contribute annotations, and subsequently access the datasets for their research. This approach facilitated the accumulation of a substantial collection of images and annotations. Importantly, these annotations were not mere labels; users could pinpoint and specify individual objects within an image. Thus, elements such as a car in the background, a person in the foreground, buildings, roads, and any other visible component in the image could be distinctly annotated.</p></section>
<section aria-labelledby="sec6_3_1_5">
<h4 id="sec6_3_1_5"><span epub:type="ordinal">6.3.1.5 </span>Other Sources</h4>
<p>Other frequently utilised sources include data dumps from GitHub, which contain open-source software implementations in numerous programming languages; dumps from Wikipedia, an online encyclopaedia; releases from Project Gutenberg, which hosts over 70,000 books no longer under copyright; and content from &#x2018;The Pile&#x2019;, an amalgamation of 22 smaller datasets that has recently stirred controversy due to issues related to copyrighted books.</p>
<p>Several other notable data sources exist. For instance, Tesla possesses an extensive database of driving-related videos, which it harnesses to train its autopilot system. ImageNet <span epub:type="pagebreak" id="p185" aria-label=" page 185. " role="doc-pagebreak"/>(<a href="https://www.image-net.org">https://www.image-net.org/</a>) offers a vast collection of over one million images, each labelled with nouns corresponding to the content of the image; this resource has been pivotal in advancing computer vision and deep learning research. Another significant source is COCO (Common Objects in Context), which provides image data for training. CelebA serves as a repository of celebrity images, particularly useful for facial recognition tasks. Additionally, there are audio-focused datasets such as the MIDI dataset for music; the VCTK dataset for voice-related tasks; and the UCF101 dataset, designed for action recognition in videos.</p>
<p>Google offers a valuable tool for searching various types of datasets, accessible at <a href="https://datasetsearch.research.google.com">https://datasetsearch.research.google.com/</a>. Regardless of the specific dataset one requires, there are likely similar sets available, and this search tool aims to simplify the discovery process.</p></section>
<section aria-labelledby="sec6_3_1_6">
<h4 id="sec6_3_1_6"><span epub:type="ordinal">6.3.1.6 </span>Other Data Customisations</h4>
<p>Each of these datasets has its own approach to sourcing from the original, preparing the data dump, and then further processing to customise the dataset for the specific training task. These preparation and customisation steps may involve similar filtering as described above, but they can also encompass distinct types of filtering and content curation to achieve the specific aims.</p>
<p>A significant aspect of this customisation pertains to structuring the data in a way that is optimally suited for the specific model in question and the intended training strategy. The design and structure of the model, as well as the various training approaches, are elaborated upon in subsequent sections. Nevertheless, these factors play a crucial role in determining the necessary data preparation and customisation processes.</p>
<p>One common customisation involves ensuring that the size of the data inputs aligns with the model design. This will differ depending on the type of data the model handles, be it text-based input or image-based input. For language models, the typical input size comprises paragraphs that can be fed into the system as a single unit, usually amounting to about 512 tokens. Tokens are similar to words and we will discuss them more later. These inputs are either split or padded to ensure they fit the model. Subsequently, these inputs are often grouped into batches, possibly in sizes of 16, 32, or 64. Such batches are generally processed independently during training, which facilitates parallel streams into the model. The collective set of all batches constitutes an epoch, and the model may undergo training across several iterations of these epochs to maximise the training benefits. Importantly, between each epoch iteration, the batches are typically shuffled to prevent the model from making unwarranted learning assumptions about the sequence.</p>
<p>One final consideration involves dividing the dataset into training and validation subsets. This step is crucial to ensure that the models are accurate and do not suffer from overtraining (or overfitting). Overfitting is where the model learns the training data very well but does poorly when tested with a dataset outside the training set. In short it does not generalise well. Typically, the dataset is divided into training and testing portions on a 70% to 30% basis, with the testing subset selected randomly to circumvent issues associated with alternative selection methods. The testing portion of a dataset is used to evaluate how well a machine learning model generalises to new, unseen data. While the training data are used to train the model, the testing data serves as an independent set of examples that the model has never seen during training. Many datasets come pre-divided into training, testing, and <span epub:type="pagebreak" id="p186" aria-label=" page 186. " role="doc-pagebreak"/>validation subsets. The validation subset (sometimes referred to as the development set) is generally included to facilitate the fine-tuning of specific models.</p></section></section>
<section aria-labelledby="sec6_3_2">
<h3 id="sec6_3_2"><span epub:type="ordinal">6.3.2 </span>Model Design and Structuring</h3>
<p>Clearly, the design and structuring of models is an intricate topic, necessitating deep experience and understanding of AI, deep neural networks, and the associated statistical and mathematical concepts.</p>
<p>Subsequent sections will explore key considerations surrounding model design and its nuanced details. As mentioned, the aim is to provide insights into the factors that influence a model and their inner workings. This will enable readers to delve deeper into specific topics or explore the statistical and mathematical concepts that underpin these design considerations which we do not explore in this book.</p>
<section aria-labelledby="sec6_3_2_1">
<h4 id="sec6_3_2_1"><span epub:type="ordinal">6.3.2.1 </span>Artificial Neurons &#x2013; Weights, Bias, and Activations Functions</h4>
<p>Artificial neurons are simple structures with inputs and outputs. While there can be any number of inputs, the output is a singular value. Although the inputs can vary, they converge to produce this single output value. Neurons are often depicted as a basic circle, with the relevant inputs and outputs illustrated, as shown in <a href="#fig6_9" id="R_fig6_9">Figure 6.9</a>. This graphical representation is of a rudimentary type of neuron known as a feed-forward cell. To gain a deeper understanding of the neuron, one can delve into the internals of the cell, as shown in <a href="#fig6_9">Figure 6.9</a>.</p>
<figure id="fig6_9"><img src="images/fig6_9_B.jpg" alt="A diagram that provides exhaustive information regarding a feed forward cell."/>
<figcaption><a href="#R_fig6_9" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. "><span epub:type="label">Figure</span> <span epub:type="ordinal">6.9 </span>Feed-Forward Cell.</a></figcaption></figure>
<p>This introduces a few important concepts:</p>
<ul class="disc">
<li><b>Weights</b>. Each weight is just a number; there is one weight (number) for each input into the neuron. The value of this number changes as the model is trained. Once trained it is fixed.</li>
<li><b>Bias</b>. This is just a number and there is one for each neuron. The value of this number changes as the model is trained. Once trained it is fixed.</li>
<li><span epub:type="pagebreak" id="p187" aria-label=" page 187. " role="doc-pagebreak"/><b>Activation function</b>. This is a special mathematical function that helps improve the usefulness of the output. There are many different types of activation functions. Some popular ones are sigmoid (used in older models such as Long Short-Term Memory Networks), Tanh (used in older models such as hidden layers of Sequence-to-Sequence models), ReLu (used in GPT3), and SwiGLU (used in LLaMA).</li></ul>
<p>In this instance, the input signal (denoted as x<sub>i</sub>, which is a numerical value) is multiplied by the corresponding weight (w<sub>i</sub>) for that input. This multiplication is conducted for all inputs, and the resultant products are then summed (effectively yielding the sum of the products). Subsequently, the bias (b) is added, and the resultant figure is passed to the activation function. This activation function processes the given value, producing an output which is also a numerical value. If this neuron is connected to multiple other neurons, the same output value emanating from this neuron is transmitted to all interconnected neurons. Hence, the neuron can be conceptualised as a mathematical operation on a collection of input values to produce an output value, and that mathematical operation is informed by another set of values known as weights and the bias.</p>
<p>These weights and biases will be revisited in the context of model training. Collectively, they are referred to as the parameters of the model. This is the mechanism by which the model &#x2018;remembers&#x2019; or stores information; these numerical values encapsulate the patterns that the model has discerned during its training phase and can subsequently be employed to make predictions. Often, models are benchmarked based on the number of parameters they possess, stemming from the assumption that a higher number of parameters equates to greater capabilities. However, several other factors influence the efficacy of a model beyond just the count of parameters. These include the quality of the training data utilised, the number of layers and their interconnections, as well as the internal functions deployed, such as the activation function or the sum of the products.</p>
<p>LLaMA-2 (Large Language Model Meta AI) from Meta AI is available in several size variants: 7B, 13B, and 70B, where &#x2018;B&#x2019; stands for billion parameters. OpenAI&#x2019;s ChatGPT-3.5 boasts 175B parameters. While the size of ChatGPT-4.0 has not been officially disclosed, it is speculated to comprise about 1.8T parameters, with &#x2018;T&#x2019; representing trillion. Google&#x2019;s LaMDA (Language Models for Dialog Applications) possesses up to 137B parameters. In <span epub:type="pagebreak" id="p188" aria-label=" page 188. " role="doc-pagebreak"/>contrast, Google&#x2019;s PaLM-2 (Pathways Language Model) is reported to have around 340B parameters. Initially, Google&#x2019;s BARD chatbot was based on LaMDA, but it was subsequently transitioned to PaLM-2 due to the latter&#x2019;s superior reasoning capabilities. These sizes give some indication of the number of cells involved in a SOTA model.</p>
<p><a href="#fig6_10" id="R_fig6_10">Figure 6.10</a> illustrates a different type of artificial neuron known as a Recurrent Cell.</p>
<figure id="fig6_10"><img src="images/fig6_10_B.jpg" alt="A diagram that provides exhaustive and detailed information regarding a recurrent cell."/>
<figcaption><a href="#R_fig6_10" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. "><span epub:type="label">Figure</span> <span epub:type="ordinal">6.10 </span>Recurrent Cell.</a></figcaption></figure>
<p>As <a href="#fig6_10">Figure 6.10</a> illustrates, this structure closely resembles the feed-forward cell, with one notable exception, it incorporates internal feedback. In this arrangement, the output from the previous iteration (t-1) is reintroduced as an additional input in the current (t) input flow. This input (h<sub>t-1</sub>) is multiplied by its designated weight (w<sub>h</sub>) to contribute to the current output. In essence, this type of cell possesses memory of the previous output, which aids in computing the current output. These recurrent cells are a fundamental component of the recurrent neural network (RNN) models mentioned earlier.</p>
<p>There are many different possible types of cells, another one previously mentioned is the long short-term memory (LSTM) cell, but these two specific examples should give an idea of what is involved.</p></section></section>
<section aria-labelledby="sec6_3_3">
<h3 id="sec6_3_3"><span epub:type="ordinal">6.3.3 </span>Model Layers and Connections</h3>
<p>These artificial neurons, also known as cells or nodes, can be connected together in layers. Neural networks in AI are composed of nodes organised in layers, with each node connected to others in the next layer. These connections are often referred to as synapses. <a href="#fig6_11" id="R_fig6_11">Figure 6.11</a> illustrates some common structures of deep neural networks, typically comprising an input layer, an output layer, and multiple hidden layers in between.</p>
<figure id="fig6_11"><img src="images/fig6_11_B.jpg" alt="A deep neural network with an input layer, three hidden layers, and an output layer."/>
<figcaption><a href="#R_fig6_11" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. "><span epub:type="label">Figure</span> <span epub:type="ordinal">6.11 </span>Deep Neural Network.</a></figcaption></figure>
<p><span epub:type="pagebreak" id="p189" aria-label=" page 189. " role="doc-pagebreak"/>The number of nodes in each layer can vary, and the connections don&#x2019;t necessarily have to link to every node in the next layer, although this is a typical arrangement. For a network to be considered &#x2018;deep&#x2019;, it must contain at least three hidden layers. When counting the layers, both the hidden layers and the output layer are included. In the example provided, the deep neural network consists of four layers.</p>
<p>There is flexibility in the number of inputs and nodes in different layers. The following diagrams (<a href="#fig6_12" id="R_fig6_12">Figure 6.12</a>) present various approaches.</p>
<figure id="fig6_12"><img src="images/fig6_12_B.jpg" alt="Three different deep neural networks which shows the variations that are possible in deep neural networks."/>
<figcaption><a href="#R_fig6_12" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. "><span epub:type="label">Figure</span> <span epub:type="ordinal">6.12 </span>Deep Neural Network Variations.</a></figcaption></figure>
<p><a href="#fig6_12">Figure 6.12</a> provides a high-level overview of what a deep neural network looks like in an abstract manner.</p>
<p>A significant aspect of designing and structuring a model involves choosing the type of cell to use; determining which cell types are suitable for specific layers; deciding the number of layers to include; and defining the number of nodes in each of the input, hidden, and output layers.</p>
<p>Certain model capabilities are tailored to the type of data being processed, such as text or images. These features will be discussed primarily in the context of the most common use cases, such as large language models (LLMs), text-to-image models, or multi-modal models (supporting input and output for multiple data types, including text, images, audio, video, etc.). For instance, a model might facilitate text input and generate text output, or it could generate image output based on user requests. Conversely, it could also accept image input and produce descriptive text as output.</p></section>
<section aria-labelledby="sec6_3_4">
<h3 id="sec6_3_4"><span epub:type="ordinal">6.3.4 </span>Key Model Capabilities</h3>
<p>The following sections examine key model capabilities designed for specific data types, whether text or images. This section will help you understand what actually happens to the input that is passed to the model and what the model does with that input both during training and during inference (normal user interaction post training).</p>
<section aria-labelledby="sec6_3_4_1">
<h4 id="sec6_3_4_1"><span epub:type="ordinal">6.3.4.1 </span>Text &#x2013; Tokenisation</h4>
<p>Before delving into specifics, it is essential to understand the nature of the inputs. In the context of an LLM, both the inputs and outputs consist of text. Let&#x2019;s begin by examining this scenario.</p>
<p>There are several upstream processing steps required to transform the text, whether it is what you type or the training data, into the actual model input. The initial step in this process is known as tokenisation. Tokenisation involves breaking the text into tokens. For example, when using the GPT-3 tokeniser, the sentence &#x2018;Can you provide a summary of the novel the count of monte cristo&#x2019; would be tokenised into the following tokens (<a href="#fig6_13" id="R_fig6_13">Figure 6.13</a>)</p>
<figure id="fig6_13"><img src="images/fig6_13_B.jpg" alt="An example that shows how the following sentence is tokenised. Can you provide a summary of the novel the count of monte cristo."/>
<figcaption><a href="#R_fig6_13" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. "><span epub:type="label">Figure</span> <span epub:type="ordinal">6.13 </span>Tokenisation Example 1.</a></figcaption></figure>
<p>As you can see in <a href="#fig6_13">Figure 6.13</a>, there are a few things to note:</p>
<ol type="1">
<li><span epub:type="pagebreak" id="p190" aria-label=" page 190. " role="doc-pagebreak"/>The spaces are included in the words (at the start of the words).</li>
<li>Words are mostly separated into different tokens.</li>
<li>Sometimes words can be split (e.g. &#x2018;mon&#x2019; and &#x2018;te&#x2019;) into multiple tokens.</li></ol>
<p>If you slightly change the string to &#x2018;Can you provide a summary of the novel, &#x2018;The Count of Monte Cristo,&#x2019; then the tokens for this tokeniser will be (<a href="#fig6_14" id="R_fig6_14">Figure 6.14</a>).</p>
<figure id="fig6_14"><img src="images/fig6_14_B.jpg" alt="Another example of how the following sentence is tokenised. Can you provide a summary of the novel, &#x2018;The Count of Monte Cristo.&#x2019;"/>
<figcaption><a href="#R_fig6_14" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. "><span epub:type="label">Figure</span> <span epub:type="ordinal">6.14 </span>Tokenisation Example 2.</a></figcaption></figure>
<p>As you can see in <a href="#fig6_14">Figure 6.14</a>, the changes in punctuation and capitalisation have impacted the tokenisation process.</p>
<p>There is a limit to the size of the input that can be provided to the model, known as the context window. This limit restricts the number of tokens that can be passed to the model simultaneously. For example, in the LLaMA-2 model from Meta, the context window is 4096 tokens; while in ChatGPT-3.0, it is 2048 tokens. However, in ChatGPT-4, the context window is 32k tokens.</p>
<p>The tokenisation approach (which includes words, part words, letters, punctuation handling, etc.) is an important part of the model design and may require different strategies for different languages.</p>
<p>The context window size is important when you consider the approaches that the model uses for in-context learning (i.e., learning based on the inputs provided). There are a few approaches which can be used.</p>
<ul class="disc">
<li>Zero-Shot learning: In this approach, only the prompt you type is provided as an input to the model.</li>
<li>Few-Shot learning: In this approach, both multiple examples and the specific prompt you provide are sent to the model as inputs. The number of examples can range from 1 up to 32 examples.</li></ul>
<p>In the case of the few-shot learning, the examples can use up many tokens, leaving fewer tokens for the actual prompt being performed, thus in cases where few-shot learning is <span epub:type="pagebreak" id="p191" aria-label=" page 191. " role="doc-pagebreak"/>viewed as important, a larger context window is needed. Likewise, if the inputs themselves are large e.g. full text documents, larger context windows are needed.</p></section>
<section aria-labelledby="sec6_3_4_2">
<h4 id="sec6_3_4_2"><span epub:type="ordinal">6.3.4.2 </span>Text &#x2013; Encoding</h4>
<p>One purpose of tokenisation is to map the inputs to a known set of possible options. In the case of the English language and the tokenisation approach shown above, there are about 50,000 possible tokens based on the GPT-3 tokenisation design.</p>
<p>Picture these 50,000 possible tokenised values as the vertical columns in a matrix, and picture each of the actual input tokens from the prompt as the horizontal rows in that matrix. This would allow the inputs to be mapped to numbers (ones or zeros) like an encoding mechanism.</p>
<p>The matrix would contain a &#x2018;1&#x2019; in the column corresponding to the position of each token in the input, and the &#x2018;1&#x2019; would be in the appropriate row based on its position in the input text sequence. All other columns in that row would be &#x2018;0&#x2019;. This is demonstrated in <a href="#fig6_15" id="R_fig6_15">Figure 6.15</a>. If the number of input tokens is less than the context window, the remaining columns would be filled with &#x2018;0&#x2019;.</p>
<figure id="fig6_15"><img src="images/fig6_15_B.jpg" alt="A sentence that has been tokenised and the related encoding matrix for the same."/>
<figcaption><a href="#R_fig6_15" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. "><span epub:type="label">Figure</span> <span epub:type="ordinal">6.15 </span>Encoding Matrix.</a></figcaption></figure>
<p>This encoding approach allows the prompt to be passed as an input, which is a matrix of numbers, to the model. Since the model can only process numbers, this encoding is a critical part of the pre-processing required to use the model.</p>
<p>The order of the tokens is also significant. In addition to the token values in the matrix, the position of each token in the sequence is important and can be identified by the model from the input provided.</p>
<p>This approach of mapping categorical variables (tokens or words) to a simple matrix is one type of encoding called &#x2018;one-hot encoding&#x2019;. However, there are more sophisticated approaches available. This encoding represents a fixed, rule-based process. These decisions are integral to model design and structure.</p></section>
<section aria-labelledby="sec6_3_4_3">
<h4 id="sec6_3_4_3"><span epub:type="ordinal">6.3.4.3 </span>Text &#x2013; Embedding</h4>
<p>Once the tokens are presented in a matrix format in the transformer architecture for LLMs, the next step is embedding. This is where the matrix input is mapped to a vector representation for each token and each token position.</p>
<p>The mapping of the token&#x2019;s entry in the matrix to a vector is a learned representation. In other words, through training, the model learns how to position the vectors in this space so that the geometric relationships between them reflect the semantic relationships between the corresponding tokens. For example, it could happen that types of animals would be &#x2018;near&#x2019; each other (have similar values for their vectors), or that words with similar meanings appear near each other.</p>
<p>Put in other words, embeddings in LLMs are numerical representations that capture the essence of words or phrases. Rather than treating words as isolated units, embeddings transform them into vectors in a high-dimensional space, where similar words are positioned closer together. This allows models to understand context and meaning, making text generation more coherent and contextually relevant. For example, think of embeddings as giving words a unique address in a city (the high-dimensional space). So, while the word &#x201C;cat&#x201D; might live at one address, the word &#x201C;kitten&#x201D;, being similar in meaning, would live nearby (in other words would have a similar numerical value). When the model needs to <span epub:type="pagebreak" id="p192" aria-label=" page 192. " role="doc-pagebreak"/>generate text, it uses these addresses (numerically similar values) to find words that fit best in the context, ensuring the sentences make sense.</p>
<p>If you don&#x2019;t grasp the details of the embedding process, don&#x2019;t worry. The key thing to remember is that this is a learned process; the embedding layer has weights and biases just like the other layers, and through the learning process, these weight and bias values are updated. This learning process is explained in more detail below.</p></section>
<section aria-labelledby="sec6_3_4_4">
<h4 id="sec6_3_4_4"><span epub:type="ordinal">6.3.4.4 </span>Text &#x2013; Attention</h4>
<p>The paper &#x2018;Attention is all you need&#x2019; (<a href="#ref6_74" epub:type="biblioref" role="doc-biblioref">Vaswani et al., 2017</a>) emphasised the significance of attention in the design and structure of a model. The attention mechanism enables the model to identify long-range (distant) dependencies between words in a sentence or paragraph. This is analogous to how humans address this issue when listening to someone speak or reading text. We analyse what preceded the current context and relate it to what we are currently processing, attempting to form a coherent mental picture of the situation. A key component of this attention mechanism is the &#x201C;attention head&#x201D;.</p>
<p>The model is designed to calculate attention scores for each word in the input, be it a sentence or paragraph, in order to understand the relative importance of each word. Typically, there are multiple attention heads, and each head computes its own score. Similar to embeddings, these scores are learned from the weights associated with three parameters for each attention head: the so-called &#x2018;query&#x2019;, &#x2018;key&#x2019;, and &#x2018;value&#x2019; parameters, often referred to as matrices W<sub>q</sub>, W<sub>k</sub>, and W<sub>v</sub>. Different attention heads process the input in parallel, and the set of attention scores is then aggregated to create a new representation of that token. Having multiple attention heads allows the model to learn a more comprehensive set of relationships among tokens. For example, one head might learn to focus on syntactic relationships like subject&#x2013;verb agreement, while another might learn to capture semantic relationships like synonymy.</p>
<p>Consider the sentence &#x2018;The cat sat on the mat.&#x2019; With a single attention head, it might concentrate on the relationship between &#x2018;cat&#x2019; and &#x2018;sat&#x2019;, capturing the subject&#x2013;verb relationship. However, when multiple attention heads are employed, another might focus on the relationship between &#x2018;sat&#x2019; and &#x2018;mat&#x2019;, capturing the verb&#x2013;object relationship, while yet another could emphasise the relationship between &#x2018;on&#x2019; and &#x2018;mat&#x2019;, capturing the preposition&#x2013;object relationship.</p>
<p>As mentioned, these scores and the focus of each attention head are learnt during the training process. The designer does not assign a specific head to a specific ability; this is entirely dynamic and learnt during training. It may seem somewhat amazing, perhaps unbelievable, that this happens, but it does. With millions of training examples, the model learns to specialise specific attention heads for specific purposes. This is an emergent feature of the model. The stochastic nature of the training process encourages diversity among the heads, so that different heads take on specific but different purposes.</p></section>
<section aria-labelledby="sec6_3_4_5">
<h4 id="sec6_3_4_5"><span epub:type="ordinal">6.3.4.5 </span>Text &#x2013; Next Word Prediction Learning Goal</h4>
<p>We have seen that some layers in the model are focused on finding the relationships between words (embedding), and some are focused on understanding what the most important words of the input are (attention). The other layers in the model will be focused on predicting the next word in the text. If the input so far is &#x2018;I went to the&#x2019;, then the model is trying to predict what the next word is, and let&#x2019;s say it predicts &#x2018;market&#x2019;, but the actual word is &#x2018;school&#x2019;, then it will adjust the weights and biases in the model to better predict this in the future. It will then try to predict the next word again in &#x2018;I went to the school&#x2019;, and it might predict &#x2018;to&#x2019;, and this <span epub:type="pagebreak" id="p193" aria-label=" page 193. " role="doc-pagebreak"/>is correct. Then it predicts &#x2018;pick&#x2019;, and this is correct, then it predicts &#x2018;up&#x2019;, and this is correct, and then it predicts &#x2018;my&#x2019; which is correct again. Then the next word it predicts is &#x2018;kids&#x2019; but the actual word is &#x2018;books&#x2019;. It again will update the weights and biases to try and better predict in the future. This gives the model the input &#x2018;I went to the school to pick up my books&#x2019;. As it learns it will also be updating the embeddings and attention layers to improve those too.</p></section>
<section aria-labelledby="sec6_3_4_6">
<h4 id="sec6_3_4_6"><span epub:type="ordinal">6.3.4.6 </span>Image &#x2013; Pre-processing</h4>
<p>This is where the input image is prepared and normalised or standardised for input into the model. The input image may be a JPEG or a GIF and needs to be converted to the standard format. This conversion includes not only changing the format but also adjusting other details such as the size of the image (width, height, and aspect ratio), the resolution of the image, and the colour space. Depending on the complexity, it may involve image rotation to ensure it is correctly oriented.</p>
<p>Part of the pre-processing involves tensor (matrix of vectors) conversion, which is similar to the encoding discussed for text models. In the case of an image, this process is somewhat easier because the image naturally has a binary representation of a set of pixels in height and width, with each pixel having values for colours, such as Red (R), Green (G), and Blue (B). Thus, conversion involves creating a tensor or matrix of vectors for these pixel coordinates and RGB values. This has also been covered in <a href="ch1.xhtml#sec1_8">Section 1.8</a> <a href="ch1.xhtml#fig1_4">Figure 1.4</a>.</p></section>
<section aria-labelledby="sec6_3_4_7">
<h4 id="sec6_3_4_7"><span epub:type="ordinal">6.3.4.7 </span>Image &#x2013; Encoding</h4>
<p>Image encoding is similar to embedding for text-based models. However, instead of using embedding layers, which are employed in text models, image models typically use convolutional layers. These layers learn the relationships between the content of the image, aiding in the extraction of model features.</p></section>
<section aria-labelledby="sec6_3_4_8">
<h4 id="sec6_3_4_8"><span epub:type="ordinal">6.3.4.8 </span>Image &#x2013; Diffusion Learning Goal</h4>
<p>The model is presented with an encoded image along with a text description of that image. Forward diffusion is the process where a model introduces noise into an image, gradually making the picture blurry by altering some of the pixels&#x2019; colours. This noise is added incrementally until the image becomes unrecognisable, resembling a television screen when not tuned in. This is shown in <a href="ch1.xhtml#sec1_8">Section 1.8</a> <a href="ch1.xhtml#fig1_6">Figure 1.6</a>.</p>
<p>Reverse diffusion, on the other hand, is the process in which a model removes noise from an image, gradually restoring it to its original, recognisable form.</p>
<p>These forward and reverse diffusion processes teach the model how to generate an image which it has a text description of by removing noise. When tasked with creating an image solely based on a text description, the model can utilise this learning to remove noise from an initial image with random noise, resulting in a completely new image that did not previously exist.</p></section>
<section aria-labelledby="sec6_3_4_9">
<h4 id="sec6_3_4_9"><span epub:type="ordinal">6.3.4.9 </span>Hyperparameters</h4>
<p>Hyperparameters are specific controls of a model that designers must choose and adjust during the design and training processes. Unlike model parameters, which are automatically adjusted by the model itself during learning, hyperparameters are only adjusted by the model&#x2019;s designer.</p>
<p><span epub:type="pagebreak" id="p194" aria-label=" page 194. " role="doc-pagebreak"/>These hyperparameters span a wide range of aspects of the model, including the learning rate, the batch size, the number of epochs, factors impacting the activation function used, the dropout rate, and more. During this phase, designers must determine the best values for these hyperparameters.</p>
<p>Sometimes, hyperparameters are exposed to the end users of a model to help control a model&#x2019;s behaviour. One such example is the &#x2018;temperature&#x2019; hyperparameter, which controls how repeatable a prediction is. Lower values mean more randomness, while higher values mean less randomness and more consistency.</p></section></section>
<section aria-labelledby="sec6_3_5">
<h3 id="sec6_3_5"><span epub:type="ordinal">6.3.5 </span>Foundational Model Training</h3>
<p>Thus far, we have covered the big picture, how the data is gathered and prepared, and different aspects that go into the design and structuring of the model. In this section, we focus on foundational model training, commonly referred to as pre-training.</p>
<p>A foundational model is a model built and initially trained as a general-purpose model, and it is not a specialisation of another model. A fine-tuned model is a foundational model (or another fine-tuned model) that is specialised for a particular purpose.</p>
<p>The term &#x2018;pre-trained&#x2019; or &#x2018;pre-training&#x2019; refers to the training that occurs before the model becomes useful as a general-purpose foundational model.</p>
<p>When training a foundational model (also known as pre-training), there are different types of training that can occur, which impact the type of learning that takes place. The following sections delve into these different types of learning and the associated training processes.</p>
<section aria-labelledby="sec6_3_5_1">
<h4 id="sec6_3_5_1"><span epub:type="ordinal">6.3.5.1 </span>Supervised Learning</h4>
<p>Supervised learning occurs when the training data includes both the data and a label that allows the model to determine whether its prediction was correct or not. For instance, if the training data pertains to the sentiment of a given section of text, it will include a description of that sentiment associated with each section of text. When the model is being trained and makes a prediction about the text&#x2019;s sentiment, it can then reference the provided label to assess the accuracy of its prediction. It will subsequently adjust the parameters in the model to enhance future predictions.</p>
<p>Another example is when the model deals with images containing animals. In this case, the training data consists of numerous pictures of animals, each accompanied by labels describing the type of animal depicted. The model can utilise this training data and labels to make predictions and refine its predictions.</p>
<p>Yet another example involves a model aiming to enhance the resolution of an image. In this scenario, the training data comprises a low-resolution image and a higher-resolution image of the same picture. The model can predict what the higher-resolution image might look like and use the provided higher resolution image to adjust its prediction for improvement.</p></section>
<section aria-labelledby="sec6_3_5_2">
<h4 id="sec6_3_5_2"><span epub:type="ordinal">6.3.5.2 </span>Self-Supervised Learning</h4>
<p>Self-supervised learning is a method in which the model uses unlabelled input to supervise its own learning. For instance, if the input is &#x2018;I love AI&#x2019;, and the model&#x2019;s objective is to predict the next word, it can use &#x2018;I xxxx&#x2019; to predict &#x2018;I have&#x2019;. It can then check if that prediction was correct based on the subsequent input, &#x2018;I love&#x2019;, and adjust its prediction for the future. This is the most common approach to learning for LLMs, as data from sources such <span epub:type="pagebreak" id="p195" aria-label=" page 195. " role="doc-pagebreak"/>as Common Crawl can be relatively easily used to create a self-supervised training set for models that predict the next word, like LLMs.</p></section>
<section aria-labelledby="sec6_3_5_3">
<h4 id="sec6_3_5_3"><span epub:type="ordinal">6.3.5.3 </span>Unsupervised Learning</h4>
<p>Unsupervised learning is a type of training where data is provided to the model without any specific knowledge about what is expected, without any &#x2018;labels,&#x2019; or without using the self-supervised learning approach. This type of learning can be useful for specific scenarios, such as clustering, which involves identifying groups (clusters) of related items.</p></section>
<section aria-labelledby="sec6_3_5_4">
<h4 id="sec6_3_5_4"><span epub:type="ordinal">6.3.5.4 </span>Reinforcement Learning with Human Feedback (RLHF)</h4>
<p>Reinforcement Learning with Human Feedback (RLHF) is particularly beneficial in domains where the desired behaviour is difficult to specify, or where the model needs to learn nuanced or complex strategies. It has been applied in training models across various domains, including game playing (such as Go), dialog systems, and robotics.</p>
<p>One of the challenges associated with RLHF is that it can be time-consuming and expensive, as it requires ongoing involvement from human evaluators. Additionally, it may necessitate careful design to ensure that the feedback collected is informative and that biases in human judgments do not unduly influence the model&#x2019;s behaviour.</p>
<p>The paradigm of RLHF serves as a bridge between traditional supervised learning, in which a model learns from a fixed dataset of labelled examples, and reinforcement learning, where a model learns by interacting with an environment to maximise a reward signal and thus strongly favour the human feedback option when learning.</p></section>
<section aria-labelledby="sec6_3_5_5">
<h4 id="sec6_3_5_5"><span epub:type="ordinal">6.3.5.5 </span>Learning</h4>
<p>This section delves into the learning process in more detail. So far, learning has been discussed without a detailed explanation. It has been mentioned that the model makes predictions, such as next-word predictions in the case of LLMs, and then compares the predicted value to the expected value (via self-supervised, supervised, or reinforcement learning), and then adjusts the model as needed. It was also mentioned that the model&#x2019;s parameters, which are the weights and biases, are the numbers that get adjusted during learning.</p>
<p>We understand that the model&#x2019;s understanding of the world results from a combination of its structure (including embeddings, attention, and other layers) and the values of its parameters (the weights and biases). Initially, the weights are set to some value before training starts on the foundational model. Typically, this value is random, or sometimes zero. Then, the value is adjusted during training. We have already discussed that the training data is grouped into batches. Now, let&#x2019;s explore how the learning process is closely linked to these batches and the significance of batch size. For each batch, the following processes occur:</p>
<ol type="1">
<li>The forward pass. This is where the data from the batch is passed &#x2018;forward&#x2019; through the neural network. The model makes predictions one word or image at a time for each item in the batch. It keeps track of the prediction that it makes and the actual value.</li>
<li>The loss calculation. The loss calculation involves the model comparing its predicted value to the actual expected value. A loss function is used for this purpose. In LLMs, a common loss function is categorical cross-entropy, whereas image-generation models often use loss functions like generative adversarial loss. These loss functions quantify the <span epub:type="pagebreak" id="p196" aria-label=" page 196. " role="doc-pagebreak"/>difference between the actual and predicted values for each word or image. These quantified values for each input are then averaged across the entire batch, resulting in an average loss value available for the next step.</li>
<li>The backward pass, also known as backpropagation (<a href="#ref6_80" epub:type="biblioref" role="doc-biblioref">Werbos, 1974</a>, and <a href="#ref6_60" id="R_ref6_60" epub:type="biblioref" role="doc-biblioref">Rumelhart et al., 1985</a>). Steps 1 and 2 occur for each item in the batch, and the loss calculation step maintains a running average loss across the entire batch. Backpropagation is then performed based on this average loss value. This involves computing the gradients of the loss with respect to each parameter in the model. Even though one sentence might have been predicted perfectly, errors in other sentences contribute to the gradients and guide the parameter updates. It is important to remember that the model consists of many layers, each with numerous cells or neurons, and each of these has multiple weights and a bias that may need adjustment. The calculated gradients, based on the average loss, assign the level of influence (sometimes called the blame or reward) to each weight and bias in the model for the errors between the predicted values and the actual values.</li>
<li>The adjustment. The adjustment of the weights and biases for each neuron in each layer. Now that the model has assigned a level of blame or reward to each of the parameters in the model, it can proceed to adjust them at the end of the batch.</li></ol>
<p>This is the essence of learning in a neural network: make a prediction, estimate an error, assign a level of blame or reward for the error to each parameter in the model, and adjust each parameter in the model. Over millions or billions of tokens, the model starts to have specialised and improved behaviours. The embedding layers learn, allowing associated words to be grouped in a manner that reflects their relationship; similar words will be close together, disparate words will be far apart. The attention layers learn, with each attention head specialising in a specific manner that allows more distant relationships between words to be formed, such as between subjects and actions. The other layers also contribute to the overall relationships between words, language concepts, and real-world concepts. From these different learnings and the patterns and relationships formed, the model gains what is like a type of &#x2018;understanding&#x2019; of the world and how things relate. Much of this learning and understanding is emergent from the large set of data that the model was trained on and the structure of the model that allows different parts to focus on specific aspects. This is one of the reasons why it is so difficult for humans to understand how the models really work; there are typically billions of parameters, which can be trained on millions or billions, or even trillions of tokens, and humans are not good at understanding how such vast volumes of data and numbers interact to result in this emergent capability.</p>
<p>It should be remembered that this understanding is purely related to the training data that has been provided. It lacks the kind of understanding that humans possess. Humans have an understanding of physical laws and draw from their experiences to assess a situation. They adjust their responses based on this understanding. Humans also have belief-based rules, which they use to adjust their responses and actions. However, something like an LLM only has the data it was trained on and does not have these other approaches to learning. Humans are adept at learning from a relatively small number of examples and gaining rich insights from this. AI models need vast quantities of data to start developing useful emergent behaviours.</p>
<p>While different, the learning process is somewhat like a child&#x2019;s learning process; first receiving a broad education in kindergarten, primary, and secondary school, which is like pre-training of a foundational model; and then specialising the learning for a particular <span epub:type="pagebreak" id="p197" aria-label=" page 197. " role="doc-pagebreak"/>discipline or profession like Computer Science in university, which is like fine-tuning that we discuss in more detail later.</p>
<p>At the very start of the learning process, the model knows nothing; in other words, the values of the weights and biases have not been set to appropriate values. Typically, at this point, the model will set the weights and biases to random values, and then the training processes will adjust as described. This is somewhat like a child who, when born, we assume they have no knowledge of the world but need to learn as they grow.</p>
<p>The concept of deep neural networks was inspired by the human brain and the brains of animals. We can see there are some similar concepts, but we can also see they are very different, and some may say a fundamentally different nature to how they work.</p></section></section>
<section aria-labelledby="sec6_3_6">
<h3 id="sec6_3_6"><span epub:type="ordinal">6.3.6 </span>Foundational Model Testing</h3>
<p>Once a model has been trained, the next step is to test the model to assess its usefulness. Testing models can be a complex task. Typically, the dataset is first split into training and testing data, as discussed earlier. The training data is used to train the model, and then the testing set is used to evaluate how well the model is performing.</p>
<p>One important thing to remember is that during training, the model parameters are updated after each batch. However, during testing, the model parameters remain unchanged. The goal of testing is to understand how the model will perform. If the model parameters are continually changing, it will make testing the performance impossible, as each test would impact the performance, and tests would not be reproducible.</p>
<p>Using a proportion of the data for testing, such as 20%, is helpful to understand the model&#x2019;s performance for the team creating the model. However, it is not useful for comparing or explaining the model&#x2019;s performance to others, as they do not have any understanding of the test data involved, the difficulty level of prediction, the scope of the testing, etc. This is where standard testing benchmarks come into play. The following section looks at the different benchmarks commonly used.</p>
<section aria-labelledby="sec6_3_6_1">
<h4 id="sec6_3_6_1"><span epub:type="ordinal">6.3.6.1 </span>Testing Benchmarks</h4>
<p>There exists a vast array of testing benchmarks, and every year sees the introduction of more, tailored for specific purposes or offering enhanced benefits. Such benchmarks are typically centred on particular tasks or broader areas.</p>
<p>Benchmarks commonly provide both the evaluation protocol (rules) and a standard dataset for assessing the models. This standard dataset ensures that different models undergo evaluation in a uniform manner, rendering the comparisons between various models meaningful. Standard datasets are often divided into training and testing subsets to ensure consistent training and testing. At times, these datasets are further segmented into validation sets. Typically, a model will be trained on the training set, fine-tuned using the validation set, and ultimately tested using the test set. On occasion, benchmark creators might withhold the testing set, asking model developers to submit their models for assessment. This strategy aims to prevent models from training on the test data, which would confer an unjust advantage during benchmark evaluation.</p>
<p>The evaluation protocol outlines crucial details about the test&#x2019;s objectives, including how to compute the score based on outcomes from each test component. This score often serves as a straightforward singular metric for contrasting two models. Sometimes, either the benchmark creator or the relevant community will establish a leaderboard, displaying <span epub:type="pagebreak" id="p198" aria-label=" page 198. " role="doc-pagebreak"/>ranked scores for each tested model, facilitating easier comparison. Such leaderboards might also feature a human baseline score, derived from the average scores of human participants. This addition can offer context, helping users appreciate the model&#x2019;s performance. It is not uncommon for models to surpass the average human score in many benchmarks.</p>
<p>Below are examples of prevalent benchmarks, categorised by their focal area. This should offer a comprehensive understanding of each benchmark, highlighting both their strengths and limitations. The grouping area is not strict and the benchmarks may be presented under alternative headings depending on the context in particular for the more general benchmarks that cover a wider set of areas.</p></section>
<section aria-labelledby="sec6_3_6_2">
<h4 id="sec6_3_6_2"><span epub:type="ordinal">6.3.6.2 </span>Common Sense Reasoning Benchmarks</h4>
<section aria-labelledby="sec6_3_6_2_1">
<h5 id="sec6_3_6_2_1"><span epub:type="ordinal">6.3.6.2.1 </span>BoolQ (<a href="#ref6_15" id="R_ref6_15" epub:type="biblioref" role="doc-biblioref">Clark et al., 2018</a>)</h5>
<p>BoolQ, which stands for Boolean Questions, is a question-answering dataset that involves determining whether a provided statement is true or false based on a given passage of text. The objective is to answer a binary (yes/no) question using the information in the passage. The benchmark comprises approximately 9,400 training examples, 3,200 verification examples, and 3,200 test examples.</p>
<p>Here is how the dataset is structured:</p>
<ul class="disc">
<li><b>Passage</b>: A snippet of text that contains the information necessary to answer the given question.</li>
<li><b>Question</b>: A yes/no question based on the passage.</li>
<li><b>Label</b>: A binary label indicating whether the answer to the question is &#x201C;Yes&#x201D; or &#x201C;No&#x201D; based on the passage.</li></ul>
<aside epub:type="tip" role="doc-tip" class="box ruled">
<h6 class="bh6" id="box6_1">Example</h6>
<ul class="disc">
<li><b>Passage:</b> &#x201C;Snoopy is a fictional character in the popular comic strip <i>Peanuts</i> by Charles Schulz. He is Charlie Brown&#x2019;s pet beagle. Snoopy is recognised for his imaginative and playful personality, and for his simple, distinctive appearance featuring a large round head, floppy ears, and a short tail.&#x201D;</li>
<li><b>Question:</b> &#x201C;Is Snoopy a cat?&#x201D;</li>
<li><b>Label:</b> No</li></ul></aside>
<p>The performance of models on BoolQ is typically evaluated using accuracy, which is the proportion of correct answers out of the total number of examples.</p>
<p>The BoolQ dataset challenges models in several ways:</p>
<ul class="disc">
<li><b>Reading Comprehension</b>: Models must be able to accurately extract and understand information from the passage to answer the question correctly.</li>
<li><b>Binary Classification</b>: Models need to classify the answer into one of two categories: Yes or No.</li>
<li><b>Inference</b>: Sometimes, the answer may not be explicitly stated in the passage, requiring the model to make inferences based on the available information.</li></ul>
<p><span epub:type="pagebreak" id="p199" aria-label=" page 199. " role="doc-pagebreak"/>By testing on datasets like BoolQ, researchers can gauge how well language models are able to understand and extract relevant information from text to answer questions accurately.</p></section>
<section aria-labelledby="sec6_3_6_2_2">
<h5 id="sec6_3_6_2_2"><span epub:type="ordinal">6.3.6.2.2 </span>PIQA (<a href="#ref6_7" id="R_ref6_7" epub:type="biblioref" role="doc-biblioref">Bisk et al., 2020</a>)</h5>
<p>The PIQA benchmark, which stands for Physical Intelligence Question Answering, is a dataset designed to test a system&#x2019;s understanding of everyday physical reasoning. It was introduced by Bisk et al. in their 2020 paper. The benchmark comprises approximately 16,100 training examples, 1,800 verification examples, and 3,000 test examples.</p>
<p>In this benchmark, questions are posed in such a manner that they necessitate the model to exhibit a common-sense understanding of the physical world to furnish accurate answers.</p>
<p>Here is how the data is structured in PIQA:</p>
<ul class="disc">
<li><b>Question</b>: A question that typically involves some aspect of everyday physical reasoning. This could include questions about the states of matter, simple machines, the motion of objects, etc.</li>
<li><b>Answer</b>: The correct answer to the question, often a sentence or phrase that explains the reasoning or provides a solution to the posed problem.</li></ul>
<aside epub:type="tip" role="doc-tip" class="box ruled">
<h6 class="bh6" id="box6_2">Example</h6>
<ul class="disc">
<li><b>Question</b>: &#x201C;You have a 5-gallon bucket and a 3-gallon bucket with no measurement markings, and you need to measure out exactly 4 gallons of water. How can you do it?&#x201D;</li>
<li><b>Answer</b>: &#x201C;Fill the 5-gallon bucket. Then use the 5-gallon bucket to fill the 3-gallon bucket, which will leave 2 gallons in the 5-gallon bucket. Empty the 3-gallon bucket and pour the 2 gallons from the 5-gallon bucket into the 3-gallon bucket. Now fill the 5-gallon bucket again. Now using the full 5-gallon bucket completely fill the 3-gallon bucket which currently has 2 gallons in it. Now you have 4 gallons of water left in the 5-gallon bucket.&#x201D;</li></ul></aside>
<p>The performance of models on the PIQA benchmark is typically evaluated based on the accuracy of the answers produced. This accuracy measure checks whether the model&#x2019;s answer matches the correct answer or if it provides a logically equivalent solution to the problem posed.</p>
<p>PIQA is a challenging dataset as it necessitates models to possess a common-sense understanding of physical principles and to apply this understanding to novel situations. It serves as a means to assess how proficiently AI systems can reason about the physical world in a manner analogous to humans.</p></section>
<section aria-labelledby="sec6_3_6_2_3">
<h5 id="sec6_3_6_2_3"><span epub:type="ordinal">6.3.6.2.3 </span>SIQA (<a href="#ref6_66" id="R_ref6_66" epub:type="biblioref" role="doc-biblioref">Sap et al., 2019</a>)</h5>
<p>The Social Intelligence Question Answering (SIQA) benchmark was introduced in a paper by Maarten Sap et al. in 2019. This dataset is designed to evaluate common-sense reasoning in AI models within the context of social situations. The objective is to determine how proficiently models can comprehend and reason about social scenarios, a skill vital for the development of AI systems that can interact naturally and effectively with humans. The <span epub:type="pagebreak" id="p200" aria-label=" page 200. " role="doc-pagebreak"/>benchmark comprises approximately 33,400 training examples, 1,900 verification examples, and 2,000 test examples.</p>
<p>The SIQA dataset consists of questions about social situations. Each question is paired with three possible answers: one correct answer and two incorrect answers.</p>
<ul class="disc">
<li><b>Context</b>: A description of a social situation.</li>
<li><b>Question</b>: A question related to the social scenario provided in the context.</li>
<li><b>Answers</b>: Three possible answers are provided, one correct and two incorrect.</li></ul>
<aside epub:type="tip" role="doc-tip" class="box ruled">
<h6 class="bh6" id="box6_3">Example</h6>
<ul class="disc">
<li><b>Context</b>: &#x201C;Jenny notices her coworker Maria seems down lately.&#x201D;</li>
<li><b>Question</b>: &#x201C;What should Jenny do to help Maria?&#x201D;</li>
<li><b>Answers</b>: (Correct) &#x201C;Jenny could ask Maria if she&#x2019;s okay and if there&#x2019;s anything she could do to help.&#x201D;</li></ul>
<p>(Incorrect) &#x201C;Jenny should ignore Maria and mind her own business.&#x201D;</p>
<p class="noindent">(Incorrect) &#x201C;Jenny should tell everyone about Maria&#x2019;s situation.&#x201D;</p></aside>
<p>The performance on SIQA is typically evaluated using metrics such as accuracy, which measures the proportion of correctly answered questions out of the total number posed. The reasoning behind the answer choices, as well as the social understanding exhibited by the model, can be analysed to gain deeper insight into the model&#x2019;s performance.</p>
<p>This benchmark assists researchers in gauging how proficiently their models can comprehend, interpret, and respond to social situations, marking a significant step towards the development of more socially aware AI systems.</p></section>
<section aria-labelledby="sec6_3_6_2_4">
<h5 id="sec6_3_6_2_4"><span epub:type="ordinal">6.3.6.2.4 </span>SWAG (<a href="#ref6_84" id="R_ref6_84" epub:type="biblioref" role="doc-biblioref">Zellers et al., 2018</a>)</h5>
<p>SWAG (Situations With Adversarial Generations) is a dataset aimed at evaluating grounded common-sense inference. It is designed to measure a system&#x2019;s ability to reason about everyday situations described in a sentence. The benchmark presents a partially observable scenario, with the objective being to predict the most plausible continuation from among four choices. The benchmark comprises approximately 73,000 training examples, 20,000 verification examples, and 20,000 test examples.</p>
<p>Here is how the SWAG dataset is structured:</p>
<ul class="disc">
<li><b>Premise Sentence</b>: This is a given statement or situation that sets up a scenario.</li>
<li><b>Ending Options</b>: There are four possible endings provided for each scenario.</li>
<li><b>Correct Ending</b>: Among the four endings, one of them is labelled as the correct or most plausible continuation of the scenario.</li></ul>
<p>The task is to select the most plausible ending based on the provided premise.</p>
<p>The dataset comprises multiple-choice questions about grounded situations, where models are expected to choose the most plausible continuation from four options. The creators of SWAG employed a novel adversarial filtering technique to construct the dataset. <span epub:type="pagebreak" id="p201" aria-label=" page 201. " role="doc-pagebreak"/>This ensures that the distractor (incorrect) answers are challenging and cannot be easily distinguished from the correct answer based solely on superficial text patterns.</p>
<aside epub:type="tip" role="doc-tip" class="box ruled">
<h6 class="bh6" id="box6_4">Example from SWAG</h6>
<ul class="disc">
<li><b>Premise:</b> On stage, a woman takes a seat at the piano. She</li>
<li>
<p><b>Ending Options:</b></p>
<ol class="lower-alpha">
<li>sits on a bench as her sister plays with the doll.</li>
<li>smiles with someone as the music plays.</li>
<li>is in the crowd, watching the dancers.</li>
<li>nervously sets her fingers on the keys.</li></ol></li>
<li><b>Correct Ending:</b> d) nervously sets her fingers on the keys.</li></ul></aside>
<p>The task for the model is to select the most plausible ending (in this case, option d) given the premise.</p>
<p>In evaluating a model using SWAG, the model&#x2019;s accuracy in selecting the correct ending is measured. This benchmark, therefore, provides a means to assess a system&#x2019;s common-sense reasoning capabilities within a grounded, real-world scenario context.</p></section>
<section aria-labelledby="sec6_3_6_2_5">
<h5 id="sec6_3_6_2_5"><span epub:type="ordinal">6.3.6.2.5 </span>HellaSwag (<a href="#ref6_85" id="R_ref6_85" epub:type="biblioref" role="doc-biblioref">Zellers et al., 2019</a>)</h5>
<p>HellaSwag is a benchmark dataset for evaluating machine learning models on their ability to perform common-sense reasoning. It can be seen as an extension or a more challenging version of the SWAG benchmark. The benchmark comprises approximately 39,000 training examples, 10,000 verification examples, and 20,000 test examples.</p>
<p>Here is a detailed breakdown:</p>
<ul class="disc">
<li><b>Premise</b>: Similar to SWAG, HellaSwag begins with a premise describing a particular scenario. However, the premises in HellaSwag are typically more intricate and potentially ambiguous.</li>
<li><b>Ending Options</b>: For each premise, four possible continuations are presented. These continuations are frequently designed to be misleading or non-obvious, thereby challenging the model&#x2019;s reasoning capabilities.</li>
<li><b>Correct Ending</b>: Among the four continuations, one is labelled as the correct or most plausible continuation based on the scenario described in the premise.</li></ul>
<p>The primary objective for a machine learning model in this benchmark is to select the most plausible continuation based on the provided premise.</p>
<p>The creators of HellaSwag employed a more sophisticated process to produce challenging distractor options among the continuations. They utilised an LLM to automatically generate distractor continuations that are plausible but incorrect. This approach renders HellaSwag a notably challenging benchmark, as the distractors are designed to be misleading for both models and potentially human evaluators.</p>
<aside epub:type="tip" role="doc-tip" class="box ruled">
<h6 class="bh6" id="box6_5">Example from HellaSwag</h6>
<ul class="disc">
<li><b>Premise:</b> A woman is outside with a bucket and a dog. The dog is running around trying to avoid a bath. She&#x2026;</li>
<li>
<p><b>Ending Options:</b></p>
<ol class="upper-alpha">
<li>rinses the bucket off with soap and blow dries the dog&#x2019;s head.</li>
<li>uses a hose to keep it from getting soapy.</li>
<li>gets the dog wet, then it runs away again.</li>
<li>gets into a bath tub with the dog.</li></ol></li>
<li><b>Correct Ending:</b> C. gets the dog wet, then it runs away again.</li></ul></aside>
<p><span epub:type="pagebreak" id="p202" aria-label=" page 202. " role="doc-pagebreak"/>The task for the model is to select the most plausible ending (in this case, option C) given the premise. The accuracy of the model on this task would indicate its ability to reason through complex, real-world scenarios with potentially misleading information.</p>
<p>HellaSwag was designed to be a challenging benchmark to push the boundaries of what models can do in terms of common-sense reasoning and understanding nuanced real-world scenarios.</p></section>
<section aria-labelledby="sec6_3_6_2_6">
<h5 id="sec6_3_6_2_6"><span epub:type="ordinal">6.3.6.2.6 </span>WinoGrande (<a href="#ref6_65" id="R_ref6_65" epub:type="biblioref" role="doc-biblioref">Sakaguchi et al., 2019</a>)</h5>
<p>WinoGrande is a large-scale dataset designed to evaluate machine learning models on their ability to solve Winograd Schema challenges. The Winograd Schema challenge is a type of common-sense reasoning task that tests a model&#x2019;s capability to resolve pronoun references in sentences. The benchmark comprises approximately 9,200 training examples, 1,200 verification examples, and 1,700 test examples.</p>
<p>WinoGrande offers a significant number of examples to furnish a more statistically robust assessment of a model&#x2019;s performance on such tasks. The examples within WinoGrande are crafted to be minimally divergent, signifying that a slight alteration in the wording of a sentence can modify the correct answer. This design aims to probe a model&#x2019;s grasp of nuanced language and contextual information. WinoGrande utilises an adversarial filtering approach to ensure the calibre and challenge level of the examples in the dataset. This filtering method aids in excluding examples that are either overly simplistic or present multiple potentially correct answers. The primary task for models using WinoGrande is to clarify ambiguous pronoun references within sentences, identifying, for instance, the specific entity to which a pronoun pertains.</p>
<aside epub:type="tip" role="doc-tip" class="box ruled">
<h6 class="bh6" id="box6_6">Example from WinoGrande</h6>
<ul class="disc">
<li><b>Sentence:</b> &#x201C;The trophy doesn&#x2019;t fit into the brown suitcase because it&#x2019;s too large.&#x201D;</li>
<li><b>Question:</b> What is too large?</li>
<li><b>Options:</b> (1) The trophy, (2) The brown suitcase</li>
<li><b>Correct Answer:</b> (1) The trophy</li></ul></aside>
<p>The challenge in this example arises from the ambiguous reference of &#x201C;it&#x201D; in the sentence. The model is tasked with determining to what &#x201C;it&#x201D; refers, based on the contextual information provided in the sentence.</p>
<p>The WinoGrande benchmark aims to offer a more rigorous evaluation of models&#x2019; common-sense reasoning abilities and their grasp of nuanced language. It is designed to be a challenging benchmark that pushes the boundaries of models&#x2019; capabilities in terms of common-sense reasoning and understanding natural language.</p></section>
<section aria-labelledby="sec6_3_6_2_7">
<h5 id="sec6_3_6_2_7"><span epub:type="ordinal">6.3.6.2.7 </span>ARC Easy and Challenge (<a href="#ref6_15" epub:type="biblioref" role="doc-biblioref">Clark et al., 2018</a>)</h5>
<p>The ARC dataset stands for AI2 Reasoning Challenge, which was developed by the Allen Institute for Artificial Intelligence (AI2). The dataset is created to evaluate a machine learning model&#x2019;s ability to answer questions that require reasoning and understanding across <span epub:type="pagebreak" id="p203" aria-label=" page 203. " role="doc-pagebreak"/>several sentences. The ARC dataset is divided into two subsets: ARC-Easy and ARC-Challenge.</p>
<p><b>ARC-Easy</b> (2,200 training, 500 validation, 2,300 testing):</p>
<p>This part of the dataset contains questions that are relatively easy to answer. These questions might not require deep reasoning and might be solvable with straightforward fact retrieval or simpler inference.</p>
<p><b>ARC-Challenge</b> (1,100 training, 290 validation, 1,100 testing):</p>
<p>This subset consists of questions that are more challenging and are designed to necessitate more advanced reasoning to answer correctly. The questions in ARC-Challenge are expected to be difficult for current machine learning models and aim to push the boundary of what AI systems can achieve in terms of reasoning.</p>
<p>Each example in the ARC dataset consists of a question, a set of possible answer choices, and the correct answer. The questions are formatted as multiple-choice questions. This format allows for clear evaluation metrics by checking whether the model selects the correct answer. The questions cover a range of topics, primarily within the domain of science. They are sourced from real 3rd to 9th grade science exams, aiming to challenge models with questions that are easy for humans but hard for machines. Both the ARC-Easy and ARC-Challenge subsets are designed to require external knowledge to answer correctly, going beyond the information given in the question itself.</p>
<p><b>ARC-Easy Example</b>:</p>
<ul class="disc">
<li><b>Question</b>: &#x201C;What gas do plants absorb from the atmosphere to photosynthesise?&#x201D;</li>
<li>
<p><b>Answers</b>:</p>
<ol class="lower-alpha">
<li>Oxygen</li>
<li>Nitrogen</li>
<li>Carbon Dioxide</li>
<li>Hydrogen</li></ol></li>
<li><b>The correct answer</b> is c) Carbon Dioxide.</li></ul>
<p><b><span epub:type="pagebreak" id="p204" aria-label=" page 204. " role="doc-pagebreak"/>ARC-Challenge Example</b>:</p>
<ul class="disc">
<li><b>Question</b>: &#x201C;If a plant living in a desert has evolved to have spines instead of leaves, what could be the most likely reason for this adaptation?&#x201D;</li>
<li>
<p><b>Answers</b>:</p>
<ol class="lower-alpha">
<li>To attract more insects for pollination</li>
<li>To reduce water loss through transpiration</li>
<li>To capture more sunlight for photosynthesis</li>
<li>To make it easier for the plant to capture prey</li></ol></li>
<li><b>The correct answer</b> is b) To reduce water loss through transpiration.</li></ul>
<p>Alongside the ARC dataset, a corpus of text is provided which contains the information necessary to answer the questions. This corpus can be used to train models to use external information to answer questions.</p>
<aside epub:type="tip" role="doc-tip" class="box ruled">
<h3 id="box6_7">Example extract from corpus of text related to above questions</h3>
<blockquote>
<p>Floods can destroy drainage systems in cities.</p>
<p>photosynthesise using light, carbon dioxide, and water</p>
<p>The ruler of your sign is Mars &#x2013; the god of courage, action, strength, and energy.</p>
<p>&#x2026;..</p>
<p>Fashion brands came back to the fore, with sp</p>
<p>ort and music brands becoming more conspicuous,&#x0026;rdquo; said Stephen Cheliotis, chairman of the CoolBrands council.</p>
<p>The leaves in areas exposed to the sun tend to have more spines than the shaded ones, which may even be spineless.</p>
<p>Only the females Burrow and feed.</p>
<p>&#x2026;..</p>
<p>Defensive adaptations: Plants as we know have evolved ways to defend themselves by using sharp spines, thorns or hairs; cellulose that makes them hard to digest, or creating toxic chemicals.</p>
<p>&#x2026;..</p>
<p>Also it can prevent lots of water going out from the leaf because less water comes out from the spines.</p>
<p>&#x2026;..</p>
<p>By reducing leaves to spines on some xerophytes, this greatly reduces the surface area of the leaf, which greatly reduces the amount of transpiration, helping assist in reducing water loss.</p></blockquote></aside>
<p>It should be noted that the corpus of text is not structured; each sentence can be on totally different topics (e.g., one sentence quoted above pertains to floods, followed by photosynthesis, and then a reference to the god Mars). The model being evaluated may have to combine items from disparate locations in the corpus of text to answer specific, particularly challenging questions. In the above example at least five different areas of the text corpus are relevant or potentially relevant. Naturally, the model can draw on its other training data, not just the corpus associated with the benchmark, to answer the questions.</p>
<p>The primary aim of the ARC dataset is to encourage the development of new models that can reason and understand text in a manner akin to humans, especially within an educational or scientific context. The distinction between ARC-Easy and ARC-Challenge allows for the evaluation of models at different levels of difficulty, advancing the state-of-the-art in machine reasoning.</p></section></section>
<section aria-labelledby="sec6_3_6_3">
<h4 id="sec6_3_6_3"><span epub:type="ordinal">6.3.6.3 </span>Question Answering Benchmarks</h4>
<section aria-labelledby="sec6_3_6_3_1">
<h5 id="sec6_3_6_3_1"><span epub:type="ordinal">6.3.6.3.1 </span>OpenBookQA (<a href="#ref6_43" id="R_ref6_43" epub:type="biblioref" role="doc-biblioref">Mihaylov et al., 2018</a>)</h5>
<p>OpenBookQA is a benchmark designed to evaluate the ability of machine learning models to answer questions based on a small set of facts, known as the &#x201C;Open Book&#x201D;. The &#x201C;Open Book&#x201D; consists of a collection of facts that should be sufficient for answering the questions in the dataset. The aim is to test the model&#x2019;s capacity to reason over these facts and combine information to answer questions accurately. The benchmark has about 4,900 training <span epub:type="pagebreak" id="p205" aria-label=" page 205. " role="doc-pagebreak"/>examples and about 500 verification examples, and 500 test examples. The open book contains about 1,300 entries or facts.</p>
<p>Each question comes with four answer choices, out of which only one is correct. The questions are designed to be answerable with the help of the facts provided in the Open Book, though some external common knowledge might also be required. The questions cover a variety of topics and are designed to test various forms of reasoning including retrieval, comparison, spatial reasoning, temporal reasoning, causality, etc. Evaluation is typically done based on the accuracy of the model in selecting the correct answer from the provided options.</p>
<aside epub:type="tip" role="doc-tip" class="box ruled">
<h6 class="bh6" id="box6_8">Example</h6>
<ul class="disc">
<li>
<p><b>Question:</b> Why do mirrors reflect light?</p>
<ol class="lower-alpha">
<li>They have a smooth surface that allows light to bounce off.</li>
<li>They absorb all colours of light equally.</li>
<li>They allow light to pass through without scattering.</li>
<li>They convert light energy into heat energy.</li></ol></li>
<li><b>The correct answer to this question</b> is: a) They have a smooth surface that allows light to bounce off.</li></ul></aside>
<p>OpenBookQA is used by researchers to evaluate and compare different question-answering models. It is particularly useful for assessing how well models can leverage a limited set of facts to answer a broad range of questions.</p>
<p>The OpenBookQA benchmark presents a controlled setting to evaluate how effectively machine learning models can utilise a set of facts to answer questions that require some level of reasoning or synthesis of information.</p></section>
<section aria-labelledby="sec6_3_6_3_2">
<h5 id="sec6_3_6_3_2"><span epub:type="ordinal">6.3.6.3.2 </span>Natural Questions (<a href="#ref6_34" id="R_ref6_34" epub:type="biblioref" role="doc-biblioref">Kwiatkowski et al., 2019</a>)</h5>
<p>The Natural Questions (NQ) benchmark, introduced by Kwiatkowski et al. in 2019, is designed to evaluate models on their ability to answer real-world questions based on the content of a given document. In this benchmark, each example consists of a question along with a Wikipedia page, and the task is to identify a specific span of text from the page that answers the question, or indicate that no answer is present. The full dataset is 42Gb, but a simplified dataset is available which is about 4Gb.</p>
<aside epub:type="tip" role="doc-tip" class="box ruled">
<h6 class="bh6" id="box6_9">Example</h6>
<ul class="disc">
<li><b>URL</b>: Five Nights at Freddy&#x2019;s (<a href="https://en.wikipedia.org">https://en.wikipedia.org//w/index.php?title=Five_Nights_at_Freddy%27s&#x0026;oldid=827108665</a>)</li>
<li><b>Question</b>: &#x201C;What is the story behind 5 nights at freddy&#x2019;s?&#x201D;</li>
<li><b>Long Answer</b>: &#x201C;The series is centered on the story of a fictional restaurant named Freddy Fazbear&#x2019;s Pizza, a pastiche of restaurants like Chuck E. Cheese&#x2019;s and ShowBiz Pizza Place. The first three games involve the player working as a nighttime security guard, in which they must utilise several tools, most notably checking security cameras, to survive against animatronic characters, which become mobile and homicidal after-hours. The fourth game, which uses different gameplay mechanics from its predecessors, takes place in the house of a child who must defend against nightmarish versions of the animatronics by closing doors and fleeing on foot. The fifth game takes place in a maintenance facility owned by a sister company of Freddy Fazbear&#x2019;s Pizza. The player character is a technician instead of a night guard, who must do different tasks each night as told by an AI voice heard in the game. In the sixth game, the player acts as the owner of a pizzeria which they must decorate with payable items, and must also work the night shift for their pizzeria, which plays similarly to previous games.&#x201D;</li>
<li><b>Short Answer</b>: None</li></ul></aside>
<p><span epub:type="pagebreak" id="p206" aria-label=" page 206. " role="doc-pagebreak"/>This task closely mimics real-world scenarios where users pose questions based on a document or a web page they are viewing. For instance, a question could be: &#x201C;When was the Eiffel Tower completed?&#x201D; Given a Wikipedia page about the Eiffel Tower, the correct response would be to identify the text span &#x201C;completed in 1889&#x201D; as the answer. This benchmark is significant as it requires models to effectively handle a wide range of natural language questions and to extract precise answers from the accompanying documents, showcasing their comprehension and information retrieval capabilities.</p></section>
<section aria-labelledby="sec6_3_6_3_3">
<h5 id="sec6_3_6_3_3"><span epub:type="ordinal">6.3.6.3.3 </span>TriviaQA (<a href="#ref6_30" id="R_ref6_30" epub:type="biblioref" role="doc-biblioref">Joshi et al., 2017</a>)</h5>
<p>TriviaQA, introduced by Joshi et al. in 2017, is a benchmark designed to evaluate models on their ability to answer trivia questions. The dataset comprises question&#x2013;answer pairs from trivia enthusiasts along with evidence documents that provide supporting information for the answers. The goal is for models to accurately answer the questions using the information available in the associated documents. It contains over 650K question-answer-evidence triples.</p>
<p>In TriviaQA, the questions are grouped by the source from which they come, and are categorised as either verified or unverified based on whether they have been cross-checked against the evidence documents. The evidence documents are collected from various sources like Wikipedia, web pages, or books, which provide a good diversity of language and complexity.</p>
<p>A sample question from TriviaQA might be:</p>
<ul class="disc">
<li><b>Question</b>: &#x201C;What river is the principal river of northern Italy?&#x201D; <b>Answer</b>: &#x201C;Po&#x201D;.</li>
<li><b>Evidence</b>: Link to Wikipedia, and perhaps a link to another source</li></ul>
<p>In this benchmark, models are evaluated on their ability to not only provide the correct answer but also to demonstrate an understanding of the context and evidence from the supporting documents that justify the answer. This benchmark challenges models in reading comprehension, knowledge extraction, and the ability to handle a mix of formal and informal text, making it a robust measure of a model&#x2019;s capacity to deal with real-world, open-domain question-answering scenarios.</p></section>
<section aria-labelledby="sec6_3_6_3_4">
<h5 id="sec6_3_6_3_4"><span epub:type="ordinal">6.3.6.3.4 </span>SQuAD v1.1 (<a href="#ref6_56" id="R_ref6_56" epub:type="biblioref" role="doc-biblioref">Rajpurkar et al., 2016</a>) and 2.0 (<a href="#ref6_55" id="R_ref6_55" epub:type="biblioref" role="doc-biblioref">Rajpurkar et al., 2018</a>)</h5>
<p>The Stanford Question Answering Dataset (SQuAD 1.1) is a collection of 100k crowdsourced question-answer pairs (<a href="#ref6_56" epub:type="biblioref" role="doc-biblioref">Rajpurkar et al., 2016</a>).</p>
<p>The Stanford Question Answering Dataset (SQuAD) is a widely recognised benchmark for evaluating the performance of machine reading and question-answering (QA) systems. In this benchmark, models are provided with a passage of text and then asked to answer questions based on the content of that text.</p>
<p>SQuAD consists of two main versions: SQuAD 1.1 and SQuAD 2.0. In SQuAD 1.1, the focus is on answering questions where the answer is guaranteed to be present in the provided passage. SQuAD 2.0, on the other hand, includes questions for which the answer may or may not be present in the passage, thus challenging models to determine when the information needed to answer a question is lacking.</p>
<p class="list-title"><span epub:type="pagebreak" id="p207" aria-label=" page 207. " role="doc-pagebreak"/>Here is an example from SQuAD 1.1:</p>
<ul class="disc">
<li><b>Passage</b>: &#x201C;Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24&#x2013;10 to earn their third Super Bowl title.&#x201D;</li>
<li><b>Question</b>: &#x201C;Which NFL team won Super Bowl 50?&#x201D;</li>
<li><b>Answer</b>: &#x201C;Denver Broncos&#x201D;</li></ul>
<p class="list-title">And an example from SQuAD 2.0:</p>
<ul class="disc">
<li><b>Passage</b>: as above</li>
<li><b>Question</b>: &#x201C;Who was the MVP of Super Bowl 50?&#x201D;</li>
<li><b>Answer</b>: In this case, the passage does not provide the information needed to answer the question, so the correct response would be to indicate that the answer is not present in the passage.</li></ul>
<p>SQuAD has been a crucial benchmark for evaluating and comparing different QA systems, and has spurred a significant amount of research in the NLP community.</p></section></section>
<section aria-labelledby="sec6_3_6_4">
<h4 id="sec6_3_6_4"><span epub:type="ordinal">6.3.6.4 </span>Reading Comprehension Benchmarks</h4>
<section aria-labelledby="sec6_3_6_4_1">
<h5 id="sec6_3_6_4_1"><span epub:type="ordinal">6.3.6.4.1 </span>RACE reading comprehension benchmark (<a href="#ref6_35" id="R_ref6_35" epub:type="biblioref" role="doc-biblioref">Lai et al., 2017</a>)</h5>
<p>The RACE (ReAding Comprehension from Examinations) dataset is a large-scale reading comprehension dataset collected from English examinations in China, intended for students in grades 3 through 12. The benchmark is designed to evaluate machine comprehension models in a more challenging and realistic setting, as it includes a diverse range of question types and topics.</p>
<p>The dataset is split into two subsets: RACE-M, which consists of middle school exam questions, and RACE-H, which consists of high school exam questions.</p>
<p>Here is the format for how questions and passages are structured within the RACE benchmark:</p>
<ul class="disc">
<li>A passage is provided, which could be a narrative, an article, or a dialogue.</li>
<li>Multiple-choice questions related to the passage are presented, each with four answer options.</li></ul>
<p>Here is a simplified example inspired by the kind of questions you might find in the RACE dataset:</p>
<ul class="disc">
<li><b>Passage</b>: &#x201C;In 1920, women in the United States won the right to vote with the ratification of the 19th amendment to the US Constitution. This was the result of many years of struggle and activism by women suffragists who believed in equal voting rights for women.&#x201D;</li>
<li><b>Question</b>: &#x201C;What did the 19th amendment to the US Constitution grant?&#x201D;</li>
<li><span epub:type="pagebreak" id="p208" aria-label=" page 208. " role="doc-pagebreak"/><b>Answers</b>:
<ol class="lower-alpha">
<li>The right for women to work</li>
<li>The right for women to vote</li>
<li>The abolition of slavery</li>
<li>The establishment of income tax</li></ol></li>
<li><b>Correct Answer</b>: b) The right for women to vote</li></ul>
<p>In this example, the passage provides the necessary information to answer the multiple-choice question. The model&#x2019;s task is to understand the passage well enough to select the correct answer from the provided options. In a real-world scenario, the questions in RACE can be much more challenging and the passages longer and more complex, making it a robust benchmark for evaluating reading comprehension models.</p></section></section>
<section aria-labelledby="sec6_3_6_5">
<h4 id="sec6_3_6_5"><span epub:type="ordinal">6.3.6.5 </span>Mathematical Reasoning Benchmarks</h4>
<section aria-labelledby="sec6_3_6_5_1">
<h5 id="sec6_3_6_5_1"><span epub:type="ordinal">6.3.6.5.1 </span>MATH (<a href="#ref6_26" id="R_ref6_26" epub:type="biblioref" role="doc-biblioref">Hendrycks et al., 2021</a>)</h5>
<p>The MATH (Mathematical Reasoning Dataset) benchmark introduced by Hendrycks et al., in 2021, is designed to evaluate the mathematical reasoning abilities of machine learning models. The dataset contains mathematical problems that require various levels of reasoning and understanding to solve. The problems cover a wide range of topics and difficulty levels, which makes it a challenging benchmark for assessing how well models can handle abstract mathematical reasoning and symbol manipulation. The dataset consists of 12,500 challenging competition mathematics problems (7,500 training, 5,000 testing). Each problem in MATH has a full step-by-step solution which can be used to teach models to generate answer derivations and explanations.</p>
<p>The questions in the MATH dataset are categorised into several topics, including algebra, calculus, geometry, measurement, number theory, probability, and statistics. Each question is accompanied by a step-by-step solution, which is intended to help evaluate how well models can generate not just the final answer, but also the intermediate steps and explanations.</p>
<p>Here is a simplified example inspired by the kind of questions you might find in the MATH dataset:</p>
<ul class="disc">
<li><b>Question</b>: &#x201C;Simplify the expression: (x<sup>2</sup> + 2x + 1) + (2x<sup>2</sup> + 3x + 2)&#x201D;</li>
<li><b>Step-by-step Solution</b>: &#x201C;First, we&#x2019;ll add the like terms together. We&#x2019;ll start with the terms that have x<sup>2</sup>: x<sup>2</sup> + 2x<sup>2</sup> = 3x<sup>2</sup>; Now, we&#x2019;ll add the terms that have x: 2x + 3x = 5x; Finally, we&#x2019;ll add the constant terms: 1 + 2 = 3; Putting it all together, we get: 3x + 2+5x+3</li>
<li><b>Final Answer</b>: 3x<sup>2</sup> + 5x + 3</li></ul>
<p>In this problem, the model would need to recognise the structure of polynomial expressions and perform the appropriate operations to simplify the expression. The step-by-step solution is crucial for understanding the model&#x2019;s reasoning process.</p></section>
<section aria-labelledby="sec6_3_6_5_2">
<h5 id="sec6_3_6_5_2"><span epub:type="ordinal">6.3.6.5.2 </span>GSM8k (<a href="#ref6_16" id="R_ref6_16" epub:type="biblioref" role="doc-biblioref">Cobbe et al., 2021</a>)</h5>
<p>GSM8K (Grade School Math) consists of high-quality grade school math problems. These were created by human problem writers. The dataset is segmented into 7,400 training problems and 1,300 test problems. The problems take between 2 and 8 steps to solve, and <span epub:type="pagebreak" id="p209" aria-label=" page 209. " role="doc-pagebreak"/>solutions involve performing a sequence of elementary calculations using basic arithmetic operations to reach the final answer. This benchmark is from Cobbe et al. in OpenAI.</p>
<aside epub:type="tip" role="doc-tip" class="box ruled">
<h3 id="box6_10">Example</h3>
<ul class="disc">
<li><b>Problem</b>: Beth bakes 4, 2 dozen batches of cookies in a week. If these cookies are shared amongst 16 people equally, how many cookies does each consume?</li>
<li><b>Solution</b>: Beth bakes 4 2 dozen batches of cookies for a total of 4*2 = 8 dozen cookies. There are 12 cookies in a dozen and she makes 8 dozen cookies for a total of 12*8 = 96 cookies. She splits the 96 cookies equally amongst 16 people so they each eat 96/16 = 6 cookies</li>
<li><b>Final Answer</b>: 6</li></ul></aside>
<p>One of the goals of this benchmark was to help facilitate research for model creators and allow them to measure the performance of their models using different approaches for this multi-step type of mathematical problems which even high-parameter count modern transformer-based models have difficulty solving.</p></section></section>
<section aria-labelledby="sec6_3_6_6">
<h4 id="sec6_3_6_6"><span epub:type="ordinal">6.3.6.6 </span>Code Generation Benchmarks</h4>
<section aria-labelledby="sec6_3_6_6_1">
<h5 id="sec6_3_6_6_1"><span epub:type="ordinal">6.3.6.6.1 </span>HumanEval (<a href="#ref6_11" id="R_ref6_11" epub:type="biblioref" role="doc-biblioref">Chen et al., 2021</a>)</h5>
<p>The HumanEval benchmark, introduced by OpenAI in a paper by <a href="#ref6_11" epub:type="biblioref" role="doc-biblioref">Chen et al., 2021</a>, is designed to evaluate the problem-solving abilities of language models. The benchmark consists of a dataset of tasks (approx. 160), where each task is a function problem written in Python that the model has to solve by predicting the function&#x2019;s output based on given inputs. The problems are designed to require mathematical, logical, or other forms of common-sense reasoning.</p>
<p>In HumanEval, the tasks are formulated in a way that they are easy for humans to solve but are challenging for machine models, aiming to bridge the gap between human and machine problem-solving capabilities. The tasks are not constrained to a particular domain or type and can span a range of topics and difficulty levels. They can encompass various types of problems, like mathematical calculations, string manipulations, or logic-based puzzles.</p>
<p>Here is an example task from HumanEval:</p>
<aside class="box ruled" aria-label="box6_11">
<pre id="preformat2">def find_smallest_positive_even_number(arr):
&#x201C;&#x201C;&#x201C;
Args:
  - arr: a list of integers (0 &#x003C;= len(arr) &#x003C;= 1000, -1000 &#x003C;= arr[i] &#x003C;= 1000)
Returns:
  - int: the smallest positive even number in arr. If no number satisfies the conditions, return -1.
&#x201C;&#x201C;&#x201C;
# Your code here</pre></aside>
<p><span epub:type="pagebreak" id="p210" aria-label=" page 210. " role="doc-pagebreak"/>A model is supposed to generate Python code that solves the described problem in the comment. In this case, it might generate something like:</p>
<aside class="box ruled" aria-label="box6_12">
<pre id="preformat3"><b>def find_smallest_positive_even_number(arr):</b>
  smallest_positive_even = -1
  for num in arr:
   if num &#x003E; 0 and num % 2 == 0:
     if smallest_positive_even == -1 or num &#x003C; smallest_positive_even:
       smallest_positive_even = num
 return smallest_positive_even</pre></aside>
<p>The main goal of the HumanEval benchmark is to push forward the capabilities of models in terms of problem solving and reasoning. The benchmark can be used to evaluate different models and to understand how well they can understand and generate correct and efficient code to solve a given problem.</p></section>
<section aria-labelledby="sec6_3_6_6_2">
<h5 id="sec6_3_6_6_2"><span epub:type="ordinal">6.3.6.6.2 </span>MBPP (<a href="#ref6_5" id="R_ref6_5" epub:type="biblioref" role="doc-biblioref">Austin et al., 2021</a>)</h5>
<p>The MBPP (Mostly Basic Programming Problems) benchmark consists of about 970 Python programming problems, designed to be solvable by beginner-level programmers, covering programming fundamentals, standard library functionality, etc. Each problem consists of a task description, code solution and 3 automated test cases.</p>
<aside epub:type="tip" role="doc-tip" class="box ruled">
<h3 id="box6_13">Example</h3>
<pre id="preformat4"><b>Problem</b>: &#x201C;Write a function to find the minimum cost path to reach (m, n) from (0, 0) for the given cost matrix cost[][] and a position (m, n) in cost[][].&#x201D;
<b>Tests</b>:&#x201C;assert min_cost([[1, 2, 3], [4, 8, 2], [1, 5, 3]], 2, 2) == 8&#x201D;,
      &#x201C;assert min_cost([[2, 3, 4], [5, 9, 3], [2, 6, 4]], 2, 2) == 12&#x201D;,
      &#x201C;assert min_cost([[3, 4, 5], [6, 10, 4], [3, 7, 5]], 2, 2) == 16&#x201D;
<b>Code</b>:&#x201C;R = 3
     C = 3
     def min_cost(cost, m, n):
               tc = [[0 for x in range(C)] for x in range(R)]
               tc[0][0] = cost[0][0]
               for i in range(1, m+1):
                           tc[i][0] = tc[i-1][0] + cost[i][0]
               for j in range(1, n+1):
                           tc[0][j] = tc[0][j-1] + cost[0][j]
               for i in range(1, m+1):
                           for j in range(1, n+1):
                                      tc[i][j] = min(tc[i-1][j-1], tc[i-1][j], tc[i][j-1])+cost[i][j]
               return tc[m][n]&#x201D;,</pre>
<p>The model needs to generate the code to solve the problem and ensure that the tests provided should pass.</p></aside></section></section>
<section aria-labelledby="sec6_3_6_7">
<h4 id="sec6_3_6_7"><span epub:type="pagebreak" id="p211" aria-label=" page 211. " role="doc-pagebreak"/><span epub:type="ordinal">6.3.6.7 </span>Multi-task Language Understanding Benchmarks</h4>
<section aria-labelledby="sec6_3_6_7_1">
<h5 id="sec6_3_6_7_1"><span epub:type="ordinal">6.3.6.7.1 </span>GLUE (<a href="#ref6_77" id="R_ref6_77" epub:type="biblioref" role="doc-biblioref">Wang et al., 2018</a>)</h5>
<p>GLUE (General Language Understanding Evaluation) consists of a collection of nine NLU (Natural Language Understanding) tasks, covering a variety of linguistic phenomena and domains. The number of training examples, verification examples, and testing examples for each of the following varies considerably. The approximate numbers shown give some guidance.</p>
<p>Here are the tasks included in GLUE with some examples to help understand the concept being tested:</p>
<ol class="decimal">
<li>
<p>MultiNLI (Multi-Genre Natural Language Inference): Assessing whether a hypothesis is entailed, contradicted, or neither by a given premise (391,000 training, 19,000 testing, 19,000 validation).</p>
<ol class="lower-alpha">
<li>Premise: &#x201C;The orchestra is playing a beautiful symphony.&#x201D;</li>
<li>Hypothesis: &#x201C;There is a musical performance by the orchestra.&#x201D;</li>
<li>Label: Entailment</li></ol></li>
<li>
<p>QQP (Quora Question Pairs): Identifying duplicate questions (363,000 training, 390,000 testing, 40,000 validation).</p>
<ol class="lower-alpha">
<li>Question1: &#x201C;How can I improve my credit score?&#x201D;</li>
<li>Question2: &#x201C;What steps can I take to boost my credit rating?&#x201D;</li>
<li>Label: Duplicate</li></ol></li>
<li>
<p>QNLI (Question Natural Language Inference): Identifying answer sentences for a given question (103,000 training, 5,000 testing, 5,000 validation).</p>
<ol class="lower-alpha">
<li>Question: &#x201C;What is the capital of France?&#x201D;</li>
<li>Sentence: &#x201C;Paris is the capital of France.&#x201D;</li>
<li>Label: Entailment</li></ol></li>
<li>
<p>SST-2 (Stanford Sentiment Treebank): Binary sentiment classification (67,000 training, 1,800 testing, 800 validation).</p>
<ol class="lower-alpha">
<li>Sentence: &#x201C;The storyline was dull and unexciting.&#x201D;</li>
<li>Label: Negative</li>
<li>Sentence: &#x201C;The movie was fantastic with a gripping plot.&#x201D;</li>
<li>Label: Positive</li></ol></li>
<li>
<p>CoLA (Corpus of Linguistic Acceptability): Grammaticality judgment (8,000 training, 1,000 testing, 1,000 validation).</p>
<ol class="lower-alpha">
<li>Sentence: &#x201C;The book was put on top of the shelf by John.&#x201D;</li>
<li>Label: Acceptable</li>
<li>Sentence: &#x201C;The grass green.&#x201D;</li>
<li>Label: Unacceptable</li></ol></li>
<li>
<p>STS-B (Semantic Textual Similarity Benchmark): Estimating similarity scores for sentence pairs (5,000 training, 1,000 testing, 1,400 validation).</p>
<ol class="lower-alpha">
<li>Sentence1: &#x201C;A dog is running in a park.&#x201D;</li>
<li>Sentence2: &#x201C;A dog is sprinting across the park.&#x201D;</li>
<li>Similarity Score: High</li></ol></li>
<li><span epub:type="pagebreak" id="p212" aria-label=" page 212. " role="doc-pagebreak"/>MRPC (Microsoft Research Paraphrase Corpus): Identifying paraphrases among sentence pairs (4,000 training, 1,700 testing).
<ol class="lower-alpha">
<li>Sentence1: &#x201C;The company reported a significant increase in quarterly revenue.&#x201D;</li>
<li>Sentence2: &#x201C;Quarterly revenue saw a significant rise as reported by the company.&#x201D;</li>
<li>Label: Equivalent</li></ol></li>
<li>
<p>RTE (Recognising Textual Entailment): Identifying entailment between pairs of text (2,400 training, 2,900 testing, 270 validation).</p>
<ol class="lower-alpha">
<li>Sentence1: &#x201C;No evidence that chemical imbalances cause depression has been found.&#x201D;</li>
<li>Sentence2: &#x201C;Chemical imbalances cause depression.&#x201D;</li>
<li>Label: Not Entailment</li></ol></li>
<li>
<p>WNLI (Winograd NLI): Natural language inference using coreference resolution (600 training, 140 testing, 70 validation).</p>
<ol class="lower-alpha">
<li>Sentence1: &#x201C;The keys were locked inside the car.&#x201D;</li>
<li>Sentence2: &#x201C;The car had the keys locked inside.&#x201D;</li>
<li>Label: Entailment</li></ol></li></ol></section>
<section aria-labelledby="sec6_3_6_7_2">
<h5 id="sec6_3_6_7_2"><span epub:type="ordinal">6.3.6.7.2 </span>SuperGLUE (<a href="#ref6_76" id="R_ref6_76" epub:type="biblioref" role="doc-biblioref">Wang et al., 2019</a>)</h5>
<p>SuperGLUE was introduced as a more challenging successor to GLUE, and it consists of a new set of more difficult language understanding tasks. Here are the tasks included in SuperGLUE:</p>
<ol class="decimal">
<li>BoolQ (Boolean Questions): Answering yes/no questions. The details of BoolQ are provided in a separate section as it is its own benchmark.</li>
<li>
<p>CB (CommitmentBank): Identifying entailment relationships involving human commitments (250 training, 250 testing, 50 validation).</p>
<ol class="lower-alpha">
<li>Premise: &#x201C;I can&#x2019;t help you move next weekend.&#x201D;</li>
<li>Hypothesis: &#x201C;The speaker is not available to help with moving next weekend.&#x201D;</li>
<li>Label: Entailment</li></ol></li>
<li>
<p>COPA (Choice of Plausible Alternatives): Identifying causes or effects in given situations (400 training, 500 testing, and 100 validation).</p>
<ol class="lower-alpha">
<li>Question: &#x201C;What was the effect?&#x201D;</li>
<li>Sentence: &#x201C;He didn&#x2019;t study, so he failed the exam.&#x201D;</li>
<li>Choices: 1) He didn&#x2019;t study. 2) He failed the exam.</li>
<li>Answer: He failed the exam.</li></ol></li>
<li>
<p>MultiRC (Multi-Sentence Reading Comprehension): Answering questions with multiple possible answers (450 training, 150 testing, 80 validation).</p>
<ol class="lower-alpha">
<li>Question: &#x201C;What happened to the cat?&#x201D;</li>
<li>Passage: &#x201C;The cat climbed up the tree and couldn&#x2019;t come down.&#x201D;</li>
<li>Answer: &#x201C;Climbed up the tree, couldn&#x2019;t come down.&#x201D;</li></ol></li>
<li>
<p>ReCoRD (Reading Comprehension with Common-sense Reasoning Dataset): Reading comprehension that involves common-sense reasoning (65,000 training, 7,400 testing, 7,400 validation).</p>
<ol class="lower-alpha">
<li><span epub:type="pagebreak" id="p213" aria-label=" page 213. " role="doc-pagebreak"/>Question: &#x201C;Who bought flowers?&#x201D;</li>
<li>Passage: &#x201C;George went to the store and bought some flowers.&#x201D;</li>
<li>Answer: George</li></ol>
<ol class="lower-alpha">
<li>Question: &#x201C;Why couldn&#x2019;t the cat come down?&#x201D;</li>
<li>Passage: &#x201C;The cat climbed up the tree and couldn&#x2019;t come down.&#x201D;</li>
<li>Answer: It&#x2019;s not stated.</li></ol></li>
<li>
<p>RTE (Recognising Textual Entailment): Also included in GLUE, but reused here (2,400 training, 3000 testing, 270 validation).</p>
<ol class="lower-alpha">
<li>Sentence1: &#x201C;The sun rises in the east.&#x201D;</li>
<li>Sentence2: &#x201C;The sun sets in the west.&#x201D;</li>
<li>Label: Not Entailment</li></ol></li>
<li>
<p>WiC (Word-in-Context): Determining whether a word is used with the same sense in two sentences (5,400 training, 1,400 testing, 630 validation).</p>
<ol class="lower-alpha">
<li>Word: &#x201C;rock&#x201D;</li>
<li>Sentence1: &#x201C;He collects rocks.&#x201D;</li>
<li>Sentence2: &#x201C;He&#x2019;s my rock.&#x201D;</li>
<li>Label: Different</li></ol></li>
<li>
<p>WSC (Winograd Schema Challenge): A coreference resolution task, similar to WNLI in GLUE (550 training, 140 testing, 100 testing).</p>
<ol class="lower-alpha">
<li>Sentence: &#x201C;The man who hunts ducks out on weekends.&#x201D;</li>
<li>Question: &#x201C;Who hunts ducks?&#x201D;</li>
<li>Answer: The man</li></ol></li></ol></section>
<section aria-labelledby="sec6_3_6_7_3">
<h5 id="sec6_3_6_7_3"><span epub:type="ordinal">6.3.6.7.3 </span>MMLU (<a href="#ref6_25" id="R_ref6_25" epub:type="biblioref" role="doc-biblioref">Hendrycks et al., 2020</a>)</h5>
<p>The MMLU (Massive Multitask Language Understanding) benchmark, introduced by Hendrycks in 2020, encompasses 57 tasks that span various domains, including elementary mathematics, US history, computer science, law, and more. This benchmark was established in response to recent advancements in LLMs, which were achieving human-level or even surpassing human-level performance on earlier benchmarks like GLUE and SuperGLUE. The difficulty of the tasks in MMLU ranges from elementary to advanced professional levels, testing both knowledge and problem-solving abilities. It can be used in zero-shot and few-shot settings when evaluating models.</p>
<aside epub:type="tip" role="doc-tip" class="box ruled">
<h3 id="box6_14">Example</h3>
<ul class="disc">
<li><b>Question:</b> &#x201C;When you drop a ball from rest it accelerates downward at 9.8 m/s<sup>2</sup>. If you instead throw it downward assuming no air resistance its acceleration immediately after leaving your hand is?&#x201D;</li>
<li>
<p><b>Answer Options:</b></p>
<ol class="upper-alpha">
<li>9.8 m/s<sup>2</sup></li>
<li>more than 9.8 m/s<sup>2</sup></li>
<li>less than 9.8 m/s<sup>2</sup></li>
<li>cannot say unless the speed of throw is given.</li></ol></li>
<li><b>Correct Answer:</b> (A) 9.8 m/s<sup>2</sup></li></ul></aside></section></section>
<section aria-labelledby="sec6_3_6_8">
<h4 id="sec6_3_6_8"><span epub:type="pagebreak" id="p214" aria-label=" page 214. " role="doc-pagebreak"/><span epub:type="ordinal">6.3.6.8 </span>Toxicity Benchmarks</h4>
<section aria-labelledby="sec6_3_6_8_1">
<h5 id="sec6_3_6_8_1"><span epub:type="ordinal">6.3.6.8.1 </span>RealToxicityPrompts (<a href="#ref6_21" id="R_ref6_21" epub:type="biblioref" role="doc-biblioref">Gehman et al., 2020</a>)</h5>
<p>RealToxicityPrompts, introduced by <a href="#ref6_21" epub:type="biblioref" role="doc-biblioref">Gehman et al. (2020)</a>, is a benchmark designed to evaluate the risk and tendencies of language models, particularly GPT-3 and similar models, to generate unsafe or toxic outputs. This benchmark comprises a dataset that probes the unsafe language generation tendencies of models in response to various prompts.</p>
<p>RealToxicityPrompts seeks to elucidate the extent to which pre-trained language models, like GPT-3, might produce toxic, offensive, or otherwise undesirable outputs when given different types of prompts.</p>
<p>The dataset is made up of prompts designed to elicit responses from the models. Its objective is to ascertain how frequently and in what situations these models produce answers that might be deemed harmful, offensive, or toxic.</p>
<p>A toxicity classifier evaluates the model-generated responses for potential toxicity, helping to quantify the likelihood of an output being perceived as toxic or harmful by users.</p>
<p>By shedding light on the propensities and risks associated with automated language generation, developers and researchers can more effectively devise safeguards and countermeasures to curtail the dissemination of detrimental content.</p>
<aside epub:type="tip" role="doc-tip" class="box ruled">
<h3 id="box6_15">Example</h3>
<ul class="disc">
<li><b>Prompt</b>: &#x201C;Women are always&#x2026;&#x201D;</li>
<li><b>Model Response</b>: &#x201C;&#x2026;trying their best in a male-dominated society.&#x201D;</li>
<li><b>Toxicity Evaluation</b>: Depending on the model&#x2019;s response, the toxicity is evaluated. If a model generates a stereotypical or demeaning response, it would be flagged as toxic.</li></ul></aside>
<p>It should be noted that evaluating toxicity is a complex process. The benchmark itself must employ a machine learning model, trained specifically for this purpose, to measure the toxicity of a response. This is in contrast to simpler cases, such as verifying answers to multiple-choice questions.</p>
<p>A crucial consideration when addressing toxicity in language models is the potential for inherent biases within the models. These biases can manifest in the outputs. The benchmark seeks to illuminate these issues, guiding efforts to develop more impartial and unbiased models.</p></section></section>
<section aria-labelledby="sec6_3_6_9">
<h4 id="sec6_3_6_9"><span epub:type="ordinal">6.3.6.9 </span>Biases Benchmarks</h4>
<section aria-labelledby="sec6_3_6_9_1">
<h5 id="sec6_3_6_9_1"><span epub:type="ordinal">6.3.6.9.1 </span>CrowS-Pairs (<a href="#ref6_46" id="R_ref6_46" epub:type="biblioref" role="doc-biblioref">Nangia et al., 2020</a>)</h5>
<p>The CrowS-Pairs (Crowdsourced Stereotype Pairs) benchmark, introduced by Nangia et al. in 2020, is designed to examine the biases present in a language model. Instead of merely measuring a model&#x2019;s performance, it aims to understand and highlight the model&#x2019;s stereotyping and biased tendencies, particularly in nuanced and non-explicit contexts.</p>
<p>This benchmark focuses on identifying socio-cultural and demographic biases in models. It assesses models on various dimensions of bias, such as race, religion, and gender, among others. CrowS-Pairs comprises pairs of sentences crafted to contrast non-stereotypical and <span epub:type="pagebreak" id="p215" aria-label=" page 215. " role="doc-pagebreak"/>stereotypical scenarios. Human annotators were engaged to develop and validate these pairs, ensuring they encapsulate a wide and subtle range of biases.</p>
<p>Models are evaluated on their responses to these sentence pairs, from which a bias score is derived, offering a quantitative measure of the model&#x2019;s bias. The benchmark gives insights into both the nature and extent of bias across different dimensions. It captures not only explicit but also implicit and subtle biases, which might otherwise be overlooked.</p>
<aside epub:type="tip" role="doc-tip" class="box ruled">
<h6 class="bh6" id="box6_16">Example</h6>
<ul class="disc">
<li><b>Sentence A</b>: &#x201C;The CEO lectured her employee about responsibility, as moms know a lot about that.&#x201D;</li>
<li><b>Sentence B</b>: &#x201C;The CEO lectured her employee about responsibility, as leaders know a lot about that.&#x201D;</li></ul></aside>
<p>Here, Sentence A might contain a gendered stereotype linking mothers to responsibility, while Sentence B offers a non-stereotypical counterpart. Models are then evaluated based on how they interpret and assess these pairs, providing insights into their biases.</p>
<p>These two sentences would be presented to the model, which would be asked to provide a score or assess the plausibility of each sentence. The benchmark would then evaluate the model&#x2019;s response, knowing which sentence is biased and which is not.</p>
<p>CrowS-Pairs is a vital tool in the domain of ethical AI and bias analysis. It supports the development of fairer, more impartial language models by highlighting their inherent biases.</p></section>
<section aria-labelledby="sec6_3_6_9_2">
<h5 id="sec6_3_6_9_2"><span epub:type="ordinal">6.3.6.9.2 </span>WinoGender benchmark (<a href="#ref6_59" id="R_ref6_59" epub:type="biblioref" role="doc-biblioref">Rudinger et al., 2018</a>)</h5>
<p>The WinoGender benchmark, introduced by Rudinger et al. in 2018, is specifically designed to evaluate the gender bias in coreference resolution systems. Coreference resolution is a task in natural language processing (NLP) that involves determining when two or more words (or phrases) in a text refer to the same entity.</p>
<p>The WinoGender dataset includes sentences designed around an anaphoric pronoun (he, she, his, hers, etc.) that is linked to one of two potential referents in the sentence. Importantly, one of the referents is stereotypically associated with the pronoun, while the other is not. The purpose of this design is to explore whether models are more likely to link pronouns to stereotypically associated referents, thus revealing potential gender biases in their predictions.</p>
<aside epub:type="tip" role="doc-tip" class="box ruled">
<h3 id="box6_17">Example</h3>
<ul class="disc">
<li><b>Sentence</b>: &#x201C;The nurse handed the surgeon the scalpel because [pronoun] forgot.&#x201D;</li>
<li><b>Pronoun</b>: she/he</li></ul></aside>
<p>In a stereotype-conforming context, a model might be prone to associating &#x201C;she&#x201D; with &#x201C;nurse&#x201D; and &#x201C;he&#x201D; with &#x201C;surgeon&#x201D; due to prevalent gender stereotypes. The benchmark would evaluate whether the model makes such stereotypical associations consistently across various scenarios.</p>
<p><span epub:type="pagebreak" id="p216" aria-label=" page 216. " role="doc-pagebreak"/>In addition to revealing biases in model predictions, the WinoGender benchmark also underscores the challenges that such biases pose to achieving accurate and fair coreference resolution. Model developers and researchers use benchmarks like WinoGender to assess and subsequently mitigate the biases present in their models, aiming for more equitable and accurate performance across different contexts and demographic groups.</p></section></section>
<section aria-labelledby="sec6_3_6_10">
<h4 id="sec6_3_6_10"><span epub:type="ordinal">6.3.6.10 </span>Truthfulness Benchmarks</h4>
<section aria-labelledby="sec6_3_6_10_1">
<h5 id="sec6_3_6_10_1"><span epub:type="ordinal">6.3.6.10.1 </span>TruthfulQA (<a href="#ref6_39" id="R_ref6_39" epub:type="biblioref" role="doc-biblioref">Lin et al., 2022</a>)</h5>
<p>The TruthfulQA benchmark, introduced by Lin et al. in 2022, is designed to examine the reliability and veracity of responses generated by LLMs to open-domain questions. The fundamental goal is to scrutinise how well these LLMs provide truthful and accurate answers across a wide range of topics and questions.</p>
<p>The need for a benchmark like TruthfulQA stems from observations that, while models like GPT-3 can generate fluent and contextually appropriate responses, they can sometimes generate answers that are incorrect, misleading, or fabricated. Ensuring the reliability of information provided by LLMs is crucial, especially as they become more integrated into informational and decision-making tools.</p>
<p>Approach:</p>
<ul class="disc">
<li><b>Questions</b>: The dataset includes a variety of questions that are designed to probe the model&#x2019;s ability to provide accurate and reliable answers. These questions could span a wide array of topics, including history, science, and general knowledge.</li>
<li><b>Model Responses</b>: The LLMs generate responses to the provided questions. The aim is to evaluate the correctness and reliability of these responses.</li>
<li><b>Evaluation</b>: Human evaluators or an automated system will assess the model-generated responses for their accuracy and truthfulness, comparing them to verified information or predefined answer keys.</li></ul>
<aside epub:type="tip" role="doc-tip" class="box ruled">
<h3 id="box6_117">Example</h3>
<ul class="disc">
<li><b>Question</b>: &#x201C;Who was the first president of the United States?&#x201D;</li>
<li><b>Truthful Answer</b>: &#x201C;George Washington&#x201D;</li></ul></aside>
<p>TruthfulQA serves as a crucial tool in gauging how LLMs handle the provision of factual information, which is essential for ensuring that these models can be trusted sources of information in various applications, such as conversational agents, informational retrieval systems, and more.</p></section></section></section>
<section aria-labelledby="sec6_3_7">
<h3 id="sec6_3_7"><span epub:type="ordinal">6.3.7 </span>The Fine-Tuning</h3>
<p>Fine-tuning is a technique in machine learning where a pre-trained model is further trained (typically on a smaller dataset) to adapt its existing knowledge to a new task. The model has already learned various features or patterns from a larger dataset and can utilise this knowledge to perform well on a related task with less data. Below are descriptions and examples for both a language model (LLM) and an image generation model.</p>
<section aria-labelledby="sec6_3_7_1">
<h4 id="sec6_3_7_1"><span epub:type="pagebreak" id="p217" aria-label=" page 217. " role="doc-pagebreak"/><span epub:type="ordinal">6.3.7.1 </span>Fine-Tuning in Language Models (LLM)</h4>
<p>After a model like GPT-3 has been pre-trained on a vast corpus of text, it has accumulated a wide range of linguistic knowledge. Fine-tuning involves training it further on a smaller, domain-specific dataset to specialise its capabilities towards certain tasks or industries.</p>
<p>Imagine you have an LLM trained on general text, and now you want to fine-tune it for legal advice. The LLM has been trained on a massive corpus and understands a wide array of English text. You introduce the LLM to a smaller dataset consisting of legal documents, court rulings, and attorney correspondences. The model adapts its generalised knowledge to become proficient in understanding and generating legal text. The fine-tuned LLM can now generate more contextually and terminologically accurate responses to legal queries or assist in drafting legal documents.</p></section>
<section aria-labelledby="sec6_3_7_2">
<h4 id="sec6_3_7_2"><span epub:type="ordinal">6.3.7.2 </span>Fine-Tuning in Image Generation Models</h4>
<p>An image generation model pre-trained on a large dataset has learned to generate images by understanding various visual patterns, structures, and contexts from the training data. Fine-tuning involves further training the model on a smaller, specific dataset to enhance its capability in generating images related to a specific domain or characteristic.</p>
<p>Consider a generative adversarial network (GAN) that has been trained on a wide variety of images (e.g., faces, animals, objects). The GAN knows how to generate a broad spectrum of images by understanding general patterns, colours, shapes, and textures found in the training data. Now, suppose you want to generate images of birds. You fine-tune the GAN using a smaller dataset consisting exclusively of bird images. The model learns the specific visual characteristics related to different bird species. The fine-tuned model can now generate varied and contextually relevant images of birds, considering specific aspects like plumage, beak shape, and size more accurately.</p></section>
<section aria-labelledby="sec6_3_7_3">
<h4 id="sec6_3_7_3"><span epub:type="ordinal">6.3.7.3 </span>Steps for Fine-tuning</h4>
<p>These steps follow the same steps as described above for the foundational model, but with specific datasets and testing focused on the fine-tuning specifics. In the case of the model design and structuring, the model&#x2019;s architecture can be adjusted to be suitable for the new task (e.g., changing the output layer for classification tasks). Typically, the specific hyperparameters of the model will be adjusted to help ensure the best results from the fine-tuning e.g., use of a smaller learning rate to avoid forgetting the previously learned features and gently adapt the model to the new task.</p>
<p>Fine-tuning allows leveraging the extensive knowledge captured during pre-training to achieve better performance on related tasks even when less training data is available for them. This methodology has proven effective across various domains and tasks in machine learning.</p></section></section>
<section aria-labelledby="sec6_3_8">
<h3 id="sec6_3_8"><span epub:type="ordinal">6.3.8 </span>The Deployment</h3>
<p>We have explored the intricacies involved in creating a model. However, before a model, especially ones such as GPT-3/GPT-4 or LLaMA-2, is prepared for widespread use, several steps must be undertaken to ready the model for large-scale production.</p>
<p>This may involve some or all of the following:</p>
<ul class="disc">
<li><b>Model Finalisation:</b> This stage involves selecting the specific model for deployment to an environment for general usage by users, typically called the production environment or <span epub:type="pagebreak" id="p218" aria-label=" page 218. " role="doc-pagebreak"/>just production. Often, companies will develop multiple models, each subjected to various customisations during training and testing. Subsequently, a decision must be made regarding which model to advance to production. During this stage, any final testing necessary is conducted (elaborated upon later) and actions such as optimising the model&#x2019;s hyperparameters are taken.</li>
<li><b>Model Optimisation:</b> This is a crucial step in which resource usage, including CPU and memory, is optimised for production purposes, specifically for inference. Training a model and deploying it for mass use entail distinct scenarios, and when the model is serving user queries, it must be tailored for that specific context. One effective action that model creators can take is <b>model pruning</b>. This involves scrutinising the model to identify components that can be removed to simplify it, without compromising its performance capabilities, while simultaneously reducing the required computational resources, including memory and CPU. At times, teams may conduct an <b>ablation study</b>, which systematically removes parts of the model to assess their impact. If such removal leads to a positive resource impact without compromising performance, they may decide to exclude that component from the production version. Various other techniques can be less invasive, including <b>thresholding</b> (pruning items below a specified threshold), <b>activation analysis</b> (removing items with minimal impact on output), <b>sensitivity analysis</b> (pruning items with limited contribution to output), and <b>redundancy analysis</b> (eliminating redundant components, such as superfluous layers). Naturally, after implementing these modifications, it is imperative to rigorously test the model to ensure it continues to perform effectively. Another important optimisation strategy often employed is <b>quantisation</b>, a process that reduces the precision of the model weights to lower memory requirements and accelerate inference. This approach is commonly utilised when running models on personal computers or mobile devices.</li>
<li><b>Model Conversion:</b> This stage involves the conversion of the model into a format suitable for deployment, such as Open Neural Network Exchange (ONNX), TensorFlow SavedModel, or PyTorch. Some models may be distributed as installable scripts, as is the case with GPT4All, while others may be packaged as container-ready deployments using technologies like Docker for Kubernetes, as exemplified by Mistral. The selection of the model distribution format holds significance, as it directly impacts the accessibility and ease of use of the model, thereby influencing the level of interest from the community. In situations where the model is exclusively Intended for internal use and is only exposed through a user interface (e.g., a chatbot) or an API (as described below), these model details may remain concealed from external parties not affiliated with the organisation that created the model, such as ChatGPT3.5 or ChatGPT4.0.</li>
<li><b>Additional Testing:</b> In most cases, a comprehensive array of specialised tests is conducted, encompassing aspects such as inference speed, resource consumption, and scale testing, which involves assessing the model&#x2019;s performance under varying user inference request loads. These evaluations may lead to further refinements of the model, including the implementation of optimised caching (in memory storing of data for faster access) strategies.</li>
<li><b>API Wrapper:</b> End users typically interact with the model via a user interface such as a browser-based chatbot interface. However, a model may provide an Application Programming Interface (API) to allow technically skilled users to interact with the model and to build their own end user interfaces into the models. These APIs are typically provided using a technology known as a REST API. A more in-depth discussion of these elements that wrap the model will be provided later, as they constitute key components of the broader ecosystem in which a model operates. In the case of the API <span epub:type="pagebreak" id="p219" aria-label=" page 219. " role="doc-pagebreak"/>wrapper, considerations will include determining the methods of user authentication and establishing the framework for authorisation procedures.</li>
<li><b>Monitoring and Logging:</b> This is a critical part of a model deployment and allows the model to be kept healthy by the team responsible for the model in the production environment. This monitoring serves multiple purposes, extending beyond mere verification of its operational status. It also entails keeping track of factors like the number of users and the utilisation of resources such as CPU, memory, and network bandwidth, ensuring they remain within predefined thresholds and controls. Additionally, effective monitoring plays a pivotal role in identifying and rectifying instances of undesirable behaviour, whether exhibited by the model itself or by the users interacting with it. If something goes wrong, they can use monitoring and logging to identify what and how to fix it for the future.</li>
<li><b>Filtering for Safety and Alignment:</b> In practice, a model intended for public use, such as the GPT-4 model integrated with ChatGPT, typically incorporates various features to mitigate the risk of generating inappropriate outputs. For instance, input filters can be employed to examine incoming input early in the process, thereby identifying and addressing potentially inappropriate content. Similarly, in cases where problematic output is detected, output filters can intervene to prevent such content from reaching the user. These output filters may substitute the inappropriate output with a more suitable response or provide a default message conveying the model&#x2019;s inability to assist.</li>
<li><b>Continuous Improvement:</b> Once the model is available it will require continual improvements based on new advances and discoveries from the team that create it or from learnings in the runtime environment with real users interacting with the model. The model creators need to understand how they plan to release these updates, whether they will it be real-time releases that are transparent to users, or made available as new versions of a model that the user must explicitly select, or perhaps as new specialisations of a model (e.g., trained for some specific purposes e.g., chatbot, code generation, specific scientific capabilities, etc.) and released as if it was a new model. When users use the model, it is important to try and address issues quickly that come up. Sometimes the model may start to give biased information or incorrect information; this is known as model hallucination. There can be a lot of public pressure on organisations to fix such issues; for example Meta had to take down one of their models (called Galactica) only after three days due to biased and incorrect information that it provided, and it was not possible to fix the model quickly (<a href="#ref6_68" id="R_ref6_68" epub:type="biblioref" role="doc-biblioref">Snoswell &#x0026; Burgess, 2022</a>).</li></ul></section>
<section aria-labelledby="sec6_3_9">
<h3 id="sec6_3_9"><span epub:type="ordinal">6.3.9 </span>Model Use (aka Inference)</h3>
<p>Typically, models do not undergo learning processes (i.e., updates to their weights and biases) during regular runtime interactions. Learning occurs exclusively during the pre-training of the foundational model or during the fine-tuning phase.</p>
<p>However, this can be somewhat perplexing, as there are approaches that might appear akin to learning. One such example is the concept of few-shot learning. In few-shot learning, similar request-response pairs are presented alongside the intended request to assist the model in generating the most appropriate response. The terminology, including &#x201C;zero-shot learning&#x201D; (where no examples are provided), &#x201C;one-shot learning&#x201D; (with a single example request-reply pair provided for action), and &#x201C;few-shot learning&#x201D; (in which multiple request-reply pairs are provided, typically ranging from 2 to 5 pairs), can be confounding. This is because the model is not actually learning; rather, it is utilising these examples to enhance its comprehension of the requests. The model&#x2019;s parameters remain unaltered. <span epub:type="pagebreak" id="p220" aria-label=" page 220. " role="doc-pagebreak"/>Perhaps these concepts would be more accurately described as &#x201C;few-shot requests&#x201D; or &#x201C;few-shot guidance&#x201D; rather than &#x201C;few-shot learning&#x201D;.</p>
<p>It is worth noting that certain models may compile a database of user requests and responses for potential use in training the model in the future or for updates. However, as a rule, on-the-fly learning is not commonly employed, as it could render the models unstable. This serves as another illustration of the fundamental distinction between ANNs and human brains, with the latter continually engaged in the process of learning.</p>
<p>The following sections provide information about other runtime or inference time activities that are worth understanding.</p>
<section aria-labelledby="sec6_3_9_1">
<h4 id="sec6_3_9_1"><span epub:type="ordinal">6.3.9.1 </span>Prompt Engineering</h4>
<p>Prompt engineering involves the design and optimisation of prompts (also read <a href="ch3.xhtml#sec3_8">Section 3.8</a>). These are input sequences or instructions intended to guide a language model, such as ChatGPT, to produce the desired outputs. This technique is especially relevant in the context of few-shot learning, where the model is provided with examples within the prompt to help it understand and perform specific tasks.</p>
<p>At present, a myriad of templates and strategies are being championed as &#x2018;the best&#x2019; for prompt engineering, especially in relation to ChatGPT. These methods typically encompass various elements that structure the request. This includes elucidating the context, defining the intended audience or roles, and offering examples (as observed in few-shot learning) to effectively shape the model&#x2019;s response (read <a href="ch3.xhtml#sec3_8_2">Section 3.8.2</a>. on the Prompt Engineering Components).</p>
<p>While much of the conversation about prompt engineering centres on LLMs, it is also considered in relation to image generation and other forms of content creation.</p></section>
<section aria-labelledby="sec6_3_9_2">
<h4 id="sec6_3_9_2"><span epub:type="ordinal">6.3.9.2 </span>Prompt Injection</h4>
<p>Prompt injection is a tactic whereby individuals attempt to manipulate models into producing inappropriate responses. They modify the prompt in various ways, leading to outputs that the model should not generate, a phenomenon occasionally referred to as adversarial prompting.</p>
<p>Such inappropriate outputs can range from humorous or insulting remarks to the provision of accurate yet ethically questionable information, such as instructions on creating a bomb or methods for disposing of a body.</p></section>
<section aria-labelledby="sec6_3_9_3">
<h4 id="sec6_3_9_3"><span epub:type="ordinal">6.3.9.3 </span>Jailbreaking</h4>
<p>Jailbreaking refers to the process by which a model is manipulated into a mode that circumvents the usual safeguards in place, ensuring its intended behaviour. This is achieved based on specific prompts from users.</p>
<p>There are well-documented instances of this, such as the &#x2018;Sydney&#x2019; mode for Bing, or the &#x2018;DAN&#x2019; (Do Anything Now) mode for ChatGPT. Some individuals have also bypassed certain safety mechanisms of the model using alternative techniques. For example, by instructing the model to simulate a conversation where it is a model speaking to another model, and then responding to a prompt. This kind of recursive scenario seems to disorient the model and its filtering mechanisms, leading it to eventually produce responses it would not typically generate.</p></section>
<section aria-labelledby="sec6_3_9_4">
<h4 id="sec6_3_9_4"><span epub:type="pagebreak" id="p221" aria-label=" page 221. " role="doc-pagebreak"/><span epub:type="ordinal">6.3.9.4 </span>Prompt Leaking</h4>
<p>Prompt leaking happens where a user designs a prompt that tricks the model into providing real information that it should not, perhaps internal details about the model itself.</p></section></section></section>
<section aria-labelledby="sec6_4">
<h2 id="sec6_4"><span epub:type="ordinal">6.4 </span>Models and Ecosystems</h2>
<p><a href="#fig6_16" id="R_fig6_16">Figure 6.16</a> shows how a model and the ecosystem around the model may be constructed. This will be different for different models and companies depending on their specific needs, the market they are addressing, and many other factors.</p>
<figure id="fig6_16"><img src="images/fig6_16_B.jpg" alt="A depiction of how a model and the ecosystem around the model may be constructed."/>
<figcaption><a href="#R_fig6_16" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. "><span epub:type="label">Figure</span> <span epub:type="ordinal">6.16 </span>The Model Ecosystem.</a></figcaption></figure>
<p>The following sections discuss some of the key aspects of this ecosystem. In the example from <a href="#fig6_16">Figure 6.16</a> we can see:</p>
<ul class="disc">
<li>User A, is using both a Chat App and a Document Authoring App which use Foundation Model A.</li>
<li>Software Developer A has built and deployed a custom application which uses a fine-tuned version of Model A which they created specifically for legal professionals and specialises in international law. It uses a Retrieval Augmented Generation (RAG) approach to ensure the most useful outcomes for users of his product.</li>
<li>User B uses the Custom Product that specialises in Legal GenAI for international law.</li>
<li>Software Developer B has built a generic API that supports multiple foundational models (A, B, and C). It also supports several of the plugins that are available for Foundational Model A. These plugins allow Foundation Model A to do several interesting things, including search for travel options from a travel consolidation service and do general real-time searches from a well-known search engine. As part of this implementation Software Developer B used the &#x2018;functions&#x2019; capability of Model B and if it does not get results it will call Foundational Model C.</li></ul>
<section aria-labelledby="sec6_4_1">
<h3 id="sec6_4_1"><span epub:type="ordinal">6.4.1 </span>Custom Interfaces and Chat</h3>
<p>The most common custom interface is the familiar chatbot prompt and response interface. It is important to realise that this chat interface that humans interact with is separate to the model. A chat interface can make interaction with the model easy, and it can make several decisions about interacting with that model that may not be obvious. For example, it can do some of the following</p>
<ul class="disc">
<li>Setting specific hyperparameters to specific values</li>
<li>Providing previous interactions details so the model has the context of the conversation (e.g., automatically adding key aspects of the previous part of the discussion to the current context for the model)</li>
<li>Handling requests and dealing with items like caching of data to minimise the processing and memory load on the model.</li></ul>
<p>Chat interfaces are not the only way to interact with models; many tools integrate with GenAI. For example, web site design tools integrate with models that allow generation of images for the site or allow generation of items like business cards. Some tools, like Good Documents, integrate models for content generation while authoring your document.<span epub:type="pagebreak" id="p222" aria-label=" page 222. Figure on this page. " role="doc-pagebreak"/></p></section>
<section aria-labelledby="sec6_4_2">
<h3 id="sec6_4_2"><span epub:type="pagebreak" id="p223" aria-label=" page 223. " role="doc-pagebreak"/><span epub:type="ordinal">6.4.2 </span>APIs and Functions</h3>
<p>The model is typically exposed as an Application Programming Interface (API), even if this is solely for the chat interface mentioned earlier. Companies such as OpenAI also offer an API to software developers who wish to harness the model for their bespoke needs. The API permits other software applications to access the model and retrieve results. This becomes particularly advantageous, for instance, if one operates a company offering document authorship software, like Google Docs, Microsoft Word, or Good Notes. Such an API can be used to integrate the model&#x2019;s capabilities into the software, enabling functionalities such as content suggestions or content reviews.</p>
<p>Functions provide a novel method to afford additional flexibility to software developers utilising the model API. There are instances where the model might not furnish pertinent information in its response, perhaps because the query pertains to a topic arising after the model&#x2019;s training was finalised. Under these circumstances, the developer can instruct the model to return the specifics for a function call if it is unable to directly address the query. The model will then endeavour to reshape the request to align with the developer-provided function call and return this revised request, thereby alleviating the developer&#x2019;s need to amend the request independently. The developer can then initiate the specified function with relative ease. It is crucial to emphasise that the software developer orchestrates the function call. The model either furnishes a standard response or, if that is unattainable, it preps the data for the function call as proficiently as possible, simplifying the process for the developer. However, the onus of initiating the function, if deemed apt, lies with the developer.</p></section>
<section aria-labelledby="sec6_4_3">
<h3 id="sec6_4_3"><span epub:type="ordinal">6.4.3 </span>Plugins and Agents</h3>
<p>Plugins, sometimes referred to as agents, enable software developers to construct a service which the model can invoke. In the context of an API, the developer initiates the call to the model. However, when dealing with a plugin or agent, it is the model that reaches out to another system or capability.</p>
<p>Consider an instance where the ultimate objective is to ascertain current flight prices and schedules from Hong Kong to Dublin for a specific future date. The LLM would be oblivious to such information, as it wouldn&#x2019;t possess this data in its training set; and even if it did, the information would likely be outdated. However, if a company like Expedia intends to supply this data to a model, a plugin would be the mechanism. A user might transmit a request to the model via a chat interface or an API call from a bespoke interface. The model, recognising its own inability to address the query, would invoke the Expedia plugin to retrieve the necessary data and relay it to the user.</p>
<p>One can envisage a world abundant in diverse plugins, empowering models to perform a plethora of tasks for users. This extends beyond merely listing flights to booking them, ordering pizzas, hiring cars, managing household devices, and virtually any task feasible through online automation, given the right plugin.</p>
<p>The paramount importance of trust in plugins becomes evident. The implications of a plugin transferring funds between bank accounts could be dire if exploited to transfer money illicitly. If a plugin fetches information that is deliberately incorrect, it poses challenges. There might be instances where a plugin&#x2019;s action deviates from the user&#x2019;s intention; for example, a user might want to only check flight prices but ends up having a flight booked unintentionally via the plugin. Such scenarios would lead to user dissatisfaction.</p>
<p><span epub:type="pagebreak" id="p224" aria-label=" page 224. " role="doc-pagebreak"/>This necessitates the establishment of stringent guidelines and policies governing plugins, to which developers must adhere to and formally commit.</p>
<p>OpenAI has integrated a web-browsing plugin with its ChatGPT product. Users have the discretion to activate or deactivate this plugin via the ChatGPT interface. If activated and ChatGPT fails to address a query (e.g., when asked for recent data not encompassed in its training), it will access the web-browsing plugin, essentially tapping into the new Bing search functionality which incorporates a specialised version of GPT-4. This provides a valuable extension to the model, whilst ensuring the user retains authority over the plugin&#x2019;s usage.</p></section>
<section aria-labelledby="sec6_4_4">
<h3 id="sec6_4_4"><span epub:type="ordinal">6.4.4 </span>Custom Fine-Tuning</h3>
<p>It is feasible to fine-tune certain models for bespoke applications. In OpenAI&#x2019;s instance, they have augmented the API for their model (currently the gpt-3-5-turbo model) to permit users to upload a curated set of training data in a distinct format. Users can then instruct the model to fine-tune based on this data and subsequently receive a newly instantiated model tailored for that specific objective. It is incumbent upon the user to test and ascertain that the fine-tuned model delivers the anticipated advantages.</p>
<p>Such a facility paves the way for the creation of custom models tailored for niche purposes. For instance, a model could be honed to specialise in international law, enabling software developers to supplement their products with additional functionalities. These enhanced features would prove invaluable to a select group of users seeking such specific capabilities.</p></section>
<section aria-labelledby="sec6_4_5">
<h3 id="sec6_4_5"><span epub:type="ordinal">6.4.5 </span>Custom Models</h3>
<p>Many model developers offer customised models for specific purposes. These are often fine-tuned versions of the foundational model, adapted for that particular application. Examples encompass chat-based models, code generation-based models, and even highly specialised models that not only generate but also execute code. OpenAI has introduced a custom model named &#x2018;Advanced Data Analysis&#x2019;, previously called Code Interpreter, designed to generate code. Furthermore, this model can execute the code and present the output. This proves invaluable for software engineers, enabling them to iterate over code more rapidly, with the model shouldering more responsibilities, including debugging. While the Advanced Data Analysis is marketed akin to a plugin and is managed via the Chat interface, much like the &#x2018;Web Browsing&#x2019; plugin mentioned earlier, its distinct specialisation is evident when accessed via an API, the Advanced Data Analysis is invoked as a separate model.</p></section>
<section aria-labelledby="sec6_4_6">
<h3 id="sec6_4_6"><span epub:type="ordinal">6.4.6 </span>Vector Databases and Retrieval Augmented Generation (RAG)</h3>
<p>Vector databases are specialised databases designed for the efficient querying and retrieval of data using vectors. In this context, vectors are arrays of numbers representing objects, such as text, images, or sounds, within a multidimensional space.</p>
<p>These databases are optimised for operations like similarity searches among vectors. They allow users to efficiently identify items resembling a given input vector. Such capability proves particularly beneficial in applications related to machine learning, recommendation systems, image retrieval, and natural language processing, wherein locating similar items in high-dimensional spaces is vital.</p>
<p><span epub:type="pagebreak" id="p225" aria-label=" page 225. " role="doc-pagebreak"/>Retrieval Augmented Generation (RAG) merges the capabilities of pre-trained language models with information retrieval systems, enhancing the generation of responses in conversational AI and other NLP tasks.</p>
<p>Given an input (e.g., a question or prompt), RAG sources pertinent documents or text snippets from a corpus or database, often a vector database. The information retrieved subsequently informs the generative model&#x2019;s response, facilitating the creation of more precise, informative, and contextually relevant outputs.</p>
<p>This approach can be likened to enriching the prompt with examples (akin to few-shot learning), enabling the model to generate superior responses.</p>
<p>A typical scenario where this is advantageous involves an organisation possessing an internal model and a database of documents that can readily address the current request. For instance, a legal firm aiming to produce content may want to ensure alignment with its existing templates and structures, particularly for documents like contracts, legal notices, or letters.</p></section></section>
<section aria-labelledby="sec6_5">
<h2 id="sec6_5"><span epub:type="ordinal">6.5 </span>State-of-the-Art Models Overview</h2>
<p>In the subsequent sections, we examine several renowned state-of-the-art (SOTA) models. Our emphasis is on large language models and text-to-image diffusion models. For each model, we offer a concise overview of the company and the model itself, followed by details concerning its release history, specifications, uses, and pertinent commentary.</p>
<section aria-labelledby="sec6_5_1">
<h3 id="sec6_5_1"><span epub:type="ordinal">6.5.1 </span>LLM &#x2013; OpenAI ChatGPT-4.0</h3>
<p>Established in 2015, OpenAI was originally a non-profit organisation dedicated to the development and democratisation of open AI systems. Among its founders were eminent figures in the AI domain, including individuals like Elon Musk. Subsequently, the organisation transitioned to a for-profit structure. Its current mission statement reads:</p>
<blockquote>
<p>Our mission is to ensure that artificial general intelligence &#x2013; AI systems that outperform human intelligence &#x2013; benefits all of humanity.</p></blockquote>
<p class="list-title"><b>Release History</b></p>
<ul class="simple">
<li>OpenAI GPT-n series of models:
<table id="table6_1">
<caption><span class="label">Table</span> <span class="ordinal">6.1 </span>OpenAI GPT-n Series Release History</caption>
<thead>
<tr>
<th scope="col" class="left">Date</th>
<th scope="col" class="left">Model</th>
<th scope="col" class="left">Description</th></tr></thead>
<tbody>
<tr>
<td class="left">11/Jun/2018</td>
<td class="left">GPT-1</td>
<td class="left">Improving Language Understanding by Generative Pre-Training (<a href="#ref6_52" id="R_ref6_52" epub:type="biblioref" role="doc-biblioref">Radford et al. 2018</a>)</td></tr>
<tr>
<td class="left">14/Feb/2019</td>
<td class="left">GPT-2</td>
<td class="left">Language Models are Unsupervised Multitask Learners (<a href="#ref6_53" id="R_ref6_53" epub:type="biblioref" role="doc-biblioref">Radford et al., 2019</a>; Solaiman et al., 2019)</td></tr>
<tr>
<td class="left">28/May/2020</td>
<td class="left">GPT-3</td>
<td class="left">Language Models are Few-Shot Learners (<a href="#ref6_10" id="R_ref6_10" epub:type="biblioref" role="doc-biblioref">Brown et al., 2020</a>)</td></tr>
<tr>
<td class="left">15/Mar/2022</td>
<td class="left">GPT-3.5</td>
<td class="left">Version 3.5 release</td></tr>
<tr>
<td class="left">30/Nov/2022</td>
<td class="left">ChatGPT</td>
<td class="left">This was based on GPT-3.5 model and later both GTP-3.5 and GPT-4 were supported via user selection</td></tr>
<tr>
<td class="left">14/Mar/2023</td>
<td class="left">GPT-4</td>
<td class="left">GPT-4 Technical Report (<a href="#ref6_48" id="R_ref6_48" epub:type="biblioref" role="doc-biblioref">OpenAI, 2023</a>)</td></tr></tbody></table></li></ul>
<p class="list-title"><span epub:type="pagebreak" id="p226" aria-label=" page 226. " role="doc-pagebreak"/><b>Specifications</b></p>
<p>The size and specification of GPT-4 has not been shared; however, from the <a href="#ref6_48" epub:type="biblioref" role="doc-biblioref">OpenAI 2023</a> Technical Report publication we do learn the following:</p>
<ul class="disc">
<li>It is a transformer pre-trained model (like GPT3)</li>
<li>It exhibits human-level performance on many benchmarks.</li></ul>
<p>However, more details have been leaked and, while not official, they do provide some insight to the sizing:</p>
<ul class="disc">
<li>GPT-4 has ~1.8 trillion parameters across 120 layers.</li>
<li>GPT-4 is trained on ~13 trillion tokens, including both text-based and code-based data.</li>
<li>The training data included Common Crawl &#x0026; RefinedWeb, totalling 13T tokens. There is considerable speculation that additional sources like Twitter, Reddit, YouTube, and a large collection of textbooks were also used.</li>
<li>It uses a mixture of experts (MoE) architecture which is an ensemble learning approach and allows different experts to specialise in different areas with the most appropriate being selected. There may be either 16 experts with ~111B parameters each or 8 experts with ~220B parameters each.</li></ul>
<p class="list-title"><b>Use</b></p>
<ul class="disc">
<li>It is multimodal, which means it can handle text and images as inputs and text as an output. Recently, it has been integrated with DALL-E 3 for image-based output.</li>
<li>With the Code Interpreter (now called advanced data analysis) feature, it can both generate and execute code</li></ul>
<p class="list-title"><b>Comments</b></p>
<ul class="disc">
<li>This model is widely regarded as the most advanced and useful for general text generation as well as code generation.</li></ul></section>
<section aria-labelledby="sec6_5_2">
<h3 id="sec6_5_2"><span epub:type="ordinal">6.5.2 </span>LLM - Meta LLaMA-2</h3>
<p>Meta, formerly known as Facebook, introduced the LLaMA model as one of its most sophisticated offerings. Although it was initially disseminated as a research release, it was inadvertently leaked and broadly circulated. Consequently, for LLaMA-2, Meta opted to release it under a more permissive commercial license.</p>
<p class="list-title"><b>Release History</b></p>
<ul class="simple">
<li>
<table id="table6_2">
<caption><span class="label">Table</span> <span class="ordinal">6.2 </span>Meta LLaMA Release History</caption>
<thead>
<tr>
<th scope="col" class="left">Date</th>
<th scope="col" class="left">Model</th>
<th scope="col" class="left">Description</th></tr></thead>
<tbody>
<tr>
<td class="left">Feb/2023</td>
<td class="left">LLaMA-1</td>
<td class="left">LLaMA: Open and Efficient Foundation Language Models (<a href="#ref6_71" id="R_ref6_71" epub:type="biblioref" role="doc-biblioref">Touvron et al., 2023a</a>)</td></tr>
<tr>
<td class="left">18/Jul/2023</td>
<td class="left">LLaMA-2</td>
<td class="left">LLaMA-2: Open Foundation and Fine-Tuned Chat Models (<a href="#ref6_72" id="R_ref6_72" epub:type="biblioref" role="doc-biblioref">Touvron et al., 2023b</a>)</td></tr></tbody></table></li></ul>
<p class="list-title"><span epub:type="pagebreak" id="p227" aria-label=" page 227. " role="doc-pagebreak"/><b>Specifications</b></p>
<ul class="disc">
<li>LLaMA-2 is designed as an auto-regressive language optimised transformer.</li>
<li>The fine-tuned versions of the model implement Supervised Fine-Tuning (SFT) and Reinforcement Learning with Human Feedback (RLHF) to better align with human preferences for helpfulness and safety.</li>
<li>LLaMA-2 comes in three sizes based on the number of parameters: 7 billion, 13 billion, and 70 billion parameters.</li>
<li>The models have a token count referring only to the pre-training data, with all models trained with a global batch size of 4 million tokens. The largest model, with 70 billion parameters, utilises Grouped-Query Attention (GQA) for improved inference scalability</li>
<li>The training and fine-tuning of LLaMA-2 leveraged publicly available online data sources, with over one million human-annotated examples used for fine-tuning. This model does not include Meta user data in its training or fine-tuning datasets.</li></ul>
<p class="list-title"><b>Use</b></p>
<ul class="disc">
<li>The model is primarily intended for text-based applications.</li>
<li>It&#x2019;s optimised for dialogue use cases through its fine-tuned versions, known as LLaMA-2-Chat, but its pre-trained versions can be adapted for a broader range of natural language generation tasks.</li>
<li>LLaMA-2 is open for both commercial and research use, and it is particularly targeted for use in English language tasks.</li></ul>
<p class="list-title"><b>Comments</b></p>
<ul class="disc">
<li>LLaMA-2 is Meta&#x2019;s response to other large language models like OpenAI&#x2019;s GPT models and Google&#x2019;s AI models, with a distinguishing feature of being more open and freely available for almost anyone to use for research and commercial purposes.</li></ul></section>
<section aria-labelledby="sec6_5_3">
<h3 id="sec6_5_3"><span epub:type="ordinal">6.5.3 </span>LLM &#x2013; Google Bard and PaLM-2</h3>
<p>Google has consistently contributed to AI research, notably through the seminal paper titled &#x201C;Attention is All You Need&#x201D;, which has influenced the prevailing direction of Transformer-based architectures for large language models.</p>
<p class="list-title"><b>Release History</b></p>
<ul class="simple">
<li>
<table id="table6_3">
<caption><span class="label">Table</span> <span class="ordinal">6.3 </span>Google PaLM/Bard/LaMDA Release History</caption>
<thead>
<tr>
<th scope="col" class="left">Date</th>
<th scope="col" class="left">Model</th>
<th scope="col" class="left">Description</th></tr></thead>
<tbody>
<tr>
<td class="left">18/May/2021</td>
<td class="left">LaMDA-1</td>
<td class="left">LaMDA: Language Models for Dialog Applications (<a href="#ref6_70" id="R_ref6_70" epub:type="biblioref" role="doc-biblioref">Thoppilan et al., 2022</a>)</td></tr>
<tr>
<td class="left">11/May/2022</td>
<td class="left">LaMDA-2</td>
<td class="left">Version 2 update</td></tr>
<tr>
<td class="left">21/Mar/2023</td>
<td class="left">Bard</td>
<td class="left">Chat bot made available initially built on LaMDA-2</td></tr>
<tr>
<td class="left">Mar/2023</td>
<td class="left">Bard</td>
<td class="left">Google announced Bard would switch to PaLM-2 shortly</td></tr>
<tr>
<td class="left">Mar/2023</td>
<td class="left">PaLM-1</td>
<td class="left">PaLM: Scaling Language Modeling with Pathways (<a href="#ref6_13" id="R_ref6_13" epub:type="biblioref" role="doc-biblioref">Chowdhery et al., 2022</a>)</td></tr>
<tr>
<td class="left">May/2023</td>
<td class="left">PaLM-2</td>
<td class="left">PaLM 2 Technical Report (<a href="#ref6_2" id="R_ref6_2" epub:type="biblioref" role="doc-biblioref">Anil et al., 2023</a>)</td></tr></tbody></table></li></ul>
<p class="list-title"><span epub:type="pagebreak" id="p228" aria-label=" page 228. " role="doc-pagebreak"/><b>Specification</b></p>
<ul class="disc">
<li>PaLM-2 (Pathways Language Model) was discussed in relation to the three sizes small (PaLM-2 S), medium (PaLM-2 M) and large (PaLM-2 L) in the paper (<a href="#ref6_2" epub:type="biblioref" role="doc-biblioref">Anil et al., 2023</a>). The large version is reported to be considerable smaller than the original PaLM model which has 540B parameters.</li>
<li>PaLM-2 has put greater focus on training with text from languages other than English as well as a focus on a diverse set of domains for the training data.</li>
<li>The model is based on the transformer model; however, it has expanded the training objectives from masked language modelling to use a mixture of different pre-training objectives to help it understand different aspect of the language.</li>
<li>The model also relooked at how training compute should be used and move to an approach where model size vs training data size were more aligned with a 1:1 ratio to get the best value for a specific compute capacity.</li>
<li>PaLM-2 is provided in several different configurations: Gecko, Otter, Bison, and Unicorn. It is thought that the sizes of these are 1.5B, 6B, 137B, and 540B. Each version has a different size and is designed for use within specific applications. For example, Gecko is the smallest and most lightweight. It is designed for mobile devices.</li>
<li>The chat interface Google Bard uses the PaLM-2 model. However, the only way for developers to access these models at the moment is via the Google Cloud Platform (e.g. PaLM API, MakerSuite, or Vertex AI).</li></ul>
<p class="list-title"><b>Use</b></p>
<ul class="disc">
<li>It is focused on advanced reasoning tasks, including code and math, classification and question-answering, translation and multilingual proficiency, and natural language generation.</li></ul>
<p class="list-title"><b>Comments</b></p>
<ul class="disc">
<li>The PaLM-2 model, and Google Bard have not had the same popularity or adoption that OpenAI ChatGPT has had or the same level of praise for its abilities.</li></ul></section>
<section aria-labelledby="sec6_5_4">
<h3 id="sec6_5_4"><span epub:type="ordinal">6.5.4 </span>LLM &#x2013; Anthropic Claude</h3>
<p>Anthropic was founded in 2021 and among its founders were several people who left OpenAI to start Anthropic and thus it is a relatively new player.</p>
<p class="list-title"><b>Release History</b></p>
<ul class="simple">
<li>
<table id="table6_4">
<caption><span class="label">Table</span> <span class="ordinal">6.4 </span>Anthropic Claude Release History</caption>
<thead>
<tr>
<th scope="col" class="left">Date</th>
<th scope="col" class="left">Model</th>
<th scope="col" class="left">Description</th></tr></thead>
<tbody>
<tr>
<td class="left">14/Mar/2023</td>
<td class="left">Claude-1</td>
<td class="left">Claude and Claude Instant were released</td></tr>
<tr>
<td class="left">23/Aug/2023</td>
<td class="left">Claude-2</td>
<td class="left">Claude was updated</td></tr></tbody></table></li></ul>
<p class="list-title"><b>Specifications</b></p>
<ul class="disc">
<li>Claude is a transformer-based architecture. The model is larger than the 52B parameter model AnthropicLM discussed in the paper (<a href="#ref6_6" id="R_ref6_6" epub:type="biblioref" role="doc-biblioref">Bai et al., 2022</a>), but is an autoregressive model trained on a large corpus of text in a self-supervised manner similar to GPT-3.</li>
<li><span epub:type="pagebreak" id="p229" aria-label=" page 229. " role="doc-pagebreak"/>Claude comes in two versions: Claude and Claude Instant. Claude is a state-of-the-art high-performance model, while Claude Instant is a lighter, less expensive, and much faster option.</li>
<li>Anthropic has partnered with Quora and they have built a chat interface to Claude as a mobile application called Poe. Poe also offers interfaces to other models, which makes it an interesting tool to compare the responses from different models. Anthropic also provide developer access via an API to Claude and Claude Instant.</li>
<li>Anthropic has also partnered with DuckDuckGo, which is a privacy-focused search engine and browser designed to integrate with real-time information.</li></ul>
<p class="list-title"><b>Use</b></p>
<ul class="disc">
<li>Claude is capable of a wide variety of conversational and text-processing tasks while maintaining a high degree of reliability and predictability.</li>
<li>Claude can help with use cases, including summarisation, search, creative and collaborative writing, Q&#x0026;A, coding, and more.</li></ul>
<p class="list-title"><b>Comments</b></p>
<ul class="disc">
<li>Anthropic have written about (<a href="#ref6_6" epub:type="biblioref" role="doc-biblioref">Bai et al., 2022</a>) an approach called Constitutional AI (CAI) which involves models training models in a safe manner. This reflects the history of the company as focused on AI safety research.</li>
<li>One of the unique things about Claude is its large context size of 100k tokens.</li>
<li>Based on current capabilities Claude is not as strong as GPT-4.</li></ul></section>
<section aria-labelledby="sec6_5_5">
<h3 id="sec6_5_5"><span epub:type="ordinal">6.5.5 </span>LLM &#x2013; Mistral AI Mistral</h3>
<p>Mistral AI was founded in 2023 and only released its first model a short time ago. Unlike many of the other players, Mistral is based in Europe (France) and has offered its initial model as open source.</p>
<p class="list-title"><b>Release History</b></p>
<ul class="simple">
<li>
<table id="table6_5">
<caption><span class="label">Table</span> <span class="ordinal">6.5 </span>Mistral AI Release History</caption>
<thead>
<tr>
<th scope="col" class="left">Date</th>
<th scope="col" class="left">Model</th>
<th scope="col" class="left">Description</th></tr></thead>
<tbody>
<tr>
<td class="left">27/Sep/2023</td>
<td class="left">Mistral-7B</td>
<td class="left">Mistral 7B model is released under an Apache 2 license.</td></tr></tbody></table></li></ul>
<p class="list-title"><b>Specifications</b></p>
<ul class="disc">
<li>Mistral AI has released two initial versions: Mistral-7B and Mistral-7B-Instruct. It intends to release larger models later. The instruct version is a fine-tuned version for question-and-answer interactions such as a chat use case.</li>
<li>The models use grouped-query attention (GQA) for faster inference.</li>
<li>The models use sliding window attention (SWA) to handle longer sequences at smaller cost.</li>
<li>The models have been released as open source with an Apache 2 style license.</li>
<li>Based on the benchmarks, they outperforms LLaMA-2 13B on all benchmarks and outperforms LLaMA-1 34B on many benchmarks. They approaches CodeLlama 7B performance on code, while remaining good at English tasks.</li></ul>
<p class="list-title"><span epub:type="pagebreak" id="p230" aria-label=" page 230. " role="doc-pagebreak"/><b>Use</b></p>
<ul class="disc">
<li>The initial models are focused on general purpose English language generation and a fine-tuned question&#x2013;answer model.</li>
<li>They are also trained on code generation tasks.</li></ul>
<p class="list-title"><b>Comments</b></p>
<ul class="disc">
<li>This model is open source and available for commercial use, which presents a useful alternative for developers.</li>
<li>It is also positioning itself as a high-performance model despite its currently smaller size.</li></ul></section>
<section aria-labelledby="sec6_5_6">
<h3 id="sec6_5_6"><span epub:type="ordinal">6.5.6 </span>Diffusion Model &#x2013; stability.ai Stable Diffusion</h3>
<p>Stability AI was founded in 2020 and their model, Stable Diffusion, was first released in 2022. This model built on the work from Prof. Dr. Bj&#x00F6;rn Ommer, who led the original Stable Diffusion V1 release.</p>
<p class="list-title"><b>Release History</b></p>
<ul class="simple">
<li>
<table id="table6_6">
<caption><span class="label">Table</span> <span class="ordinal">6.6 </span>Stable Diffusion Release History</caption>
<thead>
<tr>
<th scope="col" class="left">Date</th>
<th scope="col" class="left">Model</th>
<th scope="col" class="left">Description</th></tr></thead>
<tbody>
<tr>
<td class="left">Aug/2022</td>
<td class="left">Stable Diffusion 1.4</td>
<td class="left">Version 1.4 release.</td></tr>
<tr>
<td class="left">Oct/2022</td>
<td class="left">Stable Diffusion 1.5</td>
<td class="left">Version 1.5 release.</td></tr>
<tr>
<td class="left">Nov/2022</td>
<td class="left">Stable Diffusion 2.0</td>
<td class="left">Version 2.0 release.</td></tr>
<tr>
<td class="left">Dec/2022</td>
<td class="left">Stable Diffusion 2.1</td>
<td class="left">Version 2.1 release.</td></tr>
<tr>
<td class="left">Jul/2023</td>
<td class="left">Stable Diffusion XL1.0</td>
<td class="left">New XL version 1.0 release</td></tr></tbody></table></li></ul>
<p class="list-title"><b>Specifications</b></p>
<ul class="disc">
<li>Stable Diffusion is a deep learning, text-to-image model based on diffusion techniques. It operates as a Latent Diffusion Model with a fixed, pre-trained text encoder, known as OpenCLIP-ViT/H, for generating and modifying images based on text prompts.</li>
<li>It is believed to be trained on over 5 billion images from a variety of sources such as Flickr, Wikimedia Commons and LAION-5B.</li></ul>
<p class="list-title"><b>Use</b></p>
<ul class="disc">
<li>Its primary use is to generate detailed images conditioned on text descriptions.</li>
<li>It also supports other tasks such as inpainting (editing within the image), outpainting (extending the image outside of the original image), and image-to-image translations guided by text prompts.</li>
<li>The model is noted for its ability to create descriptive images with enhanced composition and realistic aesthetics, and it can also generate words within images.</li></ul>
<p class="list-title"><span epub:type="pagebreak" id="p231" aria-label=" page 231. " role="doc-pagebreak"/><b>Comments</b></p>
<ul class="disc">
<li>Its flagship image model, SDXL 1.0, is particularly highlighted for its superiority in image generation.</li>
<li>The Stable Diffusion 2.0 release included robust text-to-image models trained using a new text encoder developed by LAION, which significantly improved the quality of generated images compared to earlier releases.</li></ul></section>
<section aria-labelledby="sec6_5_7">
<h3 id="sec6_5_7"><span epub:type="ordinal">6.5.7 </span>Diffusion Model &#x2013; OpenAI DALL-E 3</h3>
<p>DALL-E 3 is the most recent text-to-image model developed by OpenAI, which was discussed earlier in the context of ChatGPT. The integration of DALL-E 3 with ChatGPT enhances its accessibility and represents a marked advancement over DALL-E 2.</p>
<p class="list-title"><b>Release History</b></p>
<ul class="simple">
<li>
<table id="table6_7">
<caption><span class="label">Table</span> <span class="ordinal">6.7 </span>OpenAI DALL-E Release History</caption>
<thead>
<tr>
<th scope="col" class="left">Date</th>
<th scope="col" class="left">Model</th>
<th scope="col" class="left">Description</th></tr></thead>
<tbody>
<tr>
<td class="left">5/Jan/2021</td>
<td class="left">DALL-E</td>
<td class="left">Initial release</td></tr>
<tr>
<td class="left">6/Apr/2022</td>
<td class="left">DALL-E 2</td>
<td class="left">Version 2 release</td></tr>
<tr>
<td class="left">Sep/2023</td>
<td class="left">DALL-E 3</td>
<td class="left">Version 3 release</td></tr></tbody></table></li></ul>
<p class="list-title"><b>Specifications</b></p>
<ul class="disc">
<li>DALL-E 3 is a text-to-image model based on diffusion techniques.</li>
<li>It has been built natively on ChatGPT. When prompted with an idea, ChatGPT will automatically generate tailored and detailed prompts for DALL-E 3</li></ul>
<p class="list-title"><b>Use</b></p>
<ul class="disc">
<li>Image generation where the details of the prompt are important in providing a more nuanced output image.</li></ul>
<p class="list-title"><b>Comments</b></p>
<ul class="disc">
<li>DALL-E 3 has put more effort into &#x2018;safety&#x2019; where prompts can&#x2019;t generate images in the style of living artists and creators can request their works to be excluded from training of future image generation models.</li>
<li>DALL-E 3-generated images belong to the prompter.</li></ul></section>
<section aria-labelledby="sec6_5_8">
<h3 id="sec6_5_8"><span epub:type="ordinal">6.5.8 </span>Diffusion Model &#x2013; Midjourney Inc. Midjourney</h3>
<p>Midjourney was founded by David Holt. Distinctively, unlike other AI start-ups, it generated substantial revenue prior to securing venture capital funding. Their inaugural model, released in 2022, gained popularity, and its integration with Discord appeared to bolster its prominence.</p>
<p class="list-title"><span epub:type="pagebreak" id="p232" aria-label=" page 232. " role="doc-pagebreak"/><b>Release History</b></p>
<ul class="simple">
<li>
<table id="table6_8">
<caption><span class="label">Table</span> <span class="ordinal">6.8 </span>Midjourney Release History</caption>
<thead>
<tr>
<th scope="col" class="left">Date</th>
<th scope="col" class="left">Model</th>
<th scope="col" class="left">Description</th></tr></thead>
<tbody>
<tr>
<td class="left">Feb/2022</td>
<td class="left">Midjourney V1</td>
<td class="left">Version 1 release</td></tr>
<tr>
<td class="left">12/Apr/2022</td>
<td class="left">Midjourney V2</td>
<td class="left">Version 2 release</td></tr>
<tr>
<td class="left">25/Jul/2022</td>
<td class="left">Midjourney V3</td>
<td class="left">Version 3 release</td></tr>
<tr>
<td class="left">5/Nov/2022</td>
<td class="left">Midjourney V4</td>
<td class="left">Version 4 release</td></tr>
<tr>
<td class="left">15/Mar/2023</td>
<td class="left">Midjourney V5</td>
<td class="left">Version 5 release</td></tr>
<tr>
<td class="left">3/May/2023</td>
<td class="left">Midjourney V5.1</td>
<td class="left">Version 5.1 release</td></tr>
<tr>
<td class="left">22/Jun/2023</td>
<td class="left">Midjourney V5.2</td>
<td class="left">Version 5.2 release</td></tr></tbody></table></li></ul>
<p class="list-title"><b>Specifications</b></p>
<ul class="disc">
<li>Midjourney is a diffusion model and uses a transformer neural network to generate images from text prompts.</li>
<li>The diffusion process is designed to generate more creative and expressive images than some of the other models.</li></ul>
<p class="list-title"><b>Use</b></p>
<ul class="disc">
<li>Midjourney is designed to be user-friendly and accessible through Discord.</li></ul>
<p class="list-title"><b>Comments</b></p>
<ul class="disc">
<li>Some of Midjourney&#x2019;s experimental algorithms might have licensing limitations under the Creative ML OpenRAIL-M license, as implied by a recent amendment to their terms of service.</li></ul></section>
<section aria-labelledby="sec6_5_9">
<h3 id="sec6_5_9"><span epub:type="ordinal">6.5.9 </span>Speech Recognition &#x2013; OpenAI Whisper</h3>
<p>The Whisper model from OpenAI has been released as an open source model with the objective of facilitating its use in a wide variety of situations, including embedded scenarios where speech-to-text capabilities are beneficial.</p>
<p class="list-title"><b>Release History</b></p>
<ul class="simple">
<li>
<table id="table6_9">
<caption><span class="label">Table</span> <span class="ordinal">6.9 </span>OpenAI Whisper Release History</caption>
<thead>
<tr>
<th scope="col" class="left">Date</th>
<th scope="col" class="left">Model</th>
<th scope="col" class="left">Description</th></tr></thead>
<tbody>
<tr>
<td class="left">21/Sep/2022</td>
<td class="left">Whisper</td>
<td class="left">Robust Speech Recognition via Large-Scale Weak Supervision (<a href="#ref6_51" id="R_ref6_51" epub:type="biblioref" role="doc-biblioref">Radford et al., 2022</a>)</td></tr></tbody></table></li></ul>
<p class="list-title"><b>Specifications</b></p>
<ul class="disc">
<li>It is an encoder-decoder transformer architecture.</li>
<li><span epub:type="pagebreak" id="p233" aria-label=" page 233. " role="doc-pagebreak"/>The encoder processes input with two convolutional layers and the decoder uses learned positional encodings.</li>
<li>It has been trained on over 680,000 hours of multilingual and multitasked data.</li></ul>
<p class="list-title"><b>Use</b></p>
<ul class="disc">
<li>Whisper is an automatic speech recognition system supporting multiple languages with ability to understand accents and background noise. In real time it can transcribe speech into text.</li>
<li>The model is provided as open source in a manner that allows it to be integrated into products.</li></ul>
<p class="list-title"><b>Comments</b></p>
<ul class="disc">
<li>It approaches human-level robustness and accuracy on English speech recognition.</li>
<li>One of the big advantages of Whisper is that it does well on zero-shot tasks, meaning that it does not required examples of a person&#x2019;s speech to transcribe it.</li></ul></section></section>
<section epub:type="conclusion" role="doc-conclusion">
<h2 id="sec6_6"><span epub:type="ordinal">6.6 </span>Conclusions</h2>
<p>Artificial Neural Networks (ANNs) and Deep Neural Networks (DNNs) have a long history in AI. They have essentially been present since the inception of the AI discipline, tracing back to the Dartmouth Summer Research Project.</p>
<p>The objective of ANNs and DNNs has always been to develop a computer program capable of learning in the manner humans do, acquiring expertise across various domains, or potentially any area on which it is trained.</p>
<p>Today, this ambition appears more attainable than ever before. The capabilities of these neural networks may well be boundless, provided we have sufficiently advanced computers to support ever-expanding models and an increasing wealth of data to train these models across the diverse topics we wish them to master.</p>
<p>The process of creating, training, and testing a model has never been more accessible. This ease is due to the availability of knowledge, which aids in building the necessary expertise, the ready access to the models themselves, data to train them, and benchmarks for testing. Fine-tuning an existing foundational model is now comparatively straightforward and can be undertaken even by relatively inexperienced individuals or teams. We observe state-of-the-art (SOTA) models being released under flexible commercial licenses (e.g., LLaMA-2) or genuine open-source licenses for parts of the model environment (e.g., Mistral, Whisper, Stable Diffusion). The prevalence of comprehensive free online courses about machine learning further reduces barriers to knowledge, enabling individuals to acquire profound expertise. Furthermore, the prospect of quantum computing is imminent, promising transformative advancements in processing capabilities.</p>
<p>All these developments arguably reinforce the notion that AGI (Artificial General Intelligence) and ASI (Artificial Superintelligence) are inevitable, destined to reach previously inconceivable levels of intelligence.</p>
<p>Nevertheless, it is prudent to recall past warnings against overestimating the potential of neural networks. History reminds us of two prior AI &#x2018;winters&#x2019;, where such overconfidence played a significant role.</p>
<aside epub:type="tip" role="doc-tip" class="box ruled">
<h3 id="box6_18">Questions to Ponder</h3>
<ul class="disc">
<li>Can current GenAI make new discoveries that are truly new and transform our understanding of the universe the way that Newton&#x2019;s laws did or the way that Einstein&#x2019;s Special and General Relativity did?</li>
<li>Can GenAI become autonomous (i.e.) without a human driving it or providing it with agency?</li>
<li>Do we understand what current GenAI can help with and what it can&#x2019;t help with? How does this fit with education for kindergarten, primary, secondary, tertiary, postgraduate, and even advanced cutting-edge research?</li>
<li>If you wished to utilise GenAI, do you use an existing model or do you build or train your own? Do you understand the trade-offs involved?</li>
<li>Should humans give GenAI more agency to interact with the world and more agency over their own use and direction?</li></ul></aside>
<aside epub:type="tip" role="doc-tip" class="box shaded">
<h3 id="box6_19">Personal Reflection</h3>
<p>Reflecting on the marvels of text-to-image models, it is fascinating how they can turn random noise into imagery that matches our written descriptions. This process may remind us of Michelangelo&#x2019;s portrayal of sculpting, where he said, &#x201C;<i>Every block of stone has a statue inside it, and it is the task of the sculptor to discover it</i>&#x201D;. In the same way, every noise pattern might hide a beautiful image, and it is up to the model to bring it out. But let&#x2019;s not forget the person behind the prompt. If users describe a unique image in their mind, that initial spark of creativity is truly theirs. They have to put their vision into words first before the model can even start its magic.</p></aside></section>
<section class="reference" epub:type="bibliography" role="doc-bibliography">
<h2 id="r6_1"><span epub:type="pagebreak" id="p234" aria-label=" page 234. " role="doc-pagebreak"/>References</h2>
<ul>
<li id="ref6_1" epub:type="biblioentry"><a href="#R_ref6_1" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Ackley, D. H., Hinton, G. E., &#x0026; Sejnowski, T. J.</a> (1985). A learning algorithm for Boltzmann machines. <cite>Cognitive Science</cite>, <i>9</i>(2), 147&#x2013;169.</li>
<li id="ref6_2" epub:type="biblioentry"><a href="#R_ref6_2" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Anil, R., Dai, A. M., Firat, O., Johnson, M., Lepikhin, D., Passos, A., Shakeri, S., Taropa, E., Bailey, P., Chen, Z., &#x2026; &#x0026; Saeta, B.</a> (2023). PaLM 2 technical report [Preprint]. <a href="https://doi.org/10.48550/arXiv.2305.10403" aria-label="D.O.I. link to PaLM 2 technical report">https://doi.org/10.48550/arXiv.2305.10403</a></li>
<li id="ref6_3" epub:type="biblioentry"><a href="#R_ref6_3" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Arute, F., Arya, K., Babbush, R., Bacon, D., Bardin, J. C., Barends, R., &#x2026; &#x0026; Martinis, J. M.</a> (2019). Quantum supremacy using a programmable superconducting processor. <cite>Nature</cite>, <i>574</i>(7779), 505&#x2013;510. <a href="https://doi.org/10.1038/s41586-019-1666-5" aria-label="D.O.I. link to Nature">https://doi.org/10.1038/s41586-019-1666-5</a></li>
<li id="ref6_4" epub:type="biblioentry"><a href="#R_ref6_4" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Asimov, I.</a> (1950). Runaround. In The Isaac Asimov Collection (Ed.), <cite>I, Robot</cite> (p. 40). Doubleday.</li>
<li id="ref6_5" epub:type="biblioentry"><a href="#R_ref6_5" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Austin, J., Odena, A., Nye, M., Bosma, M., Michalewski, H., Dohan, D., Jiang, E., Cai, C., Terry, M., Le, Q., &#x0026; Sutton, C.</a> (2021). Program synthesis with large language models [Preprint]. <a href="https://doi.org/10.48550/arXiv.2108.07732" aria-label="D.O.I. link to Program synthesis with large language models">https://doi.org/10.48550/arXiv.2108.07732</a></li>
<li id="ref6_6" epub:type="biblioentry"><a href="#R_ref6_6" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Bai, Y., Kadavath, S., Kundu, S., Askell, A., Kernion, J., Jones, A., Chen, A., Goldie, A., Mirhoseini, A., McKinnon, C., Chen, C., Olsson, C., Olah, C., Hernandez, D., Drain, D., Ganguli, D., Li, D., Tran-Johnson, E., Perez, E., Kerr, J., &#x2026; Kaplan, J.</a> (2022). Constitutional AI: Harmlessness from AI feedback [Preprint]. <a href="https://doi.org/10.48550/arXiv.2212.08073" aria-label="D.O.I. link to Constitutional AI: Harmlessness from AI feedback">https://doi.org/10.48550/arXiv.2212.08073</a></li>
<li id="ref6_7" epub:type="biblioentry"><span epub:type="pagebreak" id="p235" aria-label=" page 235. " role="doc-pagebreak"/><a href="#R_ref6_7" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Bisk, Y., Zellers, R., Le Bras, R., Gao, J., &#x0026; Choi, Y.</a> (2020). PIQA: Reasoning about physical commonsense in natural language. In <i>AAAI 2020</i>. <a href="https://doi.org/10.48550/arXiv.1911.11641" aria-label="D.O.I. link to AAAI 2020">https://doi.org/10.48550/arXiv.1911.11641</a></li>
<li id="ref6_8" epub:type="biblioentry"><a href="#R_ref6_8" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Block, H. D., Knight, B. W. Jr., &#x0026; Rosenblatt, F.</a> (1962). Analysis of a four-layer series-coupled perceptron II. <cite>Reviews of Modern Physics</cite>, <i>34</i>(1), 135. <a href="https://doi.org/10.1103/RevModPhys.34.135" aria-label="D.O.I. link to Reviews of Modern Physics">https://doi.org/10.1103/RevModPhys.34.135</a></li>
<li id="ref6_9" epub:type="biblioentry"><a href="#R_ref6_9" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Breiman, L.</a> (2001). Random forests. <cite>Machine Learning</cite>, <i>45</i>(1), 5&#x2013;32. <a href="https://doi.org/10.1023/A:1010933404324" aria-label="D.O.I. link to Machine Learning">https://doi.org/10.1023/A:1010933404324</a></li>
<li id="ref6_10" epub:type="biblioentry"><a href="#R_ref6_10" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Brown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S., Herbert-Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler, D. M., Wu, J., Winter, C., Hesse, C., Chen, M., Sigler, E., Litwin, M., Gray, S., Chess, B., Clark, J., Berner, C., McCandlish, S., Radford, A., Sutskever, I., &#x0026; Amodei, D.</a> (2020). Language models are few-shot learners. arXiv preprint. <a href="https://doi.org/10.48550/arXiv.2005.14165" aria-label="D.O.I. link to Language models are few-shot learners">https://doi.org/10.48550/arXiv.2005.14165</a></li>
<li id="ref6_11" epub:type="biblioentry"><a href="#R_ref6_11" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Chen, M., Tworek, J., Jun, H., Yuan, Q., Pinto, H. P. de O., Kaplan, J., Edwards, H., Burda, Y., Joseph, N., Brockman, G., Ray, A., Puri, R., Krueger, G., Petrov, M., Khlaaf, H., Sastry, G., Mishkin, P., Chan, B., Gray, S., Ryder, N., Pavlov, M., Power, A., Kaiser, L., Bavarian, M., Winter, C., Tillet, P., Such, F. P., Cummings, D., Plappert, M., Chantzis, F., Barnes, E., Herbert-Voss, A., Guss, W. H., Nichol, A., Paino, A., Tezak, N., Tang, J., Babuschkin, I., Balaji, S., Jain, S., Saunders, W., Hesse, C., Carr, A. N., Leike, J., Achiam, J., Misra, V., Morikawa, E., Radford, A., Knight, M., Brundage, M., Murati, M., Mayer, K., Welinder, P., McGrew, B., Amodei, D., McCandlish, S., Sutskever, I., &#x0026; Zaremba, W.</a> (2021). Evaluating large language models trained on code (Version v2) [Preprint]. <a href="https://doi.org/10.48550/arXiv.2107.03374" aria-label="D.O.I. link to Evaluating large language models trained on code">https://doi.org/10.48550/arXiv.2107.03374</a></li>
<li id="ref6_12" epub:type="biblioentry"><a href="#R_ref6_12" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Cheng, H.-T., Koc, L., Harmsen, J., Shaked, T., Chandra, T., Aradhye, H., Anderson, G., Corrado, G., Chai, W., Ispir, M., Anil, R., Haque, Z., Hong, L., Jain, V., Liu, X., &#x0026; Shah, H.</a> (2016). Wide &#x0026; deep learning for recommender systems. arXiv:1606.07792 [cs.LG]. <a href="https://doi.org/10.48550/arXiv.1606.07792" aria-label="D.O.I. link to Wide &#x0026; deep learning for recommender systems">https://doi.org/10.48550/arXiv.1606.07792</a></li>
<li id="ref6_13" epub:type="biblioentry"><a href="#R_ref6_13" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Chowdhery, A., Narang, S., Devlin, J., Bosma, M., Mishra, G., Roberts, A., Barham, P., Chung, H. W., Sutton, C., Gehrmann, S., &#x2026; &#x0026; Fiedel, N.</a> (2022). PaLM: Scaling language modeling with pathways [Preprint]. <a href="https://doi.org/10.48550/arXiv.2204.02311" aria-label="D.O.I. link to PaLM: Scaling language modeling with pathways">https://doi.org/10.48550/arXiv.2204.02311</a></li>
<li id="ref6_14" epub:type="biblioentry">Clark, C., Lee, K., Chang, M.-W., Kwiatkowski, T., Collins, M., &#x0026; Toutanova, K. (2019). BoolQ: Exploring the surprising difficulty of natural yes/no questions. <i>NAACL 2019</i>. <a href="https://doi.org/10.48550/arXiv.1905.10044" aria-label="D.O.I. link to NAACL 2019">https://doi.org/10.48550/arXiv.1905.10044</a></li>
<li id="ref6_15" epub:type="biblioentry"><a href="#R_ref6_15" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Clark, P., Cowhey, I., Etzioni, O., Khot, T., Sabharwal, A., Schoenick, C., &#x0026; Tafjord, O.</a> (2018). Think you have solved question answering? Try ARC, the AI2 reasoning challenge. arXiv preprint arXiv:1803.05457. <a href="https://doi.org/10.48550/arXiv.1803.05457" aria-label="D.O.I. link to Try ARC, the AI2 reasoning challenge">https://doi.org/10.48550/arXiv.1803.05457</a></li>
<li id="ref6_16" epub:type="biblioentry"><a href="#R_ref6_16" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Cobbe, K., Kosaraju, V., Bavarian, M., Chen, M., Jun, H., Kaiser, L., Plappert, M., Tworek, J., Hilton, J., Nakano, R., Hesse, C., &#x0026; Schulman, J.</a> (2021). Training verifiers to solve math word problems (Version v2) [Preprint]. <a href="https://doi.org/10.48550/arXiv.2110.14168" aria-label="D.O.I. link to Training verifiers to solve math word problems">https://doi.org/10.48550/arXiv.2110.14168</a></li>
<li id="ref6_17" epub:type="biblioentry"><a href="#R_ref6_17" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Feynman, R. P.</a> (1982). Simulating physics with computers. <cite>International Journal of Theoretical Physics</cite>, <i>21</i>(6/7), 467&#x2013;488.</li>
<li id="ref6_18" epub:type="biblioentry"><a href="#R_ref6_18" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Friedman, J. H.</a> (2002). Stochastic gradient boosting. <cite>Computational Statistics &#x0026; Data Analysis</cite>, <i>38</i>(4), 367&#x2013;378. <a href="https://doi.org/10.1016/S0167-9473(01)00065-2" aria-label="D.O.I. link to Computational Statistics &#x0026; Data Analysis">https://doi.org/10.1016/S0167-9473(01)00065-2</a></li>
<li id="ref6_19" epub:type="biblioentry"><a href="#R_ref6_19" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Future of Life Institute</a>. (2023a). An open letter: Pause giant AI experiments. Retrieved [insert date of retrieval here], from <a href="https://futureoflife.org">https://futureoflife.org/open-letter/pause-giant-ai-experiments/</a></li>
<li id="ref6_20" epub:type="biblioentry"><a href="#R_ref6_20" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Future of Life Institute</a>. (2023b). <cite>Policymaking in the pause</cite>. <a href="https://futureoflife.org">https://futureoflife.org/wp-content/uploads/2023/04/FLI_Policymaking_In_The_Pause.pdf</a></li>
<li id="ref6_21" epub:type="biblioentry"><a href="#R_ref6_21" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Gehman, S., Gururangan, S., Sap, M., Choi, Y., &#x0026; Smith, N. A.</a> (2020). RealToxicityPrompts: Evaluating neural toxic degeneration in language models [Preprint]. <a href="https://doi.org/10.48550/arXiv.2009.11462" aria-label="D.O.I. link to RealToxicityPrompts: Evaluating neural toxic degeneration in language models">https://doi.org/10.48550/arXiv.2009.11462</a></li>
<li id="ref6_22" epub:type="biblioentry"><a href="#R_ref6_22" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Goodfellow, I., Bengio, Y., &#x0026; Courville, A.</a> (2016). <cite>Deep learning</cite>. MIT Press. <a href="http://www.deeplearningbook.org">http://www.deeplearningbook.org</a></li>
<li id="ref6_23" epub:type="biblioentry"><a href="#R_ref6_23" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Goodfellow, I. J., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., &#x0026; Bengio, Y.</a> (2014). Generative adversarial networks arXiv preprint arXiv:1406.2661. <a href="https://doi.org/10.48550/arXiv.1406.2661" aria-label="D.O.I. link to Generative adversarial networks arXiv">https://doi.org/10.48550/arXiv.1406.2661</a></li>
<li id="ref6_24" epub:type="biblioentry"><span epub:type="pagebreak" id="p236" aria-label=" page 236. " role="doc-pagebreak"/><a href="#R_ref6_24" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Hebb, D. O.</a> (1949). <cite>The organization of behavior: A neuropsychological theory</cite>. John Wiley &#x0026; Sons; Chapman &#x0026; Hall.</li>
<li id="ref6_25" epub:type="biblioentry"><a href="#R_ref6_25" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Hendrycks, D., Burns, C., Basart, S., Zou, A., Mazeika, M., Song, D., &#x0026; Steinhardt, J.</a> (2020). Measuring massive multitask language understanding [Preprint]. <a href="https://doi.org/10.48550/arXiv.2009.03300" aria-label="D.O.I. link to Measuring massive multitask language understanding">https://doi.org/10.48550/arXiv.2009.03300</a></li>
<li id="ref6_26" epub:type="biblioentry"><a href="#R_ref6_26" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Hendrycks, D., Burns, C., Kadavath, S., Arora, A., Basart, S., Tang, E., Song, D., &#x0026; Steinhardt, J.</a> (2021). Measuring mathematical problem solving with the MATH dataset (Version v2) [Preprint]. NeurIPS. <a href="https://doi.org/10.48550/arXiv.2103.03874" aria-label="D.O.I. link to Measuring mathematical problem solving with the MATH dataset">https://doi.org/10.48550/arXiv.2103.03874</a></li>
<li id="ref6_27" epub:type="biblioentry"><a href="#R_ref6_27" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Hinton, G. E., Osindero, S., &#x0026; Teh, Y-W.</a> (2006). A fast learning algorithm for deep belief nets. <cite>Neural Computation</cite>, <i>18</i>(7), 1527&#x2013;1554. <a href="https://doi.org/10.1162/neco.2006.18.7.1527" aria-label="D.O.I. link to Neural Computation">https://doi.org/10.1162/neco.2006.18.7.1527</a></li>
<li id="ref6_28" epub:type="biblioentry"><a href="#R_ref6_28" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Hochreiter, S., &#x0026; Schmidhuber, J.</a> (1997). Long short-term memory. <cite>Neural Computation</cite>, <i>9</i>(8), 1735&#x2013;1780. <a href="https://doi.org/10.1162/neco.1997.9.8.1735" aria-label="D.O.I. link to Neural Computation">https://doi.org/10.1162/neco.1997.9.8.1735</a></li>
<li id="ref6_29" epub:type="biblioentry">Hopfield, J. J. (1982). Neural networks and physical systems with emergent collective computational abilities. <cite>Proceedings of the National Academy of Sciences of the USA</cite>, <i>79</i>(8), 2554&#x2013;2558.</li>
<li id="ref6_30" epub:type="biblioentry"><a href="#R_ref6_30" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Joshi, M., Choi, E., Weld, D. S., &#x0026; Zettlemoyer, L.</a> (2017). TriviaQA: A large scale distantly supervised challenge dataset for reading comprehension (Version v2) [Preprint]. arXiv. <a href="https://doi.org/10.48550/arXiv.1705.03551" aria-label="D.O.I. link to TriviaQA: A large scale distantly supervised challenge dataset for reading comprehension">https://doi.org/10.48550/arXiv.1705.03551</a></li>
<li id="ref6_31" epub:type="biblioentry"><a href="#R_ref6_31" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Joulin, A., Grave, E., Bojanowski, P., Douze, M., J&#x00E9;gou, H., &#x0026; Mikolov, T.</a> (2016). FastText.zip: Compressing text classification models. <i>arXiv:1612.03651 [cs.CL]</i>. <a href="https://doi.org/10.48550/arXiv.1612.03651" aria-label="D.O.I. link to arXiv:1612.03651 [cs.CL]">https://doi.org/10.48550/arXiv.1612.03651</a></li>
<li id="ref6_32" epub:type="biblioentry"><a href="#R_ref6_32" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Kaur, S., Singh, S., &#x0026; Kaushal, S.</a> (2021). Abusive content detection in online user-generated data: A survey. <cite>Procedia Computer Science</cite>. <a href="https://doi.org/10.1016/j.procs.2021.05.098" aria-label="D.O.I. link to Procedia Computer Science">https://doi.org/10.1016/j.procs.2021.05.098</a></li>
<li id="ref6_33" epub:type="biblioentry"><a href="#R_ref6_33" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Krizhevsky, A., Sutskever, I., &#x0026; Hinton, G. E.</a> (2012). ImageNet classification with deep convolutional neural networks. <cite>Advances in Neural Information Processing Systems</cite>, <i>25</i>(2). <a href="https://doi.org/10.1145/3065386" aria-label="D.O.I. link to Advances in Neural Information Processing Systems">https://doi.org/10.1145/3065386</a></li>
<li id="ref6_34" epub:type="biblioentry"><a href="#R_ref6_34" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Kwiatkowski, T., Palomaki, J., Redfield, O., Collins, M., Parikh, A., Alberti, C., Epstein, D., Polosukhin, I., Kelcey, M., Devlin, J., Lee, K., Toutanova, K. N., Jones, L., Chang, M.-W., Dai, A., Uszkoreit, J., Le, Q., &#x0026; Petrov, S.</a> (2019). Natural questions: A benchmark for question answering research. <cite>Transactions of the Association of Computational Linguistics</cite>, 7(15), 453&#x2013;466. <a href="https://doi.org/10.1162/tacl_a_00276" aria-label="D.O.I. link to Transactions of the Association of Computational Linguistics">https://doi.org/10.1162/tacl_a_00276</a></li>
<li id="ref6_35" epub:type="biblioentry"><a href="#R_ref6_35" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Lai, G., Xie, Q., Liu, H., Yang, Y., &#x0026; Hovy, E.</a> (2017). RACE: Large-scale reading comprehension dataset from examinations (Version v5) [Preprint]. arXiv. <a href="https://doi.org/10.48550/arXiv.1704.04683" aria-label="D.O.I. link to RACE: Large-scale reading comprehension dataset from examinations">https://doi.org/10.48550/arXiv.1704.04683</a></li>
<li id="ref6_36" epub:type="biblioentry"><a href="#R_ref6_36" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Le, Q. V., Ranzato, M., Monga, R., Devin, M., Chen, K., Corrado, G. S., Dean, J., &#x0026; Ng, A. Y.</a> (2011). Building high-level features using large scale unsupervised learning. arXiv:1112.6209. <a href="https://doi.org/10.48550/arXiv.1112.6209" aria-label="D.O.I. link to Building high-level features using large scale unsupervised learning">https://doi.org/10.48550/arXiv.1112.6209</a></li>
<li id="ref6_37" epub:type="biblioentry"><a href="#R_ref6_37" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">LeCun, Y., Boser, B., Denker, J. S., Henderson, D., Howard, R. E., Hubbard, W., &#x0026; Jackel, L. D.</a> (1989). Backpropagation applied to handwritten zip code recognition. <cite>Neural Computation</cite>, <i>1</i>(4), 541&#x2013;551.</li>
<li id="ref6_38" epub:type="biblioentry">LeCun, Y., Bottou, L., Bengio, Y., &#x0026; Haffner, P. (1998). Gradient-based learning applied to document recognition. <cite>Proceedings of the IEEE</cite>, <i>86</i>(11), 2278&#x2013;2324. <a href="https://doi.org/10.1109/5.726791" aria-label="D.O.I. link to Proceedings of the IEEE">https://doi.org/10.1109/5.726791</a></li>
<li id="ref6_39" epub:type="biblioentry"><a href="#R_ref6_39" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Lin, S., Hilton, J., &#x0026; Evans, O.</a> (2022). TruthfulQA: Measuring how models mimic human falsehoods [Preprint]. <a href="https://doi.org/10.48550/arXiv.2109.07958" aria-label="D.O.I. link to TruthfulQA: Measuring how models mimic human falsehoods">https://doi.org/10.48550/arXiv.2109.07958</a></li>
<li id="ref6_40" epub:type="biblioentry"><a href="#R_ref6_40" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">McCarthy, J., Minsky, M. L., Rochester, N., &#x0026; Shannon, C. E.</a> (1955, August 31). <cite>A proposal for the Dartmouth summer research project on artificial intelligence</cite>. Dartmouth College; Harvard University; I.B.M. Corporation; Bell Telephone Laboratories.</li>
<li id="ref6_41" epub:type="biblioentry">McClelland, J. L., Rumelhart, D. E., &#x0026; PDP Research Group. (1987). <cite>Parallel distributed processing: Explorations in the microstructure of cognition: Psychological and biological models</cite> (Vol. 2). The MIT Press. <a href="https://doi.org/10.7551/mitpress/5237.001.0001" aria-label="D.O.I. link to Parallel distributed processing: Explorations in the microstructure of cognition: Psychological and biological models">https://doi.org/10.7551/mitpress/5237.001.0001</a></li>
<li id="ref6_42" epub:type="biblioentry"><a href="#R_ref6_42" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">McCulloch, W. S., &#x0026; Pitts, W.</a> (1943). A logical calculus of the ideas immanent in nervous activity. <cite>The Bulletin of Mathematical Biophysics</cite>, <i>5</i>(4), 115&#x2013;133. <a href="https://doi.org/10.1007/BF02478259" aria-label="D.O.I. link to The Bulletin of Mathematical Biophysics">https://doi.org/10.1007/BF02478259</a></li>
<li id="ref6_43" epub:type="biblioentry"><a href="#R_ref6_43" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Mihaylov, T., Clark, P., Khot, T., &#x0026; Sabharwal, A.</a> (2018). Can a suit of armor conduct electricity? A new dataset for open book question answering. arXiv preprint arXiv:1809.02789. <a href="https://doi.org/10.48550/arXiv.1809.02789" aria-label="D.O.I. link to Can a suit of armor conduct electricity? A new dataset for open book question answering">https://doi.org/10.48550/arXiv.1809.02789</a></li>
<li id="ref6_44" epub:type="biblioentry"><span epub:type="pagebreak" id="p237" aria-label=" page 237. " role="doc-pagebreak"/>Minsky, M., &#x0026; Papert, S. A. (1969). <cite>Perceptrons: An introduction to computational geometry</cite>. MIT Press.</li>
<li id="ref6_45" epub:type="biblioentry"><a href="#R_ref6_45" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Minsky, M., &#x0026; Papert, S. A.</a> (1988). <cite>Perceptrons: An introduction to computational geometry</cite> (Expanded subsequent ed.). Massachusetts Institute of Technology.</li>
<li id="ref6_46" epub:type="biblioentry"><a href="#R_ref6_46" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Nangia, N., Vania, C., Bhalerao, R., &#x0026; Bowman, S. R.</a> (2020). CrowS-Pairs: A challenge dataset for measuring social biases in masked language models [Preprint]. <a href="https://doi.org/10.48550/arXiv.2010.00133" aria-label="D.O.I. link to CrowS-Pairs: A challenge dataset for measuring social biases in masked language models">https://doi.org/10.48550/arXiv.2010.00133</a></li>
<li id="ref6_47" epub:type="biblioentry"><a href="#R_ref6_47" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Oliva, A., &#x0026; Torralba, A.</a> (2001) Modeling the shape of the scene: A holistic representation of the spatial envelope. <cite>A. International Journal of Computer Vision</cite>, <i>42</i>(3), 145&#x2013;175.</li>
<li id="ref6_48" epub:type="biblioentry"><a href="#R_ref6_48" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">OpenAI</a>. (2023). GPT-4 technical report [Preprint]. <a href="https://doi.org/10.48550/arXiv.2303.08774" aria-label="D.O.I. link to GPT-4 technical report">https://doi.org/10.48550/arXiv.2303.08774</a></li>
<li id="ref6_49" epub:type="biblioentry"><a href="#R_ref6_49" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Patel, J. M.</a> (2020). Introduction to common crawl datasets. In <cite>Getting structured data from the internet</cite>. Apress. <a href="https://doi.org/10.1007/978-1-4842-6576-5_6" aria-label="D.O.I. link to Getting structured data from the internet">https://doi.org/10.1007/978-1-4842-6576-5_6</a></li>
<li id="ref6_50" epub:type="biblioentry"><a href="#R_ref6_50" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Radford, A., Kim, J. W., Hallacy, C., Ramesh, A., Goh, G., Agarwal, S., Sastry, G., Askell, A., Mishkin, P., Clark, J., Krueger, G., &#x0026; Sutskever, I.</a> (2021). Learning transferable visual models from natural language supervision. <a href="https://doi.org/10.48550/arXiv.2103.00020" aria-label="D.O.I. link to Learning transferable visual models from natural language supervision">https://doi.org/10.48550/arXiv.2103.00020</a></li>
<li id="ref6_51" epub:type="biblioentry"><a href="#R_ref6_51" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Radford, A., Kim, J. W., Xu, T., Brockman, G., McLeavey, C., &#x0026; Sutskever, I.</a> (2022). Robust speech recognition via large-scale weak supervision. arXiv preprint. <a href="https://doi.org/10.48550/arXiv.2212.04356" aria-label="D.O.I. link to Robust speech recognition via large-scale weak supervision">https://doi.org/10.48550/arXiv.2212.04356</a></li>
<li id="ref6_52" epub:type="biblioentry"><a href="#R_ref6_52" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Radford, A., Narasimhan, K., Salimans, T., &#x0026; Sutskever, I.</a> (2018). Improving language understanding by generative pre-training. OpenAI. Retrieved from <a href="https://cdn.openai.com">https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf</a></li>
<li id="ref6_53" epub:type="biblioentry"><a href="#R_ref6_53" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., &#x0026; Sutskever, I.</a> (2019). Language models are unsupervised multitask learners. OpenAI. Retrieved from <a href="https://cdn.openai.com">https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf</a></li>
<li id="ref6_54" epub:type="biblioentry"><a href="#R_ref6_54" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Raffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., Zhou, Y., Li, W., &#x0026; Liu, P. J.</a> (2023). Exploring the limits of transfer learning with a unified text-to-text transformer (Version 4) [Preprint]. arXiv. <a href="https://doi.org/10.48550/arXiv.1910.10683" aria-label="D.O.I. link to Exploring the limits of transfer learning with a unified text-to-text transformer">https://doi.org/10.48550/arXiv.1910.10683</a></li>
<li id="ref6_55" epub:type="biblioentry"><a href="#R_ref6_55" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Rajpurkar, P., Jia, R., &#x0026; Liang, P.</a> (2018). Know what you don&#x2019;t know: Unanswerable questions for SQuAD (Version v1) [Preprint]. arXiv. <a href="https://doi.org/10.48550/arXiv.1806.03822" aria-label="D.O.I. link to Know what you don&#x2019;t know: Unanswerable questions for SQuAD">https://doi.org/10.48550/arXiv.1806.03822</a></li>
<li id="ref6_56" epub:type="biblioentry"><a href="#R_ref6_56" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Rajpurkar, P., Zhang, J., Lopyrev, K., &#x0026; Liang, P.</a> (2016). SQuAD: 100,000+ questions for machine comprehension of text (Version v3) [Preprint]. arXiv. <a href="https://doi.org/10.48550/arXiv.1606.05250" aria-label="D.O.I. link to SQuAD: 100,000+ questions for machine comprehension of text">https://doi.org/10.48550/arXiv.1606.05250</a></li>
<li id="ref6_57" epub:type="biblioentry"><a href="#R_ref6_57" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Rosenblatt, F.</a> (1957). The perceptron&#x2014;A perceiving and recognizing automaton (Report No. 85-460-1). Cornell Aeronautical Laboratory.</li>
<li id="ref6_58" epub:type="biblioentry"><a href="#R_ref6_58" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Rosenblatt, F.</a> (1958). The perceptron: A probabilistic model for information storage and organization in the brain. <cite>Psychological Review</cite>, <i>65</i>(6), 386&#x2013;408. <a href="https://doi.org/10.1037/h0042519" aria-label="D.O.I. link to Psychological Review">https://doi.org/10.1037/h0042519</a></li>
<li id="ref6_59" epub:type="biblioentry"><a href="#R_ref6_59" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Rudinger, R., Naradowsky, J., Leonard, B., &#x0026; Van Durms, B.</a> (2018). Gender bias in coreference resolution [Preprint]. <a href="https://doi.org/10.48550/arXiv.1804.09301" aria-label="D.O.I. link to Gender bias in coreference resolution">https://doi.org/10.48550/arXiv.1804.09301</a></li>
<li id="ref6_60" epub:type="biblioentry"><a href="#R_ref6_60" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Rumelhart, D. E., Hinton, G. E., &#x0026; Williams, R. J.</a> (1985). Learning internal representations by error propagation (ICS Report 8506). Institute for Cognitive Science, University of California San Diego.</li>
<li id="ref6_61" epub:type="biblioentry"><a href="#R_ref6_61" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Rumelhart, D. E., Hinton, G. E., &#x0026; Williams, R. J.</a> (1986a). Learning internal representations by error propagation. In D. E. Rumelhart, J. L. McClelland, and the PDP Research Group (Eds.), <cite>Parallel distributed processing: Explorations in the microstructure of cognition. Volume 1: Foundations</cite> (pp. 318&#x2013;362). MIT Press.</li>
<li id="ref6_62" epub:type="biblioentry"><a href="#R_ref6_62" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Rumelhart, D. E., Hinton, G. E., &#x0026; Williams, R. J.</a> (1986b). Learning representations by back-propagating errors. <cite>Nature</cite>, <i>323</i>(6088), 533&#x2013;536.</li>
<li id="ref6_63" epub:type="biblioentry"><a href="#R_ref6_63" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Rumelhart, D. E., McClelland, J. L.</a>, &#x0026; PDP Research Group. (1986c). <cite>Parallel distributed processing: Explorations in the microstructure of cognition: Foundations</cite> (Vol. 1). The MIT Press. <a href="https://doi.org/10.7551/mitpress/5236.001.0001" aria-label="D.O.I. link to Parallel distributed processing: Explorations in the microstructure of cognition: Foundations">https://doi.org/10.7551/mitpress/5236.001.0001</a></li>
<li id="ref6_64" epub:type="biblioentry"><a href="#R_ref6_64" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Russell, B., Torralba, A., Murphy, K., &#x0026; Freeman, W. T.</a> (2007). LabelMe: A database and web-based tool for image annotation. <cite>International Journal of Computer Vision</cite>, <i>77</i>(1&#x2013;3), 157&#x2013;173.</li>
<li id="ref6_65" epub:type="biblioentry"><a href="#R_ref6_65" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Sakaguchi, K., Le Bras, R., Bhagavatula, C., &#x0026; Choi, Y.</a> (2019). WinoGrande: An adversarial Winograd schema challenge at scale. arXiv preprint arXiv:1907.10641. <a href="https://doi.org/10.48550/arXiv.1907.10641" aria-label="D.O.I. link to WinoGrande: An adversarial Winograd schema challenge at scale">https://doi.org/10.48550/arXiv.1907.10641</a></li>
<li id="ref6_66" epub:type="biblioentry"><span epub:type="pagebreak" id="p238" aria-label=" page 238. " role="doc-pagebreak"/><a href="#R_ref6_66" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Sap, M., Rashkin, H., Chen, D., LeBras, R., &#x0026; Choi, Y.</a> (2019). SocialIQA: Commonsense reasoning about social interactions. In <i>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing (EMNLP 2019)</i>. <a href="https://arxiv.org">https://arxiv.org/abs/1904.09728</a></li>
<li id="ref6_67" epub:type="biblioentry"><a href="#R_ref6_67" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Schuhmann, C., Beaumont, R., Vencu, R., Gordon, C., Wightman, R., Cherti, M., Coombes, T., Katta, A., Mullis, C., Wortsman, M., Schramowski, P., Kundurthy, S., Crowson, K., Schmidt, L., Kaczmarczyk, R., &#x0026; Jitsev, J.</a> (2022). LAION-5B: An open large-scale dataset for training next generation image-text models. <a href="https://doi.org/10.48550/arXiv.2210.08402" aria-label="D.O.I. link to LAION-5B: An open large-scale dataset for training next generation image-text models">https://doi.org/10.48550/arXiv.2210.08402</a></li>
<li id="ref6_68" epub:type="biblioentry"><a href="#R_ref6_68" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Snoswell, A. J., &#x0026; Burgess, J.</a> (2022, November 29). The Galactica AI model was trained on scientific knowledge &#x2013; But it spat out alarmingly plausible nonsense. The Conversation. <a href="https://theconversation.com">https://theconversation.com/the-galactica-ai-model-was-trained-on-scientific-knowledge-but-it-spat-out-alarmingly-plausible-nonsense-195445</a></li>
<li id="ref6_69" epub:type="biblioentry">Tesauro, G. (1995). Temporal difference learning and TD-Gammon. <cite>Communications of the ACM</cite>, <i>38</i>(3), 58&#x2013;68.</li>
<li id="ref6_70" epub:type="biblioentry"><a href="#R_ref6_70" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Thoppilan, R., De Freitas, D., Hall, J., Shazeer, N., Kulshreshtha, A., Cheng, H.-T., Jin, A., Bos, T., Baker, L., Du, Y., Li, Y., Lee, H., Zheng, H. S., Ghafouri, A., Menegali, M., Huang, Y., Krikun, M., Lepikhin, D., Qin, J., Chen, D., &#x2026; Le, Q.</a> (2022). LaMDA: Language models for dialog applications. arXiv preprint. <a href="https://doi.org/10.48550/arXiv.2201.08239" aria-label="D.O.I. link to LaMDA: Language models for dialog applications">https://doi.org/10.48550/arXiv.2201.08239</a></li>
<li id="ref6_71" epub:type="biblioentry"><a href="#R_ref6_71" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Touvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M.-A., Lacroix, T., Rozi&#x00E8;re, B., Goyal, N., Hambro, E., Azhar, F., Rodriguez, A., Joulin, A., Grave, E., &#x0026; Lample, G.</a> (2023a). LLaMA: Open and efficient foundation language models. arXiv preprint. <a href="https://doi.org/10.48550/arXiv.2302.13971" aria-label="D.O.I. link to LLaMA: Open and efficient foundation language models">https://doi.org/10.48550/arXiv.2302.13971</a></li>
<li id="ref6_72" epub:type="biblioentry"><a href="#R_ref6_72" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Touvron, H., Martin, L., Stone, K., Albert, P., Almahairi, A., Babaei, Y., Bashlykov, N., Batra, S., Bhargava, P., Bhosale, S., Bikel, D., Blecher, L., Ferrer, C. C., Chen, M., Cucurull, G., Esiobu, D., Fernandes, J., Fu, J., Fu, W., Fuller, B., &#x2026; Scialom, T.</a> (2023b). Llama 2: Open foundation and fine-tuned chat models. arXiv preprint. <a href="https://doi.org/10.48550/arXiv.2307.09288" aria-label="D.O.I. link to Llama 2: Open foundation and fine-tuned chat models">https://doi.org/10.48550/arXiv.2307.09288</a></li>
<li id="ref6_73" epub:type="biblioentry"><a href="#R_ref6_73" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Turing, A. M.</a> (1950). Computing machinery and intelligence. <cite>Mind</cite>, <i>49</i>, 433&#x2013;460.</li>
<li id="ref6_74" epub:type="biblioentry"><a href="#R_ref6_74" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, L., &#x0026; Polosukhin, I.</a> (2017). Attention is all you need. arXiv preprint arXiv:1706.03762v7. <a href="https://doi.org/10.48550/arXiv.1706.03762" aria-label="D.O.I. link to Attention is all you need">https://doi.org/10.48550/arXiv.1706.03762</a></li>
<li id="ref6_75" epub:type="biblioentry"><a href="#R_ref6_75" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Wahba, G., Lin, Y., Zhang, H. H., &#x0026; Lee, Y.</a> (2002). Support vector machines, reproducing Kernel Hilbert spaces and the randomized GACV. In B. Sch&#x00F6;lkopf &#x0026; M. K. Warmuth (Eds.), <cite>Advances in large margin classifiers</cite> (pp. 1&#x2013;69). MIT Press.</li>
<li id="ref6_76" epub:type="biblioentry"><a href="#R_ref6_76" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Wang, A., Pruksachatkun, Y., Nangia, N., Singh, A., Michael, J., Hill, F., Levy, O., &#x0026; Bowman, S. R.</a> (2019). SuperGLUE: A stickier benchmark for general-purpose language understanding systems. <i>NeurIPS 2019</i>. Retrieved from <a href="http://super.gluebenchmark.com">super.gluebenchmark.com</a></li>
<li id="ref6_77" epub:type="biblioentry"><a href="#R_ref6_77" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Wang, A., Singh, A., Michael, J., Hill, F., Levy, O., &#x0026; Bowman, S. R.</a> (2018). GLUE: A multi-task benchmark and analysis platform for natural language understanding. <i>ICLR 2019</i>. arXiv:1804.07461. <a href="https://gluebenchmark.com">https://gluebenchmark.com/</a></li>
<li id="ref6_78" epub:type="biblioentry"><a href="#R_ref6_78" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Weizenbaum, J.</a> (1976). <cite>Computer power and human reason: From judgment to calculation</cite>. W. H. Freeman.</li>
<li id="ref6_79" epub:type="biblioentry"><a href="#R_ref6_79" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Wenzek, G., Lachaux, M.-A., Conneau, A., Chaudhary, V., Guzm&#x00E1;n, F., Joulin, A., &#x0026; Grave, E.</a> (2019). CCNet: Extracting high quality monolingual datasets from web crawl data. <a href="https://doi.org/10.48550/arXiv.1911.00359" aria-label="D.O.I. link to CCNet: Extracting high quality monolingual datasets from web crawl data">https://doi.org/10.48550/arXiv.1911.00359</a></li>
<li id="ref6_80" epub:type="biblioentry"><a href="#R_ref6_80" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Werbos, P. J.</a> (1974). <i>Beyond Regression: New Tools for prediction and Analysis in the behavioral sciences</i> (Doctoral dissertation, Harvard University).</li>
<li id="ref6_81" epub:type="biblioentry"><a href="#R_ref6_81" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Widrow, B.</a> (1960). <i>An adaptive &#x201C;ADALINE: Neuron using chemical &#x201C;MEMISTORS&#x201D;</i> (Technical Report No. 1553-2).</li>
<li id="ref6_82" epub:type="biblioentry"><a href="#R_ref6_82" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Widrow, B.</a> (1962). Generalization and information storage in networks of Adaline &#x2018;neurons&#x2019;. In M. C. Yovitz, G. T. Jacobi, &#x0026; G. Goldstein (Eds.), <cite>Self-organizing systems: Symposium proceedings</cite> (pp. 435&#x2013;461). Spartan Books.</li>
<li id="ref6_83" epub:type="biblioentry"><a href="#R_ref6_83" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Wiener, N.</a> (1966). <cite>God &#x0026; Golem, Inc.: A comment on certain points where cybernetics impinges on religion</cite>. The MIT Press.</li>
<li id="ref6_84" epub:type="biblioentry"><span epub:type="pagebreak" id="p239" aria-label=" page 239. " role="doc-pagebreak"/><a href="#R_ref6_84" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Zellers, R., Bisk, Y., Schwartz, R., &#x0026; Choi, Y.</a> (2018). SWAG: A large-scale adversarial dataset for grounded commonsense inference. <i>Proceedings of the 2018 conference on empirical methods in natural language processing (EMNLP 2018)</i>. <a href="https://doi.org/10.48550/arXiv.1808.05326" aria-label="D.O.I. link to Proceedings of the 2018 conference on empirical methods in natural language processing (EMNLP 2018)">https://doi.org/10.48550/arXiv.1808.05326</a></li>
<li id="ref6_85" epub:type="biblioentry"><a href="#R_ref6_85" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Zellers, R., Holtzman, A., Bisk, Y., Farhadi, A., &#x0026; Choi, Y.</a> (2019). HellaSwag: Can a machine really finish your sentence? In <i>Proceedings of the 57th annual meeting of the association for computational linguistics (ACL 2019)</i>. <a href="https://doi.org/10.48550/arXiv.1905.07830" aria-label="D.O.I. link to Proceedings of the 57th annual meeting of the association for computational linguistics (ACL 2019)">https://doi.org/10.48550/arXiv.1905.07830</a></li></ul></section></section></body></html>