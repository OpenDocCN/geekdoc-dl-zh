- en: 6 Technology Behind GenAI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'DOI: [10.4324/9781003459026-6](https://dx.doi.org/10.4324/9781003459026-6)'
  prefs: []
  type: TYPE_NORMAL
- en: Big centralised AI models have amazed people. Personal, portable, and secure
    AI will make everyone amazing.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Tom Colloton
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 6.1 Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The aim of this chapter is to equip the reader with a clearer understanding
    of the technology behind generative Artificial Intelligence (GenAI). While the
    book primarily focuses on GenAI in higher education, we recognise that some readers
    may be curious to learn more about the “black box” of GenAI. Thus, we will delve
    into its history, processes, methods, and the foundational technology of GenAI.
    In this exploration, the reader will encounter terminology commonly used in the
    Artificial Intelligence (AI) field.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will discuss GenAI models, henceforth referred to simply
    as ‘models’ for brevity. It is crucial not to confuse these with other types of
    models mentioned in the book, such as assessment models. Contemporary GenAI systems
    predominantly employ deep neural networks (DNN) as the foundational approach for
    their models. As illustrated in [Figure 6.1](#fig6_1), DNNs are a type of artificial
    neural network (ANN). The concept of using artificial neural networks (ANNs) has
    deep roots in AI, drawing inspiration from studies on the biological brain’s functionality.
    We will delve deeper into this history, providing context leading up to the present-day
    state-of-the-art models. As illustrated in [Figure 6.1](#fig6_1), GenAI and its
    various model types, including large language models (LLMs) and text-to-image
    models like diffusion models, reside within the realm of deep learning ANNs.
  prefs: []
  type: TYPE_NORMAL
- en: '![A I categories include Artificial intelligence, machine learning, artificial
    neural networks, deep learning, and gen A I which include L L M and text to image.](images/fig6_1_B.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '[Figure 6.1 AI Categorisation.](#R_fig6_1)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Artificial neural networks (ANNs)** are computational models inspired by
    the human brain’s structure and function. They consist of interconnected nodes,
    called neurons, which process and transmit information through weighted connections.
    ANNs are designed to learn and recognise patterns from input data, making them
    useful for tasks such as classification, prediction, and decision-making in various
    fields like computer vision, natural language processing, and robotics. This chapter
    will delve into the processes and techniques that underpin these capabilities.'
  prefs: []
  type: TYPE_NORMAL
- en: The precise mechanisms by which neural networks store experiences and utilise
    them for predictions remain somewhat enigmatic. This elusive nature has led some
    to describe their operation as “magic”, given that the complete intricacies and
    potential limitations are not yet fully understood. This chapter will try to share
    what is known and what is not yet understood about how these models work.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter involves examining specific GenAI solutions that are currently
    popular and widely used. It will delve into these specific examples in detail,
    while also referencing broader methods. By juxtaposing specific examples with
    general concepts, we aim to offer non-experts a more insightful perspective than
    if we merely discussed the topic in general terms.
  prefs: []
  type: TYPE_NORMAL
- en: The chapter is structured in a manner that facilitates a gradual understanding,
    building later concepts on top of earlier concepts as much as possible. However,
    some topics are interrelated and require more of an iterative approach rather
    than a pure serial reading of the information, thus it is advised to read the
    chapter end to end and then re-read to get a deeper understanding of these concepts
    that required a more iterative approach.
  prefs: []
  type: TYPE_NORMAL
- en: 'The structure of the chapter is outlined below:'
  prefs: []
  type: TYPE_NORMAL
- en: '**The history**. This section looks at the history of artificial neural networks
    (ANNs), the early work that was done and some of the recent advancements.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Creating a model**. This section aims to furnish a comprehensive understanding
    of how a model operates and the processes involved in its creation. It examines
    the various stages of model creation: from gathering vast quantities of data to
    considerations in design and structure; the training phase; and testing the model
    for quality, performance, and safety.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Models and ecosystems**. This section looks at how models are being used
    and the ecosystems that have built up around them to allow people to interact
    with models in different ways and allow the models to interact with their environments.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**State-of-the-art models**. This section aims to provide an overview of some
    currently popular models considered state-of-the-art. It examines the applications
    of these models, discusses their design approaches, and comments on their strengths
    and weaknesses.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Conclusions**. This section recaps the key points of GenAI and reflects on
    the current boundaries of its application.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 6.2 The History
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The subsequent sections present the history of artificial neural networks (ANNs)
    in chronological order. You might encounter terms that have not yet been discussed
    or elaborated upon, such as the specifics of an artificial neuron or cell, the
    connectivity within artificial neural networks, the concept of a layer, and the
    roles of weights and biases. However, these intricacies will be addressed in due
    course. Initially, our focus will be on providing a chronological overview of
    how these concepts evolved. Later, we will delve into the particulars, emphasising
    those aspects that remain pertinent today, all while employing contemporary terminology.
  prefs: []
  type: TYPE_NORMAL
- en: The history of AI research can be understood as an evolving interplay of several
    distinct approaches or “camps”. These different approaches often reflected the
    diverse intellectual backgrounds of AI’s founding figures and were influenced
    by the available technology, prevailing scientific paradigms, and broader societal
    trends. Two of these camps were the Symbolists and the Connectionists.
  prefs: []
  type: TYPE_NORMAL
- en: The **Symbolists** believed that intelligence could be attained through the
    manipulation of symbols and rules. Their methodologies encompassed logic-based
    systems, rule-based expert systems, and semantic networks. Key figures within
    this camp included John McCarthy, Marvin Minsky, and Herbert Simon. Their primary
    focus was on determining how the essential rules of understanding, logic, and
    reason could be represented within a machine and discerning what these fundamental
    rules encompassed.
  prefs: []
  type: TYPE_NORMAL
- en: The **Connectionists** believed that intelligence emerges from interconnected
    networks of simple units, often referred to as cells or neurons. Their methodologies
    are exemplified by neural networks and deep neural networks, which include diverse
    architectures such as RNNs (recurrent neural networks), CNNs (convolutional neural
    networks), and Transformers. Notable figures within this camp included Frank Rosenblatt,
    Geoffrey Hinton, Yann LeCun, James Rumelhart, and James McClelland. Their primary
    focus was on determining how a machine could learn the necessary rules, how to
    train the said machine, and how to structure its architecture to facilitate learning
    in a manner as comprehensive as a human.
  prefs: []
  type: TYPE_NORMAL
- en: We discuss these two camps in more detail later.
  prefs: []
  type: TYPE_NORMAL
- en: It is important to recognise that advancements have been made in other areas
    of AI beyond the scope of this discussion. [Figure 6.2](#fig6_2) illustrates AI’s
    application in gaming; notably, many of these milestones didn’t employ ANNs until
    more recent times. In specific instances, such as checkers, there is debate as
    to whether an ANN could even match a rule-based approach, especially given that
    it is considered a ‘solved’ game. Our primary focus in this context is on ANNs
    and, consequently, on the types of challenges where ANNs excel, including natural
    language processing (NLP), image recognition and generation, and certain gaming
    scenarios. Nonetheless, AI encompasses a vast range of areas, many of which are
    crucial; however, not all will be discussed here.
  prefs: []
  type: TYPE_NORMAL
- en: '![A timeline from 1947 to 2023 that shows the advances of A I and gaming.](images/fig6_2_B.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '[Figure 6.2 AI and Gaming Timeline.](#R_fig6_2)'
  prefs: []
  type: TYPE_NORMAL
- en: As we embark on a journey through the rich history of Artificial Intelligence
    (AI), with a keen focus on ANNs, it is important to grasp the evolution of this
    field in stages. This journey not only simplifies our understanding but also provides
    a structured lens through which we can appreciate the milestones, challenges,
    and rapid innovations that AI has undergone. Thus, the history has been broken
    into three phases.
  prefs: []
  type: TYPE_NORMAL
- en: '**The Genesis Phase (1940s–1980s)**: This was the birth of AI. During this
    period, the foundational ideas were laid down. Think of these as the foundational
    years of AI, where pioneers set the stage, developing the very first algorithms
    and concepts. Many of the ideas from this era served as the bedrock upon which
    later innovations were built. See [Figure 6.4](#fig6_4) for key milestones in
    the Genesis Phase.![A timeline from 1947 to 2023 that shows the advances of hardware
    and another timeline from 1947 to 2033 for A I periods.](images/fig6_3_B.jpg)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Figure 6.3 AI Periods and Hardware Advances.](#R_fig6_3)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![A timeline from 1947 to 1994 about the genesis phase and publications and
    models.](images/fig6_4_B.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: '[Figure 6.4 The Genesis Phase (1940s to1980s) – Publications and Models.](#R_fig6_4)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**The Maturing Phase (1980s–2010s)**: After its birth, AI went through a phase
    of growth and maturation. During this period, the foundational ideas from the
    genesis phase were refined, expanded, and implemented in various applications.
    The concepts became clearer, and the tools more sophisticated. It was a time of
    exploration, consolidation, and practical application. See [Figure 6.5](#fig6_5)
    for key milestones in the Maturing Phase.![A timeline from 1980 to 2010 about
    the maturing phase and publications and models.](images/fig6_5_B.jpg)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Figure 6.5 The Maturing Phase (1980s to 2010s) – Publications and Models.](#R_fig6_5)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**The Acceleration Phase (2010s–2030s)**: Entering the current era, we see
    an explosion in AI capabilities and applications. Thanks to advances in computational
    power, data availability, and refined algorithms, AI, especially ANNs, is now
    evolving at an unprecedented rate and we expect this to continue for some considerable
    time. This phase captures the whirlwind of innovation, and the transformative
    impact AI is having on nearly every facet of our lives. At the end of this phase,
    we expect that AI will have been integrated and adopted into society. It is not
    clear what that picture will look like, but the anticipation of this future drives
    current research and application efforts. For more on what the future may look
    like, we invite you to read [Chapter 7](ch7.xhtml) on some of our predictions.
    See [Figure 6.6](#fig6_6) for key milestones in the Acceleration Phase.![A timeline
    from 2010 to 2023 about the acceleration phase and publications and models.](images/fig6_6_B.jpg)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Figure 6.6 The Acceleration Phase (2010s to 2030s) – Publications and Models.](#R_fig6_6)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: By breaking down the history of AI and ANNs into these three distinct phases,
    readers will find it easier to digest the information, understand the context
    of current AI developments, and quickly reference the most recent and relevant
    advancements that shape our daily interactions with technology.
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 6.3](#fig6_3) helps depict these phases and how they relate to commonly
    referred to periods in AI history such as the AI winters and AI boom periods.
    It also highlights some of the key hardware advancements that have facilitated
    progress in the field. These phases will be discussed in the respective sections
    below.'
  prefs: []
  type: TYPE_NORMAL
- en: As we delve deeper into each phase, we will uncover the stories, the challenges,
    the breakthroughs, and the visionaries that have made AI the formidable force
    it is today.
  prefs: []
  type: TYPE_NORMAL
- en: 6.2.1 The Genesis Phase (1940s–1980s)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 6.2.1.1 New Fields of Study
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In the earliest days of AI, there was a desire to build machines that could
    solve problems by learning, similar to how the brain works. This approach was
    fundamentally different from explicitly programming a machine to solve a specific
    problem. To build these machines, scientists studied animal brains to understand
    their biological models. This can be seen in the work by [McCulloch and Pitts
    (1943)](#ref6_42) on modelling a neuron, and in the work by [Hebb (1949)](#ref6_24)
    on Hebbian Learning. These works, along with contributions from others in the
    fields of neurophysiology and psychology, were used by those in the fields of
    Mathematics, Statistical Theory, Information Science, and Computer Science (both
    Information Science and Computer Science were in their infancy at this point).
  prefs: []
  type: TYPE_NORMAL
- en: Given the availability of these biological models and the extensive research
    conducted in these areas, it might have seemed reasonable to anticipate swift
    solutions to problems that explicit programming struggled with, such as pattern
    recognition, reasoning, and the understanding and use of language.
  prefs: []
  type: TYPE_NORMAL
- en: 6.2.1.2 The Symbolists
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'In 1955, McCarthy, along with Marvin Minsky, Nathaniel Rochester, and Claude
    Shannon, penned a proposal for a workshop to be held at Dartmouth College in the
    summer of 1956\. The primary objective of this workshop was as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: An attempt will be made to find how to make machines use language, form abstractions,
    and concepts, solve kinds of problems now reserved for humans, and improve themselves.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ([McCarthy et al., 1955](#ref6_40), p. 1)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: This workshop is widely regarded as the birth of AI as a formal academic discipline.
    The Dartmouth workshop was the first occasion where the term “artificial intelligence”
    was used, a term coined by McCarthy himself.
  prefs: []
  type: TYPE_NORMAL
- en: The optimism of the Dartmouth attendees was high. They genuinely believed that
    with a dedicated effort over the summer, they could make significant inroads into
    achieving machine intelligence. This is partly a reflection of the overall optimism
    about technology and computing that pervaded the 1950s. They thought that the
    available computational capacity should be sufficient for their tasks. Their main
    challenge, as they saw it, was the need to develop appropriate algorithms and
    program instructions to guide the machines.
  prefs: []
  type: TYPE_NORMAL
- en: The group was heavily influenced by what later became known as the “Symbolist”
    school of AI. As mentioned, Symbolists believed that intelligence arises from
    the manipulation of symbols and that it can be achieved through rule-based systems
    and formal reasoning. This was in stark contrast to other paradigms, such as the
    Connectionist approach that sought to replicate neural networks and the evolutionary
    approach that took inspiration from Darwinian processes.
  prefs: []
  type: TYPE_NORMAL
- en: This Symbolist approach is reflected in early AI projects like the Logic Theorist
    and General Problem Solver, which aimed to simulate human problem-solving capabilities
    through symbolic manipulations.
  prefs: []
  type: TYPE_NORMAL
- en: In hindsight, while the Dartmouth workshop didn’t achieve its lofty goals within
    a single summer, it marked the beginning of a new and transformative field. The
    event catalysed research and set the direction for AI for many years. Even though
    we now recognise the challenges in achieving human-like AI are more complex than
    McCarthy and his colleagues initially imagined, their vision, ambition, and foundational
    work laid the groundwork for the field of AI.
  prefs: []
  type: TYPE_NORMAL
- en: 6.2.1.3 The Connectionists
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Connectionists of AI, often associated with the development and study of Artificial
    Neural Networks (ANNs), take inspiration from the human brain’s intricate web
    of neurons to design computational models. These models aim to emulate the brain’s
    ability to recognise patterns, process information, and learn from experiences.
    Unlike traditional symbolic AI, which relies on explicit rules to make decisions,
    Connectionism adopts a bottom-up approach. By adjusting the connections (or weights)
    between a myriad of simple processing nodes (akin to neurons), Connectionists
    believe that complex cognition can emerge organically. Since their inception,
    ANNs and the Connectionist paradigm have faced waves of both enthusiasm and skepticism.
    However, with advancements in computational power and algorithmic techniques in
    recent decades, Connectionism has become central to many of AI’s most groundbreaking
    achievements, particularly in deep learning and areas such as image and speech
    recognition.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the early days of Artificial Intelligence, there was a promising glimmer
    on the horizon, a belief that ‘neuron nets’ might just hold the answer to some
    of AI’s most perplexing questions. Among these was the intriguing query, “How
    can a set of hypothetical neurons be arranged to form concepts?” Scholars like
    Uttley, Rashevsky and his ensemble, the duo Farley and Clark, and pioneers like
    Pitts, McCulloch, Minsky, Rochester, and Holland, were all engrossed in deciphering
    this enigma. Despite their vast and varied contributions, the consensus remained:
    the field desperately needed more theoretical depth ([McCarthy et al., 1955](#ref6_40)).'
  prefs: []
  type: TYPE_NORMAL
- en: 'The legacy of artificial neural networks (ANNs) is deeply intertwined with
    AI’s history. These networks, which might seem contemporary, have been the bedrock
    of AI research since its inception. The landmark Dartmouth summer project was
    indeed a milestone, but even before this event, McCulloch and his colleagues had
    ventured into the neural realms. Their 1943 publication, ‘A logical calculus of
    the ideas immanent in nervous activity’ ([McCulloch et al., 1943](#ref6_42)),
    presented an avant-garde notion: neurons could be emulated using simplistic switches,
    which when networked in unique arrangements, could replicate the logic of a Turing
    machine.'
  prefs: []
  type: TYPE_NORMAL
- en: However, it wasn’t until 1958 that the perceptron, a term now synonymous with
    AI, was born. In 1958, Frank Rosenblatt wrote about it in his paper ([Rosenblatt,
    1958](#ref6_58)). Think of it like a mini-brain with different parts working together,
    similar to modern ANNs. This mini-brain had different types of units, known as
    S-units, A-units, and R-units, which formed a basic two-layer network. Though
    at the time, people saw it as a ‘three-layered network’. Rosenblatt called it
    ‘photoperceptron’, and it was designed to recognise objects in photos, like circles
    and rectangles ([Rosenblatt, 1957](#ref6_57)).
  prefs: []
  type: TYPE_NORMAL
- en: The 1960s saw the perceptron’s blueprint being taken and expanded upon. Widrow
    and Hoff birthed ADALINE ([Widrow, 1960](#ref6_81)) and MADALINE ([Widrow, 1962](#ref6_82)),
    employing novel algorithms to fine-tune weights and biases, laying the foundation
    for modern feed forward networks. Block and team ([Block et al., 1962](#ref6_8))
    added a layer to the perceptron model, propelling it into the realm of deep neural
    networks. Their model aimed for more extensive image classification, however,
    training this improved network was tough because there weren’t yet good methods
    to correct errors in multi-layer networks.
  prefs: []
  type: TYPE_NORMAL
- en: 'In 1969, however, a cautionary tale emerged. Minsky and others published “Perceptrons:
    An introduction to computational geometry” ([Minsky & Papert, 1988](#ref6_45)),
    highlighting the perceptron’s mathematical limitations. The book particularly
    scrutinised the single-layer perceptron and expressed skepticism about its potential
    in resolving intricate challenges.'
  prefs: []
  type: TYPE_NORMAL
- en: In 1985, Rumelhart and his team introduced a new technique that helped teach
    multi-layered machines. This method, which corrected mistakes as it learned, opened
    the door for what we call deep learning. Still, we didn’t have the powerful computers
    needed to fully use this new technique. It is worth noting that Paul Werbos’ earlier
    doctoral dissertation ([Werbos, 1974](#ref6_80)) had pre-empted Rumelhart’s work,
    laying the groundwork for backpropagation.
  prefs: []
  type: TYPE_NORMAL
- en: Intriguingly, Minsky and Papert, in an extended edition of their earlier book
    ([Minsky & Papert, 1988](#ref6_45)), critically reviewed advances like those made
    by Rumelhart and McClelland. Despite acknowledging progress, they felt the claims,
    especially those surrounding the efficiency of gradient descent and the generalised
    delta rule, were overstated. The debates and differences of opinion serve as reminders
    of the cautious notes sounded by thinkers like Weizenbaum in the 1970s (see the
    next section on philosophical concerns), warning against getting too excited too
    soon.
  prefs: []
  type: TYPE_NORMAL
- en: Over time, even with advances like this new teaching method, backpropagation,
    the big hopes for ANNs started to fade. This led to periods known as ‘AI winters’
    where people lost interest and didn’t invest much in AI. But, as always, after
    a cold period of winter, things tend to warm up again in spring.
  prefs: []
  type: TYPE_NORMAL
- en: 6.2.1.4 Philosophical and Ethical Considerations
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 6.2.1.4.1 The Turing Test – Alan Turing
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Philosophical questions concerning the ability of machines to think emerged
    in these early days. In 1950, Alan Turing addressed this in his paper, “Computing
    Machinery and Intelligence” ([Turing, 1950](#ref6_73)). Instead of directly asking
    “can machines think?”, Turing proposed an alternative method. He suggested a game,
    which he named “The Imitation Game”. This game measured the likelihood of a machine
    deceiving an interrogator against the probability of a real person doing the same,
    relying solely on written communications in a question-and-answer format. This
    challenge subsequently became renowned as the Turing test.
  prefs: []
  type: TYPE_NORMAL
- en: 6.2.1.4.2 Three Laws of Robotics – Isaac Asimov
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: In a related development around the ethical considerations regarding machine
    intelligence, Isaac Asimov – a science fiction writer and professor of biochemistry
    – developed the “Three Laws of Robotics” in 1942\. These were featured in his
    short story “Runaround”, which formed part of the “I, Robot” series ([Asimov,
    1950](#ref6_4)), as mentioned in [Chapter 5](ch5.xhtml).
  prefs: []
  type: TYPE_NORMAL
- en: A robot may not injure a human being, or, through inaction, allow a human being
    to come to harm.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A robot must obey the orders given it by human beings except where such orders
    would conflict with the First Law.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A robot must protect its own existence as long as such protection does not conflict
    with the First or Second Laws.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 6.2.1.4.3 Computer Power and Human Reason – Joseph Weizenbaum
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Joseph Weizenbaum, the creator of the ELIZA chatbot and author of *Computer
    Power and Human Reason: From Judgment to Calculation* ([1976](#ref6_78)), grew
    increasingly wary of the expanding influence of computer technology. He argued
    that machines shouldn’t handle tasks needing genuine compassion, emphasising their
    inability to exercise human judgement and distinguishing between mere decision-making
    and genuine choice.'
  prefs: []
  type: TYPE_NORMAL
- en: During the 1970s, skepticism about computers replicating human thought was prevalent.
    Many felt that the AI community had made overly ambitious promises. In his book,
    Weizenbaum delved into the overhyped expectations of AI and the unsettling emotional
    bonds people formed with AI systems. He also expressed concerns about society’s
    growing dependency on technology. As we will see, these ambitious claims would
    continue to be a major topic of debate in the AI world.
  prefs: []
  type: TYPE_NORMAL
- en: 6.2.1.4.4 Father of Cybernetics – Norbert Wiener
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Furthermore, Norbert Wiener, often referred to as the “father of cybernetics”,
    expressed concerns about the potential for automation to lead to unintended consequences
    in his work “God & Golem, Inc.: A Comment on Certain Points where Cybernetics
    Impinges on Religion” ([Wiener, 1966](#ref6_83)) He posited that once we can effectively
    replicate human decision-making processes, extreme caution is imperative in managing
    these innovations. To illustrate, he drew upon the tale of ‘The Monkey’s Paw’,
    highlighting how wielding power without full comprehension could result in catastrophic
    outcomes.'
  prefs: []
  type: TYPE_NORMAL
- en: From the 1940s to the 1980s, the field of AI embarked on an exhilarating journey,
    laying the bedrock upon which future innovations would thrive. The essence of
    ANNs drew inspiration from the intricate webs of neurons in our brains, thanks
    to the pioneering work of individuals like McCulloch and Pitts. As the decades
    progressed, this biological inspiration was interwoven with a fabric of mathematical
    and statistical rigour, establishing proofs and formulas that defined how artificial
    neurons would interact and collaborate within networks. By the 1980s, this foundational
    work bore fruit in the form of breakthrough learning techniques like backpropagation
    and gradient descent. These mechanisms optimised the training of ANNs, equipping
    them with the capability to refine their performance and solve complex problems.
    Alongside these technical advancements, the era was also marked by deep philosophical
    introspection, questioning the boundaries of AI, its relation to consciousness,
    and the ethics surrounding its potential. By the close of the 1980s, the AI landscape
    had been primed with the necessary fundamentals, ready for the transformations
    that would follow including the concept of the quantum computer such as those
    discussed by Richard Feynman ([Feynman, 1982](#ref6_17)) that are perhaps a still
    long way off from delivering their benefits to AI.
  prefs: []
  type: TYPE_NORMAL
- en: 6.2.2 The Maturing Phase (1980s to 2010s)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the span between the 1980s and 2010s, ANNs experienced both challenges and
    pivotal advancements. Initial enthusiasm for ANNs had diminished due to persistent
    issues like the vanishing gradient problem, but the 1980s brought about key innovations
    that would later be instrumental for the field’s revival.
  prefs: []
  type: TYPE_NORMAL
- en: The introduction of the backpropagation algorithm by Rumelhart, Hinton, and
    Williams in 1986 was a seminal moment (Rumelhart et al., [1986a](#ref6_61), [1986b](#ref6_62),
    [1986c](#ref6_63)). This algorithm optimised the weights in multi-layer perceptrons,
    sparking renewed interest and research in ANNs. Following this, the torchbearers
    of the field, namely LeCun, Bengio, and Hinton, made significant contributions.
    Their efforts during this phase laid the foundation for deep learning and the
    transformative changes of the next era ([Goodfellow et al., 2016](#ref6_22)).
  prefs: []
  type: TYPE_NORMAL
- en: In the 1990s, there were important developments in using neural networks. Researchers
    found ways to use them for complex data analysis ([Breiman, 2001](#ref6_9)), to
    simplify data by reducing its complexity ([Hinton et al., 2006](#ref6_27)), and
    to improve algorithms for better performance ([Friedman, 2002](#ref6_18)). They
    also developed new techniques for training and managing neural networks, like
    energy-based models ([Ackley et al., 1985](#ref6_1)), and introduced new types
    of neural cells, such as long short-term memory (LSTM), to solve problems with
    gradients ([Hochreiter & Schmidhuber, 1997](#ref6_28)). Additionally, researchers
    gained a better understanding of Support Vector Machines (SVM) and kernel methods,
    which improved the creation of robust predictive models ([Wahba et al., 2002](#ref6_75)).
    With innovations like LeCun’s convolutional neural networks (CNNs) for image recognition
    ([LeCun et al., 1989](#ref6_37)) and the advent of recurrent neural networks (RNNs)
    for sequential data ([Hochreiter & Schmidhuber, 1997](#ref6_28)), the vast potential
    of ANNs was increasingly realised.
  prefs: []
  type: TYPE_NORMAL
- en: However, the full potential of deep ANNs was hampered by computational restraints
    and the scarcity of comprehensive labelled datasets. Despite these hurdles, the
    maturing phase was crucial in embedding the importance of ANNs and setting the
    groundwork for the momentous progress of the acceleration phase that would follow.
  prefs: []
  type: TYPE_NORMAL
- en: 6.2.3 The Acceleration Phase (2010s to 2030s)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The early 2010s marked a monumental shift for ANNs with developments powered
    by larger datasets, increased computational capabilities - particularly from GPUs,
    and innovative algorithms. One notable paper in this regard was “Building High-level
    Features Using Large Scale Unsupervised Learning” by Le et al., which showcased
    the strength of refined algorithms in propelling ANNs’ capabilities ([Le et al.,
    2011](#ref6_36)).
  prefs: []
  type: TYPE_NORMAL
- en: The subfield of deep learning, an advanced application of ANNs, took centre
    stage during this period. Esteemed figures like Geoffrey Hinton, Yann LeCun, and
    Yoshua Bengio were instrumental in these evolutions ([Goodfellow et al., 2016](#ref6_22)).
    A groundbreaking moment occurred with the creation of AlexNet, a convolutional
    neural network (CNN) designed by Alex Krizhevsky under Geoffrey Hinton’s guidance.
    In 2012, AlexNet achieved unmatched performance in the ImageNet competition, a
    benchmark in image recognition, marking what many called the “ImageNet moment”
    ([Krizhevsky et al., 2012](#ref6_33)).
  prefs: []
  type: TYPE_NORMAL
- en: Such triumphs galvanised the broader tech industry. Companies like Google and
    Facebook not only adopted but also significantly contributed to ANN research.
    For instance, Google’s approach to recommendation systems was articulated in “Wide
    & Deep Learning for Recommender Systems” ([Cheng et al., 2016](#ref6_12)), while
    Facebook advanced text understanding and user modelling through ANNs, as evidenced
    by their studies ([Joulin et al., 2016](#ref6_31); [Kaur et al., 2021](#ref6_32)).
  prefs: []
  type: TYPE_NORMAL
- en: As the decade progressed, ANNs’ applications diversified. Recurrent neural networks
    (RNNs), and particularly their evolved form, long short-term memory networks (LSTMs),
    became the go-to for handling sequential data, finding applications in natural
    language processing and time-series analysis ([Hochreiter et al., 1997](#ref6_28)).
    In parallel, generative adversarial networks (GANs), introduced by Ian Goodfellow,
    transformed generative models, enabling feats like image synthesis and style transfer
    ([Goodfellow et al., 2014](#ref6_23)).
  prefs: []
  type: TYPE_NORMAL
- en: By the late 2010s, the introduction of transformer architectures, like the one
    described in the “Attention Is All You Need” paper, signalled another paradigm
    shift, especially in NLP. This paper served as a bedrock for models such as BERT
    and GPT variants, including OpenAI’s ChatGPT-3.5 and GPT 4.0, redefining text
    comprehension and generation ([Vaswani et al., 2017](#ref6_74)).
  prefs: []
  type: TYPE_NORMAL
- en: With the dawn of the 2020s, the drive behind ANNs only intensified. Breakthroughs
    in areas like few-shot learning and self-supervised learning signalled the continuous
    advancement of the field. Yet, as AI capabilities surged, so did ethical and societal
    concerns. These concerns were highlighted in March 2023 open letter from the Future
    of Life Institute, urging a pause on the development of models more advanced than
    GPT-4, underlining the need for a more reflective approach to AI’s rapid advancement
    (Future of Life Institute, [2023a](#ref6_19), [2023b](#ref6_20)).
  prefs: []
  type: TYPE_NORMAL
- en: While the path towards artificial general intelligence (AGI) or even artificial
    super intelligence (ASI) remains debated, what is unequivocal is the transformative
    role of AI will have on society and humanity. In addition, this transformative
    role is likely to be further compounded by future advancements. Echoing Richard
    Feynman’s proposition, quantum computers might surpass classical computers in
    simulating complex systems ([Feynman, 1982](#ref6_17)), potentially steering AI
    into its next epoch. Indeed, milestones like achieving quantum supremacy, where
    quantum devices outpace their classical counterparts, hint at a future where the
    bounds of AI’s potential could be redefined ([Arute et al., 2019](#ref6_3)).
  prefs: []
  type: TYPE_NORMAL
- en: 6.3 Creating a Model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now that we have covered the history of ANNs in some detail, we will turn our
    attention to the process of creating a GenAI model. This discussion will focus
    on recent approaches and will delve deeper into the terminology and advances previously
    outlined in the historical overview. As we delve into the creation and comprehension
    of models, you will recognise some of the key people and advances mentioned in
    the earlier history section.
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 6.7](#fig6_7) illustrates the essential steps in creating a model.
    This process encompasses both the training and the testing of a foundational model,
    followed by its fine-tuning. A foundational model is an initial, untrained model
    with a generic purpose (i.e.) to learn from data. Many foundational models undergo
    fine-tuning for specific applications. For instance, the LLaMA-2 (Large Language
    Model Meta AI) foundational model was fine-tuned for chat functionality, resulting
    in the finely-tuned model known as LLaMA-2-chat. This fine-tuning involves further
    training of the foundational model on specific data to serve a more specialised
    purpose, such as functioning as a chatbot to answer user queries or engage in
    conversations with users.'
  prefs: []
  type: TYPE_NORMAL
- en: '![A model which shows the larger picture about creating a model.](images/fig6_7_B.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '[Figure 6.7 Creating a Model – The Big Picture.](#R_fig6_7)'
  prefs: []
  type: TYPE_NORMAL
- en: 'The steps involved in creating a model are:'
  prefs: []
  type: TYPE_NORMAL
- en: The Training Data
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Data Gathering and Preparation
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Dataset Customisation
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: The Foundation Model
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Model Design and Structuring
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Model Training
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Model Testing
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: The Fine-Tuning
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Fine-Tuning Data Set Customisation
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Model Fine-Tuning Training
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Model Testing
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: The Deployment and Use
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Model Deployment
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Model Monitoring
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Model Use (aka inference)
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Fine-tuning can employ a variety of training techniques, including reinforcement
    learning with human feedback (RLHF), which will be discussed below. The following
    sections will cover each of these areas to provide an understanding of what is
    involved.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.1 The Training Data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The initial step in the comprehensive model creation process is data gathering
    and preparation. Modern deep neural networks (DNNs), especially large language
    models (LLMs), require vast amounts of training data. While several well-known
    data sources are available, some companies maintain their own unique repositories.
    Prominent entities such as Meta, Google, and Microsoft possess vast amounts of
    data, owing to the diverse services they offer. Meanwhile, companies like OpenAI
    have ventured into developing their own data-sourcing solutions, such as the web
    crawling tool, GPTbot, which gathers publicly accessible data from the web for
    OpenAI.
  prefs: []
  type: TYPE_NORMAL
- en: After the initial acquisition, the dataset might be further refined to improve
    quality or to better align with the desired outcomes of a particular model. The
    processes of gathering and preparation often intertwine with dataset customisation,
    especially when an organisation sources its data directly, rather than relying
    on externally provided datasets.
  prefs: []
  type: TYPE_NORMAL
- en: It is crucial to acknowledge the complexity and sophistication inherent in the
    data gathering, preparation, and customisation phases. To provide a clearer understanding
    of these processes, they will be explored in more depth using several widely utilised
    data sources as examples.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.1.1 Text Data – Common Crawl
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Common Crawl (see [https://commoncrawl.org/](https://commoncrawl.org)) ([Patel,
    2020](#ref6_49)) is an organisation that offers data dumps from billions of web
    pages on a regular basis, typically 6 to 12 times per year. While it has some
    data from as far back as 2008, there have been more consistent outputs since 2011\.
    Common Crawl employs a tool known as a spider bot to access the content of web
    pages. A spider bot starts with a list of URLs and retrieves the content of these
    web pages. Additionally, it can identify other URLs within a web page (i.e., links
    to different sites) and pursue these links to access those pages. For each page
    accessed, the spider bot saves the content and recognises other links to pursue,
    expanding outwards much like a spider’s web to encompass other URLs.
  prefs: []
  type: TYPE_NORMAL
- en: The CCBot, commonly referred to as the Common Crawl spider bot, processes a
    candidate database of URLs for each iteration. It updates this database with new
    URLs based on its findings during the crawl. While the set of URLs is expansive,
    they are not rigorously reviewed, organised, or managed. As a result, the quality
    of the data obtained can vary significantly, encompassing content in multiple
    languages. Surprisingly, there is a minimal overlap between the outputs of one
    crawl and the next. For instance, the overlap between the data dumps from February
    2023 and June 2023 is only around 1% (see [https://commoncrawl.github.io/cc-crawl-statistics/plots/crawloverlap](https://commoncrawl.github.io)).
  prefs: []
  type: TYPE_NORMAL
- en: The volume of data provided in each release is indeed staggering. For example,
    the June 2023 release (CC-MAIN-2023-23) comprises 100 segments. Each segment contains
    800 files for WARC (approximately 1.1 GB compressed), WAT (around 285 MB compressed),
    and WET (roughly 115 MB compressed) formats. Including various metadata, the total
    size of the June 2023 release is about 120 TB when compressed. The compression
    ratio for text data is favourable, ranging from 3 to 5 times, which results in
    an uncompressed size of approximately 580 TB. However, not all users will need
    every format. Some might focus only on the WET format (plaintext), which alone
    amounts to about 26 TB when uncompressed.
  prefs: []
  type: TYPE_NORMAL
- en: 'The output from Common Crawl varies in both content and quality. When training
    a large language model (LLM), this data undergoes further processing and cleaning
    to enhance its quality. Specialised tools, such as CCNet ([Wenzek et al., 2019](#ref6_79)),
    have been designed to help with this, especially when dealing with outputs like
    those from Common Crawl. For instance, these tools can restructure the files,
    decompress them, and divide them into shards. Each web page entry is then housed
    in a specifically formatted ‘json’ file. Data deduplication occurs at the paragraph
    level, and language detection is performed, enabling the sorting of different
    languages into separate datasets. Some of these steps are complex. Take the language
    detection feature as an example: it uses another language model, fastText ([https://fasttext.cc/](https://fasttext.cc)),
    which is pre-trained on alternative data sources like Wikipedia, Tatoeba, and
    SETimes, to identify the language of the Common Crawl output. [Figure 6.8](#fig6_8)
    showcases the intricacy of the data gathering and post-processing stages.'
  prefs: []
  type: TYPE_NORMAL
- en: '![A flowchart like diagram that shows the processes in the data gathering and
    customisation pipeline.](images/fig6_8_B.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '[Figure 6.8 Data Gathering and Customisation Pipeline.](#R_fig6_8)'
  prefs: []
  type: TYPE_NORMAL
- en: It does not end there; further processing by other models is also possible.
    For instance, data quality can be assessed, and, based on the quality score, specific
    data can either be retained or removed from the dataset. One model employed in
    this manner is the 5-gram Kneser-Ney model, which utilises a perplexity measure
    to compare the input from Common Crawl with another source deemed of higher quality,
    such as Wikipedia.
  prefs: []
  type: TYPE_NORMAL
- en: The perplexity is a measure of the predictability of the text within a specific
    paragraph. The higher the perplexity, the more surprised (or perplexed) the model
    becomes, suggesting a lower quality in this data customisation pipeline. If the
    perplexity surpasses a certain threshold for a given paragraph, that paragraph
    may be removed from the dataset with the aim of enhancing the overall quality
    of the dataset. You may recall that Perplexity is also used for GenAI text detection
    in [Section 4.7](ch4.xhtml#sec4_7).
  prefs: []
  type: TYPE_NORMAL
- en: Given the vast volume of data involved, the necessity to execute complex tasks
    like these pre-processing models, and the fact that the customisation processes
    operate on specialised data processing environments requiring significant expertise
    to build and manage, the cost of undertaking this task is considerable.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.1.2 Text Data – Colossal Clean Crawled Corpus (C4)
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The Colossal Clean Crawled Corpus (C4) dataset is derived from dumps provided
    by Common Crawl ([Raffel et al., 2023](#ref6_54)). This dataset undergoes various
    filtering and formatting processes to produce a version compatible with models
    developed using the TensorFlow runtime. TensorFlow is an important widely used
    tool for those building and training models. The filtering process includes tasks
    such as deduplication and the removal of sensitive words.
  prefs: []
  type: TYPE_NORMAL
- en: Initially, Google created the C4 data set for their own use. While they provided
    a description and some tools to generate the dataset from the Common Crawl inputs,
    they did not release the actual dataset. Recognising the value of this dataset,
    another organisation, the Allen Institute for AI (see [https://allenai.org/](https://allenai.org);
    founded by the late Paul G. Allen, co-founder of Microsoft), reproduced the C4
    dataset. They collaborated with a company called Hugging Face (see [https://huggingface.co/](https://huggingface.co))
    to host and make this dataset accessible to all.
  prefs: []
  type: TYPE_NORMAL
- en: Recreating the C4 dataset is not only costly (with expenses estimated between
    US$100s and US$1,000s in compute costs) but also requires significant expertise
    and knowledge.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.1.3 Image Data – LAION-5B
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The LAION-5B image dataset (see [https://laion.ai/blog/laion-5b/](https://laion.ai))
    ([Schuhmann et al., 2022](#ref6_67)) is a contemporary dataset designed for state-of-the-art
    (SOTA) model training. Its primary objective is to provide an open and readily
    accessible dataset for text-to-image model training. The dataset comprises 5.85
    billion filtered image-text pairs, of which 2.32 billion are in the English language.
  prefs: []
  type: TYPE_NORMAL
- en: 'The foundation for this dataset was the Common Crawl, from which image URLs
    were extracted and subsequently filtered using an existing OpenAI CLIP (Contrastive
    Language-Image Pre-Training) model ([Radford et al., 2021](#ref6_50)). This process
    resulted in a dataset comprising: a) 2.32 billion English image-text examples,
    b) 2.26 billion multilingual examples, and c) 1.27 billion examples not tied to
    any specific language (e.g., pertaining to places, products, etc.). Notably, this
    dataset is considerably more extensive than other comparable datasets. By making
    it publicly accessible, it promotes greater transparency, especially concerning
    the ethical considerations linked to large datasets of publicly sourced images.'
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.1.4 Image Data – LabelMe
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The primary objective of the LabelMe dataset (see [http://labelme.csail.mit.edu/](http://labelme.csail.mit.edu))
    ([Russell et al., 2007](#ref6_64); [Oliva, 2001](#ref6_47)) is to offer an online
    annotation tool to construct image datasets for computer vision research. Users
    could register for an account, contribute annotations, and subsequently access
    the datasets for their research. This approach facilitated the accumulation of
    a substantial collection of images and annotations. Importantly, these annotations
    were not mere labels; users could pinpoint and specify individual objects within
    an image. Thus, elements such as a car in the background, a person in the foreground,
    buildings, roads, and any other visible component in the image could be distinctly
    annotated.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.1.5 Other Sources
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Other frequently utilised sources include data dumps from GitHub, which contain
    open-source software implementations in numerous programming languages; dumps
    from Wikipedia, an online encyclopaedia; releases from Project Gutenberg, which
    hosts over 70,000 books no longer under copyright; and content from ‘The Pile’,
    an amalgamation of 22 smaller datasets that has recently stirred controversy due
    to issues related to copyrighted books.
  prefs: []
  type: TYPE_NORMAL
- en: Several other notable data sources exist. For instance, Tesla possesses an extensive
    database of driving-related videos, which it harnesses to train its autopilot
    system. ImageNet ([https://www.image-net.org/](https://www.image-net.org)) offers
    a vast collection of over one million images, each labelled with nouns corresponding
    to the content of the image; this resource has been pivotal in advancing computer
    vision and deep learning research. Another significant source is COCO (Common
    Objects in Context), which provides image data for training. CelebA serves as
    a repository of celebrity images, particularly useful for facial recognition tasks.
    Additionally, there are audio-focused datasets such as the MIDI dataset for music;
    the VCTK dataset for voice-related tasks; and the UCF101 dataset, designed for
    action recognition in videos.
  prefs: []
  type: TYPE_NORMAL
- en: Google offers a valuable tool for searching various types of datasets, accessible
    at [https://datasetsearch.research.google.com/](https://datasetsearch.research.google.com).
    Regardless of the specific dataset one requires, there are likely similar sets
    available, and this search tool aims to simplify the discovery process.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.1.6 Other Data Customisations
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Each of these datasets has its own approach to sourcing from the original, preparing
    the data dump, and then further processing to customise the dataset for the specific
    training task. These preparation and customisation steps may involve similar filtering
    as described above, but they can also encompass distinct types of filtering and
    content curation to achieve the specific aims.
  prefs: []
  type: TYPE_NORMAL
- en: A significant aspect of this customisation pertains to structuring the data
    in a way that is optimally suited for the specific model in question and the intended
    training strategy. The design and structure of the model, as well as the various
    training approaches, are elaborated upon in subsequent sections. Nevertheless,
    these factors play a crucial role in determining the necessary data preparation
    and customisation processes.
  prefs: []
  type: TYPE_NORMAL
- en: One common customisation involves ensuring that the size of the data inputs
    aligns with the model design. This will differ depending on the type of data the
    model handles, be it text-based input or image-based input. For language models,
    the typical input size comprises paragraphs that can be fed into the system as
    a single unit, usually amounting to about 512 tokens. Tokens are similar to words
    and we will discuss them more later. These inputs are either split or padded to
    ensure they fit the model. Subsequently, these inputs are often grouped into batches,
    possibly in sizes of 16, 32, or 64\. Such batches are generally processed independently
    during training, which facilitates parallel streams into the model. The collective
    set of all batches constitutes an epoch, and the model may undergo training across
    several iterations of these epochs to maximise the training benefits. Importantly,
    between each epoch iteration, the batches are typically shuffled to prevent the
    model from making unwarranted learning assumptions about the sequence.
  prefs: []
  type: TYPE_NORMAL
- en: One final consideration involves dividing the dataset into training and validation
    subsets. This step is crucial to ensure that the models are accurate and do not
    suffer from overtraining (or overfitting). Overfitting is where the model learns
    the training data very well but does poorly when tested with a dataset outside
    the training set. In short it does not generalise well. Typically, the dataset
    is divided into training and testing portions on a 70% to 30% basis, with the
    testing subset selected randomly to circumvent issues associated with alternative
    selection methods. The testing portion of a dataset is used to evaluate how well
    a machine learning model generalises to new, unseen data. While the training data
    are used to train the model, the testing data serves as an independent set of
    examples that the model has never seen during training. Many datasets come pre-divided
    into training, testing, and validation subsets. The validation subset (sometimes
    referred to as the development set) is generally included to facilitate the fine-tuning
    of specific models.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.2 Model Design and Structuring
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Clearly, the design and structuring of models is an intricate topic, necessitating
    deep experience and understanding of AI, deep neural networks, and the associated
    statistical and mathematical concepts.
  prefs: []
  type: TYPE_NORMAL
- en: Subsequent sections will explore key considerations surrounding model design
    and its nuanced details. As mentioned, the aim is to provide insights into the
    factors that influence a model and their inner workings. This will enable readers
    to delve deeper into specific topics or explore the statistical and mathematical
    concepts that underpin these design considerations which we do not explore in
    this book.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.2.1 Artificial Neurons – Weights, Bias, and Activations Functions
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Artificial neurons are simple structures with inputs and outputs. While there
    can be any number of inputs, the output is a singular value. Although the inputs
    can vary, they converge to produce this single output value. Neurons are often
    depicted as a basic circle, with the relevant inputs and outputs illustrated,
    as shown in [Figure 6.9](#fig6_9). This graphical representation is of a rudimentary
    type of neuron known as a feed-forward cell. To gain a deeper understanding of
    the neuron, one can delve into the internals of the cell, as shown in [Figure
    6.9](#fig6_9).
  prefs: []
  type: TYPE_NORMAL
- en: '![A diagram that provides exhaustive information regarding a feed forward cell.](images/fig6_9_B.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '[Figure 6.9 Feed-Forward Cell.](#R_fig6_9)'
  prefs: []
  type: TYPE_NORMAL
- en: 'This introduces a few important concepts:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Weights**. Each weight is just a number; there is one weight (number) for
    each input into the neuron. The value of this number changes as the model is trained.
    Once trained it is fixed.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Bias**. This is just a number and there is one for each neuron. The value
    of this number changes as the model is trained. Once trained it is fixed.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Activation function**. This is a special mathematical function that helps
    improve the usefulness of the output. There are many different types of activation
    functions. Some popular ones are sigmoid (used in older models such as Long Short-Term
    Memory Networks), Tanh (used in older models such as hidden layers of Sequence-to-Sequence
    models), ReLu (used in GPT3), and SwiGLU (used in LLaMA).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this instance, the input signal (denoted as x[i], which is a numerical value)
    is multiplied by the corresponding weight (w[i]) for that input. This multiplication
    is conducted for all inputs, and the resultant products are then summed (effectively
    yielding the sum of the products). Subsequently, the bias (b) is added, and the
    resultant figure is passed to the activation function. This activation function
    processes the given value, producing an output which is also a numerical value.
    If this neuron is connected to multiple other neurons, the same output value emanating
    from this neuron is transmitted to all interconnected neurons. Hence, the neuron
    can be conceptualised as a mathematical operation on a collection of input values
    to produce an output value, and that mathematical operation is informed by another
    set of values known as weights and the bias.
  prefs: []
  type: TYPE_NORMAL
- en: These weights and biases will be revisited in the context of model training.
    Collectively, they are referred to as the parameters of the model. This is the
    mechanism by which the model ‘remembers’ or stores information; these numerical
    values encapsulate the patterns that the model has discerned during its training
    phase and can subsequently be employed to make predictions. Often, models are
    benchmarked based on the number of parameters they possess, stemming from the
    assumption that a higher number of parameters equates to greater capabilities.
    However, several other factors influence the efficacy of a model beyond just the
    count of parameters. These include the quality of the training data utilised,
    the number of layers and their interconnections, as well as the internal functions
    deployed, such as the activation function or the sum of the products.
  prefs: []
  type: TYPE_NORMAL
- en: 'LLaMA-2 (Large Language Model Meta AI) from Meta AI is available in several
    size variants: 7B, 13B, and 70B, where ‘B’ stands for billion parameters. OpenAI’s
    ChatGPT-3.5 boasts 175B parameters. While the size of ChatGPT-4.0 has not been
    officially disclosed, it is speculated to comprise about 1.8T parameters, with
    ‘T’ representing trillion. Google’s LaMDA (Language Models for Dialog Applications)
    possesses up to 137B parameters. In contrast, Google’s PaLM-2 (Pathways Language
    Model) is reported to have around 340B parameters. Initially, Google’s BARD chatbot
    was based on LaMDA, but it was subsequently transitioned to PaLM-2 due to the
    latter’s superior reasoning capabilities. These sizes give some indication of
    the number of cells involved in a SOTA model.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 6.10](#fig6_10) illustrates a different type of artificial neuron known
    as a Recurrent Cell.'
  prefs: []
  type: TYPE_NORMAL
- en: '![A diagram that provides exhaustive and detailed information regarding a recurrent
    cell.](images/fig6_10_B.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '[Figure 6.10 Recurrent Cell.](#R_fig6_10)'
  prefs: []
  type: TYPE_NORMAL
- en: As [Figure 6.10](#fig6_10) illustrates, this structure closely resembles the
    feed-forward cell, with one notable exception, it incorporates internal feedback.
    In this arrangement, the output from the previous iteration (t-1) is reintroduced
    as an additional input in the current (t) input flow. This input (h[t-1]) is multiplied
    by its designated weight (w[h]) to contribute to the current output. In essence,
    this type of cell possesses memory of the previous output, which aids in computing
    the current output. These recurrent cells are a fundamental component of the recurrent
    neural network (RNN) models mentioned earlier.
  prefs: []
  type: TYPE_NORMAL
- en: There are many different possible types of cells, another one previously mentioned
    is the long short-term memory (LSTM) cell, but these two specific examples should
    give an idea of what is involved.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.3 Model Layers and Connections
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: These artificial neurons, also known as cells or nodes, can be connected together
    in layers. Neural networks in AI are composed of nodes organised in layers, with
    each node connected to others in the next layer. These connections are often referred
    to as synapses. [Figure 6.11](#fig6_11) illustrates some common structures of
    deep neural networks, typically comprising an input layer, an output layer, and
    multiple hidden layers in between.
  prefs: []
  type: TYPE_NORMAL
- en: '![A deep neural network with an input layer, three hidden layers, and an output
    layer.](images/fig6_11_B.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '[Figure 6.11 Deep Neural Network.](#R_fig6_11)'
  prefs: []
  type: TYPE_NORMAL
- en: The number of nodes in each layer can vary, and the connections don’t necessarily
    have to link to every node in the next layer, although this is a typical arrangement.
    For a network to be considered ‘deep’, it must contain at least three hidden layers.
    When counting the layers, both the hidden layers and the output layer are included.
    In the example provided, the deep neural network consists of four layers.
  prefs: []
  type: TYPE_NORMAL
- en: There is flexibility in the number of inputs and nodes in different layers.
    The following diagrams ([Figure 6.12](#fig6_12)) present various approaches.
  prefs: []
  type: TYPE_NORMAL
- en: '![Three different deep neural networks which shows the variations that are
    possible in deep neural networks.](images/fig6_12_B.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '[Figure 6.12 Deep Neural Network Variations.](#R_fig6_12)'
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 6.12](#fig6_12) provides a high-level overview of what a deep neural
    network looks like in an abstract manner.'
  prefs: []
  type: TYPE_NORMAL
- en: A significant aspect of designing and structuring a model involves choosing
    the type of cell to use; determining which cell types are suitable for specific
    layers; deciding the number of layers to include; and defining the number of nodes
    in each of the input, hidden, and output layers.
  prefs: []
  type: TYPE_NORMAL
- en: Certain model capabilities are tailored to the type of data being processed,
    such as text or images. These features will be discussed primarily in the context
    of the most common use cases, such as large language models (LLMs), text-to-image
    models, or multi-modal models (supporting input and output for multiple data types,
    including text, images, audio, video, etc.). For instance, a model might facilitate
    text input and generate text output, or it could generate image output based on
    user requests. Conversely, it could also accept image input and produce descriptive
    text as output.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.4 Key Model Capabilities
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The following sections examine key model capabilities designed for specific
    data types, whether text or images. This section will help you understand what
    actually happens to the input that is passed to the model and what the model does
    with that input both during training and during inference (normal user interaction
    post training).
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.4.1 Text – Tokenisation
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Before delving into specifics, it is essential to understand the nature of the
    inputs. In the context of an LLM, both the inputs and outputs consist of text.
    Let’s begin by examining this scenario.
  prefs: []
  type: TYPE_NORMAL
- en: There are several upstream processing steps required to transform the text,
    whether it is what you type or the training data, into the actual model input.
    The initial step in this process is known as tokenisation. Tokenisation involves
    breaking the text into tokens. For example, when using the GPT-3 tokeniser, the
    sentence ‘Can you provide a summary of the novel the count of monte cristo’ would
    be tokenised into the following tokens ([Figure 6.13](#fig6_13))
  prefs: []
  type: TYPE_NORMAL
- en: '![An example that shows how the following sentence is tokenised. Can you provide
    a summary of the novel the count of monte cristo.](images/fig6_13_B.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '[Figure 6.13 Tokenisation Example 1.](#R_fig6_13)'
  prefs: []
  type: TYPE_NORMAL
- en: 'As you can see in [Figure 6.13](#fig6_13), there are a few things to note:'
  prefs: []
  type: TYPE_NORMAL
- en: The spaces are included in the words (at the start of the words).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Words are mostly separated into different tokens.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Sometimes words can be split (e.g. ‘mon’ and ‘te’) into multiple tokens.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If you slightly change the string to ‘Can you provide a summary of the novel,
    ‘The Count of Monte Cristo,’ then the tokens for this tokeniser will be ([Figure
    6.14](#fig6_14)).
  prefs: []
  type: TYPE_NORMAL
- en: '![Another example of how the following sentence is tokenised. Can you provide
    a summary of the novel, ‘The Count of Monte Cristo.’](images/fig6_14_B.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '[Figure 6.14 Tokenisation Example 2.](#R_fig6_14)'
  prefs: []
  type: TYPE_NORMAL
- en: As you can see in [Figure 6.14](#fig6_14), the changes in punctuation and capitalisation
    have impacted the tokenisation process.
  prefs: []
  type: TYPE_NORMAL
- en: There is a limit to the size of the input that can be provided to the model,
    known as the context window. This limit restricts the number of tokens that can
    be passed to the model simultaneously. For example, in the LLaMA-2 model from
    Meta, the context window is 4096 tokens; while in ChatGPT-3.0, it is 2048 tokens.
    However, in ChatGPT-4, the context window is 32k tokens.
  prefs: []
  type: TYPE_NORMAL
- en: The tokenisation approach (which includes words, part words, letters, punctuation
    handling, etc.) is an important part of the model design and may require different
    strategies for different languages.
  prefs: []
  type: TYPE_NORMAL
- en: The context window size is important when you consider the approaches that the
    model uses for in-context learning (i.e., learning based on the inputs provided).
    There are a few approaches which can be used.
  prefs: []
  type: TYPE_NORMAL
- en: 'Zero-Shot learning: In this approach, only the prompt you type is provided
    as an input to the model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Few-Shot learning: In this approach, both multiple examples and the specific
    prompt you provide are sent to the model as inputs. The number of examples can
    range from 1 up to 32 examples.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the case of the few-shot learning, the examples can use up many tokens, leaving
    fewer tokens for the actual prompt being performed, thus in cases where few-shot
    learning is viewed as important, a larger context window is needed. Likewise,
    if the inputs themselves are large e.g. full text documents, larger context windows
    are needed.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.4.2 Text – Encoding
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: One purpose of tokenisation is to map the inputs to a known set of possible
    options. In the case of the English language and the tokenisation approach shown
    above, there are about 50,000 possible tokens based on the GPT-3 tokenisation
    design.
  prefs: []
  type: TYPE_NORMAL
- en: Picture these 50,000 possible tokenised values as the vertical columns in a
    matrix, and picture each of the actual input tokens from the prompt as the horizontal
    rows in that matrix. This would allow the inputs to be mapped to numbers (ones
    or zeros) like an encoding mechanism.
  prefs: []
  type: TYPE_NORMAL
- en: The matrix would contain a ‘1’ in the column corresponding to the position of
    each token in the input, and the ‘1’ would be in the appropriate row based on
    its position in the input text sequence. All other columns in that row would be
    ‘0’. This is demonstrated in [Figure 6.15](#fig6_15). If the number of input tokens
    is less than the context window, the remaining columns would be filled with ‘0’.
  prefs: []
  type: TYPE_NORMAL
- en: '![A sentence that has been tokenised and the related encoding matrix for the
    same.](images/fig6_15_B.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '[Figure 6.15 Encoding Matrix.](#R_fig6_15)'
  prefs: []
  type: TYPE_NORMAL
- en: This encoding approach allows the prompt to be passed as an input, which is
    a matrix of numbers, to the model. Since the model can only process numbers, this
    encoding is a critical part of the pre-processing required to use the model.
  prefs: []
  type: TYPE_NORMAL
- en: The order of the tokens is also significant. In addition to the token values
    in the matrix, the position of each token in the sequence is important and can
    be identified by the model from the input provided.
  prefs: []
  type: TYPE_NORMAL
- en: This approach of mapping categorical variables (tokens or words) to a simple
    matrix is one type of encoding called ‘one-hot encoding’. However, there are more
    sophisticated approaches available. This encoding represents a fixed, rule-based
    process. These decisions are integral to model design and structure.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.4.3 Text – Embedding
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Once the tokens are presented in a matrix format in the transformer architecture
    for LLMs, the next step is embedding. This is where the matrix input is mapped
    to a vector representation for each token and each token position.
  prefs: []
  type: TYPE_NORMAL
- en: The mapping of the token’s entry in the matrix to a vector is a learned representation.
    In other words, through training, the model learns how to position the vectors
    in this space so that the geometric relationships between them reflect the semantic
    relationships between the corresponding tokens. For example, it could happen that
    types of animals would be ‘near’ each other (have similar values for their vectors),
    or that words with similar meanings appear near each other.
  prefs: []
  type: TYPE_NORMAL
- en: Put in other words, embeddings in LLMs are numerical representations that capture
    the essence of words or phrases. Rather than treating words as isolated units,
    embeddings transform them into vectors in a high-dimensional space, where similar
    words are positioned closer together. This allows models to understand context
    and meaning, making text generation more coherent and contextually relevant. For
    example, think of embeddings as giving words a unique address in a city (the high-dimensional
    space). So, while the word “cat” might live at one address, the word “kitten”,
    being similar in meaning, would live nearby (in other words would have a similar
    numerical value). When the model needs to generate text, it uses these addresses
    (numerically similar values) to find words that fit best in the context, ensuring
    the sentences make sense.
  prefs: []
  type: TYPE_NORMAL
- en: If you don’t grasp the details of the embedding process, don’t worry. The key
    thing to remember is that this is a learned process; the embedding layer has weights
    and biases just like the other layers, and through the learning process, these
    weight and bias values are updated. This learning process is explained in more
    detail below.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.4.4 Text – Attention
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The paper ‘Attention is all you need’ ([Vaswani et al., 2017](#ref6_74)) emphasised
    the significance of attention in the design and structure of a model. The attention
    mechanism enables the model to identify long-range (distant) dependencies between
    words in a sentence or paragraph. This is analogous to how humans address this
    issue when listening to someone speak or reading text. We analyse what preceded
    the current context and relate it to what we are currently processing, attempting
    to form a coherent mental picture of the situation. A key component of this attention
    mechanism is the “attention head”.
  prefs: []
  type: TYPE_NORMAL
- en: 'The model is designed to calculate attention scores for each word in the input,
    be it a sentence or paragraph, in order to understand the relative importance
    of each word. Typically, there are multiple attention heads, and each head computes
    its own score. Similar to embeddings, these scores are learned from the weights
    associated with three parameters for each attention head: the so-called ‘query’,
    ‘key’, and ‘value’ parameters, often referred to as matrices W[q], W[k], and W[v].
    Different attention heads process the input in parallel, and the set of attention
    scores is then aggregated to create a new representation of that token. Having
    multiple attention heads allows the model to learn a more comprehensive set of
    relationships among tokens. For example, one head might learn to focus on syntactic
    relationships like subject–verb agreement, while another might learn to capture
    semantic relationships like synonymy.'
  prefs: []
  type: TYPE_NORMAL
- en: Consider the sentence ‘The cat sat on the mat.’ With a single attention head,
    it might concentrate on the relationship between ‘cat’ and ‘sat’, capturing the
    subject–verb relationship. However, when multiple attention heads are employed,
    another might focus on the relationship between ‘sat’ and ‘mat’, capturing the
    verb–object relationship, while yet another could emphasise the relationship between
    ‘on’ and ‘mat’, capturing the preposition–object relationship.
  prefs: []
  type: TYPE_NORMAL
- en: As mentioned, these scores and the focus of each attention head are learnt during
    the training process. The designer does not assign a specific head to a specific
    ability; this is entirely dynamic and learnt during training. It may seem somewhat
    amazing, perhaps unbelievable, that this happens, but it does. With millions of
    training examples, the model learns to specialise specific attention heads for
    specific purposes. This is an emergent feature of the model. The stochastic nature
    of the training process encourages diversity among the heads, so that different
    heads take on specific but different purposes.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.4.5 Text – Next Word Prediction Learning Goal
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We have seen that some layers in the model are focused on finding the relationships
    between words (embedding), and some are focused on understanding what the most
    important words of the input are (attention). The other layers in the model will
    be focused on predicting the next word in the text. If the input so far is ‘I
    went to the’, then the model is trying to predict what the next word is, and let’s
    say it predicts ‘market’, but the actual word is ‘school’, then it will adjust
    the weights and biases in the model to better predict this in the future. It will
    then try to predict the next word again in ‘I went to the school’, and it might
    predict ‘to’, and this is correct. Then it predicts ‘pick’, and this is correct,
    then it predicts ‘up’, and this is correct, and then it predicts ‘my’ which is
    correct again. Then the next word it predicts is ‘kids’ but the actual word is
    ‘books’. It again will update the weights and biases to try and better predict
    in the future. This gives the model the input ‘I went to the school to pick up
    my books’. As it learns it will also be updating the embeddings and attention
    layers to improve those too.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.4.6 Image – Pre-processing
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: This is where the input image is prepared and normalised or standardised for
    input into the model. The input image may be a JPEG or a GIF and needs to be converted
    to the standard format. This conversion includes not only changing the format
    but also adjusting other details such as the size of the image (width, height,
    and aspect ratio), the resolution of the image, and the colour space. Depending
    on the complexity, it may involve image rotation to ensure it is correctly oriented.
  prefs: []
  type: TYPE_NORMAL
- en: Part of the pre-processing involves tensor (matrix of vectors) conversion, which
    is similar to the encoding discussed for text models. In the case of an image,
    this process is somewhat easier because the image naturally has a binary representation
    of a set of pixels in height and width, with each pixel having values for colours,
    such as Red (R), Green (G), and Blue (B). Thus, conversion involves creating a
    tensor or matrix of vectors for these pixel coordinates and RGB values. This has
    also been covered in [Section 1.8](ch1.xhtml#sec1_8) [Figure 1.4](ch1.xhtml#fig1_4).
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.4.7 Image – Encoding
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Image encoding is similar to embedding for text-based models. However, instead
    of using embedding layers, which are employed in text models, image models typically
    use convolutional layers. These layers learn the relationships between the content
    of the image, aiding in the extraction of model features.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.4.8 Image – Diffusion Learning Goal
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The model is presented with an encoded image along with a text description of
    that image. Forward diffusion is the process where a model introduces noise into
    an image, gradually making the picture blurry by altering some of the pixels’
    colours. This noise is added incrementally until the image becomes unrecognisable,
    resembling a television screen when not tuned in. This is shown in [Section 1.8](ch1.xhtml#sec1_8)
    [Figure 1.6](ch1.xhtml#fig1_6).
  prefs: []
  type: TYPE_NORMAL
- en: Reverse diffusion, on the other hand, is the process in which a model removes
    noise from an image, gradually restoring it to its original, recognisable form.
  prefs: []
  type: TYPE_NORMAL
- en: These forward and reverse diffusion processes teach the model how to generate
    an image which it has a text description of by removing noise. When tasked with
    creating an image solely based on a text description, the model can utilise this
    learning to remove noise from an initial image with random noise, resulting in
    a completely new image that did not previously exist.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.4.9 Hyperparameters
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Hyperparameters are specific controls of a model that designers must choose
    and adjust during the design and training processes. Unlike model parameters,
    which are automatically adjusted by the model itself during learning, hyperparameters
    are only adjusted by the model’s designer.
  prefs: []
  type: TYPE_NORMAL
- en: These hyperparameters span a wide range of aspects of the model, including the
    learning rate, the batch size, the number of epochs, factors impacting the activation
    function used, the dropout rate, and more. During this phase, designers must determine
    the best values for these hyperparameters.
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes, hyperparameters are exposed to the end users of a model to help control
    a model’s behaviour. One such example is the ‘temperature’ hyperparameter, which
    controls how repeatable a prediction is. Lower values mean more randomness, while
    higher values mean less randomness and more consistency.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.5 Foundational Model Training
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Thus far, we have covered the big picture, how the data is gathered and prepared,
    and different aspects that go into the design and structuring of the model. In
    this section, we focus on foundational model training, commonly referred to as
    pre-training.
  prefs: []
  type: TYPE_NORMAL
- en: A foundational model is a model built and initially trained as a general-purpose
    model, and it is not a specialisation of another model. A fine-tuned model is
    a foundational model (or another fine-tuned model) that is specialised for a particular
    purpose.
  prefs: []
  type: TYPE_NORMAL
- en: The term ‘pre-trained’ or ‘pre-training’ refers to the training that occurs
    before the model becomes useful as a general-purpose foundational model.
  prefs: []
  type: TYPE_NORMAL
- en: When training a foundational model (also known as pre-training), there are different
    types of training that can occur, which impact the type of learning that takes
    place. The following sections delve into these different types of learning and
    the associated training processes.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.5.1 Supervised Learning
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Supervised learning occurs when the training data includes both the data and
    a label that allows the model to determine whether its prediction was correct
    or not. For instance, if the training data pertains to the sentiment of a given
    section of text, it will include a description of that sentiment associated with
    each section of text. When the model is being trained and makes a prediction about
    the text’s sentiment, it can then reference the provided label to assess the accuracy
    of its prediction. It will subsequently adjust the parameters in the model to
    enhance future predictions.
  prefs: []
  type: TYPE_NORMAL
- en: Another example is when the model deals with images containing animals. In this
    case, the training data consists of numerous pictures of animals, each accompanied
    by labels describing the type of animal depicted. The model can utilise this training
    data and labels to make predictions and refine its predictions.
  prefs: []
  type: TYPE_NORMAL
- en: Yet another example involves a model aiming to enhance the resolution of an
    image. In this scenario, the training data comprises a low-resolution image and
    a higher-resolution image of the same picture. The model can predict what the
    higher-resolution image might look like and use the provided higher resolution
    image to adjust its prediction for improvement.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.5.2 Self-Supervised Learning
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Self-supervised learning is a method in which the model uses unlabelled input
    to supervise its own learning. For instance, if the input is ‘I love AI’, and
    the model’s objective is to predict the next word, it can use ‘I xxxx’ to predict
    ‘I have’. It can then check if that prediction was correct based on the subsequent
    input, ‘I love’, and adjust its prediction for the future. This is the most common
    approach to learning for LLMs, as data from sources such as Common Crawl can be
    relatively easily used to create a self-supervised training set for models that
    predict the next word, like LLMs.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.5.3 Unsupervised Learning
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Unsupervised learning is a type of training where data is provided to the model
    without any specific knowledge about what is expected, without any ‘labels,’ or
    without using the self-supervised learning approach. This type of learning can
    be useful for specific scenarios, such as clustering, which involves identifying
    groups (clusters) of related items.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.5.4 Reinforcement Learning with Human Feedback (RLHF)
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Reinforcement Learning with Human Feedback (RLHF) is particularly beneficial
    in domains where the desired behaviour is difficult to specify, or where the model
    needs to learn nuanced or complex strategies. It has been applied in training
    models across various domains, including game playing (such as Go), dialog systems,
    and robotics.
  prefs: []
  type: TYPE_NORMAL
- en: One of the challenges associated with RLHF is that it can be time-consuming
    and expensive, as it requires ongoing involvement from human evaluators. Additionally,
    it may necessitate careful design to ensure that the feedback collected is informative
    and that biases in human judgments do not unduly influence the model’s behaviour.
  prefs: []
  type: TYPE_NORMAL
- en: The paradigm of RLHF serves as a bridge between traditional supervised learning,
    in which a model learns from a fixed dataset of labelled examples, and reinforcement
    learning, where a model learns by interacting with an environment to maximise
    a reward signal and thus strongly favour the human feedback option when learning.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.5.5 Learning
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: This section delves into the learning process in more detail. So far, learning
    has been discussed without a detailed explanation. It has been mentioned that
    the model makes predictions, such as next-word predictions in the case of LLMs,
    and then compares the predicted value to the expected value (via self-supervised,
    supervised, or reinforcement learning), and then adjusts the model as needed.
    It was also mentioned that the model’s parameters, which are the weights and biases,
    are the numbers that get adjusted during learning.
  prefs: []
  type: TYPE_NORMAL
- en: 'We understand that the model’s understanding of the world results from a combination
    of its structure (including embeddings, attention, and other layers) and the values
    of its parameters (the weights and biases). Initially, the weights are set to
    some value before training starts on the foundational model. Typically, this value
    is random, or sometimes zero. Then, the value is adjusted during training. We
    have already discussed that the training data is grouped into batches. Now, let’s
    explore how the learning process is closely linked to these batches and the significance
    of batch size. For each batch, the following processes occur:'
  prefs: []
  type: TYPE_NORMAL
- en: The forward pass. This is where the data from the batch is passed ‘forward’
    through the neural network. The model makes predictions one word or image at a
    time for each item in the batch. It keeps track of the prediction that it makes
    and the actual value.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The loss calculation. The loss calculation involves the model comparing its
    predicted value to the actual expected value. A loss function is used for this
    purpose. In LLMs, a common loss function is categorical cross-entropy, whereas
    image-generation models often use loss functions like generative adversarial loss.
    These loss functions quantify the difference between the actual and predicted
    values for each word or image. These quantified values for each input are then
    averaged across the entire batch, resulting in an average loss value available
    for the next step.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The backward pass, also known as backpropagation ([Werbos, 1974](#ref6_80),
    and [Rumelhart et al., 1985](#ref6_60)). Steps 1 and 2 occur for each item in
    the batch, and the loss calculation step maintains a running average loss across
    the entire batch. Backpropagation is then performed based on this average loss
    value. This involves computing the gradients of the loss with respect to each
    parameter in the model. Even though one sentence might have been predicted perfectly,
    errors in other sentences contribute to the gradients and guide the parameter
    updates. It is important to remember that the model consists of many layers, each
    with numerous cells or neurons, and each of these has multiple weights and a bias
    that may need adjustment. The calculated gradients, based on the average loss,
    assign the level of influence (sometimes called the blame or reward) to each weight
    and bias in the model for the errors between the predicted values and the actual
    values.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The adjustment. The adjustment of the weights and biases for each neuron in
    each layer. Now that the model has assigned a level of blame or reward to each
    of the parameters in the model, it can proceed to adjust them at the end of the
    batch.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'This is the essence of learning in a neural network: make a prediction, estimate
    an error, assign a level of blame or reward for the error to each parameter in
    the model, and adjust each parameter in the model. Over millions or billions of
    tokens, the model starts to have specialised and improved behaviours. The embedding
    layers learn, allowing associated words to be grouped in a manner that reflects
    their relationship; similar words will be close together, disparate words will
    be far apart. The attention layers learn, with each attention head specialising
    in a specific manner that allows more distant relationships between words to be
    formed, such as between subjects and actions. The other layers also contribute
    to the overall relationships between words, language concepts, and real-world
    concepts. From these different learnings and the patterns and relationships formed,
    the model gains what is like a type of ‘understanding’ of the world and how things
    relate. Much of this learning and understanding is emergent from the large set
    of data that the model was trained on and the structure of the model that allows
    different parts to focus on specific aspects. This is one of the reasons why it
    is so difficult for humans to understand how the models really work; there are
    typically billions of parameters, which can be trained on millions or billions,
    or even trillions of tokens, and humans are not good at understanding how such
    vast volumes of data and numbers interact to result in this emergent capability.'
  prefs: []
  type: TYPE_NORMAL
- en: It should be remembered that this understanding is purely related to the training
    data that has been provided. It lacks the kind of understanding that humans possess.
    Humans have an understanding of physical laws and draw from their experiences
    to assess a situation. They adjust their responses based on this understanding.
    Humans also have belief-based rules, which they use to adjust their responses
    and actions. However, something like an LLM only has the data it was trained on
    and does not have these other approaches to learning. Humans are adept at learning
    from a relatively small number of examples and gaining rich insights from this.
    AI models need vast quantities of data to start developing useful emergent behaviours.
  prefs: []
  type: TYPE_NORMAL
- en: While different, the learning process is somewhat like a child’s learning process;
    first receiving a broad education in kindergarten, primary, and secondary school,
    which is like pre-training of a foundational model; and then specialising the
    learning for a particular discipline or profession like Computer Science in university,
    which is like fine-tuning that we discuss in more detail later.
  prefs: []
  type: TYPE_NORMAL
- en: At the very start of the learning process, the model knows nothing; in other
    words, the values of the weights and biases have not been set to appropriate values.
    Typically, at this point, the model will set the weights and biases to random
    values, and then the training processes will adjust as described. This is somewhat
    like a child who, when born, we assume they have no knowledge of the world but
    need to learn as they grow.
  prefs: []
  type: TYPE_NORMAL
- en: The concept of deep neural networks was inspired by the human brain and the
    brains of animals. We can see there are some similar concepts, but we can also
    see they are very different, and some may say a fundamentally different nature
    to how they work.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.6 Foundational Model Testing
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Once a model has been trained, the next step is to test the model to assess
    its usefulness. Testing models can be a complex task. Typically, the dataset is
    first split into training and testing data, as discussed earlier. The training
    data is used to train the model, and then the testing set is used to evaluate
    how well the model is performing.
  prefs: []
  type: TYPE_NORMAL
- en: One important thing to remember is that during training, the model parameters
    are updated after each batch. However, during testing, the model parameters remain
    unchanged. The goal of testing is to understand how the model will perform. If
    the model parameters are continually changing, it will make testing the performance
    impossible, as each test would impact the performance, and tests would not be
    reproducible.
  prefs: []
  type: TYPE_NORMAL
- en: Using a proportion of the data for testing, such as 20%, is helpful to understand
    the model’s performance for the team creating the model. However, it is not useful
    for comparing or explaining the model’s performance to others, as they do not
    have any understanding of the test data involved, the difficulty level of prediction,
    the scope of the testing, etc. This is where standard testing benchmarks come
    into play. The following section looks at the different benchmarks commonly used.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.6.1 Testing Benchmarks
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: There exists a vast array of testing benchmarks, and every year sees the introduction
    of more, tailored for specific purposes or offering enhanced benefits. Such benchmarks
    are typically centred on particular tasks or broader areas.
  prefs: []
  type: TYPE_NORMAL
- en: Benchmarks commonly provide both the evaluation protocol (rules) and a standard
    dataset for assessing the models. This standard dataset ensures that different
    models undergo evaluation in a uniform manner, rendering the comparisons between
    various models meaningful. Standard datasets are often divided into training and
    testing subsets to ensure consistent training and testing. At times, these datasets
    are further segmented into validation sets. Typically, a model will be trained
    on the training set, fine-tuned using the validation set, and ultimately tested
    using the test set. On occasion, benchmark creators might withhold the testing
    set, asking model developers to submit their models for assessment. This strategy
    aims to prevent models from training on the test data, which would confer an unjust
    advantage during benchmark evaluation.
  prefs: []
  type: TYPE_NORMAL
- en: The evaluation protocol outlines crucial details about the test’s objectives,
    including how to compute the score based on outcomes from each test component.
    This score often serves as a straightforward singular metric for contrasting two
    models. Sometimes, either the benchmark creator or the relevant community will
    establish a leaderboard, displaying ranked scores for each tested model, facilitating
    easier comparison. Such leaderboards might also feature a human baseline score,
    derived from the average scores of human participants. This addition can offer
    context, helping users appreciate the model’s performance. It is not uncommon
    for models to surpass the average human score in many benchmarks.
  prefs: []
  type: TYPE_NORMAL
- en: Below are examples of prevalent benchmarks, categorised by their focal area.
    This should offer a comprehensive understanding of each benchmark, highlighting
    both their strengths and limitations. The grouping area is not strict and the
    benchmarks may be presented under alternative headings depending on the context
    in particular for the more general benchmarks that cover a wider set of areas.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.6.2 Common Sense Reasoning Benchmarks
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 6.3.6.2.1 BoolQ ([Clark et al., 2018](#ref6_15))
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: BoolQ, which stands for Boolean Questions, is a question-answering dataset that
    involves determining whether a provided statement is true or false based on a
    given passage of text. The objective is to answer a binary (yes/no) question using
    the information in the passage. The benchmark comprises approximately 9,400 training
    examples, 3,200 verification examples, and 3,200 test examples.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is how the dataset is structured:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Passage**: A snippet of text that contains the information necessary to answer
    the given question.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Question**: A yes/no question based on the passage.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Label**: A binary label indicating whether the answer to the question is
    “Yes” or “No” based on the passage.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The performance of models on BoolQ is typically evaluated using accuracy, which
    is the proportion of correct answers out of the total number of examples.
  prefs: []
  type: TYPE_NORMAL
- en: 'The BoolQ dataset challenges models in several ways:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Reading Comprehension**: Models must be able to accurately extract and understand
    information from the passage to answer the question correctly.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Binary Classification**: Models need to classify the answer into one of two
    categories: Yes or No.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Inference**: Sometimes, the answer may not be explicitly stated in the passage,
    requiring the model to make inferences based on the available information.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By testing on datasets like BoolQ, researchers can gauge how well language models
    are able to understand and extract relevant information from text to answer questions
    accurately.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.6.2.2 PIQA ([Bisk et al., 2020](#ref6_7))
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The PIQA benchmark, which stands for Physical Intelligence Question Answering,
    is a dataset designed to test a system’s understanding of everyday physical reasoning.
    It was introduced by Bisk et al. in their 2020 paper. The benchmark comprises
    approximately 16,100 training examples, 1,800 verification examples, and 3,000
    test examples.
  prefs: []
  type: TYPE_NORMAL
- en: In this benchmark, questions are posed in such a manner that they necessitate
    the model to exhibit a common-sense understanding of the physical world to furnish
    accurate answers.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is how the data is structured in PIQA:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Question**: A question that typically involves some aspect of everyday physical
    reasoning. This could include questions about the states of matter, simple machines,
    the motion of objects, etc.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Answer**: The correct answer to the question, often a sentence or phrase
    that explains the reasoning or provides a solution to the posed problem.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The performance of models on the PIQA benchmark is typically evaluated based
    on the accuracy of the answers produced. This accuracy measure checks whether
    the model’s answer matches the correct answer or if it provides a logically equivalent
    solution to the problem posed.
  prefs: []
  type: TYPE_NORMAL
- en: PIQA is a challenging dataset as it necessitates models to possess a common-sense
    understanding of physical principles and to apply this understanding to novel
    situations. It serves as a means to assess how proficiently AI systems can reason
    about the physical world in a manner analogous to humans.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.6.2.3 SIQA ([Sap et al., 2019](#ref6_66))
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The Social Intelligence Question Answering (SIQA) benchmark was introduced in
    a paper by Maarten Sap et al. in 2019\. This dataset is designed to evaluate common-sense
    reasoning in AI models within the context of social situations. The objective
    is to determine how proficiently models can comprehend and reason about social
    scenarios, a skill vital for the development of AI systems that can interact naturally
    and effectively with humans. The benchmark comprises approximately 33,400 training
    examples, 1,900 verification examples, and 2,000 test examples.
  prefs: []
  type: TYPE_NORMAL
- en: 'The SIQA dataset consists of questions about social situations. Each question
    is paired with three possible answers: one correct answer and two incorrect answers.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Context**: A description of a social situation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Question**: A question related to the social scenario provided in the context.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Answers**: Three possible answers are provided, one correct and two incorrect.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The performance on SIQA is typically evaluated using metrics such as accuracy,
    which measures the proportion of correctly answered questions out of the total
    number posed. The reasoning behind the answer choices, as well as the social understanding
    exhibited by the model, can be analysed to gain deeper insight into the model’s
    performance.
  prefs: []
  type: TYPE_NORMAL
- en: This benchmark assists researchers in gauging how proficiently their models
    can comprehend, interpret, and respond to social situations, marking a significant
    step towards the development of more socially aware AI systems.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.6.2.4 SWAG ([Zellers et al., 2018](#ref6_84))
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: SWAG (Situations With Adversarial Generations) is a dataset aimed at evaluating
    grounded common-sense inference. It is designed to measure a system’s ability
    to reason about everyday situations described in a sentence. The benchmark presents
    a partially observable scenario, with the objective being to predict the most
    plausible continuation from among four choices. The benchmark comprises approximately
    73,000 training examples, 20,000 verification examples, and 20,000 test examples.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is how the SWAG dataset is structured:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Premise Sentence**: This is a given statement or situation that sets up a
    scenario.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Ending Options**: There are four possible endings provided for each scenario.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Correct Ending**: Among the four endings, one of them is labelled as the
    correct or most plausible continuation of the scenario.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The task is to select the most plausible ending based on the provided premise.
  prefs: []
  type: TYPE_NORMAL
- en: The dataset comprises multiple-choice questions about grounded situations, where
    models are expected to choose the most plausible continuation from four options.
    The creators of SWAG employed a novel adversarial filtering technique to construct
    the dataset. This ensures that the distractor (incorrect) answers are challenging
    and cannot be easily distinguished from the correct answer based solely on superficial
    text patterns.
  prefs: []
  type: TYPE_NORMAL
- en: The task for the model is to select the most plausible ending (in this case,
    option d) given the premise.
  prefs: []
  type: TYPE_NORMAL
- en: In evaluating a model using SWAG, the model’s accuracy in selecting the correct
    ending is measured. This benchmark, therefore, provides a means to assess a system’s
    common-sense reasoning capabilities within a grounded, real-world scenario context.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.6.2.5 HellaSwag ([Zellers et al., 2019](#ref6_85))
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: HellaSwag is a benchmark dataset for evaluating machine learning models on their
    ability to perform common-sense reasoning. It can be seen as an extension or a
    more challenging version of the SWAG benchmark. The benchmark comprises approximately
    39,000 training examples, 10,000 verification examples, and 20,000 test examples.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a detailed breakdown:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Premise**: Similar to SWAG, HellaSwag begins with a premise describing a
    particular scenario. However, the premises in HellaSwag are typically more intricate
    and potentially ambiguous.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Ending Options**: For each premise, four possible continuations are presented.
    These continuations are frequently designed to be misleading or non-obvious, thereby
    challenging the model’s reasoning capabilities.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Correct Ending**: Among the four continuations, one is labelled as the correct
    or most plausible continuation based on the scenario described in the premise.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The primary objective for a machine learning model in this benchmark is to select
    the most plausible continuation based on the provided premise.
  prefs: []
  type: TYPE_NORMAL
- en: The creators of HellaSwag employed a more sophisticated process to produce challenging
    distractor options among the continuations. They utilised an LLM to automatically
    generate distractor continuations that are plausible but incorrect. This approach
    renders HellaSwag a notably challenging benchmark, as the distractors are designed
    to be misleading for both models and potentially human evaluators.
  prefs: []
  type: TYPE_NORMAL
- en: The task for the model is to select the most plausible ending (in this case,
    option C) given the premise. The accuracy of the model on this task would indicate
    its ability to reason through complex, real-world scenarios with potentially misleading
    information.
  prefs: []
  type: TYPE_NORMAL
- en: HellaSwag was designed to be a challenging benchmark to push the boundaries
    of what models can do in terms of common-sense reasoning and understanding nuanced
    real-world scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.6.2.6 WinoGrande ([Sakaguchi et al., 2019](#ref6_65))
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: WinoGrande is a large-scale dataset designed to evaluate machine learning models
    on their ability to solve Winograd Schema challenges. The Winograd Schema challenge
    is a type of common-sense reasoning task that tests a model’s capability to resolve
    pronoun references in sentences. The benchmark comprises approximately 9,200 training
    examples, 1,200 verification examples, and 1,700 test examples.
  prefs: []
  type: TYPE_NORMAL
- en: WinoGrande offers a significant number of examples to furnish a more statistically
    robust assessment of a model’s performance on such tasks. The examples within
    WinoGrande are crafted to be minimally divergent, signifying that a slight alteration
    in the wording of a sentence can modify the correct answer. This design aims to
    probe a model’s grasp of nuanced language and contextual information. WinoGrande
    utilises an adversarial filtering approach to ensure the calibre and challenge
    level of the examples in the dataset. This filtering method aids in excluding
    examples that are either overly simplistic or present multiple potentially correct
    answers. The primary task for models using WinoGrande is to clarify ambiguous
    pronoun references within sentences, identifying, for instance, the specific entity
    to which a pronoun pertains.
  prefs: []
  type: TYPE_NORMAL
- en: The challenge in this example arises from the ambiguous reference of “it” in
    the sentence. The model is tasked with determining to what “it” refers, based
    on the contextual information provided in the sentence.
  prefs: []
  type: TYPE_NORMAL
- en: The WinoGrande benchmark aims to offer a more rigorous evaluation of models’
    common-sense reasoning abilities and their grasp of nuanced language. It is designed
    to be a challenging benchmark that pushes the boundaries of models’ capabilities
    in terms of common-sense reasoning and understanding natural language.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.6.2.7 ARC Easy and Challenge ([Clark et al., 2018](#ref6_15))
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'The ARC dataset stands for AI2 Reasoning Challenge, which was developed by
    the Allen Institute for Artificial Intelligence (AI2). The dataset is created
    to evaluate a machine learning model’s ability to answer questions that require
    reasoning and understanding across several sentences. The ARC dataset is divided
    into two subsets: ARC-Easy and ARC-Challenge.'
  prefs: []
  type: TYPE_NORMAL
- en: '**ARC-Easy** (2,200 training, 500 validation, 2,300 testing):'
  prefs: []
  type: TYPE_NORMAL
- en: This part of the dataset contains questions that are relatively easy to answer.
    These questions might not require deep reasoning and might be solvable with straightforward
    fact retrieval or simpler inference.
  prefs: []
  type: TYPE_NORMAL
- en: '**ARC-Challenge** (1,100 training, 290 validation, 1,100 testing):'
  prefs: []
  type: TYPE_NORMAL
- en: This subset consists of questions that are more challenging and are designed
    to necessitate more advanced reasoning to answer correctly. The questions in ARC-Challenge
    are expected to be difficult for current machine learning models and aim to push
    the boundary of what AI systems can achieve in terms of reasoning.
  prefs: []
  type: TYPE_NORMAL
- en: Each example in the ARC dataset consists of a question, a set of possible answer
    choices, and the correct answer. The questions are formatted as multiple-choice
    questions. This format allows for clear evaluation metrics by checking whether
    the model selects the correct answer. The questions cover a range of topics, primarily
    within the domain of science. They are sourced from real 3rd to 9th grade science
    exams, aiming to challenge models with questions that are easy for humans but
    hard for machines. Both the ARC-Easy and ARC-Challenge subsets are designed to
    require external knowledge to answer correctly, going beyond the information given
    in the question itself.
  prefs: []
  type: TYPE_NORMAL
- en: '**ARC-Easy Example**:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Question**: “What gas do plants absorb from the atmosphere to photosynthesise?”'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Answers**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Oxygen
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Nitrogen
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Carbon Dioxide
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Hydrogen
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**The correct answer** is c) Carbon Dioxide.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ARC-Challenge Example**:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Question**: “If a plant living in a desert has evolved to have spines instead
    of leaves, what could be the most likely reason for this adaptation?”'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Answers**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To attract more insects for pollination
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: To reduce water loss through transpiration
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: To capture more sunlight for photosynthesis
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: To make it easier for the plant to capture prey
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**The correct answer** is b) To reduce water loss through transpiration.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Alongside the ARC dataset, a corpus of text is provided which contains the information
    necessary to answer the questions. This corpus can be used to train models to
    use external information to answer questions.
  prefs: []
  type: TYPE_NORMAL
- en: It should be noted that the corpus of text is not structured; each sentence
    can be on totally different topics (e.g., one sentence quoted above pertains to
    floods, followed by photosynthesis, and then a reference to the god Mars). The
    model being evaluated may have to combine items from disparate locations in the
    corpus of text to answer specific, particularly challenging questions. In the
    above example at least five different areas of the text corpus are relevant or
    potentially relevant. Naturally, the model can draw on its other training data,
    not just the corpus associated with the benchmark, to answer the questions.
  prefs: []
  type: TYPE_NORMAL
- en: The primary aim of the ARC dataset is to encourage the development of new models
    that can reason and understand text in a manner akin to humans, especially within
    an educational or scientific context. The distinction between ARC-Easy and ARC-Challenge
    allows for the evaluation of models at different levels of difficulty, advancing
    the state-of-the-art in machine reasoning.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.6.3 Question Answering Benchmarks
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 6.3.6.3.1 OpenBookQA ([Mihaylov et al., 2018](#ref6_43))
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: OpenBookQA is a benchmark designed to evaluate the ability of machine learning
    models to answer questions based on a small set of facts, known as the “Open Book”.
    The “Open Book” consists of a collection of facts that should be sufficient for
    answering the questions in the dataset. The aim is to test the model’s capacity
    to reason over these facts and combine information to answer questions accurately.
    The benchmark has about 4,900 training examples and about 500 verification examples,
    and 500 test examples. The open book contains about 1,300 entries or facts.
  prefs: []
  type: TYPE_NORMAL
- en: Each question comes with four answer choices, out of which only one is correct.
    The questions are designed to be answerable with the help of the facts provided
    in the Open Book, though some external common knowledge might also be required.
    The questions cover a variety of topics and are designed to test various forms
    of reasoning including retrieval, comparison, spatial reasoning, temporal reasoning,
    causality, etc. Evaluation is typically done based on the accuracy of the model
    in selecting the correct answer from the provided options.
  prefs: []
  type: TYPE_NORMAL
- en: OpenBookQA is used by researchers to evaluate and compare different question-answering
    models. It is particularly useful for assessing how well models can leverage a
    limited set of facts to answer a broad range of questions.
  prefs: []
  type: TYPE_NORMAL
- en: The OpenBookQA benchmark presents a controlled setting to evaluate how effectively
    machine learning models can utilise a set of facts to answer questions that require
    some level of reasoning or synthesis of information.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.6.3.2 Natural Questions ([Kwiatkowski et al., 2019](#ref6_34))
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The Natural Questions (NQ) benchmark, introduced by Kwiatkowski et al. in 2019,
    is designed to evaluate models on their ability to answer real-world questions
    based on the content of a given document. In this benchmark, each example consists
    of a question along with a Wikipedia page, and the task is to identify a specific
    span of text from the page that answers the question, or indicate that no answer
    is present. The full dataset is 42Gb, but a simplified dataset is available which
    is about 4Gb.
  prefs: []
  type: TYPE_NORMAL
- en: 'This task closely mimics real-world scenarios where users pose questions based
    on a document or a web page they are viewing. For instance, a question could be:
    “When was the Eiffel Tower completed?” Given a Wikipedia page about the Eiffel
    Tower, the correct response would be to identify the text span “completed in 1889”
    as the answer. This benchmark is significant as it requires models to effectively
    handle a wide range of natural language questions and to extract precise answers
    from the accompanying documents, showcasing their comprehension and information
    retrieval capabilities.'
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.6.3.3 TriviaQA ([Joshi et al., 2017](#ref6_30))
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: TriviaQA, introduced by Joshi et al. in 2017, is a benchmark designed to evaluate
    models on their ability to answer trivia questions. The dataset comprises question–answer
    pairs from trivia enthusiasts along with evidence documents that provide supporting
    information for the answers. The goal is for models to accurately answer the questions
    using the information available in the associated documents. It contains over
    650K question-answer-evidence triples.
  prefs: []
  type: TYPE_NORMAL
- en: In TriviaQA, the questions are grouped by the source from which they come, and
    are categorised as either verified or unverified based on whether they have been
    cross-checked against the evidence documents. The evidence documents are collected
    from various sources like Wikipedia, web pages, or books, which provide a good
    diversity of language and complexity.
  prefs: []
  type: TYPE_NORMAL
- en: 'A sample question from TriviaQA might be:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Question**: “What river is the principal river of northern Italy?” **Answer**:
    “Po”.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Evidence**: Link to Wikipedia, and perhaps a link to another source'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this benchmark, models are evaluated on their ability to not only provide
    the correct answer but also to demonstrate an understanding of the context and
    evidence from the supporting documents that justify the answer. This benchmark
    challenges models in reading comprehension, knowledge extraction, and the ability
    to handle a mix of formal and informal text, making it a robust measure of a model’s
    capacity to deal with real-world, open-domain question-answering scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.6.3.4 SQuAD v1.1 ([Rajpurkar et al., 2016](#ref6_56)) and 2.0 ([Rajpurkar
    et al., 2018](#ref6_55))
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The Stanford Question Answering Dataset (SQuAD 1.1) is a collection of 100k
    crowdsourced question-answer pairs ([Rajpurkar et al., 2016](#ref6_56)).
  prefs: []
  type: TYPE_NORMAL
- en: The Stanford Question Answering Dataset (SQuAD) is a widely recognised benchmark
    for evaluating the performance of machine reading and question-answering (QA)
    systems. In this benchmark, models are provided with a passage of text and then
    asked to answer questions based on the content of that text.
  prefs: []
  type: TYPE_NORMAL
- en: 'SQuAD consists of two main versions: SQuAD 1.1 and SQuAD 2.0\. In SQuAD 1.1,
    the focus is on answering questions where the answer is guaranteed to be present
    in the provided passage. SQuAD 2.0, on the other hand, includes questions for
    which the answer may or may not be present in the passage, thus challenging models
    to determine when the information needed to answer a question is lacking.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is an example from SQuAD 1.1:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Passage**: “Super Bowl 50 was an American football game to determine the
    champion of the National Football League (NFL) for the 2015 season. The American
    Football Conference (AFC) champion Denver Broncos defeated the National Football
    Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl
    title.”'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Question**: “Which NFL team won Super Bowl 50?”'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Answer**: “Denver Broncos”'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'And an example from SQuAD 2.0:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Passage**: as above'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Question**: “Who was the MVP of Super Bowl 50?”'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Answer**: In this case, the passage does not provide the information needed
    to answer the question, so the correct response would be to indicate that the
    answer is not present in the passage.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: SQuAD has been a crucial benchmark for evaluating and comparing different QA
    systems, and has spurred a significant amount of research in the NLP community.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.6.4 Reading Comprehension Benchmarks
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 6.3.6.4.1 RACE reading comprehension benchmark ([Lai et al., 2017](#ref6_35))
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The RACE (ReAding Comprehension from Examinations) dataset is a large-scale
    reading comprehension dataset collected from English examinations in China, intended
    for students in grades 3 through 12\. The benchmark is designed to evaluate machine
    comprehension models in a more challenging and realistic setting, as it includes
    a diverse range of question types and topics.
  prefs: []
  type: TYPE_NORMAL
- en: 'The dataset is split into two subsets: RACE-M, which consists of middle school
    exam questions, and RACE-H, which consists of high school exam questions.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the format for how questions and passages are structured within the
    RACE benchmark:'
  prefs: []
  type: TYPE_NORMAL
- en: A passage is provided, which could be a narrative, an article, or a dialogue.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multiple-choice questions related to the passage are presented, each with four
    answer options.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here is a simplified example inspired by the kind of questions you might find
    in the RACE dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Passage**: “In 1920, women in the United States won the right to vote with
    the ratification of the 19th amendment to the US Constitution. This was the result
    of many years of struggle and activism by women suffragists who believed in equal
    voting rights for women.”'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Question**: “What did the 19th amendment to the US Constitution grant?”'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Answers**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The right for women to work
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: The right for women to vote
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: The abolition of slavery
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: The establishment of income tax
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Correct Answer**: b) The right for women to vote'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this example, the passage provides the necessary information to answer the
    multiple-choice question. The model’s task is to understand the passage well enough
    to select the correct answer from the provided options. In a real-world scenario,
    the questions in RACE can be much more challenging and the passages longer and
    more complex, making it a robust benchmark for evaluating reading comprehension
    models.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.6.5 Mathematical Reasoning Benchmarks
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 6.3.6.5.1 MATH ([Hendrycks et al., 2021](#ref6_26))
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The MATH (Mathematical Reasoning Dataset) benchmark introduced by Hendrycks
    et al., in 2021, is designed to evaluate the mathematical reasoning abilities
    of machine learning models. The dataset contains mathematical problems that require
    various levels of reasoning and understanding to solve. The problems cover a wide
    range of topics and difficulty levels, which makes it a challenging benchmark
    for assessing how well models can handle abstract mathematical reasoning and symbol
    manipulation. The dataset consists of 12,500 challenging competition mathematics
    problems (7,500 training, 5,000 testing). Each problem in MATH has a full step-by-step
    solution which can be used to teach models to generate answer derivations and
    explanations.
  prefs: []
  type: TYPE_NORMAL
- en: The questions in the MATH dataset are categorised into several topics, including
    algebra, calculus, geometry, measurement, number theory, probability, and statistics.
    Each question is accompanied by a step-by-step solution, which is intended to
    help evaluate how well models can generate not just the final answer, but also
    the intermediate steps and explanations.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a simplified example inspired by the kind of questions you might find
    in the MATH dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Question**: “Simplify the expression: (x² + 2x + 1) + (2x² + 3x + 2)”'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Step-by-step Solution**: “First, we’ll add the like terms together. We’ll
    start with the terms that have x²: x² + 2x² = 3x²; Now, we’ll add the terms that
    have x: 2x + 3x = 5x; Finally, we’ll add the constant terms: 1 + 2 = 3; Putting
    it all together, we get: 3x + 2+5x+3'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Final Answer**: 3x² + 5x + 3'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this problem, the model would need to recognise the structure of polynomial
    expressions and perform the appropriate operations to simplify the expression.
    The step-by-step solution is crucial for understanding the model’s reasoning process.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.6.5.2 GSM8k ([Cobbe et al., 2021](#ref6_16))
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: GSM8K (Grade School Math) consists of high-quality grade school math problems.
    These were created by human problem writers. The dataset is segmented into 7,400
    training problems and 1,300 test problems. The problems take between 2 and 8 steps
    to solve, and solutions involve performing a sequence of elementary calculations
    using basic arithmetic operations to reach the final answer. This benchmark is
    from Cobbe et al. in OpenAI.
  prefs: []
  type: TYPE_NORMAL
- en: One of the goals of this benchmark was to help facilitate research for model
    creators and allow them to measure the performance of their models using different
    approaches for this multi-step type of mathematical problems which even high-parameter
    count modern transformer-based models have difficulty solving.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.6.6 Code Generation Benchmarks
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 6.3.6.6.1 HumanEval ([Chen et al., 2021](#ref6_11))
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The HumanEval benchmark, introduced by OpenAI in a paper by [Chen et al., 2021](#ref6_11),
    is designed to evaluate the problem-solving abilities of language models. The
    benchmark consists of a dataset of tasks (approx. 160), where each task is a function
    problem written in Python that the model has to solve by predicting the function’s
    output based on given inputs. The problems are designed to require mathematical,
    logical, or other forms of common-sense reasoning.
  prefs: []
  type: TYPE_NORMAL
- en: In HumanEval, the tasks are formulated in a way that they are easy for humans
    to solve but are challenging for machine models, aiming to bridge the gap between
    human and machine problem-solving capabilities. The tasks are not constrained
    to a particular domain or type and can span a range of topics and difficulty levels.
    They can encompass various types of problems, like mathematical calculations,
    string manipulations, or logic-based puzzles.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is an example task from HumanEval:'
  prefs: []
  type: TYPE_NORMAL
- en: 'A model is supposed to generate Python code that solves the described problem
    in the comment. In this case, it might generate something like:'
  prefs: []
  type: TYPE_NORMAL
- en: The main goal of the HumanEval benchmark is to push forward the capabilities
    of models in terms of problem solving and reasoning. The benchmark can be used
    to evaluate different models and to understand how well they can understand and
    generate correct and efficient code to solve a given problem.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.6.6.2 MBPP ([Austin et al., 2021](#ref6_5))
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The MBPP (Mostly Basic Programming Problems) benchmark consists of about 970
    Python programming problems, designed to be solvable by beginner-level programmers,
    covering programming fundamentals, standard library functionality, etc. Each problem
    consists of a task description, code solution and 3 automated test cases.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.6.7 Multi-task Language Understanding Benchmarks
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 6.3.6.7.1 GLUE ([Wang et al., 2018](#ref6_77))
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: GLUE (General Language Understanding Evaluation) consists of a collection of
    nine NLU (Natural Language Understanding) tasks, covering a variety of linguistic
    phenomena and domains. The number of training examples, verification examples,
    and testing examples for each of the following varies considerably. The approximate
    numbers shown give some guidance.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are the tasks included in GLUE with some examples to help understand the
    concept being tested:'
  prefs: []
  type: TYPE_NORMAL
- en: 'MultiNLI (Multi-Genre Natural Language Inference): Assessing whether a hypothesis
    is entailed, contradicted, or neither by a given premise (391,000 training, 19,000
    testing, 19,000 validation).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Premise: “The orchestra is playing a beautiful symphony.”'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Hypothesis: “There is a musical performance by the orchestra.”'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Label: Entailment'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'QQP (Quora Question Pairs): Identifying duplicate questions (363,000 training,
    390,000 testing, 40,000 validation).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Question1: “How can I improve my credit score?”'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Question2: “What steps can I take to boost my credit rating?”'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Label: Duplicate'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'QNLI (Question Natural Language Inference): Identifying answer sentences for
    a given question (103,000 training, 5,000 testing, 5,000 validation).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Question: “What is the capital of France?”'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Sentence: “Paris is the capital of France.”'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Label: Entailment'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'SST-2 (Stanford Sentiment Treebank): Binary sentiment classification (67,000
    training, 1,800 testing, 800 validation).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Sentence: “The storyline was dull and unexciting.”'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Label: Negative'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Sentence: “The movie was fantastic with a gripping plot.”'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Label: Positive'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'CoLA (Corpus of Linguistic Acceptability): Grammaticality judgment (8,000 training,
    1,000 testing, 1,000 validation).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Sentence: “The book was put on top of the shelf by John.”'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Label: Acceptable'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Sentence: “The grass green.”'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Label: Unacceptable'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'STS-B (Semantic Textual Similarity Benchmark): Estimating similarity scores
    for sentence pairs (5,000 training, 1,000 testing, 1,400 validation).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Sentence1: “A dog is running in a park.”'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Sentence2: “A dog is sprinting across the park.”'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Similarity Score: High'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'MRPC (Microsoft Research Paraphrase Corpus): Identifying paraphrases among
    sentence pairs (4,000 training, 1,700 testing).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Sentence1: “The company reported a significant increase in quarterly revenue.”'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Sentence2: “Quarterly revenue saw a significant rise as reported by the company.”'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Label: Equivalent'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'RTE (Recognising Textual Entailment): Identifying entailment between pairs
    of text (2,400 training, 2,900 testing, 270 validation).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Sentence1: “No evidence that chemical imbalances cause depression has been
    found.”'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Sentence2: “Chemical imbalances cause depression.”'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Label: Not Entailment'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'WNLI (Winograd NLI): Natural language inference using coreference resolution
    (600 training, 140 testing, 70 validation).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Sentence1: “The keys were locked inside the car.”'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Sentence2: “The car had the keys locked inside.”'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Label: Entailment'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 6.3.6.7.2 SuperGLUE ([Wang et al., 2019](#ref6_76))
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'SuperGLUE was introduced as a more challenging successor to GLUE, and it consists
    of a new set of more difficult language understanding tasks. Here are the tasks
    included in SuperGLUE:'
  prefs: []
  type: TYPE_NORMAL
- en: 'BoolQ (Boolean Questions): Answering yes/no questions. The details of BoolQ
    are provided in a separate section as it is its own benchmark.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'CB (CommitmentBank): Identifying entailment relationships involving human commitments
    (250 training, 250 testing, 50 validation).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Premise: “I can’t help you move next weekend.”'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Hypothesis: “The speaker is not available to help with moving next weekend.”'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Label: Entailment'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'COPA (Choice of Plausible Alternatives): Identifying causes or effects in given
    situations (400 training, 500 testing, and 100 validation).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Question: “What was the effect?”'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Sentence: “He didn’t study, so he failed the exam.”'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Choices: 1) He didn’t study. 2) He failed the exam.'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Answer: He failed the exam.'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'MultiRC (Multi-Sentence Reading Comprehension): Answering questions with multiple
    possible answers (450 training, 150 testing, 80 validation).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Question: “What happened to the cat?”'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Passage: “The cat climbed up the tree and couldn’t come down.”'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Answer: “Climbed up the tree, couldn’t come down.”'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'ReCoRD (Reading Comprehension with Common-sense Reasoning Dataset): Reading
    comprehension that involves common-sense reasoning (65,000 training, 7,400 testing,
    7,400 validation).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Question: “Who bought flowers?”'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Passage: “George went to the store and bought some flowers.”'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Answer: George'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Question: “Why couldn’t the cat come down?”'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Passage: “The cat climbed up the tree and couldn’t come down.”'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Answer: It’s not stated.'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'RTE (Recognising Textual Entailment): Also included in GLUE, but reused here
    (2,400 training, 3000 testing, 270 validation).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Sentence1: “The sun rises in the east.”'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Sentence2: “The sun sets in the west.”'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Label: Not Entailment'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'WiC (Word-in-Context): Determining whether a word is used with the same sense
    in two sentences (5,400 training, 1,400 testing, 630 validation).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Word: “rock”'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Sentence1: “He collects rocks.”'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Sentence2: “He’s my rock.”'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Label: Different'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'WSC (Winograd Schema Challenge): A coreference resolution task, similar to
    WNLI in GLUE (550 training, 140 testing, 100 testing).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Sentence: “The man who hunts ducks out on weekends.”'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Question: “Who hunts ducks?”'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Answer: The man'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 6.3.6.7.3 MMLU ([Hendrycks et al., 2020](#ref6_25))
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The MMLU (Massive Multitask Language Understanding) benchmark, introduced by
    Hendrycks in 2020, encompasses 57 tasks that span various domains, including elementary
    mathematics, US history, computer science, law, and more. This benchmark was established
    in response to recent advancements in LLMs, which were achieving human-level or
    even surpassing human-level performance on earlier benchmarks like GLUE and SuperGLUE.
    The difficulty of the tasks in MMLU ranges from elementary to advanced professional
    levels, testing both knowledge and problem-solving abilities. It can be used in
    zero-shot and few-shot settings when evaluating models.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.6.8 Toxicity Benchmarks
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 6.3.6.8.1 RealToxicityPrompts ([Gehman et al., 2020](#ref6_21))
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: RealToxicityPrompts, introduced by [Gehman et al. (2020)](#ref6_21), is a benchmark
    designed to evaluate the risk and tendencies of language models, particularly
    GPT-3 and similar models, to generate unsafe or toxic outputs. This benchmark
    comprises a dataset that probes the unsafe language generation tendencies of models
    in response to various prompts.
  prefs: []
  type: TYPE_NORMAL
- en: RealToxicityPrompts seeks to elucidate the extent to which pre-trained language
    models, like GPT-3, might produce toxic, offensive, or otherwise undesirable outputs
    when given different types of prompts.
  prefs: []
  type: TYPE_NORMAL
- en: The dataset is made up of prompts designed to elicit responses from the models.
    Its objective is to ascertain how frequently and in what situations these models
    produce answers that might be deemed harmful, offensive, or toxic.
  prefs: []
  type: TYPE_NORMAL
- en: A toxicity classifier evaluates the model-generated responses for potential
    toxicity, helping to quantify the likelihood of an output being perceived as toxic
    or harmful by users.
  prefs: []
  type: TYPE_NORMAL
- en: By shedding light on the propensities and risks associated with automated language
    generation, developers and researchers can more effectively devise safeguards
    and countermeasures to curtail the dissemination of detrimental content.
  prefs: []
  type: TYPE_NORMAL
- en: It should be noted that evaluating toxicity is a complex process. The benchmark
    itself must employ a machine learning model, trained specifically for this purpose,
    to measure the toxicity of a response. This is in contrast to simpler cases, such
    as verifying answers to multiple-choice questions.
  prefs: []
  type: TYPE_NORMAL
- en: A crucial consideration when addressing toxicity in language models is the potential
    for inherent biases within the models. These biases can manifest in the outputs.
    The benchmark seeks to illuminate these issues, guiding efforts to develop more
    impartial and unbiased models.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.6.9 Biases Benchmarks
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 6.3.6.9.1 CrowS-Pairs ([Nangia et al., 2020](#ref6_46))
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The CrowS-Pairs (Crowdsourced Stereotype Pairs) benchmark, introduced by Nangia
    et al. in 2020, is designed to examine the biases present in a language model.
    Instead of merely measuring a model’s performance, it aims to understand and highlight
    the model’s stereotyping and biased tendencies, particularly in nuanced and non-explicit
    contexts.
  prefs: []
  type: TYPE_NORMAL
- en: This benchmark focuses on identifying socio-cultural and demographic biases
    in models. It assesses models on various dimensions of bias, such as race, religion,
    and gender, among others. CrowS-Pairs comprises pairs of sentences crafted to
    contrast non-stereotypical and stereotypical scenarios. Human annotators were
    engaged to develop and validate these pairs, ensuring they encapsulate a wide
    and subtle range of biases.
  prefs: []
  type: TYPE_NORMAL
- en: Models are evaluated on their responses to these sentence pairs, from which
    a bias score is derived, offering a quantitative measure of the model’s bias.
    The benchmark gives insights into both the nature and extent of bias across different
    dimensions. It captures not only explicit but also implicit and subtle biases,
    which might otherwise be overlooked.
  prefs: []
  type: TYPE_NORMAL
- en: Here, Sentence A might contain a gendered stereotype linking mothers to responsibility,
    while Sentence B offers a non-stereotypical counterpart. Models are then evaluated
    based on how they interpret and assess these pairs, providing insights into their
    biases.
  prefs: []
  type: TYPE_NORMAL
- en: These two sentences would be presented to the model, which would be asked to
    provide a score or assess the plausibility of each sentence. The benchmark would
    then evaluate the model’s response, knowing which sentence is biased and which
    is not.
  prefs: []
  type: TYPE_NORMAL
- en: CrowS-Pairs is a vital tool in the domain of ethical AI and bias analysis. It
    supports the development of fairer, more impartial language models by highlighting
    their inherent biases.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.6.9.2 WinoGender benchmark ([Rudinger et al., 2018](#ref6_59))
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The WinoGender benchmark, introduced by Rudinger et al. in 2018, is specifically
    designed to evaluate the gender bias in coreference resolution systems. Coreference
    resolution is a task in natural language processing (NLP) that involves determining
    when two or more words (or phrases) in a text refer to the same entity.
  prefs: []
  type: TYPE_NORMAL
- en: The WinoGender dataset includes sentences designed around an anaphoric pronoun
    (he, she, his, hers, etc.) that is linked to one of two potential referents in
    the sentence. Importantly, one of the referents is stereotypically associated
    with the pronoun, while the other is not. The purpose of this design is to explore
    whether models are more likely to link pronouns to stereotypically associated
    referents, thus revealing potential gender biases in their predictions.
  prefs: []
  type: TYPE_NORMAL
- en: In a stereotype-conforming context, a model might be prone to associating “she”
    with “nurse” and “he” with “surgeon” due to prevalent gender stereotypes. The
    benchmark would evaluate whether the model makes such stereotypical associations
    consistently across various scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: In addition to revealing biases in model predictions, the WinoGender benchmark
    also underscores the challenges that such biases pose to achieving accurate and
    fair coreference resolution. Model developers and researchers use benchmarks like
    WinoGender to assess and subsequently mitigate the biases present in their models,
    aiming for more equitable and accurate performance across different contexts and
    demographic groups.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.6.10 Truthfulness Benchmarks
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 6.3.6.10.1 TruthfulQA ([Lin et al., 2022](#ref6_39))
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The TruthfulQA benchmark, introduced by Lin et al. in 2022, is designed to examine
    the reliability and veracity of responses generated by LLMs to open-domain questions.
    The fundamental goal is to scrutinise how well these LLMs provide truthful and
    accurate answers across a wide range of topics and questions.
  prefs: []
  type: TYPE_NORMAL
- en: The need for a benchmark like TruthfulQA stems from observations that, while
    models like GPT-3 can generate fluent and contextually appropriate responses,
    they can sometimes generate answers that are incorrect, misleading, or fabricated.
    Ensuring the reliability of information provided by LLMs is crucial, especially
    as they become more integrated into informational and decision-making tools.
  prefs: []
  type: TYPE_NORMAL
- en: 'Approach:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Questions**: The dataset includes a variety of questions that are designed
    to probe the model’s ability to provide accurate and reliable answers. These questions
    could span a wide array of topics, including history, science, and general knowledge.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Model Responses**: The LLMs generate responses to the provided questions.
    The aim is to evaluate the correctness and reliability of these responses.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Evaluation**: Human evaluators or an automated system will assess the model-generated
    responses for their accuracy and truthfulness, comparing them to verified information
    or predefined answer keys.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: TruthfulQA serves as a crucial tool in gauging how LLMs handle the provision
    of factual information, which is essential for ensuring that these models can
    be trusted sources of information in various applications, such as conversational
    agents, informational retrieval systems, and more.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.7 The Fine-Tuning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Fine-tuning is a technique in machine learning where a pre-trained model is
    further trained (typically on a smaller dataset) to adapt its existing knowledge
    to a new task. The model has already learned various features or patterns from
    a larger dataset and can utilise this knowledge to perform well on a related task
    with less data. Below are descriptions and examples for both a language model
    (LLM) and an image generation model.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.7.1 Fine-Tuning in Language Models (LLM)
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: After a model like GPT-3 has been pre-trained on a vast corpus of text, it has
    accumulated a wide range of linguistic knowledge. Fine-tuning involves training
    it further on a smaller, domain-specific dataset to specialise its capabilities
    towards certain tasks or industries.
  prefs: []
  type: TYPE_NORMAL
- en: Imagine you have an LLM trained on general text, and now you want to fine-tune
    it for legal advice. The LLM has been trained on a massive corpus and understands
    a wide array of English text. You introduce the LLM to a smaller dataset consisting
    of legal documents, court rulings, and attorney correspondences. The model adapts
    its generalised knowledge to become proficient in understanding and generating
    legal text. The fine-tuned LLM can now generate more contextually and terminologically
    accurate responses to legal queries or assist in drafting legal documents.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.7.2 Fine-Tuning in Image Generation Models
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: An image generation model pre-trained on a large dataset has learned to generate
    images by understanding various visual patterns, structures, and contexts from
    the training data. Fine-tuning involves further training the model on a smaller,
    specific dataset to enhance its capability in generating images related to a specific
    domain or characteristic.
  prefs: []
  type: TYPE_NORMAL
- en: Consider a generative adversarial network (GAN) that has been trained on a wide
    variety of images (e.g., faces, animals, objects). The GAN knows how to generate
    a broad spectrum of images by understanding general patterns, colours, shapes,
    and textures found in the training data. Now, suppose you want to generate images
    of birds. You fine-tune the GAN using a smaller dataset consisting exclusively
    of bird images. The model learns the specific visual characteristics related to
    different bird species. The fine-tuned model can now generate varied and contextually
    relevant images of birds, considering specific aspects like plumage, beak shape,
    and size more accurately.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.7.3 Steps for Fine-tuning
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: These steps follow the same steps as described above for the foundational model,
    but with specific datasets and testing focused on the fine-tuning specifics. In
    the case of the model design and structuring, the model’s architecture can be
    adjusted to be suitable for the new task (e.g., changing the output layer for
    classification tasks). Typically, the specific hyperparameters of the model will
    be adjusted to help ensure the best results from the fine-tuning e.g., use of
    a smaller learning rate to avoid forgetting the previously learned features and
    gently adapt the model to the new task.
  prefs: []
  type: TYPE_NORMAL
- en: Fine-tuning allows leveraging the extensive knowledge captured during pre-training
    to achieve better performance on related tasks even when less training data is
    available for them. This methodology has proven effective across various domains
    and tasks in machine learning.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.8 The Deployment
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We have explored the intricacies involved in creating a model. However, before
    a model, especially ones such as GPT-3/GPT-4 or LLaMA-2, is prepared for widespread
    use, several steps must be undertaken to ready the model for large-scale production.
  prefs: []
  type: TYPE_NORMAL
- en: 'This may involve some or all of the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Model Finalisation:** This stage involves selecting the specific model for
    deployment to an environment for general usage by users, typically called the
    production environment or just production. Often, companies will develop multiple
    models, each subjected to various customisations during training and testing.
    Subsequently, a decision must be made regarding which model to advance to production.
    During this stage, any final testing necessary is conducted (elaborated upon later)
    and actions such as optimising the model’s hyperparameters are taken.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Model Optimisation:** This is a crucial step in which resource usage, including
    CPU and memory, is optimised for production purposes, specifically for inference.
    Training a model and deploying it for mass use entail distinct scenarios, and
    when the model is serving user queries, it must be tailored for that specific
    context. One effective action that model creators can take is **model pruning**.
    This involves scrutinising the model to identify components that can be removed
    to simplify it, without compromising its performance capabilities, while simultaneously
    reducing the required computational resources, including memory and CPU. At times,
    teams may conduct an **ablation study**, which systematically removes parts of
    the model to assess their impact. If such removal leads to a positive resource
    impact without compromising performance, they may decide to exclude that component
    from the production version. Various other techniques can be less invasive, including
    **thresholding** (pruning items below a specified threshold), **activation analysis**
    (removing items with minimal impact on output), **sensitivity analysis** (pruning
    items with limited contribution to output), and **redundancy analysis** (eliminating
    redundant components, such as superfluous layers). Naturally, after implementing
    these modifications, it is imperative to rigorously test the model to ensure it
    continues to perform effectively. Another important optimisation strategy often
    employed is **quantisation**, a process that reduces the precision of the model
    weights to lower memory requirements and accelerate inference. This approach is
    commonly utilised when running models on personal computers or mobile devices.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Model Conversion:** This stage involves the conversion of the model into
    a format suitable for deployment, such as Open Neural Network Exchange (ONNX),
    TensorFlow SavedModel, or PyTorch. Some models may be distributed as installable
    scripts, as is the case with GPT4All, while others may be packaged as container-ready
    deployments using technologies like Docker for Kubernetes, as exemplified by Mistral.
    The selection of the model distribution format holds significance, as it directly
    impacts the accessibility and ease of use of the model, thereby influencing the
    level of interest from the community. In situations where the model is exclusively
    Intended for internal use and is only exposed through a user interface (e.g.,
    a chatbot) or an API (as described below), these model details may remain concealed
    from external parties not affiliated with the organisation that created the model,
    such as ChatGPT3.5 or ChatGPT4.0.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Additional Testing:** In most cases, a comprehensive array of specialised
    tests is conducted, encompassing aspects such as inference speed, resource consumption,
    and scale testing, which involves assessing the model’s performance under varying
    user inference request loads. These evaluations may lead to further refinements
    of the model, including the implementation of optimised caching (in memory storing
    of data for faster access) strategies.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**API Wrapper:** End users typically interact with the model via a user interface
    such as a browser-based chatbot interface. However, a model may provide an Application
    Programming Interface (API) to allow technically skilled users to interact with
    the model and to build their own end user interfaces into the models. These APIs
    are typically provided using a technology known as a REST API. A more in-depth
    discussion of these elements that wrap the model will be provided later, as they
    constitute key components of the broader ecosystem in which a model operates.
    In the case of the API wrapper, considerations will include determining the methods
    of user authentication and establishing the framework for authorisation procedures.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Monitoring and Logging:** This is a critical part of a model deployment and
    allows the model to be kept healthy by the team responsible for the model in the
    production environment. This monitoring serves multiple purposes, extending beyond
    mere verification of its operational status. It also entails keeping track of
    factors like the number of users and the utilisation of resources such as CPU,
    memory, and network bandwidth, ensuring they remain within predefined thresholds
    and controls. Additionally, effective monitoring plays a pivotal role in identifying
    and rectifying instances of undesirable behaviour, whether exhibited by the model
    itself or by the users interacting with it. If something goes wrong, they can
    use monitoring and logging to identify what and how to fix it for the future.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Filtering for Safety and Alignment:** In practice, a model intended for public
    use, such as the GPT-4 model integrated with ChatGPT, typically incorporates various
    features to mitigate the risk of generating inappropriate outputs. For instance,
    input filters can be employed to examine incoming input early in the process,
    thereby identifying and addressing potentially inappropriate content. Similarly,
    in cases where problematic output is detected, output filters can intervene to
    prevent such content from reaching the user. These output filters may substitute
    the inappropriate output with a more suitable response or provide a default message
    conveying the model’s inability to assist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Continuous Improvement:** Once the model is available it will require continual
    improvements based on new advances and discoveries from the team that create it
    or from learnings in the runtime environment with real users interacting with
    the model. The model creators need to understand how they plan to release these
    updates, whether they will it be real-time releases that are transparent to users,
    or made available as new versions of a model that the user must explicitly select,
    or perhaps as new specialisations of a model (e.g., trained for some specific
    purposes e.g., chatbot, code generation, specific scientific capabilities, etc.)
    and released as if it was a new model. When users use the model, it is important
    to try and address issues quickly that come up. Sometimes the model may start
    to give biased information or incorrect information; this is known as model hallucination.
    There can be a lot of public pressure on organisations to fix such issues; for
    example Meta had to take down one of their models (called Galactica) only after
    three days due to biased and incorrect information that it provided, and it was
    not possible to fix the model quickly ([Snoswell & Burgess, 2022](#ref6_68)).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 6.3.9 Model Use (aka Inference)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Typically, models do not undergo learning processes (i.e., updates to their
    weights and biases) during regular runtime interactions. Learning occurs exclusively
    during the pre-training of the foundational model or during the fine-tuning phase.
  prefs: []
  type: TYPE_NORMAL
- en: However, this can be somewhat perplexing, as there are approaches that might
    appear akin to learning. One such example is the concept of few-shot learning.
    In few-shot learning, similar request-response pairs are presented alongside the
    intended request to assist the model in generating the most appropriate response.
    The terminology, including “zero-shot learning” (where no examples are provided),
    “one-shot learning” (with a single example request-reply pair provided for action),
    and “few-shot learning” (in which multiple request-reply pairs are provided, typically
    ranging from 2 to 5 pairs), can be confounding. This is because the model is not
    actually learning; rather, it is utilising these examples to enhance its comprehension
    of the requests. The model’s parameters remain unaltered. Perhaps these concepts
    would be more accurately described as “few-shot requests” or “few-shot guidance”
    rather than “few-shot learning”.
  prefs: []
  type: TYPE_NORMAL
- en: It is worth noting that certain models may compile a database of user requests
    and responses for potential use in training the model in the future or for updates.
    However, as a rule, on-the-fly learning is not commonly employed, as it could
    render the models unstable. This serves as another illustration of the fundamental
    distinction between ANNs and human brains, with the latter continually engaged
    in the process of learning.
  prefs: []
  type: TYPE_NORMAL
- en: The following sections provide information about other runtime or inference
    time activities that are worth understanding.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.9.1 Prompt Engineering
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Prompt engineering involves the design and optimisation of prompts (also read
    [Section 3.8](ch3.xhtml#sec3_8)). These are input sequences or instructions intended
    to guide a language model, such as ChatGPT, to produce the desired outputs. This
    technique is especially relevant in the context of few-shot learning, where the
    model is provided with examples within the prompt to help it understand and perform
    specific tasks.
  prefs: []
  type: TYPE_NORMAL
- en: At present, a myriad of templates and strategies are being championed as ‘the
    best’ for prompt engineering, especially in relation to ChatGPT. These methods
    typically encompass various elements that structure the request. This includes
    elucidating the context, defining the intended audience or roles, and offering
    examples (as observed in few-shot learning) to effectively shape the model’s response
    (read [Section 3.8.2](ch3.xhtml#sec3_8_2). on the Prompt Engineering Components).
  prefs: []
  type: TYPE_NORMAL
- en: While much of the conversation about prompt engineering centres on LLMs, it
    is also considered in relation to image generation and other forms of content
    creation.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.9.2 Prompt Injection
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Prompt injection is a tactic whereby individuals attempt to manipulate models
    into producing inappropriate responses. They modify the prompt in various ways,
    leading to outputs that the model should not generate, a phenomenon occasionally
    referred to as adversarial prompting.
  prefs: []
  type: TYPE_NORMAL
- en: Such inappropriate outputs can range from humorous or insulting remarks to the
    provision of accurate yet ethically questionable information, such as instructions
    on creating a bomb or methods for disposing of a body.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.9.3 Jailbreaking
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Jailbreaking refers to the process by which a model is manipulated into a mode
    that circumvents the usual safeguards in place, ensuring its intended behaviour.
    This is achieved based on specific prompts from users.
  prefs: []
  type: TYPE_NORMAL
- en: There are well-documented instances of this, such as the ‘Sydney’ mode for Bing,
    or the ‘DAN’ (Do Anything Now) mode for ChatGPT. Some individuals have also bypassed
    certain safety mechanisms of the model using alternative techniques. For example,
    by instructing the model to simulate a conversation where it is a model speaking
    to another model, and then responding to a prompt. This kind of recursive scenario
    seems to disorient the model and its filtering mechanisms, leading it to eventually
    produce responses it would not typically generate.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.9.4 Prompt Leaking
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Prompt leaking happens where a user designs a prompt that tricks the model into
    providing real information that it should not, perhaps internal details about
    the model itself.
  prefs: []
  type: TYPE_NORMAL
- en: 6.4 Models and Ecosystems
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Figure 6.16](#fig6_16) shows how a model and the ecosystem around the model
    may be constructed. This will be different for different models and companies
    depending on their specific needs, the market they are addressing, and many other
    factors.'
  prefs: []
  type: TYPE_NORMAL
- en: '![A depiction of how a model and the ecosystem around the model may be constructed.](images/fig6_16_B.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '[Figure 6.16 The Model Ecosystem.](#R_fig6_16)'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following sections discuss some of the key aspects of this ecosystem. In
    the example from [Figure 6.16](#fig6_16) we can see:'
  prefs: []
  type: TYPE_NORMAL
- en: User A, is using both a Chat App and a Document Authoring App which use Foundation
    Model A.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Software Developer A has built and deployed a custom application which uses
    a fine-tuned version of Model A which they created specifically for legal professionals
    and specialises in international law. It uses a Retrieval Augmented Generation
    (RAG) approach to ensure the most useful outcomes for users of his product.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: User B uses the Custom Product that specialises in Legal GenAI for international
    law.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Software Developer B has built a generic API that supports multiple foundational
    models (A, B, and C). It also supports several of the plugins that are available
    for Foundational Model A. These plugins allow Foundation Model A to do several
    interesting things, including search for travel options from a travel consolidation
    service and do general real-time searches from a well-known search engine. As
    part of this implementation Software Developer B used the ‘functions’ capability
    of Model B and if it does not get results it will call Foundational Model C.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 6.4.1 Custom Interfaces and Chat
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The most common custom interface is the familiar chatbot prompt and response
    interface. It is important to realise that this chat interface that humans interact
    with is separate to the model. A chat interface can make interaction with the
    model easy, and it can make several decisions about interacting with that model
    that may not be obvious. For example, it can do some of the following
  prefs: []
  type: TYPE_NORMAL
- en: Setting specific hyperparameters to specific values
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Providing previous interactions details so the model has the context of the
    conversation (e.g., automatically adding key aspects of the previous part of the
    discussion to the current context for the model)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Handling requests and dealing with items like caching of data to minimise the
    processing and memory load on the model.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chat interfaces are not the only way to interact with models; many tools integrate
    with GenAI. For example, web site design tools integrate with models that allow
    generation of images for the site or allow generation of items like business cards.
    Some tools, like Good Documents, integrate models for content generation while
    authoring your document.
  prefs: []
  type: TYPE_NORMAL
- en: 6.4.2 APIs and Functions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The model is typically exposed as an Application Programming Interface (API),
    even if this is solely for the chat interface mentioned earlier. Companies such
    as OpenAI also offer an API to software developers who wish to harness the model
    for their bespoke needs. The API permits other software applications to access
    the model and retrieve results. This becomes particularly advantageous, for instance,
    if one operates a company offering document authorship software, like Google Docs,
    Microsoft Word, or Good Notes. Such an API can be used to integrate the model’s
    capabilities into the software, enabling functionalities such as content suggestions
    or content reviews.
  prefs: []
  type: TYPE_NORMAL
- en: Functions provide a novel method to afford additional flexibility to software
    developers utilising the model API. There are instances where the model might
    not furnish pertinent information in its response, perhaps because the query pertains
    to a topic arising after the model’s training was finalised. Under these circumstances,
    the developer can instruct the model to return the specifics for a function call
    if it is unable to directly address the query. The model will then endeavour to
    reshape the request to align with the developer-provided function call and return
    this revised request, thereby alleviating the developer’s need to amend the request
    independently. The developer can then initiate the specified function with relative
    ease. It is crucial to emphasise that the software developer orchestrates the
    function call. The model either furnishes a standard response or, if that is unattainable,
    it preps the data for the function call as proficiently as possible, simplifying
    the process for the developer. However, the onus of initiating the function, if
    deemed apt, lies with the developer.
  prefs: []
  type: TYPE_NORMAL
- en: 6.4.3 Plugins and Agents
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Plugins, sometimes referred to as agents, enable software developers to construct
    a service which the model can invoke. In the context of an API, the developer
    initiates the call to the model. However, when dealing with a plugin or agent,
    it is the model that reaches out to another system or capability.
  prefs: []
  type: TYPE_NORMAL
- en: Consider an instance where the ultimate objective is to ascertain current flight
    prices and schedules from Hong Kong to Dublin for a specific future date. The
    LLM would be oblivious to such information, as it wouldn’t possess this data in
    its training set; and even if it did, the information would likely be outdated.
    However, if a company like Expedia intends to supply this data to a model, a plugin
    would be the mechanism. A user might transmit a request to the model via a chat
    interface or an API call from a bespoke interface. The model, recognising its
    own inability to address the query, would invoke the Expedia plugin to retrieve
    the necessary data and relay it to the user.
  prefs: []
  type: TYPE_NORMAL
- en: One can envisage a world abundant in diverse plugins, empowering models to perform
    a plethora of tasks for users. This extends beyond merely listing flights to booking
    them, ordering pizzas, hiring cars, managing household devices, and virtually
    any task feasible through online automation, given the right plugin.
  prefs: []
  type: TYPE_NORMAL
- en: The paramount importance of trust in plugins becomes evident. The implications
    of a plugin transferring funds between bank accounts could be dire if exploited
    to transfer money illicitly. If a plugin fetches information that is deliberately
    incorrect, it poses challenges. There might be instances where a plugin’s action
    deviates from the user’s intention; for example, a user might want to only check
    flight prices but ends up having a flight booked unintentionally via the plugin.
    Such scenarios would lead to user dissatisfaction.
  prefs: []
  type: TYPE_NORMAL
- en: This necessitates the establishment of stringent guidelines and policies governing
    plugins, to which developers must adhere to and formally commit.
  prefs: []
  type: TYPE_NORMAL
- en: OpenAI has integrated a web-browsing plugin with its ChatGPT product. Users
    have the discretion to activate or deactivate this plugin via the ChatGPT interface.
    If activated and ChatGPT fails to address a query (e.g., when asked for recent
    data not encompassed in its training), it will access the web-browsing plugin,
    essentially tapping into the new Bing search functionality which incorporates
    a specialised version of GPT-4\. This provides a valuable extension to the model,
    whilst ensuring the user retains authority over the plugin’s usage.
  prefs: []
  type: TYPE_NORMAL
- en: 6.4.4 Custom Fine-Tuning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: It is feasible to fine-tune certain models for bespoke applications. In OpenAI’s
    instance, they have augmented the API for their model (currently the gpt-3-5-turbo
    model) to permit users to upload a curated set of training data in a distinct
    format. Users can then instruct the model to fine-tune based on this data and
    subsequently receive a newly instantiated model tailored for that specific objective.
    It is incumbent upon the user to test and ascertain that the fine-tuned model
    delivers the anticipated advantages.
  prefs: []
  type: TYPE_NORMAL
- en: Such a facility paves the way for the creation of custom models tailored for
    niche purposes. For instance, a model could be honed to specialise in international
    law, enabling software developers to supplement their products with additional
    functionalities. These enhanced features would prove invaluable to a select group
    of users seeking such specific capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: 6.4.5 Custom Models
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Many model developers offer customised models for specific purposes. These are
    often fine-tuned versions of the foundational model, adapted for that particular
    application. Examples encompass chat-based models, code generation-based models,
    and even highly specialised models that not only generate but also execute code.
    OpenAI has introduced a custom model named ‘Advanced Data Analysis’, previously
    called Code Interpreter, designed to generate code. Furthermore, this model can
    execute the code and present the output. This proves invaluable for software engineers,
    enabling them to iterate over code more rapidly, with the model shouldering more
    responsibilities, including debugging. While the Advanced Data Analysis is marketed
    akin to a plugin and is managed via the Chat interface, much like the ‘Web Browsing’
    plugin mentioned earlier, its distinct specialisation is evident when accessed
    via an API, the Advanced Data Analysis is invoked as a separate model.
  prefs: []
  type: TYPE_NORMAL
- en: 6.4.6 Vector Databases and Retrieval Augmented Generation (RAG)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Vector databases are specialised databases designed for the efficient querying
    and retrieval of data using vectors. In this context, vectors are arrays of numbers
    representing objects, such as text, images, or sounds, within a multidimensional
    space.
  prefs: []
  type: TYPE_NORMAL
- en: These databases are optimised for operations like similarity searches among
    vectors. They allow users to efficiently identify items resembling a given input
    vector. Such capability proves particularly beneficial in applications related
    to machine learning, recommendation systems, image retrieval, and natural language
    processing, wherein locating similar items in high-dimensional spaces is vital.
  prefs: []
  type: TYPE_NORMAL
- en: Retrieval Augmented Generation (RAG) merges the capabilities of pre-trained
    language models with information retrieval systems, enhancing the generation of
    responses in conversational AI and other NLP tasks.
  prefs: []
  type: TYPE_NORMAL
- en: Given an input (e.g., a question or prompt), RAG sources pertinent documents
    or text snippets from a corpus or database, often a vector database. The information
    retrieved subsequently informs the generative model’s response, facilitating the
    creation of more precise, informative, and contextually relevant outputs.
  prefs: []
  type: TYPE_NORMAL
- en: This approach can be likened to enriching the prompt with examples (akin to
    few-shot learning), enabling the model to generate superior responses.
  prefs: []
  type: TYPE_NORMAL
- en: A typical scenario where this is advantageous involves an organisation possessing
    an internal model and a database of documents that can readily address the current
    request. For instance, a legal firm aiming to produce content may want to ensure
    alignment with its existing templates and structures, particularly for documents
    like contracts, legal notices, or letters.
  prefs: []
  type: TYPE_NORMAL
- en: 6.5 State-of-the-Art Models Overview
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the subsequent sections, we examine several renowned state-of-the-art (SOTA)
    models. Our emphasis is on large language models and text-to-image diffusion models.
    For each model, we offer a concise overview of the company and the model itself,
    followed by details concerning its release history, specifications, uses, and
    pertinent commentary.
  prefs: []
  type: TYPE_NORMAL
- en: 6.5.1 LLM – OpenAI ChatGPT-4.0
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Established in 2015, OpenAI was originally a non-profit organisation dedicated
    to the development and democratisation of open AI systems. Among its founders
    were eminent figures in the AI domain, including individuals like Elon Musk. Subsequently,
    the organisation transitioned to a for-profit structure. Its current mission statement
    reads:'
  prefs: []
  type: TYPE_NORMAL
- en: Our mission is to ensure that artificial general intelligence – AI systems that
    outperform human intelligence – benefits all of humanity.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Release History**'
  prefs: []
  type: TYPE_NORMAL
- en: 'OpenAI GPT-n series of models:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Table 6.1 OpenAI GPT-n Series Release History
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '| Date | Model | Description |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| 11/Jun/2018 | GPT-1 | Improving Language Understanding by Generative Pre-Training
    ([Radford et al. 2018](#ref6_52)) |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| 14/Feb/2019 | GPT-2 | Language Models are Unsupervised Multitask Learners
    ([Radford et al., 2019](#ref6_53); Solaiman et al., 2019) |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| 28/May/2020 | GPT-3 | Language Models are Few-Shot Learners ([Brown et al.,
    2020](#ref6_10)) |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| 15/Mar/2022 | GPT-3.5 | Version 3.5 release |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| 30/Nov/2022 | ChatGPT | This was based on GPT-3.5 model and later both GTP-3.5
    and GPT-4 were supported via user selection |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| 14/Mar/2023 | GPT-4 | GPT-4 Technical Report ([OpenAI, 2023](#ref6_48)) |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '**Specifications**'
  prefs: []
  type: TYPE_NORMAL
- en: 'The size and specification of GPT-4 has not been shared; however, from the
    [OpenAI 2023](#ref6_48) Technical Report publication we do learn the following:'
  prefs: []
  type: TYPE_NORMAL
- en: It is a transformer pre-trained model (like GPT3)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It exhibits human-level performance on many benchmarks.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'However, more details have been leaked and, while not official, they do provide
    some insight to the sizing:'
  prefs: []
  type: TYPE_NORMAL
- en: GPT-4 has ~1.8 trillion parameters across 120 layers.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GPT-4 is trained on ~13 trillion tokens, including both text-based and code-based
    data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The training data included Common Crawl & RefinedWeb, totalling 13T tokens.
    There is considerable speculation that additional sources like Twitter, Reddit,
    YouTube, and a large collection of textbooks were also used.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It uses a mixture of experts (MoE) architecture which is an ensemble learning
    approach and allows different experts to specialise in different areas with the
    most appropriate being selected. There may be either 16 experts with ~111B parameters
    each or 8 experts with ~220B parameters each.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Use**'
  prefs: []
  type: TYPE_NORMAL
- en: It is multimodal, which means it can handle text and images as inputs and text
    as an output. Recently, it has been integrated with DALL-E 3 for image-based output.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With the Code Interpreter (now called advanced data analysis) feature, it can
    both generate and execute code
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Comments**'
  prefs: []
  type: TYPE_NORMAL
- en: This model is widely regarded as the most advanced and useful for general text
    generation as well as code generation.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 6.5.2 LLM - Meta LLaMA-2
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Meta, formerly known as Facebook, introduced the LLaMA model as one of its most
    sophisticated offerings. Although it was initially disseminated as a research
    release, it was inadvertently leaked and broadly circulated. Consequently, for
    LLaMA-2, Meta opted to release it under a more permissive commercial license.
  prefs: []
  type: TYPE_NORMAL
- en: '**Release History**'
  prefs: []
  type: TYPE_NORMAL
- en: Table 6.2 Meta LLaMA Release History
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '| Date | Model | Description |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| Feb/2023 | LLaMA-1 | LLaMA: Open and Efficient Foundation Language Models
    ([Touvron et al., 2023a](#ref6_71)) |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| 18/Jul/2023 | LLaMA-2 | LLaMA-2: Open Foundation and Fine-Tuned Chat Models
    ([Touvron et al., 2023b](#ref6_72)) |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '**Specifications**'
  prefs: []
  type: TYPE_NORMAL
- en: LLaMA-2 is designed as an auto-regressive language optimised transformer.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The fine-tuned versions of the model implement Supervised Fine-Tuning (SFT)
    and Reinforcement Learning with Human Feedback (RLHF) to better align with human
    preferences for helpfulness and safety.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'LLaMA-2 comes in three sizes based on the number of parameters: 7 billion,
    13 billion, and 70 billion parameters.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The models have a token count referring only to the pre-training data, with
    all models trained with a global batch size of 4 million tokens. The largest model,
    with 70 billion parameters, utilises Grouped-Query Attention (GQA) for improved
    inference scalability
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The training and fine-tuning of LLaMA-2 leveraged publicly available online
    data sources, with over one million human-annotated examples used for fine-tuning.
    This model does not include Meta user data in its training or fine-tuning datasets.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Use**'
  prefs: []
  type: TYPE_NORMAL
- en: The model is primarily intended for text-based applications.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It’s optimised for dialogue use cases through its fine-tuned versions, known
    as LLaMA-2-Chat, but its pre-trained versions can be adapted for a broader range
    of natural language generation tasks.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LLaMA-2 is open for both commercial and research use, and it is particularly
    targeted for use in English language tasks.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Comments**'
  prefs: []
  type: TYPE_NORMAL
- en: LLaMA-2 is Meta’s response to other large language models like OpenAI’s GPT
    models and Google’s AI models, with a distinguishing feature of being more open
    and freely available for almost anyone to use for research and commercial purposes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 6.5.3 LLM – Google Bard and PaLM-2
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Google has consistently contributed to AI research, notably through the seminal
    paper titled “Attention is All You Need”, which has influenced the prevailing
    direction of Transformer-based architectures for large language models.
  prefs: []
  type: TYPE_NORMAL
- en: '**Release History**'
  prefs: []
  type: TYPE_NORMAL
- en: Table 6.3 Google PaLM/Bard/LaMDA Release History
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '| Date | Model | Description |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| 18/May/2021 | LaMDA-1 | LaMDA: Language Models for Dialog Applications ([Thoppilan
    et al., 2022](#ref6_70)) |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| 11/May/2022 | LaMDA-2 | Version 2 update |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| 21/Mar/2023 | Bard | Chat bot made available initially built on LaMDA-2 |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| Mar/2023 | Bard | Google announced Bard would switch to PaLM-2 shortly |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| Mar/2023 | PaLM-1 | PaLM: Scaling Language Modeling with Pathways ([Chowdhery
    et al., 2022](#ref6_13)) |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| May/2023 | PaLM-2 | PaLM 2 Technical Report ([Anil et al., 2023](#ref6_2))
    |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '**Specification**'
  prefs: []
  type: TYPE_NORMAL
- en: PaLM-2 (Pathways Language Model) was discussed in relation to the three sizes
    small (PaLM-2 S), medium (PaLM-2 M) and large (PaLM-2 L) in the paper ([Anil et
    al., 2023](#ref6_2)). The large version is reported to be considerable smaller
    than the original PaLM model which has 540B parameters.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: PaLM-2 has put greater focus on training with text from languages other than
    English as well as a focus on a diverse set of domains for the training data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is based on the transformer model; however, it has expanded the training
    objectives from masked language modelling to use a mixture of different pre-training
    objectives to help it understand different aspect of the language.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model also relooked at how training compute should be used and move to an
    approach where model size vs training data size were more aligned with a 1:1 ratio
    to get the best value for a specific compute capacity.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'PaLM-2 is provided in several different configurations: Gecko, Otter, Bison,
    and Unicorn. It is thought that the sizes of these are 1.5B, 6B, 137B, and 540B.
    Each version has a different size and is designed for use within specific applications.
    For example, Gecko is the smallest and most lightweight. It is designed for mobile
    devices.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The chat interface Google Bard uses the PaLM-2 model. However, the only way
    for developers to access these models at the moment is via the Google Cloud Platform
    (e.g. PaLM API, MakerSuite, or Vertex AI).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Use**'
  prefs: []
  type: TYPE_NORMAL
- en: It is focused on advanced reasoning tasks, including code and math, classification
    and question-answering, translation and multilingual proficiency, and natural
    language generation.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Comments**'
  prefs: []
  type: TYPE_NORMAL
- en: The PaLM-2 model, and Google Bard have not had the same popularity or adoption
    that OpenAI ChatGPT has had or the same level of praise for its abilities.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 6.5.4 LLM – Anthropic Claude
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Anthropic was founded in 2021 and among its founders were several people who
    left OpenAI to start Anthropic and thus it is a relatively new player.
  prefs: []
  type: TYPE_NORMAL
- en: '**Release History**'
  prefs: []
  type: TYPE_NORMAL
- en: Table 6.4 Anthropic Claude Release History
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '| Date | Model | Description |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| 14/Mar/2023 | Claude-1 | Claude and Claude Instant were released |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| 23/Aug/2023 | Claude-2 | Claude was updated |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '**Specifications**'
  prefs: []
  type: TYPE_NORMAL
- en: Claude is a transformer-based architecture. The model is larger than the 52B
    parameter model AnthropicLM discussed in the paper ([Bai et al., 2022](#ref6_6)),
    but is an autoregressive model trained on a large corpus of text in a self-supervised
    manner similar to GPT-3.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Claude comes in two versions: Claude and Claude Instant. Claude is a state-of-the-art
    high-performance model, while Claude Instant is a lighter, less expensive, and
    much faster option.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Anthropic has partnered with Quora and they have built a chat interface to Claude
    as a mobile application called Poe. Poe also offers interfaces to other models,
    which makes it an interesting tool to compare the responses from different models.
    Anthropic also provide developer access via an API to Claude and Claude Instant.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Anthropic has also partnered with DuckDuckGo, which is a privacy-focused search
    engine and browser designed to integrate with real-time information.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Use**'
  prefs: []
  type: TYPE_NORMAL
- en: Claude is capable of a wide variety of conversational and text-processing tasks
    while maintaining a high degree of reliability and predictability.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Claude can help with use cases, including summarisation, search, creative and
    collaborative writing, Q&A, coding, and more.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Comments**'
  prefs: []
  type: TYPE_NORMAL
- en: Anthropic have written about ([Bai et al., 2022](#ref6_6)) an approach called
    Constitutional AI (CAI) which involves models training models in a safe manner.
    This reflects the history of the company as focused on AI safety research.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: One of the unique things about Claude is its large context size of 100k tokens.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Based on current capabilities Claude is not as strong as GPT-4.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 6.5.5 LLM – Mistral AI Mistral
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Mistral AI was founded in 2023 and only released its first model a short time
    ago. Unlike many of the other players, Mistral is based in Europe (France) and
    has offered its initial model as open source.
  prefs: []
  type: TYPE_NORMAL
- en: '**Release History**'
  prefs: []
  type: TYPE_NORMAL
- en: Table 6.5 Mistral AI Release History
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '| Date | Model | Description |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| 27/Sep/2023 | Mistral-7B | Mistral 7B model is released under an Apache 2
    license. |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '**Specifications**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Mistral AI has released two initial versions: Mistral-7B and Mistral-7B-Instruct.
    It intends to release larger models later. The instruct version is a fine-tuned
    version for question-and-answer interactions such as a chat use case.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The models use grouped-query attention (GQA) for faster inference.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The models use sliding window attention (SWA) to handle longer sequences at
    smaller cost.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The models have been released as open source with an Apache 2 style license.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Based on the benchmarks, they outperforms LLaMA-2 13B on all benchmarks and
    outperforms LLaMA-1 34B on many benchmarks. They approaches CodeLlama 7B performance
    on code, while remaining good at English tasks.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Use**'
  prefs: []
  type: TYPE_NORMAL
- en: The initial models are focused on general purpose English language generation
    and a fine-tuned question–answer model.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: They are also trained on code generation tasks.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Comments**'
  prefs: []
  type: TYPE_NORMAL
- en: This model is open source and available for commercial use, which presents a
    useful alternative for developers.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is also positioning itself as a high-performance model despite its currently
    smaller size.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 6.5.6 Diffusion Model – stability.ai Stable Diffusion
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Stability AI was founded in 2020 and their model, Stable Diffusion, was first
    released in 2022\. This model built on the work from Prof. Dr. Björn Ommer, who
    led the original Stable Diffusion V1 release.
  prefs: []
  type: TYPE_NORMAL
- en: '**Release History**'
  prefs: []
  type: TYPE_NORMAL
- en: Table 6.6 Stable Diffusion Release History
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '| Date | Model | Description |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| Aug/2022 | Stable Diffusion 1.4 | Version 1.4 release. |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| Oct/2022 | Stable Diffusion 1.5 | Version 1.5 release. |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| Nov/2022 | Stable Diffusion 2.0 | Version 2.0 release. |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| Dec/2022 | Stable Diffusion 2.1 | Version 2.1 release. |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| Jul/2023 | Stable Diffusion XL1.0 | New XL version 1.0 release |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '**Specifications**'
  prefs: []
  type: TYPE_NORMAL
- en: Stable Diffusion is a deep learning, text-to-image model based on diffusion
    techniques. It operates as a Latent Diffusion Model with a fixed, pre-trained
    text encoder, known as OpenCLIP-ViT/H, for generating and modifying images based
    on text prompts.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is believed to be trained on over 5 billion images from a variety of sources
    such as Flickr, Wikimedia Commons and LAION-5B.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Use**'
  prefs: []
  type: TYPE_NORMAL
- en: Its primary use is to generate detailed images conditioned on text descriptions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It also supports other tasks such as inpainting (editing within the image),
    outpainting (extending the image outside of the original image), and image-to-image
    translations guided by text prompts.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is noted for its ability to create descriptive images with enhanced
    composition and realistic aesthetics, and it can also generate words within images.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Comments**'
  prefs: []
  type: TYPE_NORMAL
- en: Its flagship image model, SDXL 1.0, is particularly highlighted for its superiority
    in image generation.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Stable Diffusion 2.0 release included robust text-to-image models trained
    using a new text encoder developed by LAION, which significantly improved the
    quality of generated images compared to earlier releases.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 6.5.7 Diffusion Model – OpenAI DALL-E 3
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: DALL-E 3 is the most recent text-to-image model developed by OpenAI, which was
    discussed earlier in the context of ChatGPT. The integration of DALL-E 3 with
    ChatGPT enhances its accessibility and represents a marked advancement over DALL-E
    2.
  prefs: []
  type: TYPE_NORMAL
- en: '**Release History**'
  prefs: []
  type: TYPE_NORMAL
- en: Table 6.7 OpenAI DALL-E Release History
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '| Date | Model | Description |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| 5/Jan/2021 | DALL-E | Initial release |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| 6/Apr/2022 | DALL-E 2 | Version 2 release |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| Sep/2023 | DALL-E 3 | Version 3 release |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '**Specifications**'
  prefs: []
  type: TYPE_NORMAL
- en: DALL-E 3 is a text-to-image model based on diffusion techniques.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It has been built natively on ChatGPT. When prompted with an idea, ChatGPT will
    automatically generate tailored and detailed prompts for DALL-E 3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Use**'
  prefs: []
  type: TYPE_NORMAL
- en: Image generation where the details of the prompt are important in providing
    a more nuanced output image.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Comments**'
  prefs: []
  type: TYPE_NORMAL
- en: DALL-E 3 has put more effort into ‘safety’ where prompts can’t generate images
    in the style of living artists and creators can request their works to be excluded
    from training of future image generation models.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: DALL-E 3-generated images belong to the prompter.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 6.5.8 Diffusion Model – Midjourney Inc. Midjourney
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Midjourney was founded by David Holt. Distinctively, unlike other AI start-ups,
    it generated substantial revenue prior to securing venture capital funding. Their
    inaugural model, released in 2022, gained popularity, and its integration with
    Discord appeared to bolster its prominence.
  prefs: []
  type: TYPE_NORMAL
- en: '**Release History**'
  prefs: []
  type: TYPE_NORMAL
- en: Table 6.8 Midjourney Release History
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '| Date | Model | Description |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| Feb/2022 | Midjourney V1 | Version 1 release |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| 12/Apr/2022 | Midjourney V2 | Version 2 release |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| 25/Jul/2022 | Midjourney V3 | Version 3 release |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| 5/Nov/2022 | Midjourney V4 | Version 4 release |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| 15/Mar/2023 | Midjourney V5 | Version 5 release |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| 3/May/2023 | Midjourney V5.1 | Version 5.1 release |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| 22/Jun/2023 | Midjourney V5.2 | Version 5.2 release |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '**Specifications**'
  prefs: []
  type: TYPE_NORMAL
- en: Midjourney is a diffusion model and uses a transformer neural network to generate
    images from text prompts.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The diffusion process is designed to generate more creative and expressive images
    than some of the other models.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Use**'
  prefs: []
  type: TYPE_NORMAL
- en: Midjourney is designed to be user-friendly and accessible through Discord.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Comments**'
  prefs: []
  type: TYPE_NORMAL
- en: Some of Midjourney’s experimental algorithms might have licensing limitations
    under the Creative ML OpenRAIL-M license, as implied by a recent amendment to
    their terms of service.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 6.5.9 Speech Recognition – OpenAI Whisper
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The Whisper model from OpenAI has been released as an open source model with
    the objective of facilitating its use in a wide variety of situations, including
    embedded scenarios where speech-to-text capabilities are beneficial.
  prefs: []
  type: TYPE_NORMAL
- en: '**Release History**'
  prefs: []
  type: TYPE_NORMAL
- en: Table 6.9 OpenAI Whisper Release History
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '| Date | Model | Description |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| 21/Sep/2022 | Whisper | Robust Speech Recognition via Large-Scale Weak Supervision
    ([Radford et al., 2022](#ref6_51)) |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '**Specifications**'
  prefs: []
  type: TYPE_NORMAL
- en: It is an encoder-decoder transformer architecture.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The encoder processes input with two convolutional layers and the decoder uses
    learned positional encodings.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It has been trained on over 680,000 hours of multilingual and multitasked data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Use**'
  prefs: []
  type: TYPE_NORMAL
- en: Whisper is an automatic speech recognition system supporting multiple languages
    with ability to understand accents and background noise. In real time it can transcribe
    speech into text.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is provided as open source in a manner that allows it to be integrated
    into products.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Comments**'
  prefs: []
  type: TYPE_NORMAL
- en: It approaches human-level robustness and accuracy on English speech recognition.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: One of the big advantages of Whisper is that it does well on zero-shot tasks,
    meaning that it does not required examples of a person’s speech to transcribe
    it.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 6.6 Conclusions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Artificial Neural Networks (ANNs) and Deep Neural Networks (DNNs) have a long
    history in AI. They have essentially been present since the inception of the AI
    discipline, tracing back to the Dartmouth Summer Research Project.
  prefs: []
  type: TYPE_NORMAL
- en: The objective of ANNs and DNNs has always been to develop a computer program
    capable of learning in the manner humans do, acquiring expertise across various
    domains, or potentially any area on which it is trained.
  prefs: []
  type: TYPE_NORMAL
- en: Today, this ambition appears more attainable than ever before. The capabilities
    of these neural networks may well be boundless, provided we have sufficiently
    advanced computers to support ever-expanding models and an increasing wealth of
    data to train these models across the diverse topics we wish them to master.
  prefs: []
  type: TYPE_NORMAL
- en: The process of creating, training, and testing a model has never been more accessible.
    This ease is due to the availability of knowledge, which aids in building the
    necessary expertise, the ready access to the models themselves, data to train
    them, and benchmarks for testing. Fine-tuning an existing foundational model is
    now comparatively straightforward and can be undertaken even by relatively inexperienced
    individuals or teams. We observe state-of-the-art (SOTA) models being released
    under flexible commercial licenses (e.g., LLaMA-2) or genuine open-source licenses
    for parts of the model environment (e.g., Mistral, Whisper, Stable Diffusion).
    The prevalence of comprehensive free online courses about machine learning further
    reduces barriers to knowledge, enabling individuals to acquire profound expertise.
    Furthermore, the prospect of quantum computing is imminent, promising transformative
    advancements in processing capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: All these developments arguably reinforce the notion that AGI (Artificial General
    Intelligence) and ASI (Artificial Superintelligence) are inevitable, destined
    to reach previously inconceivable levels of intelligence.
  prefs: []
  type: TYPE_NORMAL
- en: Nevertheless, it is prudent to recall past warnings against overestimating the
    potential of neural networks. History reminds us of two prior AI ‘winters’, where
    such overconfidence played a significant role.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Ackley, D. H., Hinton, G. E., & Sejnowski, T. J.](#R_ref6_1) (1985). A learning
    algorithm for Boltzmann machines. Cognitive Science, *9*(2), 147–169.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Anil, R., Dai, A. M., Firat, O., Johnson, M., Lepikhin, D., Passos, A., Shakeri,
    S., Taropa, E., Bailey, P., Chen, Z., … & Saeta, B.](#R_ref6_2) (2023). PaLM 2
    technical report [Preprint]. [https://doi.org/10.48550/arXiv.2305.10403](https://doi.org/10.48550/arXiv.2305.10403)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Arute, F., Arya, K., Babbush, R., Bacon, D., Bardin, J. C., Barends, R., …
    & Martinis, J. M.](#R_ref6_3) (2019). Quantum supremacy using a programmable superconducting
    processor. Nature, *574*(7779), 505–510\. [https://doi.org/10.1038/s41586-019-1666-5](https://doi.org/10.1038/s41586-019-1666-5)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Asimov, I.](#R_ref6_4) (1950). Runaround. In The Isaac Asimov Collection (Ed.),
    I, Robot (p. 40). Doubleday.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Austin, J., Odena, A., Nye, M., Bosma, M., Michalewski, H., Dohan, D., Jiang,
    E., Cai, C., Terry, M., Le, Q., & Sutton, C.](#R_ref6_5) (2021). Program synthesis
    with large language models [Preprint]. [https://doi.org/10.48550/arXiv.2108.07732](https://doi.org/10.48550/arXiv.2108.07732)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Bai, Y., Kadavath, S., Kundu, S., Askell, A., Kernion, J., Jones, A., Chen,
    A., Goldie, A., Mirhoseini, A., McKinnon, C., Chen, C., Olsson, C., Olah, C.,
    Hernandez, D., Drain, D., Ganguli, D., Li, D., Tran-Johnson, E., Perez, E., Kerr,
    J., … Kaplan, J.](#R_ref6_6) (2022). Constitutional AI: Harmlessness from AI feedback
    [Preprint]. [https://doi.org/10.48550/arXiv.2212.08073](https://doi.org/10.48550/arXiv.2212.08073)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Bisk, Y., Zellers, R., Le Bras, R., Gao, J., & Choi, Y.](#R_ref6_7) (2020).
    PIQA: Reasoning about physical commonsense in natural language. In *AAAI 2020*.
    [https://doi.org/10.48550/arXiv.1911.11641](https://doi.org/10.48550/arXiv.1911.11641)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Block, H. D., Knight, B. W. Jr., & Rosenblatt, F.](#R_ref6_8) (1962). Analysis
    of a four-layer series-coupled perceptron II. Reviews of Modern Physics, *34*(1),
    135\. [https://doi.org/10.1103/RevModPhys.34.135](https://doi.org/10.1103/RevModPhys.34.135)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Breiman, L.](#R_ref6_9) (2001). Random forests. Machine Learning, *45*(1),
    5–32\. [https://doi.org/10.1023/A:1010933404324](https://doi.org/10.1023/A:1010933404324)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Brown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P.,
    Neelakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S., Herbert-Voss,
    A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler, D. M., Wu, J.,
    Winter, C., Hesse, C., Chen, M., Sigler, E., Litwin, M., Gray, S., Chess, B.,
    Clark, J., Berner, C., McCandlish, S., Radford, A., Sutskever, I., & Amodei, D.](#R_ref6_10)
    (2020). Language models are few-shot learners. arXiv preprint. [https://doi.org/10.48550/arXiv.2005.14165](https://doi.org/10.48550/arXiv.2005.14165)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Chen, M., Tworek, J., Jun, H., Yuan, Q., Pinto, H. P. de O., Kaplan, J., Edwards,
    H., Burda, Y., Joseph, N., Brockman, G., Ray, A., Puri, R., Krueger, G., Petrov,
    M., Khlaaf, H., Sastry, G., Mishkin, P., Chan, B., Gray, S., Ryder, N., Pavlov,
    M., Power, A., Kaiser, L., Bavarian, M., Winter, C., Tillet, P., Such, F. P.,
    Cummings, D., Plappert, M., Chantzis, F., Barnes, E., Herbert-Voss, A., Guss,
    W. H., Nichol, A., Paino, A., Tezak, N., Tang, J., Babuschkin, I., Balaji, S.,
    Jain, S., Saunders, W., Hesse, C., Carr, A. N., Leike, J., Achiam, J., Misra,
    V., Morikawa, E., Radford, A., Knight, M., Brundage, M., Murati, M., Mayer, K.,
    Welinder, P., McGrew, B., Amodei, D., McCandlish, S., Sutskever, I., & Zaremba,
    W.](#R_ref6_11) (2021). Evaluating large language models trained on code (Version
    v2) [Preprint]. [https://doi.org/10.48550/arXiv.2107.03374](https://doi.org/10.48550/arXiv.2107.03374)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Cheng, H.-T., Koc, L., Harmsen, J., Shaked, T., Chandra, T., Aradhye, H.,
    Anderson, G., Corrado, G., Chai, W., Ispir, M., Anil, R., Haque, Z., Hong, L.,
    Jain, V., Liu, X., & Shah, H.](#R_ref6_12) (2016). Wide & deep learning for recommender
    systems. arXiv:1606.07792 [cs.LG]. [https://doi.org/10.48550/arXiv.1606.07792](https://doi.org/10.48550/arXiv.1606.07792)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Chowdhery, A., Narang, S., Devlin, J., Bosma, M., Mishra, G., Roberts, A.,
    Barham, P., Chung, H. W., Sutton, C., Gehrmann, S., … & Fiedel, N.](#R_ref6_13)
    (2022). PaLM: Scaling language modeling with pathways [Preprint]. [https://doi.org/10.48550/arXiv.2204.02311](https://doi.org/10.48550/arXiv.2204.02311)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Clark, C., Lee, K., Chang, M.-W., Kwiatkowski, T., Collins, M., & Toutanova,
    K. (2019). BoolQ: Exploring the surprising difficulty of natural yes/no questions.
    *NAACL 2019*. [https://doi.org/10.48550/arXiv.1905.10044](https://doi.org/10.48550/arXiv.1905.10044)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Clark, P., Cowhey, I., Etzioni, O., Khot, T., Sabharwal, A., Schoenick, C.,
    & Tafjord, O.](#R_ref6_15) (2018). Think you have solved question answering? Try
    ARC, the AI2 reasoning challenge. arXiv preprint arXiv:1803.05457\. [https://doi.org/10.48550/arXiv.1803.05457](https://doi.org/10.48550/arXiv.1803.05457)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Cobbe, K., Kosaraju, V., Bavarian, M., Chen, M., Jun, H., Kaiser, L., Plappert,
    M., Tworek, J., Hilton, J., Nakano, R., Hesse, C., & Schulman, J.](#R_ref6_16)
    (2021). Training verifiers to solve math word problems (Version v2) [Preprint].
    [https://doi.org/10.48550/arXiv.2110.14168](https://doi.org/10.48550/arXiv.2110.14168)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Feynman, R. P.](#R_ref6_17) (1982). Simulating physics with computers. International
    Journal of Theoretical Physics, *21*(6/7), 467–488.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Friedman, J. H.](#R_ref6_18) (2002). Stochastic gradient boosting. Computational
    Statistics & Data Analysis, *38*(4), 367–378\. [https://doi.org/10.1016/S0167-9473(01)00065-2](https://doi.org/10.1016/S0167-9473(01)00065-2)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Future of Life Institute](#R_ref6_19). (2023a). An open letter: Pause giant
    AI experiments. Retrieved [insert date of retrieval here], from [https://futureoflife.org/open-letter/pause-giant-ai-experiments/](https://futureoflife.org)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Future of Life Institute](#R_ref6_20). (2023b). Policymaking in the pause.
    [https://futureoflife.org/wp-content/uploads/2023/04/FLI_Policymaking_In_The_Pause.pdf](https://futureoflife.org)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Gehman, S., Gururangan, S., Sap, M., Choi, Y., & Smith, N. A.](#R_ref6_21)
    (2020). RealToxicityPrompts: Evaluating neural toxic degeneration in language
    models [Preprint]. [https://doi.org/10.48550/arXiv.2009.11462](https://doi.org/10.48550/arXiv.2009.11462)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Goodfellow, I., Bengio, Y., & Courville, A.](#R_ref6_22) (2016). Deep learning.
    MIT Press. [http://www.deeplearningbook.org](http://www.deeplearningbook.org)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Goodfellow, I. J., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D.,
    Ozair, S., Courville, A., & Bengio, Y.](#R_ref6_23) (2014). Generative adversarial
    networks arXiv preprint arXiv:1406.2661\. [https://doi.org/10.48550/arXiv.1406.2661](https://doi.org/10.48550/arXiv.1406.2661)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Hebb, D. O.](#R_ref6_24) (1949). The organization of behavior: A neuropsychological
    theory. John Wiley & Sons; Chapman & Hall.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Hendrycks, D., Burns, C., Basart, S., Zou, A., Mazeika, M., Song, D., & Steinhardt,
    J.](#R_ref6_25) (2020). Measuring massive multitask language understanding [Preprint].
    [https://doi.org/10.48550/arXiv.2009.03300](https://doi.org/10.48550/arXiv.2009.03300)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Hendrycks, D., Burns, C., Kadavath, S., Arora, A., Basart, S., Tang, E., Song,
    D., & Steinhardt, J.](#R_ref6_26) (2021). Measuring mathematical problem solving
    with the MATH dataset (Version v2) [Preprint]. NeurIPS. [https://doi.org/10.48550/arXiv.2103.03874](https://doi.org/10.48550/arXiv.2103.03874)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Hinton, G. E., Osindero, S., & Teh, Y-W.](#R_ref6_27) (2006). A fast learning
    algorithm for deep belief nets. Neural Computation, *18*(7), 1527–1554\. [https://doi.org/10.1162/neco.2006.18.7.1527](https://doi.org/10.1162/neco.2006.18.7.1527)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Hochreiter, S., & Schmidhuber, J.](#R_ref6_28) (1997). Long short-term memory.
    Neural Computation, *9*(8), 1735–1780\. [https://doi.org/10.1162/neco.1997.9.8.1735](https://doi.org/10.1162/neco.1997.9.8.1735)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hopfield, J. J. (1982). Neural networks and physical systems with emergent collective
    computational abilities. Proceedings of the National Academy of Sciences of the
    USA, *79*(8), 2554–2558.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Joshi, M., Choi, E., Weld, D. S., & Zettlemoyer, L.](#R_ref6_30) (2017). TriviaQA:
    A large scale distantly supervised challenge dataset for reading comprehension
    (Version v2) [Preprint]. arXiv. [https://doi.org/10.48550/arXiv.1705.03551](https://doi.org/10.48550/arXiv.1705.03551)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Joulin, A., Grave, E., Bojanowski, P., Douze, M., Jégou, H., & Mikolov, T.](#R_ref6_31)
    (2016). FastText.zip: Compressing text classification models. *arXiv:1612.03651
    [cs.CL]*. [https://doi.org/10.48550/arXiv.1612.03651](https://doi.org/10.48550/arXiv.1612.03651)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Kaur, S., Singh, S., & Kaushal, S.](#R_ref6_32) (2021). Abusive content detection
    in online user-generated data: A survey. Procedia Computer Science. [https://doi.org/10.1016/j.procs.2021.05.098](https://doi.org/10.1016/j.procs.2021.05.098)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Krizhevsky, A., Sutskever, I., & Hinton, G. E.](#R_ref6_33) (2012). ImageNet
    classification with deep convolutional neural networks. Advances in Neural Information
    Processing Systems, *25*(2). [https://doi.org/10.1145/3065386](https://doi.org/10.1145/3065386)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Kwiatkowski, T., Palomaki, J., Redfield, O., Collins, M., Parikh, A., Alberti,
    C., Epstein, D., Polosukhin, I., Kelcey, M., Devlin, J., Lee, K., Toutanova, K.
    N., Jones, L., Chang, M.-W., Dai, A., Uszkoreit, J., Le, Q., & Petrov, S.](#R_ref6_34)
    (2019). Natural questions: A benchmark for question answering research. Transactions
    of the Association of Computational Linguistics, 7(15), 453–466\. [https://doi.org/10.1162/tacl_a_00276](https://doi.org/10.1162/tacl_a_00276)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Lai, G., Xie, Q., Liu, H., Yang, Y., & Hovy, E.](#R_ref6_35) (2017). RACE:
    Large-scale reading comprehension dataset from examinations (Version v5) [Preprint].
    arXiv. [https://doi.org/10.48550/arXiv.1704.04683](https://doi.org/10.48550/arXiv.1704.04683)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Le, Q. V., Ranzato, M., Monga, R., Devin, M., Chen, K., Corrado, G. S., Dean,
    J., & Ng, A. Y.](#R_ref6_36) (2011). Building high-level features using large
    scale unsupervised learning. arXiv:1112.6209\. [https://doi.org/10.48550/arXiv.1112.6209](https://doi.org/10.48550/arXiv.1112.6209)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LeCun, Y., Boser, B., Denker, J. S., Henderson, D., Howard, R. E., Hubbard,
    W., & Jackel, L. D.](#R_ref6_37) (1989). Backpropagation applied to handwritten
    zip code recognition. Neural Computation, *1*(4), 541–551.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LeCun, Y., Bottou, L., Bengio, Y., & Haffner, P. (1998). Gradient-based learning
    applied to document recognition. Proceedings of the IEEE, *86*(11), 2278–2324\.
    [https://doi.org/10.1109/5.726791](https://doi.org/10.1109/5.726791)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Lin, S., Hilton, J., & Evans, O.](#R_ref6_39) (2022). TruthfulQA: Measuring
    how models mimic human falsehoods [Preprint]. [https://doi.org/10.48550/arXiv.2109.07958](https://doi.org/10.48550/arXiv.2109.07958)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[McCarthy, J., Minsky, M. L., Rochester, N., & Shannon, C. E.](#R_ref6_40)
    (1955, August 31). A proposal for the Dartmouth summer research project on artificial
    intelligence. Dartmouth College; Harvard University; I.B.M. Corporation; Bell
    Telephone Laboratories.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'McClelland, J. L., Rumelhart, D. E., & PDP Research Group. (1987). Parallel
    distributed processing: Explorations in the microstructure of cognition: Psychological
    and biological models (Vol. 2). The MIT Press. [https://doi.org/10.7551/mitpress/5237.001.0001](https://doi.org/10.7551/mitpress/5237.001.0001)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[McCulloch, W. S., & Pitts, W.](#R_ref6_42) (1943). A logical calculus of the
    ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics, *5*(4),
    115–133\. [https://doi.org/10.1007/BF02478259](https://doi.org/10.1007/BF02478259)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Mihaylov, T., Clark, P., Khot, T., & Sabharwal, A.](#R_ref6_43) (2018). Can
    a suit of armor conduct electricity? A new dataset for open book question answering.
    arXiv preprint arXiv:1809.02789\. [https://doi.org/10.48550/arXiv.1809.02789](https://doi.org/10.48550/arXiv.1809.02789)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Minsky, M., & Papert, S. A. (1969). Perceptrons: An introduction to computational
    geometry. MIT Press.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Minsky, M., & Papert, S. A.](#R_ref6_45) (1988). Perceptrons: An introduction
    to computational geometry (Expanded subsequent ed.). Massachusetts Institute of
    Technology.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Nangia, N., Vania, C., Bhalerao, R., & Bowman, S. R.](#R_ref6_46) (2020).
    CrowS-Pairs: A challenge dataset for measuring social biases in masked language
    models [Preprint]. [https://doi.org/10.48550/arXiv.2010.00133](https://doi.org/10.48550/arXiv.2010.00133)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Oliva, A., & Torralba, A.](#R_ref6_47) (2001) Modeling the shape of the scene:
    A holistic representation of the spatial envelope. A. International Journal of
    Computer Vision, *42*(3), 145–175.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[OpenAI](#R_ref6_48). (2023). GPT-4 technical report [Preprint]. [https://doi.org/10.48550/arXiv.2303.08774](https://doi.org/10.48550/arXiv.2303.08774)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Patel, J. M.](#R_ref6_49) (2020). Introduction to common crawl datasets. In
    Getting structured data from the internet. Apress. [https://doi.org/10.1007/978-1-4842-6576-5_6](https://doi.org/10.1007/978-1-4842-6576-5_6)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Radford, A., Kim, J. W., Hallacy, C., Ramesh, A., Goh, G., Agarwal, S., Sastry,
    G., Askell, A., Mishkin, P., Clark, J., Krueger, G., & Sutskever, I.](#R_ref6_50)
    (2021). Learning transferable visual models from natural language supervision.
    [https://doi.org/10.48550/arXiv.2103.00020](https://doi.org/10.48550/arXiv.2103.00020)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Radford, A., Kim, J. W., Xu, T., Brockman, G., McLeavey, C., & Sutskever,
    I.](#R_ref6_51) (2022). Robust speech recognition via large-scale weak supervision.
    arXiv preprint. [https://doi.org/10.48550/arXiv.2212.04356](https://doi.org/10.48550/arXiv.2212.04356)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Radford, A., Narasimhan, K., Salimans, T., & Sutskever, I.](#R_ref6_52) (2018).
    Improving language understanding by generative pre-training. OpenAI. Retrieved
    from [https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf](https://cdn.openai.com)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., & Sutskever, I.](#R_ref6_53)
    (2019). Language models are unsupervised multitask learners. OpenAI. Retrieved
    from [https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf](https://cdn.openai.com)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Raffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., Zhou,
    Y., Li, W., & Liu, P. J.](#R_ref6_54) (2023). Exploring the limits of transfer
    learning with a unified text-to-text transformer (Version 4) [Preprint]. arXiv.
    [https://doi.org/10.48550/arXiv.1910.10683](https://doi.org/10.48550/arXiv.1910.10683)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Rajpurkar, P., Jia, R., & Liang, P.](#R_ref6_55) (2018). Know what you don’t
    know: Unanswerable questions for SQuAD (Version v1) [Preprint]. arXiv. [https://doi.org/10.48550/arXiv.1806.03822](https://doi.org/10.48550/arXiv.1806.03822)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Rajpurkar, P., Zhang, J., Lopyrev, K., & Liang, P.](#R_ref6_56) (2016). SQuAD:
    100,000+ questions for machine comprehension of text (Version v3) [Preprint].
    arXiv. [https://doi.org/10.48550/arXiv.1606.05250](https://doi.org/10.48550/arXiv.1606.05250)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Rosenblatt, F.](#R_ref6_57) (1957). The perceptron—A perceiving and recognizing
    automaton (Report No. 85-460-1). Cornell Aeronautical Laboratory.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Rosenblatt, F.](#R_ref6_58) (1958). The perceptron: A probabilistic model
    for information storage and organization in the brain. Psychological Review, *65*(6),
    386–408\. [https://doi.org/10.1037/h0042519](https://doi.org/10.1037/h0042519)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Rudinger, R., Naradowsky, J., Leonard, B., & Van Durms, B.](#R_ref6_59) (2018).
    Gender bias in coreference resolution [Preprint]. [https://doi.org/10.48550/arXiv.1804.09301](https://doi.org/10.48550/arXiv.1804.09301)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Rumelhart, D. E., Hinton, G. E., & Williams, R. J.](#R_ref6_60) (1985). Learning
    internal representations by error propagation (ICS Report 8506). Institute for
    Cognitive Science, University of California San Diego.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Rumelhart, D. E., Hinton, G. E., & Williams, R. J.](#R_ref6_61) (1986a). Learning
    internal representations by error propagation. In D. E. Rumelhart, J. L. McClelland,
    and the PDP Research Group (Eds.), Parallel distributed processing: Explorations
    in the microstructure of cognition. Volume 1: Foundations (pp. 318–362). MIT Press.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Rumelhart, D. E., Hinton, G. E., & Williams, R. J.](#R_ref6_62) (1986b). Learning
    representations by back-propagating errors. Nature, *323*(6088), 533–536.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Rumelhart, D. E., McClelland, J. L.](#R_ref6_63), & PDP Research Group. (1986c).
    Parallel distributed processing: Explorations in the microstructure of cognition:
    Foundations (Vol. 1). The MIT Press. [https://doi.org/10.7551/mitpress/5236.001.0001](https://doi.org/10.7551/mitpress/5236.001.0001)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Russell, B., Torralba, A., Murphy, K., & Freeman, W. T.](#R_ref6_64) (2007).
    LabelMe: A database and web-based tool for image annotation. International Journal
    of Computer Vision, *77*(1–3), 157–173.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Sakaguchi, K., Le Bras, R., Bhagavatula, C., & Choi, Y.](#R_ref6_65) (2019).
    WinoGrande: An adversarial Winograd schema challenge at scale. arXiv preprint
    arXiv:1907.10641\. [https://doi.org/10.48550/arXiv.1907.10641](https://doi.org/10.48550/arXiv.1907.10641)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Sap, M., Rashkin, H., Chen, D., LeBras, R., & Choi, Y.](#R_ref6_66) (2019).
    SocialIQA: Commonsense reasoning about social interactions. In *Proceedings of
    the 2019 Conference on Empirical Methods in Natural Language Processing (EMNLP
    2019)*. [https://arxiv.org/abs/1904.09728](https://arxiv.org)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Schuhmann, C., Beaumont, R., Vencu, R., Gordon, C., Wightman, R., Cherti,
    M., Coombes, T., Katta, A., Mullis, C., Wortsman, M., Schramowski, P., Kundurthy,
    S., Crowson, K., Schmidt, L., Kaczmarczyk, R., & Jitsev, J.](#R_ref6_67) (2022).
    LAION-5B: An open large-scale dataset for training next generation image-text
    models. [https://doi.org/10.48550/arXiv.2210.08402](https://doi.org/10.48550/arXiv.2210.08402)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Snoswell, A. J., & Burgess, J.](#R_ref6_68) (2022, November 29). The Galactica
    AI model was trained on scientific knowledge – But it spat out alarmingly plausible
    nonsense. The Conversation. [https://theconversation.com/the-galactica-ai-model-was-trained-on-scientific-knowledge-but-it-spat-out-alarmingly-plausible-nonsense-195445](https://theconversation.com)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tesauro, G. (1995). Temporal difference learning and TD-Gammon. Communications
    of the ACM, *38*(3), 58–68.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Thoppilan, R., De Freitas, D., Hall, J., Shazeer, N., Kulshreshtha, A., Cheng,
    H.-T., Jin, A., Bos, T., Baker, L., Du, Y., Li, Y., Lee, H., Zheng, H. S., Ghafouri,
    A., Menegali, M., Huang, Y., Krikun, M., Lepikhin, D., Qin, J., Chen, D., … Le,
    Q.](#R_ref6_70) (2022). LaMDA: Language models for dialog applications. arXiv
    preprint. [https://doi.org/10.48550/arXiv.2201.08239](https://doi.org/10.48550/arXiv.2201.08239)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Touvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M.-A., Lacroix,
    T., Rozière, B., Goyal, N., Hambro, E., Azhar, F., Rodriguez, A., Joulin, A.,
    Grave, E., & Lample, G.](#R_ref6_71) (2023a). LLaMA: Open and efficient foundation
    language models. arXiv preprint. [https://doi.org/10.48550/arXiv.2302.13971](https://doi.org/10.48550/arXiv.2302.13971)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Touvron, H., Martin, L., Stone, K., Albert, P., Almahairi, A., Babaei, Y.,
    Bashlykov, N., Batra, S., Bhargava, P., Bhosale, S., Bikel, D., Blecher, L., Ferrer,
    C. C., Chen, M., Cucurull, G., Esiobu, D., Fernandes, J., Fu, J., Fu, W., Fuller,
    B., … Scialom, T.](#R_ref6_72) (2023b). Llama 2: Open foundation and fine-tuned
    chat models. arXiv preprint. [https://doi.org/10.48550/arXiv.2307.09288](https://doi.org/10.48550/arXiv.2307.09288)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Turing, A. M.](#R_ref6_73) (1950). Computing machinery and intelligence. Mind,
    *49*, 433–460.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.
    N., Kaiser, L., & Polosukhin, I.](#R_ref6_74) (2017). Attention is all you need.
    arXiv preprint arXiv:1706.03762v7\. [https://doi.org/10.48550/arXiv.1706.03762](https://doi.org/10.48550/arXiv.1706.03762)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Wahba, G., Lin, Y., Zhang, H. H., & Lee, Y.](#R_ref6_75) (2002). Support vector
    machines, reproducing Kernel Hilbert spaces and the randomized GACV. In B. Schölkopf
    & M. K. Warmuth (Eds.), Advances in large margin classifiers (pp. 1–69). MIT Press.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Wang, A., Pruksachatkun, Y., Nangia, N., Singh, A., Michael, J., Hill, F.,
    Levy, O., & Bowman, S. R.](#R_ref6_76) (2019). SuperGLUE: A stickier benchmark
    for general-purpose language understanding systems. *NeurIPS 2019*. Retrieved
    from [super.gluebenchmark.com](http://super.gluebenchmark.com)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Wang, A., Singh, A., Michael, J., Hill, F., Levy, O., & Bowman, S. R.](#R_ref6_77)
    (2018). GLUE: A multi-task benchmark and analysis platform for natural language
    understanding. *ICLR 2019*. arXiv:1804.07461\. [https://gluebenchmark.com/](https://gluebenchmark.com)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Weizenbaum, J.](#R_ref6_78) (1976). Computer power and human reason: From
    judgment to calculation. W. H. Freeman.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Wenzek, G., Lachaux, M.-A., Conneau, A., Chaudhary, V., Guzmán, F., Joulin,
    A., & Grave, E.](#R_ref6_79) (2019). CCNet: Extracting high quality monolingual
    datasets from web crawl data. [https://doi.org/10.48550/arXiv.1911.00359](https://doi.org/10.48550/arXiv.1911.00359)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Werbos, P. J.](#R_ref6_80) (1974). *Beyond Regression: New Tools for prediction
    and Analysis in the behavioral sciences* (Doctoral dissertation, Harvard University).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Widrow, B.](#R_ref6_81) (1960). *An adaptive “ADALINE: Neuron using chemical
    “MEMISTORS”* (Technical Report No. 1553-2).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Widrow, B.](#R_ref6_82) (1962). Generalization and information storage in
    networks of Adaline ‘neurons’. In M. C. Yovitz, G. T. Jacobi, & G. Goldstein (Eds.),
    Self-organizing systems: Symposium proceedings (pp. 435–461). Spartan Books.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Wiener, N.](#R_ref6_83) (1966). God & Golem, Inc.: A comment on certain points
    where cybernetics impinges on religion. The MIT Press.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Zellers, R., Bisk, Y., Schwartz, R., & Choi, Y.](#R_ref6_84) (2018). SWAG:
    A large-scale adversarial dataset for grounded commonsense inference. *Proceedings
    of the 2018 conference on empirical methods in natural language processing (EMNLP
    2018)*. [https://doi.org/10.48550/arXiv.1808.05326](https://doi.org/10.48550/arXiv.1808.05326)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Zellers, R., Holtzman, A., Bisk, Y., Farhadi, A., & Choi, Y.](#R_ref6_85)
    (2019). HellaSwag: Can a machine really finish your sentence? In *Proceedings
    of the 57th annual meeting of the association for computational linguistics (ACL
    2019)*. [https://doi.org/10.48550/arXiv.1905.07830](https://doi.org/10.48550/arXiv.1905.07830)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
