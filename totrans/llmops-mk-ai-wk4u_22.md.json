["```py\n`# Import the DSL (domain‑specific language) and the compiler from the Kubeflow Pipelines SDK from  kfp  import dsl from  kfp  import compiler` \n```", "```py\n`# Suppress FutureWarning originating from the Kubeflow Pipelines SDK import  warnings warnings.filterwarnings(\"ignore\", category=FutureWarning, module='kfp.*')` \n```", "```py\n`# Import the DSL module to define components and pipelines from  kfp  import dsl  # Define a simple component using the @dsl.component decorator @dsl.component def  greet_person(name: str) -> str:     # Form a greeting by combining \"Hello\" with the input name     greeting_message = f'Hello, {name}!'      # Return the constructed greeting message     return greeting_message` \n```", "```py\n`# Assign the result of calling the component function to a variable hello_task = greet_person(name=\"Erwin\") print(hello_task)` \n```", "```py\n`# Access the component’s output via the .output attribute print(hello_task.output)` \n```", "```py\n`# This will raise an error because it uses a positional argument # hello_task = greet_person(\"Erwin\")  # Correct: call with a named argument hello_task = greet_person(name=\"Erwin\")` \n```", "```py\n`# Import DSL to define components from  kfp  import dsl  # Define a component that depends on another component’s output @dsl.component def  ask_about_wellbeing(greeting_message: str) -> str:     # Form a new message that includes the greeting and a follow‑up question     follow_up_message = f\"{greeting_message}. How are you?\"      # Return the new message     return follow_up_message` \n```", "```py\n`# Create a task for the first component and keep its output greeting_task = greet_person(name=\"Erwin\")  # Feed the first component’s output into the second component wellbeing_task = ask_about_wellbeing(greeting_message=greeting_task.output) print(wellbeing_task) print(wellbeing_task.output)` \n```", "```py\n`# Incorrect: passing a PipelineTask instead of its output — this will error # wellbeing_task = ask_about_wellbeing(greeting_message=greeting_task)  # Correct: pass the task’s .output attribute wellbeing_task = ask_about_wellbeing(greeting_message=greeting_task.output)` \n```", "```py\n`# Import DSL to define pipelines from  kfp  import dsl  # Define a pipeline that orchestrates the greeting and follow‑up components @dsl.pipeline def  hello_and_wellbeing_pipeline(recipient_name: str) -> str:     # Task for the greet_person component     greeting_task = greet_person(name=recipient_name)      # Task for ask_about_wellbeing, using greeting_task’s output     wellbeing_task = ask_about_wellbeing(greeting_message=greeting_task.output)      # Return the final message produced by wellbeing_task     return wellbeing_task.output` \n```", "```py\n`# Run the pipeline with a recipient name pipeline_output = hello_and_wellbeing_pipeline(recipient_name=\"Erwin\") print(pipeline_output)` \n```", "```py\n`# Incorrect pipeline that returns a PipelineTask object @dsl.pipeline def  hello_and_wellbeing_pipeline_with_error(recipient_name: str) -> str:     greeting_task = greet_person(name=recipient_name)     wellbeing_task = ask_about_wellbeing(greeting_message=greeting_task.output)      # Incorrect: returning the PipelineTask itself     return wellbeing_task     # This will error` \n```", "```py\n`# Import the compiler from the Kubeflow Pipelines SDK from  kfp  import compiler  # Compile the pipeline to a YAML file compiler.Compiler().compile(hello_and_wellbeing_pipeline, 'pipeline.yaml')` \n```", "```py\n`# Inspect the compiled pipeline YAML (cross-platform Python approach) from  pathlib  import Path print(Path('pipeline.yaml').read_text())` \n```", "```py\n`cat  pipeline.yaml  # Linux/macOS type  pipeline.yaml  # Windows` \n```", "```py\n`# Define pipeline arguments pipeline_arguments = {     \"recipient_name\": \"World!\", }` \n```", "```py\n`from  google.cloud.aiplatform  import PipelineJob  job = PipelineJob(     template_path=\"pipeline.yaml\",     display_name=\"hello_and_wellbeing_ai_pipeline\",     parameter_values=pipeline_arguments,     location=\"us-central1\",     pipeline_root=\"./\", )  job.submit() print(job.state)` \n```", "```py\n`TRAINING_DATA_URI = \"./tune_data_stack_overflow_python_qa.jsonl\" EVALUATION_DATA_URI = \"./tune_eval_data_stack_overflow_python_qa.jsonl\"  import  datetime date = datetime.datetime.now().strftime(\"%H:%d:%m:%Y\") MODEL_NAME = f\"deep-learning-ai-model-{date}\"` \n```", "```py\n`TRAINING_STEPS = 200 EVALUATION_INTERVAL = 20` \n```", "```py\n`from  utils  import authenticate credentials, PROJECT_ID = authenticate() REGION = \"us-central1\"` \n```", "```py\n`pipeline_arguments = {     \"model_display_name\": MODEL_NAME,     \"location\": REGION,     \"large_model_reference\": \"text-bison@001\",     \"project\": PROJECT_ID,     \"train_steps\": TRAINING_STEPS,     \"dataset_uri\": TRAINING_DATA_URI,     \"evaluation_interval\": EVALUATION_INTERVAL,     \"evaluation_data_uri\": EVALUATION_DATA_URI, }` \n```", "```py\n`from  google.cloud.aiplatform  import PipelineJob  pipeline_root = \"./\"  job = PipelineJob(     template_path=template_path,     display_name=f\"deep_learning_ai_pipeline-{date}\",     parameter_values=pipeline_arguments,     location=REGION,     pipeline_root=pipeline_root,     enable_caching=True, )  job.submit() print(job.state)` \n```"]