["```r\nlibrary(torch)\nlibrary(zeallot) # for destructuring using %<-%\n\nrnn_cell <- nn_module(\n initialize = function(input_size, hidden_size) {\n self$linear_i_h <- nn_linear(input_size, hidden_size)\n self$linear_h_h <- nn_linear(hidden_size, hidden_size)\n },\n forward = function(x, prev_state) {\n torch_tanh(self$linear_i_h(x) +\n self$linear_h_h(prev_state))\n }\n)\n```", "```r\ncell <- rnn_cell(input_size = 1, hidden_size = 3)\n```", "```r\ncell(torch_randn(2, 1), torch_zeros(2, 3))\n```", "```r\ntorch_tensor\n-0.6340  0.9571 -0.9886\n-0.3007  0.9201 -0.9689\n[ CPUFloatType{2,3} ][ grad_fn = <TanhBackward0> ]\n```", "```r\nc(batch_size, timesteps, num_features) %<-% x$size()\n```", "```r\nfor (t in 1:timesteps) {\n new_state <- self$cell(x[ , t, ], cur_state)\n states[[t]] <- new_state\n cur_state <- new_state\n}\n```", "```r\nrnn_module <- nn_module(\n initialize = function(input_size, hidden_size) {\n self$cell <- rnn_cell(input_size, hidden_size)\n self$hidden_size <- hidden_size\n },\n forward = function(x) {\n c(batch_size, timesteps, num_features) %<-% x$size()\n init_hidden <- torch_zeros(batch_size, self$hidden_size)\n cur_state <- init_hidden\n\n # list containing the hidden states\n # (equivalently: outputs), of length timesteps\n states <- vector(mode = \"list\", length = timesteps)\n\n # loop over time steps\n for (t in 1:timesteps) {\n new_state <- self$cell(x[, t, ], cur_state)\n states[[t]] <- new_state\n cur_state <- new_state\n }\n\n # put sequence of states in dimension 2\n states <- torch_stack(states, dim = 2)\n\n list(states, states[, timesteps, ])\n }\n)\n```", "```r\nrnn <- rnn_module(input_size = 1, hidden_size = 3)\n\noutput <- rnn(torch_randn(2, 4, 1))\noutput\n```", "```r\n[[1]]\ntorch_tensor\n(1,.,.) = \n -0.9066  0.8149 -0.3671\n -0.9772  0.2903 -0.7938\n -0.9724  0.6242 -0.7877\n -0.9811  0.4164 -0.8839\n\n(2,.,.) = \n -0.8901  0.8795  0.3131\n -0.9512  0.4883  0.4991\n -0.9297  0.4875  0.1878\n -0.9420  0.5741  0.1564\n[ CPUFloatType{2,4,3} ][ grad_fn = <StackBackward0> ]\n\n[[2]]\ntorch_tensor\n-0.9811  0.4164 -0.8839\n-0.9420  0.5741  0.1564\n[ CPUFloatType{2,3} ][ grad_fn = <SliceBackward0> ]\n```", "```r\n# batch_size, timesteps, hidden_size\ndim(output[[1]])\n```", "```r\n[1] 2 4 3\n```", "```r\n# batch_size, hidden_size\ndim(output[[2]])\n```", "```r\n[1] 2 3\n```", "```r\nrnn <- nn_rnn(input_size = 1, \n hidden_size = 3, \n batch_first = TRUE,\n num_layers = 1)\n```", "```r\noutput <- rnn(torch_randn(2, 4, 1))\n\n# output\ndim(output[[1]]) # batch_size, timesteps, hidden_size\n\n# last hidden state (per layer)\ndim(output[[2]]) # num_layers, batch_size, hidden_size\n```", "```r\n[1] 2 4 3\n[1] 1 2 3\n```", "```r\ngru <- nn_gru(\n input_size = 1, \n hidden_size = 3, \n batch_first = TRUE,\n num_layers = 1\n)\n\noutput <- gru(torch_randn(2, 4, 1))\n\n# output\ndim(output[[1]]) # batch_size, timesteps, hidden_size\n\n# last hidden state (per layer)\ndim(output[[2]]) # num_layers, batch_size, hidden_size\n```", "```r\n[1] 2 4 3\n[1] 1 2 3\n```", "```r\nlstm <- nn_lstm(\n input_size = 1,\n hidden_size = 3,\n batch_first = TRUE\n)\n\noutput <- lstm(torch_randn(2, 4, 1))\n\n# output\ndim(output[[1]]) # batch_size, timesteps, hidden_size\n\n# last hidden state (per layer)\ndim(output[[2]][[1]]) # num_layers, batch_size, hidden_size\n\n# last cell state (per layer)\ndim(output[[2]][[2]]) # num_layers, batch_size, hidden_size\n```", "```r\n[1] 2 4 3\n[1] 1 2 3\n[1] 1 2 3\n```", "```r\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(tibble)\nlibrary(ggplot2)\nlibrary(lubridate)\n\n# Tidy Temporal Data Frames and Tools\nlibrary(tsibble) \n# Feature Extraction and Statistics for Time Series\nlibrary(feasts) \n# Diverse Datasets for 'tsibble'\nlibrary(tsibbledata) \n\nlibrary(torch)\nlibrary(luz)\n\nvic_elec\n```", "```r\n# A tsibble: 52,608 x 5 [30m] <Australia/Melbourne>\n   Time                Demand Temperature Date       Holiday\n   <dttm>               <dbl>       <dbl> <date>     <lgl>  \n 1 2012-01-01 00:00:00  4383\\.        21.4 2012-01-01 TRUE   \n 2 2012-01-01 00:30:00  4263\\.        21.0 2012-01-01 TRUE   \n 3 2012-01-01 01:00:00  4049\\.        20.7 2012-01-01 TRUE   \n 4 2012-01-01 01:30:00  3878\\.        20.6 2012-01-01 TRUE   \n 5 2012-01-01 02:00:00  4036\\.        20.4 2012-01-01 TRUE   \n 6 2012-01-01 02:30:00  3866\\.        20.2 2012-01-01 TRUE   \n 7 2012-01-01 03:00:00  3694\\.        20.1 2012-01-01 TRUE   \n 8 2012-01-01 03:30:00  3562\\.        19.6 2012-01-01 TRUE   \n 9 2012-01-01 04:00:00  3433\\.        19.1 2012-01-01 TRUE   \n10 2012-01-01 04:30:00  3359\\.        19.0 2012-01-01 TRUE   \n# … with 52,598 more rows\n```", "```r\ndecomp <- vic_elec %>% \n filter(year(Date) == 2012) %>%\n model(STL(Demand)) %>% \n components()\n\ndecomp %>% autoplot()\n```", "```r\ndecomp <- vic_elec %>% \n filter(year(Date) == 2012, month(Date) == 1) %>%\n model(STL(Demand)) %>% \n components()\n\ndecomp %>% autoplot()\n```", "```r\nlist(\n x = self$x[i:(i + self$n_timesteps - 1)],\n y = self$x[self$n_timesteps + i]\n)\n```", "```r\ndemand_dataset <- dataset(\n name = \"demand_dataset\",\n initialize = function(x, n_timesteps, sample_frac = 1) {\n self$n_timesteps <- n_timesteps\n self$x <- torch_tensor((x - train_mean) / train_sd)\n\n n <- length(self$x) - self$n_timesteps\n\n self$starts <- sort(sample.int(\n n = n,\n size = n * sample_frac\n ))\n },\n .getitem = function(i) {\n start <- self$starts[i]\n end <- start + self$n_timesteps - 1\n\n list(\n x = self$x[start:end],\n y = self$x[end + 1]\n )\n },\n .length = function() {\n length(self$starts)\n }\n)\n```", "```r\ndemand_hourly <- vic_elec %>%\n index_by(Hour = floor_date(Time, \"hour\")) %>%\n summarise(\n Demand = sum(Demand))\n\ndemand_train <- demand_hourly %>% \n filter(year(Hour) == 2012) %>%\n as_tibble() %>%\n select(Demand) %>%\n as.matrix()\n\ndemand_valid <- demand_hourly %>% \n filter(year(Hour) == 2013) %>%\n as_tibble() %>%\n select(Demand) %>%\n as.matrix()\n\ndemand_test <- demand_hourly %>% \n filter(year(Hour) == 2014) %>%\n as_tibble() %>%\n select(Demand) %>%\n as.matrix()\n```", "```r\ntrain_mean <- mean(demand_train)\ntrain_sd <- sd(demand_train)\n```", "```r\nn_timesteps <- 7 * 24\n```", "```r\ntrain_ds <- demand_dataset(demand_train, n_timesteps)\nvalid_ds <- demand_dataset(demand_valid, n_timesteps)\ntest_ds <- demand_dataset(demand_test, n_timesteps)\n\ndim(train_ds[1]$x)\ndim(train_ds[1]$y)\n```", "```r\n[1] 168   1\n[1] 1\n```", "```r\nbatch_size <- 128\n\ntrain_dl <- train_ds %>%\n dataloader(batch_size = batch_size, shuffle = TRUE)\nvalid_dl <- valid_ds %>%\n dataloader(batch_size = batch_size)\ntest_dl <- test_ds %>%\n dataloader(batch_size = length(test_ds))\n\nb <- train_dl %>%\n dataloader_make_iter() %>%\n dataloader_next()\n\ndim(b$x)\ndim(b$y)\n```", "```r\n[1] 128 168   1\n[1] 128   1\n```", "```r\nmodel <- nn_module(\n initialize = function(input_size,\n hidden_size,\n dropout = 0.2,\n num_layers = 1,\n rec_dropout = 0) {\n self$num_layers <- num_layers\n\n self$rnn <- nn_lstm(\n input_size = input_size,\n hidden_size = hidden_size,\n num_layers = num_layers,\n dropout = rec_dropout,\n batch_first = TRUE\n )\n\n self$dropout <- nn_dropout(dropout)\n self$output <- nn_linear(hidden_size, 1)\n },\n forward = function(x) {\n (x %>%\n # these two are equivalent\n # (1)\n # take output tensor,restrict to last time step\n self$rnn())[[1]][, dim(x)[2], ] %>%\n # (2)\n # from list of state tensors,take the first,\n # and pick the final layer\n # self$rnn())[[2]][[1]][self$num_layers, , ] %>%\n self$dropout() %>%\n self$output()\n }\n)\n```", "```r\ninput_size <- 1\nhidden_size <- 32\nnum_layers <- 2\nrec_dropout <- 0.2\n\nmodel <- model %>%\n setup(optimizer = optim_adam, loss = nn_mse_loss()) %>%\n set_hparams(\n input_size = input_size,\n hidden_size = hidden_size,\n num_layers = num_layers,\n rec_dropout = rec_dropout\n )\n\nrates_and_losses <- model %>% \n lr_finder(train_dl, start_lr = 1e-3, end_lr = 1)\nrates_and_losses %>% plot()\n```", "```r\nfitted <- model %>%\n fit(train_dl, epochs = 50, valid_data = valid_dl,\n callbacks = list(\n luz_callback_early_stopping(patience = 3),\n luz_callback_lr_scheduler(\n lr_one_cycle,\n max_lr = 0.1,\n epochs = 50,\n steps_per_epoch = length(train_dl),\n call_on = \"on_batch_end\")\n ),\n verbose = TRUE)\n\nplot(fitted)\n```", "```r\nEpoch 1/50\nTrain metrics: Loss: 0.3119\nValid metrics: Loss: 0.0715\nEpoch 2/50\nTrain metrics: Loss: 0.0767\nValid metrics: Loss: 0.0562\n...\n...\nEpoch 17/50\nTrain metrics: Loss: 0.0301\nValid metrics: Loss: 0.0295\nEpoch 18/50\nTrain metrics: Loss: 0.0288 \nValid metrics: Loss: 0.0263\nEarly stopping at epoch 18 of 50\n```", "```r\nevaluate(fitted, test_dl)\n```", "```r\nA `luz_module_evaluation`\n── Results ───────────────────────────────────────────────\nloss: 0.0364\n```", "```r\ndemand_viz <- demand_hourly %>%\n filter(year(Hour) == 2014, month(Hour) == 12)\n\ndemand_viz_matrix <- demand_viz %>%\n as_tibble() %>%\n select(Demand) %>%\n as.matrix()\n\nviz_ds <- demand_dataset(demand_viz_matrix, n_timesteps)\nviz_dl <- viz_ds %>% dataloader(batch_size = length(viz_ds))\n\npreds <- predict(fitted, viz_dl)\npreds <- preds$to(device = \"cpu\") %>% as.matrix()\npreds <- c(rep(NA, n_timesteps), preds)\n\npred_ts <- demand_viz %>%\n add_column(forecast = preds * train_sd + train_mean) %>%\n pivot_longer(-Hour) %>%\n update_tsibble(key = name)\n\npred_ts %>%\n autoplot() +\n scale_colour_manual(values = c(\"#08c5d1\", \"#00353f\")) +\n theme_minimal() +\n theme(legend.position = \"None\")\n```", "```r\ndemand_dataset <- dataset(\n name = \"demand_dataset\",\n initialize = function(x,\n n_timesteps,\n n_forecast,\n sample_frac = 1) {\n self$n_timesteps <- n_timesteps\n self$n_forecast <- n_forecast\n self$x <- torch_tensor((x - train_mean) / train_sd)\n\n n <- length(self$x) -\n self$n_timesteps - self$n_forecast + 1\n\n self$starts <- sort(sample.int(\n n = n,\n size = n * sample_frac\n ))\n },\n .getitem = function(i) {\n start <- self$starts[i]\n end <- start + self$n_timesteps - 1\n\n list(\n x = self$x[start:end],\n y = self$x[(end + 1):(end + self$n_forecast)]$\n squeeze(2)\n )\n },\n .length = function() {\n length(self$starts)\n }\n)\n```", "```r\nn_timesteps <- 7 * 24\nn_forecast <- 7 * 24\n\ntrain_ds <- demand_dataset(\n demand_train,\n n_timesteps,\n n_forecast,\n sample_frac = 1\n)\nvalid_ds <- demand_dataset(\n demand_valid,\n n_timesteps,\n n_forecast,\n sample_frac = 1\n)\ntest_ds <- demand_dataset(\n demand_test,\n n_timesteps,\n n_forecast\n)\n\nbatch_size <- 128\ntrain_dl <- train_ds %>%\n dataloader(batch_size = batch_size, shuffle = TRUE)\nvalid_dl <- valid_ds %>%\n dataloader(batch_size = batch_size)\ntest_dl <- test_ds %>%\n dataloader(batch_size = length(test_ds))\n```", "```r\nmodel <- nn_module(\n initialize = function(input_size,\n hidden_size,\n linear_size,\n output_size,\n dropout = 0.2,\n num_layers = 1,\n rec_dropout = 0) {\n self$num_layers <- num_layers\n\n self$rnn <- nn_lstm(\n input_size = input_size,\n hidden_size = hidden_size,\n num_layers = num_layers,\n dropout = rec_dropout,\n batch_first = TRUE\n )\n\n self$dropout <- nn_dropout(dropout)\n self$mlp <- nn_sequential(\n nn_linear(hidden_size, linear_size),\n nn_relu(),\n nn_dropout(dropout),\n nn_linear(linear_size, output_size)\n )\n },\n forward = function(x) {\n x <- self$rnn(x)[[2]][[1]][self$num_layers, , ] %>%\n self$mlp()\n }\n)\n```", "```r\ninput_size <- 1\nhidden_size <- 32\nlinear_size <- 512\ndropout <- 0.5\nnum_layers <- 2\nrec_dropout <- 0.2\n\nmodel <- model %>%\n setup(optimizer = optim_adam, loss = nn_mse_loss()) %>%\n set_hparams(\n input_size = input_size,\n hidden_size = hidden_size,\n linear_size = linear_size,\n output_size = n_forecast,\n num_layers = num_layers,\n rec_dropout = rec_dropout\n )\n\nrates_and_losses <- model %>% lr_finder(\n train_dl,\n start_lr = 1e-4,\n end_lr = 0.5\n)\nrates_and_losses %>% plot()\n```", "```r\nfitted <- model %>%\n fit(train_dl, epochs = 100, valid_data = valid_dl,\n callbacks = list(\n luz_callback_early_stopping(patience = 3),\n luz_callback_lr_scheduler(\n lr_one_cycle,\n max_lr = 0.01,\n epochs = 100,\n steps_per_epoch = length(train_dl),\n call_on = \"on_batch_end\")\n ),\n verbose = TRUE)\n\nplot(fitted)\n```", "```r\nEpoch 1/100\nTrain metrics: Loss: 0.9639                             \nValid metrics: Loss: 0.9714\nEpoch 2/100\nTrain metrics: Loss: 0.823                              \nValid metrics: Loss: 0.7729\n...\n...\nEpoch 21/100\nTrain metrics: Loss: 0.3833                             \nValid metrics: Loss: 0.4585\nEpoch 22/100\nTrain metrics: Loss: 0.3796                             \nValid metrics: Loss: 0.4404\n...\n...\nEpoch 41/100\nTrain metrics: Loss: 0.3103                             \nValid metrics: Loss: 0.3677\nEpoch 42/100\nTrain metrics: Loss: 0.3089                             \nValid metrics: Loss: 0.3646\n...\n...\nEpoch 60/100\nTrain metrics: Loss: 0.2707                             \nValid metrics: Loss: 0.3337\nEpoch 61/100\nTrain metrics: Loss: 0.2617                             \nValid metrics: Loss: 0.3317\nEarly stopping at epoch 61 of 100\n```", "```r\nevaluate(fitted, test_dl)\n```", "```r\nA `luz_module_evaluation`\n── Results ───────────────────────────────────────────────\nloss: 0.3782\n```", "```r\ndemand_viz <- demand_hourly %>%\n filter(year(Hour) == 2014, month(Hour) == 12)\n\ndemand_viz_matrix <- demand_viz %>%\n as_tibble() %>%\n select(Demand) %>%\n as.matrix()\n\nn_obs <- nrow(demand_viz_matrix)\n\nviz_ds <- demand_dataset(\n demand_viz_matrix,\n n_timesteps,\n n_forecast\n)\nviz_dl <- viz_ds %>%\n dataloader(batch_size = length(viz_ds))\n\npreds <- predict(fitted, viz_dl)\npreds <- preds$to(device = \"cpu\") %>%\n as.matrix()\n```", "```r\nexample_preds <- vector(mode = \"list\", length = 3)\nexample_indices <- c(1, 201, 401)\n\nfor (i in seq_along(example_indices)) {\n cur_obs <- example_indices[i]\n example_preds[[i]] <- c(\n rep(NA, n_timesteps + cur_obs - 1),\n preds[cur_obs, ],\n rep(\n NA,\n n_obs - cur_obs + 1 - n_timesteps - n_forecast\n )\n )\n}\n\npred_ts <- demand_viz %>%\n select(Demand) %>%\n add_column(\n p1 = example_preds[[1]] * train_sd + train_mean,\n p2 = example_preds[[2]] * train_sd + train_mean,\n p3 = example_preds[[3]] * train_sd + train_mean) %>%\n pivot_longer(-Hour) %>%\n update_tsibble(key = name)\n\npred_ts %>%\n autoplot() +\n scale_colour_manual(\n values = c(\n \"#08c5d1\", \"#00353f\", \"#ffbf66\", \"#d46f4d\"\n )\n ) +\n theme_minimal() +\n theme(legend.position = \"None\")\n```"]