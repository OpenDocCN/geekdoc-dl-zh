<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>25  Matrix computations: Convolution</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>25  Matrix computations: Convolution</h1>
<blockquote>原文：<a href="https://skeydan.github.io/Deep-Learning-and-Scientific-Computing-with-R-torch/matrix_computations_convolution.html">https://skeydan.github.io/Deep-Learning-and-Scientific-Computing-with-R-torch/matrix_computations_convolution.html</a></blockquote>

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">

</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<p>In deep learning, we talk about convolutions, convolutional layers, and convolutional neural networks. However, as explained in the chapter on image processing, the thing we’re referring to when doing so really is something different: cross-correlation.</p>
<p>Formally, the difference is minor: A sign is flipped. Semantically, these are not the same at all. As we saw, cross-correlation lets us spot similarities: It serves as a <em>feature detector</em>. Convolution is harder to characterize in an abstract way. Whole books could be written on the eminent role it plays in signal processing, as well as on its mathematical significance. Here, we have to leave aside the deeper underpinnings. Instead, we hope to gain some insight into its operation - firstly, by thinking through and picturing the steps involved, and secondly, by implementing it in code. As in the previous chapter, the focus is on understanding, and creating a basis for further explorations, should you be so inclined.</p>
<section id="why-convolution" class="level2" data-number="25.1">
<h2 data-number="25.1" class="anchored" data-anchor-id="why-convolution"><span class="header-section-number">25.1</span> Why convolution?</h2>
<p>In signal processing, <em>filters</em> are used to modify a signal in some desired way – for example, to cut off the high frequencies. Imagine you have the Fourier-transformed representation of a time series; meaning, a set of frequencies with associated magnitudes and phases. You’d like to set all frequencies higher than some threshold to zero. The easiest way is to multiply the set of frequencies by a sequence of ones and zeroes. If you do that, filtering is happening in the frequency domain, and often, that’s by far the most convenient way.</p>
<p>What, though, if the same result should be achieved in the time domain – that is, working with the raw time series? In that case, you’d have to find the time-domain representation of the filter (achieved by the <em>Inverse Fourier Transform</em>). This representation would then have to be <em>convolved</em> with the time series. Put differently, convolution in the time domain corresponds to multiplication in the frequency domain. This basic fact gets made use of all the time.</p>
<p>Now, let’s try to understand better what convolution does, and how it is implemented. We begin with a single dimension, and then, explore a bit of what happens in the two-dimensional case.</p>
</section>
<section id="convolution-in-one-dimension" class="level2" data-number="25.2">
<h2 data-number="25.2" class="anchored" data-anchor-id="convolution-in-one-dimension"><span class="header-section-number">25.2</span> Convolution in one dimension</h2>
<p>We start by creating a simple signal, <code>x</code>, and a simple filter, <code>h</code>. That choice of variable names is not a whim; in signal processing, <span class="math inline">\(h\)</span> is the usual symbol denoting the <em>impulse response</em>, a term we’ll get to very soon.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"/><span class="fu">library</span>(torch)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"/></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"/>x <span class="ot">&lt;-</span> <span class="fu">torch_arange</span>(<span class="at">start =</span> <span class="dv">1</span>, <span class="at">end =</span> <span class="dv">4</span>) </span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"/>h <span class="ot">&lt;-</span> <span class="fu">torch_tensor</span>(<span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"/></button></pre></div>
</div>
<p>Now – given that we <em>do</em> have <code>torch_conv1d()</code> available – why don’t we call it and see what happens? The way convolution is defined, output length equals input length plus filter length, minus one. Using <code>torch_conv1d()</code>, to obtain length-six output, given a filter of length three, we need to pad it by two on both sides.</p>
<p>In the following code, don’t let the calls to <code>view()</code> distract you – they’re present only due to <code>torch</code> expecting three-dimensional input, with dimensions one and two relating to batch item and channel, as usual.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"/><span class="fu">torch_conv1d</span>(</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"/>  x<span class="sc">$</span><span class="fu">view</span>(<span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">4</span>)),</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"/>  h<span class="sc">$</span><span class="fu">view</span>(<span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">3</span>)),</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"/>  <span class="at">padding =</span> <span class="dv">2</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"/>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"/></button></pre></div>
</div>
<pre><code>torch_tensor
(1,.,.) = 
  1  2  2  2 -3 -4
[ CPUFloatType{1,1,6} ]</code></pre>
<p>But wait, you’ll be thinking – didn’t we say that what <code>torch_conv1d()</code> computes is cross-correlation, not convolution? Well, R has <code>convolve()</code> – let’s double-check:<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"/>x_ <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(x)</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"/>h_ <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(h)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"/></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"/><span class="fu">convolve</span>(x_, h_, <span class="at">type =</span> <span class="st">"open"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"/></button></pre></div>
</div>
<pre><code>[1]  1  2  2  2 -3 -4</code></pre>
<p>The result is the same. However, looking into the documentation for <code>convolve()</code>, we see:</p>
<blockquote class="blockquote">
<p>Note that the usual definition of convolution of two sequences <code>x</code> and <code>y</code> is given by <code>convolve(x, rev(y), type = "o")</code>.</p>
</blockquote>
<p>Evidently, we need to reverse the order of items in the filter:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"/><span class="fu">convolve</span>(x_, <span class="fu">rev</span>(h_), <span class="at">type =</span> <span class="st">"open"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"/></button></pre></div>
</div>
<pre><code>[1] -1 -2 -2 -2  3  4</code></pre>
<p>Indeed, the result is different now. Let’s do the same with <code>torch_conv1d()</code>:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"/><span class="fu">torch_conv1d</span>(</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"/>  x<span class="sc">$</span><span class="fu">view</span>(<span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">4</span>)),</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"/>  h<span class="sc">$</span><span class="fu">flip</span>(<span class="dv">1</span>)<span class="sc">$</span><span class="fu">view</span>(<span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">3</span>)),</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"/>  <span class="at">padding =</span> <span class="dv">2</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"/>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"/></button></pre></div>
</div>
<pre><code>torch_tensor
(1,.,.) = 
 -1 -2 -2 -2  3  4
[ CPUFloatType{1,1,6} ]</code></pre>
<p>Again, the outcome is the same between <code>torch</code> and R. So: That laconic phrase, found in the “Details” section of <code>convolve()</code>’s documentation, captures the complete difference between cross-correlation and convolution: In convolution, the second argument is reversed. Or <em>flipped</em>, in signal-processing speak. (“Flipped”, indeed, happens to be a far better term, since it generalizes to higher dimensions.)</p>
<p>Technically, the difference is tiny – just a change in sign. But mathematically, it is essential – in the sense that it directly derives from what a filter <em>is</em>, and what it <em>does</em>. We’ll be able to get some insight into this soon.</p>
<p>The operation underlying convolution can be pictured in two ways.</p>
<section id="two-ways-to-think-about-convolution" class="level3" data-number="25.2.1">
<h3 data-number="25.2.1" class="anchored" data-anchor-id="two-ways-to-think-about-convolution"><span class="header-section-number">25.2.1</span> Two ways to think about convolution</h3>
<p>For one, we can look at a single output value and determine how it comes about. That is, we ask which input elements contribute to its value, and how those are being combined. This may be called the “output view”, and it’s one we’re already familiar with from cross-correlation.</p>
<p>As to cross-correlation, we described it like this. A filter “slides” over an image, and at each image location (pixel), we sum up the products of surrounding input pixels with the corresponding “overlayed” filter values. Put differently, each output pixel results from computing the <em>dot product</em> between matched input and filter values.</p>
<p>The second way of looking at things is from the point of view of the input (named, accordingly, the “input view”). It asks: In what way does each input value contribute to the output? This view takes some more getting-used-to than the first; but maybe that’s just a matter of socialization – the manner in which the topic is usually presented in a neural-networks context. In any case, the input view is highly instructive, in that it allows us to learn about the mathematical <em>meaning</em> of convolution.</p>
<p>We’re going to look at both, starting with more familiar one, the output view.</p>
<section id="output-view" class="level4" data-number="25.2.1.1">
<h4 data-number="25.2.1.1" class="anchored" data-anchor-id="output-view"><span class="header-section-number">25.2.1.1</span> Output view</h4>
<p>In the output view, we start by padding the input signal on both sides, just like we did when calling <code>torch_conv2d()</code> with <code>padding = 2</code>. As required, we flip the impulse response, turning it into <code>1, 0, -1</code>. Then, we picture the “sliding”.</p>
<p>Below, you find this visualized in tabular form (<a href="#tbl-convolution-output">tbl. <span>25.1</span></a>). The bottom row holds the result, obtained from summing up the individual products at each position.</p>
<div id="tbl-convolution-output" class="anchored">
<table class="table">
<caption>Table 25.1: Convolution: Output view.</caption>
<thead>
<tr class="header">
<th style="text-align: right;">Signal</th>
<th style="text-align: right;">Flipped IR</th>
<th style="text-align: right;"/>
<th style="text-align: right;"/>
<th style="text-align: right;"/>
<th style="text-align: right;"/>
<th style="text-align: right;"/>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;"><code>0</code></td>
<td style="text-align: right;"><code>1</code></td>
<td style="text-align: right;"/>
<td style="text-align: right;"/>
<td style="text-align: right;"/>
<td style="text-align: right;"/>
<td style="text-align: right;"/>
</tr>
<tr class="even">
<td style="text-align: right;"><code>0</code></td>
<td style="text-align: right;"><code>0</code></td>
<td style="text-align: right;"><code>1</code></td>
<td style="text-align: right;"/>
<td style="text-align: right;"/>
<td style="text-align: right;"/>
<td style="text-align: right;"/>
</tr>
<tr class="odd">
<td style="text-align: right;"><code>1</code></td>
<td style="text-align: right;"><code>-1</code></td>
<td style="text-align: right;"><code>0</code></td>
<td style="text-align: right;"><code>1</code></td>
<td style="text-align: right;"/>
<td style="text-align: right;"/>
<td style="text-align: right;"/>
</tr>
<tr class="even">
<td style="text-align: right;"><code>2</code></td>
<td style="text-align: right;"/>
<td style="text-align: right;"><code>-1</code></td>
<td style="text-align: right;"><code>0</code></td>
<td style="text-align: right;"><code>1</code></td>
<td style="text-align: right;"/>
<td style="text-align: right;"/>
</tr>
<tr class="odd">
<td style="text-align: right;"><code>3</code></td>
<td style="text-align: right;"/>
<td style="text-align: right;"/>
<td style="text-align: right;"><code>-1</code></td>
<td style="text-align: right;"><code>0</code></td>
<td style="text-align: right;"><code>1</code></td>
<td style="text-align: right;"/>
</tr>
<tr class="even">
<td style="text-align: right;"><code>4</code></td>
<td style="text-align: right;"/>
<td style="text-align: right;"/>
<td style="text-align: right;"/>
<td style="text-align: right;"><code>-1</code></td>
<td style="text-align: right;"><code>0</code></td>
<td style="text-align: right;"><code>1</code></td>
</tr>
<tr class="odd">
<td style="text-align: right;"><code>0</code></td>
<td style="text-align: right;"/>
<td style="text-align: right;"/>
<td style="text-align: right;"/>
<td style="text-align: right;"/>
<td style="text-align: right;"><code>-1</code></td>
<td style="text-align: right;"><code>0</code></td>
</tr>
<tr class="even">
<td style="text-align: right;"><code>0</code></td>
<td style="text-align: right;"/>
<td style="text-align: right;"/>
<td style="text-align: right;"/>
<td style="text-align: right;"/>
<td style="text-align: right;"/>
<td style="text-align: right;"><code>-1</code></td>
</tr>
<tr class="odd">
<td style="text-align: right;"><strong>Result</strong></td>
<td style="text-align: right;"><code>-1</code></td>
<td style="text-align: right;"><code>-2</code></td>
<td style="text-align: right;"><code>-2</code></td>
<td style="text-align: right;"><code>-2</code></td>
<td style="text-align: right;"><code>3</code></td>
<td style="text-align: right;"><code>4</code></td>
</tr>
</tbody>
</table>
</div>
<p>After all we’ve said on the topic, this depiction should offer few surprises. On to the input view.</p>
</section>
<section id="input-view" class="level4" data-number="25.2.1.2">
<h4 data-number="25.2.1.2" class="anchored" data-anchor-id="input-view"><span class="header-section-number">25.2.1.2</span> Input view</h4>
<p>The essential thing about the input view is the way we conceptualize the input signal: Each individual element is seen as a – <em>scaled</em> and <em>shifted – impulse</em>.</p>
<p>The <em>impulse</em> is given by the <em>unit sample</em> (or: impulse) function, delta (<span class="math inline">\(\delta\)</span>). This function is zero everywhere, except at zero, where its value is one:</p>
<p><span class="math display">\[
\delta [n]={\begin{cases}1\ \ \ if \ n=0\\0\ \ \ if \ n \ne 0\end{cases}}
\]</span></p>
<p>This is like a Kronecker delta, <span class="math inline">\(\delta_{ij}\)</span><a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>, with one of the indices being fixed at 0:</p>
<p><span class="math display">\[
\delta [n]= \delta _{n0}= \delta _{0n}
\]</span></p>
<p>Thus, equipped with only that function, <span class="math inline">\(\delta[n]\)</span> – with <span class="math inline">\(n\)</span> representing discrete time, say – we can represent exactly one signal value, the one at time <span class="math inline">\(n = 0\)</span><a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>, and its only possible value is <code>1</code>. Now we add to this the operations <em>scale</em> and <em>shift</em>.</p>
<ul>
<li><p>By scaling, we can produce any value at <span class="math inline">\(n = 0\)</span>; for example: <span class="math inline">\(x_0 = 0 * \delta [n]\)</span>.</p></li>
<li><p>By shifting, we can affect values at other points in time. For example, time <span class="math inline">\(n = 3\)</span> can be addressed as <span class="math inline">\(\delta [n - 3]= \delta _{n3}\)</span>, since <span class="math inline">\(n - 3 = 0\)</span>.</p></li>
<li><p>Combining both, we can represent any value at any point in time. For example: <span class="math inline">\(x_5 = 1.11 * \delta [n - 5]\)</span>.</p></li>
</ul>
<p>So far, we’ve talked just about the signal. What about the filter? Just like the impulse is essential in characterizing a signal, a filter is completely described by its <em>impulse response</em><a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>. The impulse response, by definition, is what comes out when the input is an impulse (that is, happens at time <span class="math inline">\(n = 0\)</span>). In notation analogous to that used for the signal, with <span class="math inline">\(h\)</span> denoting the impulse response, we have:</p>
<p><span class="math display">\[
h[n] = h[n- 0] \equiv h(\delta[n- 0])
\]</span></p>
<p>In our example, that would be the sequence <code>-1, 0, 1</code>. But just like the signal needs to be represented at additional times, not just at <span class="math inline">\(0\)</span>, the filter has to be applicable to other positions, as well. To that purpose, again, a shift operation is employed, and it is formalized in an analogous way: For instance, <span class="math inline">\(h[n - 1]\)</span> means the filter is applied to time <span class="math inline">\(1\)</span>, the time when <span class="math inline">\(n - 1\)</span> equals zero. These shifts correspond to what we informally refer to as “sliding”.</p>
<p>Now, all that remains to be done is combine the pieces. At time <span class="math inline">\(n = 0\)</span>, we take the un-shifted impulse response, and <em>scale</em> it by the amplitude of the signal. In our example, that value was <span class="math inline">\(1\)</span>. Thus: <span class="math inline">\(1 * h[n - 0] = 1 * [-1, 0, 1] = [-1, 0, 1]\)</span>. For the other times, we shift the impulse response to the input position in question, and multiply. Finally, once we’ve obtained all contributions from all input positions, we add them up, thus obtaining the convolved output.</p>
<p>The following table aims to illustrate that (<a href="#tbl-convolution-input">tbl. <span>25.2</span></a>):</p>
<div id="tbl-convolution-input" class="anchored">
<table class="table">
<caption>Table 25.2: Convolution: Input view.</caption>
<thead>
<tr class="header">
<th style="text-align: right;">Signal</th>
<th style="text-align: right;">Impulse response</th>
<th style="text-align: right;">Product</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;"><code>1</code></td>
<td style="text-align: right;"><code>h[n - 0]</code></td>
<td style="text-align: right;"><code>-1  0  1  0  0  0</code></td>
</tr>
<tr class="even">
<td style="text-align: right;"><code>2</code></td>
<td style="text-align: right;"><code>h[n - 1]</code></td>
<td style="text-align: right;"><code>0 -2  0  2  0  0</code></td>
</tr>
<tr class="odd">
<td style="text-align: right;"><code>3</code></td>
<td style="text-align: right;"><code>h[n - 2]</code></td>
<td style="text-align: right;"><code>0  0 -3  0  3  0</code></td>
</tr>
<tr class="even">
<td style="text-align: right;"><code>4</code></td>
<td style="text-align: right;"><code>h[n - 3]</code></td>
<td style="text-align: right;"><code>0  0  0 -4  0  4</code></td>
</tr>
<tr class="odd">
<td style="text-align: right;"><strong>Sum</strong></td>
<td style="text-align: right;"/>
<td style="text-align: right;"><code>-1 -2 -2 -2  3  4</code></td>
</tr>
</tbody>
</table>
</div>
<p>Personally, while I do find the output view easier to grasp, I feel I can derive more insight from the input view. In particular, it answers the – unavoidable – question: So <em>why</em> do we flip the impulse response?</p>
<p>It turns out that, far from being due to whatever mysterious forces, the minus sign is merely a mechanical outcome of the <em>way signals are represented</em>: The signal measured at time <span class="math inline">\(n = 2\)</span> is denoted by <span class="math inline">\(\delta [n - 2]\)</span> (two minus two yielding zero); and the filter applied to that signal, accordingly, as <span class="math inline">\(h[n -2]\)</span>.</p>
</section>
</section>
<section id="implementation" class="level3" data-number="25.2.2">
<h3 data-number="25.2.2" class="anchored" data-anchor-id="implementation"><span class="header-section-number">25.2.2</span> Implementation</h3>
<p>From the way I’ve described the output view, you may well think there’s not much to say about how to code this. It looks straightforward: Loop over the input vector, and compute the dot product at every prospective output position. But that would mean calculating many vector products, the more, the longer the input sequence.</p>
<p>Fortunately, there is a better way. Single-dimension (linear) convolution is computed by means of Toeplitz matrices, matrices that have some number of constant diagonals, and values of zero everywhere else. Once the filter has been formulated as a Toeplitz matrix, there is just a single multiplication to be carried out: that of the Toeplitz matrix and the input. And even though the matrix will need to have as many columns as the input has values (otherwise we couldn’t do the multiplication), computational cost is small due to the matrix’s being “nearly empty”.</p>
<p>Here is such a Toeplitz matrix, constructed for our running example:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"/>h <span class="ot">&lt;-</span><span class="fu">torch_tensor</span>(</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"/>  <span class="fu">rbind</span>(<span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>),</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"/>        <span class="fu">c</span>(<span class="dv">0</span>, <span class="sc">-</span><span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>),</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"/>        <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">0</span>, <span class="sc">-</span><span class="dv">1</span>, <span class="dv">0</span>),</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"/>        <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="sc">-</span><span class="dv">1</span>),</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"/>        <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>),</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"/>        <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"/>        ))</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"/>h</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"/></button></pre></div>
</div>
<pre><code>torch_tensor
-1  0  0  0
 0 -1  0  0
 1  0 -1  0
 0  1  0 -1
 0  0  1  0
 0  0  0  1
[ CPUFloatType{6,4} ]</code></pre>
<p>Let’s check that multiplication with our example input yields the expected result:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"/>h<span class="sc">$</span><span class="fu">matmul</span>(x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"/></button></pre></div>
</div>
<pre><code>torch_tensor
-1
-2
-2
-2
 3
 4
[ CPUFloatType{6} ]</code></pre>
<p>It does. Now, let’s move on to two dimensions. Conceptually, there is no difference, but actual computation (both “by hand” and using matrices) gets a lot more involved. Thus, we’ll content ourselves with presenting a (generalizeable) part of the manual calculation, and, in the computational part, don’t aim at elucidating every single detail.</p>
</section>
</section>
<section id="convolution-in-two-dimensions" class="level2" data-number="25.3">
<h2 data-number="25.3" class="anchored" data-anchor-id="convolution-in-two-dimensions"><span class="header-section-number">25.3</span> Convolution in two dimensions</h2>
<p>To show how, conceptually, one-dimensional and two-dimensional convolution are analogous, we assume the output view.</p>
<section id="how-it-works-output-view" class="level3" data-number="25.3.1">
<h3 data-number="25.3.1" class="anchored" data-anchor-id="how-it-works-output-view"><span class="header-section-number">25.3.1</span> How it works (output view)</h3>
<p>This time, the example input is two-dimensional. It could look like this:</p>
<p><span class="math display">\[
\begin{bmatrix}
  1 &amp; 4 &amp; 1\\
  2 &amp; 5 &amp; 3\\
\end{bmatrix}
\]</span></p>
<p>The same goes for the filter. Here is a possible one:</p>
<p><span class="math display">\[
\begin{bmatrix}
  1 &amp; 1\\
  1 &amp; -1\\
\end{bmatrix}
\]</span></p>
<p>We take the output view, the one where the filter “slides” over the input. But, to keep things readable, let me just pick a single output value (“pixel”) for demonstration. If the input is of size <code>m1 x n1</code>, and the filter, <code>m2 x n2</code>, the output will have size <code>(m1 + m2 - 1) x (n1 + n2 - 1)</code>; thus, it will be <code>3 x 4</code> in our case. I’ll pick the value at position <code>(0, 1)</code> – counting rows from the bottom, as is usual in image processing:</p>
<p><span class="math display">\[
\begin{bmatrix}
  . &amp; . &amp; . &amp; .\\
  . &amp; . &amp; . &amp; .\\
  . &amp; y_{01} &amp; . &amp; .\\
\end{bmatrix}
\]</span></p>
<p>Here is the input, displayed in a table that will allow us to picture elements at non-existing (negative) positions.</p>
<table class="table">
<thead>
<tr class="header">
<th>Position (x/y)</th>
<th>-1</th>
<th>0</th>
<th>1</th>
<th>2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>1</strong></td>
<td/>
<td>1</td>
<td>4</td>
<td>1</td>
</tr>
<tr class="even">
<td><strong>0</strong></td>
<td/>
<td>2</td>
<td>5</td>
<td>3</td>
</tr>
<tr class="odd">
<td><strong>-1</strong></td>
<td/>
<td/>
<td/>
<td/>
</tr>
</tbody>
</table>
<p>And here, the filter, with values arranged correspondingly:</p>
<table class="table">
<thead>
<tr class="header">
<th>Position (x/y)</th>
<th>-1</th>
<th>0</th>
<th>1</th>
<th>2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>1</strong></td>
<td/>
<td>1</td>
<td>1</td>
<td/>
</tr>
<tr class="even">
<td><strong>0</strong></td>
<td/>
<td>1</td>
<td>-1</td>
<td/>
</tr>
<tr class="odd">
<td><strong>-1</strong></td>
<td/>
<td/>
<td/>
<td/>
</tr>
</tbody>
</table>
<p>As in the one-dimensional case, the first thing to be done is flip the filter. Flipping here means rotation by hundred-eighty degrees.</p>
<table class="table">
<thead>
<tr class="header">
<th>Position (x/y)</th>
<th>-1</th>
<th>0</th>
<th>1</th>
<th>2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>1</strong></td>
<td/>
<td/>
<td/>
<td/>
</tr>
<tr class="even">
<td><strong>0</strong></td>
<td>-1</td>
<td>1</td>
<td/>
<td/>
</tr>
<tr class="odd">
<td><strong>-1</strong></td>
<td>1</td>
<td>1</td>
<td/>
<td/>
</tr>
</tbody>
</table>
<p>Next, the filter is shifted to the desired output position. What we want to do is shift to the right by one, leaving unaffected vertical position.</p>
<table class="table">
<thead>
<tr class="header">
<th>Position (x/y)</th>
<th>-1</th>
<th>0</th>
<th>1</th>
<th>2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>1</strong></td>
<td/>
<td/>
<td/>
<td/>
</tr>
<tr class="even">
<td><strong>0</strong></td>
<td/>
<td>-1</td>
<td>1</td>
<td/>
</tr>
<tr class="odd">
<td><strong>-1</strong></td>
<td/>
<td>1</td>
<td>1</td>
<td/>
</tr>
</tbody>
</table>
<p>Now we are all set to compute the output value at position <code>(0, 1)</code>. It’s the dot product of all overlapping image and filter values:</p>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;">Position (x/y)</th>
<th style="text-align: center;">-1</th>
<th style="text-align: center;">0</th>
<th style="text-align: center;">1</th>
<th style="text-align: center;">2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><strong>1</strong></td>
<td style="text-align: center;"/>
<td style="text-align: center;"/>
<td style="text-align: center;"/>
<td style="text-align: center;"/>
</tr>
<tr class="even">
<td style="text-align: center;"><strong>0</strong></td>
<td style="text-align: center;"/>
<td style="text-align: center;">-1*2=-2</td>
<td style="text-align: center;">1*5=5</td>
<td style="text-align: center;"/>
</tr>
<tr class="odd">
<td style="text-align: center;"><strong>-1</strong></td>
<td style="text-align: center;"/>
<td style="text-align: center;"/>
<td style="text-align: center;"/>
<td style="text-align: center;"/>
</tr>
</tbody>
</table>
<p>The final result, then, is <code>-2 + 5 = 3</code>.</p>
<p><span class="math display">\[
\begin{bmatrix}
  . &amp; . &amp; . &amp; .\\
  . &amp; . &amp; . &amp; .\\
  . &amp; 3 &amp; . &amp; .\\
\end{bmatrix}
\]</span></p>
<p>All values still missing can be computed in an analogous way. But we’ll skip that exercise, and take a look at how an actual computation would proceed.</p>
</section>
<section id="implementation-1" class="level3" data-number="25.3.2">
<h3 data-number="25.3.2" class="anchored" data-anchor-id="implementation-1"><span class="header-section-number">25.3.2</span> Implementation</h3>
<p>The way two-dimensional convolution is actually implemented in code again involves Toeplitz matrices. Like I already said, we won’t go into why exactly every step takes the <em>exact form</em> it takes – the intent here is to show a working example, an example you could build on, if you wanted, for your own explorations.</p>
<section id="step-one-prepare-filter-matrix" class="level4" data-number="25.3.2.1">
<h4 data-number="25.3.2.1" class="anchored" data-anchor-id="step-one-prepare-filter-matrix"><span class="header-section-number">25.3.2.1</span> Step one: Prepare filter matrix</h4>
<p>We start by padding the filter to the output size, <code>3 x 4</code>.</p>
<pre><code>0  0 0 0
1  1 0 0
1 -1 0 0</code></pre>
<p>We then create a Toeplitz matrix for every row in the filter, starting at the bottom.</p>
<pre><code># H0
 1  0  0  
-1  1  0  
 0 -1  1  
 0  0 -1  
 
# H1
 1  0  0  
 1  1  0  
 0  1  1  
 0  0  1  
 
# H2
 0  0  0  
 0  0  0  
 0  0  0  </code></pre>
<p>In code, we have:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"/>H0 <span class="ot">&lt;-</span> <span class="fu">torch_tensor</span>(</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"/>  <span class="fu">cbind</span>(</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"/>    <span class="fu">c</span>(<span class="dv">1</span>, <span class="sc">-</span><span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>),</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"/>    <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="sc">-</span><span class="dv">1</span>, <span class="dv">0</span>),</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"/>    <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="sc">-</span><span class="dv">1</span>)</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"/>  )</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"/>)</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"/></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"/>H1 <span class="ot">&lt;-</span> <span class="fu">torch_tensor</span>(</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"/>  <span class="fu">cbind</span>(</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"/>    <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>),</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"/>    <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">0</span>),</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"/>    <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"/>  )</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"/>)</span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"/></span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"/>H2 <span class="ot">&lt;-</span> <span class="fu">torch_tensor</span>(<span class="dv">0</span>)<span class="sc">$</span><span class="fu">unsqueeze</span>(<span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"/></button></pre></div>
</div>
<p>Next, these three matrices are assembled so as to form a <em>doubly-blocked Toeplitz</em> <em>matrix</em>. Like so:</p>
<pre><code>H0   0
H1  H0
H2  H1</code></pre>
<p>One way of coding this is to (twice) use <code>torch_block_diag()</code> to build up the two non-zero blocks, and concatenate them:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"/>H <span class="ot">&lt;-</span> <span class="fu">torch_cat</span>(</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"/>  <span class="fu">list</span>(</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"/>    <span class="fu">torch_block_diag</span>(<span class="fu">list</span>(H0, H0)), <span class="fu">torch_zeros</span>(<span class="dv">4</span>, <span class="dv">6</span>)</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"/>  )</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"/>) <span class="sc">+</span></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"/>  <span class="fu">torch_cat</span>(</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"/>    <span class="fu">list</span>(</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"/>      <span class="fu">torch_zeros</span>(<span class="dv">4</span>, <span class="dv">6</span>),</span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"/>      <span class="fu">torch_block_diag</span>(<span class="fu">list</span>(H1, H1))</span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"/>    )</span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"/>  )</span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"/></span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"/>H</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"/></button></pre></div>
</div>
<pre><code>torch_tensor
 1  0  0  0  0  0
-1  1  0  0  0  0
 0 -1  1  0  0  0
 0  0 -1  0  0  0
 1  0  0  1  0  0
 1  1  0 -1  1  0
 0  1  1  0 -1  1
 0  0  1  0  0 -1
 0  0  0  1  0  0
 0  0  0  1  1  0
 0  0  0  0  1  1
 0  0  0  0  0  1
[ CPUFloatType{12,6} ]</code></pre>
<p>The final matrix has two non-zero “bands”, separated by two all-zero diagonals. This is the final form of the filter needed for matrix multiplication.</p>
</section>
<section id="step-two-prepare-input" class="level4" data-number="25.3.2.2">
<h4 data-number="25.3.2.2" class="anchored" data-anchor-id="step-two-prepare-input"><span class="header-section-number">25.3.2.2</span> Step two: Prepare input</h4>
<p>To be multiplicable with this <code>12 x 6</code> matrix, the input needs to be flattened into a vector. Again, we proceed row-by-row, starting from the bottom here as well.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"/>x0 <span class="ot">&lt;-</span> <span class="fu">torch_tensor</span>(<span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">5</span>, <span class="dv">3</span>)) </span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"/>x1 <span class="ot">&lt;-</span> <span class="fu">torch_tensor</span>(<span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">4</span>, <span class="dv">1</span>))</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"/></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"/>x <span class="ot">&lt;-</span> <span class="fu">torch_cat</span>(<span class="fu">list</span>(x0, x1))</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"/>x</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"/></button></pre></div>
</div>
<pre><code>torch_tensor
 2
 5
 3
 1
 4
 1
[ CPUFloatType{6} ]</code></pre>
</section>
<section id="step-three-multiply" class="level4" data-number="25.3.2.3">
<h4 data-number="25.3.2.3" class="anchored" data-anchor-id="step-three-multiply"><span class="header-section-number">25.3.2.3</span> Step three: Multiply</h4>
<p>By now, convolution has morphed into straightforward matrix multiplication:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"/>y <span class="ot">&lt;-</span> H<span class="sc">$</span><span class="fu">matmul</span>(x)</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"/>y</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"/></button></pre></div>
</div>
<pre><code>torch_tensor
  2
  3
 -2
 -3
  3
 10
  5
  2
  1
  5
  5
  1
[ CPUFloatType{12} ]</code></pre>
<p>All that remains to be done is reshape the output into the correct two-dimensional structure. Building up the rows in order (again, bottom-first) we obtain:</p>
<p><span class="math display">\[
\begin{bmatrix}
  1 &amp; 5 &amp; 5 &amp; 1\\
  3 &amp; 10 &amp; 5 &amp; 2\\
  2 &amp; 3 &amp; -2 &amp; -3\\
\end{bmatrix}
\]</span></p>
<p>Looking at element <code>(0, 1)</code>, we see that the computation confirms our manual calculation.</p>
<p>Herewith, we conclude the topic of matrix computations with <code>torch</code>. But, as we move on to our next topic, the Fourier transform, we won’t actually stray that far away. Remember how, above, we said that time-domain convolution corresponds to frequency-domain multiplication?</p>
<p>This correspondence is often used to speed up computation: The input data are Fourier-transformed, the result is multiplied by the filter, and the filtered frequency-domain representation is transformed back again. Just have a look at the documentation for R’s <code>convolve()</code>. It directly starts out stating:</p>
<blockquote class="blockquote">
<p>Use the Fast Fourier Transform to compute the several kinds of convolutions of two sequences.</p>
</blockquote>
<p>On to the Fourier Transform, then!</p>


</section>
</section>
</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr/>
<ol>
<li id="fn1"><p>The argument <code>type = "open"</code> is passed to request linear, not circular, convolution.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>The Kronecker delta, <span class="math inline">\(\delta_{ij}\)</span>, evaluates to one if <span class="math inline">\(i\)</span> equals <span class="math inline">\(j\)</span>, and to zero, otherwise.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>I’m using <span class="math inline">\(n\)</span>, instead of <span class="math inline">\(t\)</span>, to index into different positions, because the signal – like any digitized one – only “exists” at discrete points in time (or space). In some contexts, this reads a bit awkward, but it at least is consistent.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>Like everywhere in the chapter, when I talk of filters, I think of linear time-invariant systems only. The restriction to time-invariant systems is immanent in the convolution operation.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

    
</body>
</html>