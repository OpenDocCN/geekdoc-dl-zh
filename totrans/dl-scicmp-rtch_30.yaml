- en: 23  Overview
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 23 概述
- en: 原文：[https://skeydan.github.io/Deep-Learning-and-Scientific-Computing-with-R-torch/other_overview.html](https://skeydan.github.io/Deep-Learning-and-Scientific-Computing-with-R-torch/other_overview.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://skeydan.github.io/Deep-Learning-and-Scientific-Computing-with-R-torch/other_overview.html](https://skeydan.github.io/Deep-Learning-and-Scientific-Computing-with-R-torch/other_overview.html)
- en: By now, we’ve talked a lot about deep learning. But `torch` is fruitfully employed
    in other kinds of tasks, as well – scientific applications, for example, that
    rely on mathematical methods to discover patterns, relations, and structure.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经讨论了很多关于深度学习的内容。但`torch`在其他类型的任务中也得到了有成效的应用——例如，依赖于数学方法来发现模式、关系和结构的科学应用。
- en: In this section, we concentrate on three topics. The first is matrix computations
    – a subject whose importance is hard to call into question, seeing how *all* computations
    in scientific computation and machine learning are matrix computations (tensors
    just being higher-order matrices). Concretely, we’ll solve a least-squares problem
    by means of matrix factorization, making use of functions like `linalg_cholesky()`,
    `linalg_qr()`, and `linalg_svd()`. In addition, we’ll take a short look at how
    convolution (in its original, signal-processing sense) can be implemented efficiently.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们专注于三个主题。第一个是矩阵计算——一个其重要性不容置疑的主题，因为在科学计算和机器学习中的所有计算都是矩阵计算（张量只是高阶矩阵）。具体来说，我们将通过矩阵分解的方法解决最小二乘问题，利用`linalg_cholesky()`、`linalg_qr()`和`linalg_svd()`等函数。此外，我们还将简要探讨卷积（在其原始的信号处理意义上）如何高效实现。
- en: 'Next, we move on to a famous mathematical method we’ve already made (indirect,
    but highly beneficial) use of: the Discrete Fourier Transform (DFT). This time,
    though, we don’t just *use* it; instead, we aim to understand *why* and *how*
    it works. Once we have that understanding, a straightforward implementation is
    a matter of just a few lines of code. A second chapter is then dedicated to implementing
    the DFT efficiently, by means of the Fast Fourier Transform (FFT). Again, we start
    by analyzing its workings, and go on to code it from scratch. You’ll see one of
    the hand-coded methods coming surprisingly close, in performance, to `torch`’s
    own `torch_fft_fft()`.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将继续探讨我们已经间接但高度有益地使用过的著名数学方法：离散傅里叶变换（DFT）。然而，这一次，我们不仅使用它；相反，我们旨在理解它是如何以及为什么工作的。一旦我们有了这种理解，一个直接的实现只需几行代码即可完成。然后，第二章将致力于通过快速傅里叶变换（FFT）高效实现DFT。同样，我们首先分析其工作原理，然后从头编写代码。你会发现一种手编的方法在性能上出奇地接近`torch`自己的`torch_fft_fft()`。
- en: Finally, we explore an idea that is far more recent than Fourier methods; namely,
    the Wavelet Transform. This transform is widely used in data analysis, and we’ll
    understand clearly why that’s the case. In `torch`, there is no dedicated method
    to compute the Wavelet Transform; but we’ll see how repeated use of `torch_fft_fft()`
    results in an efficient implementation.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们探索一个比傅里叶方法更近期的想法；即小波变换。这种变换在数据分析中得到了广泛应用，我们将清楚地了解为什么它是这样。在`torch`中，没有专门的方法来计算小波变换；但我们将看到重复使用`torch_fft_fft()`如何导致一个高效的实现。
