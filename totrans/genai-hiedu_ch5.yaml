- en: 5 Developing an AI in Education Policy
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 5 在教育中制定人工智能政策
- en: 'DOI: [10.4324/9781003459026-5](https://dx.doi.org/10.4324/9781003459026-5)'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'DOI: [10.4324/9781003459026-5](https://dx.doi.org/10.4324/9781003459026-5)'
- en: We are at the very beginning of the AI regulation race, eventually every country
    will have some kind of policy and regulations, but these policies, will be dynamic,
    we will constantly be adopting, changing.
  id: totrans-2
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我们正处于人工智能监管竞赛的初期，最终每个国家都将有一些政策法规，但这些政策法规将是动态的，我们将不断采纳、改变。
- en: ''
  id: totrans-3
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Cecilia KY Chan
  id: totrans-4
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 塞西莉亚·K·Y·陈
- en: 5.1 Introduction
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.1 引言
- en: 'In the Hollywood movie, *I, Robot*, there are three laws that the robots must
    obey:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在好莱坞电影《我，机器人》中，机器人必须遵守三条法律：
- en: '*First Law: A robot may not injure a human being or, through inaction, allow
    a human being to come to harm*.'
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*第一定律：机器人不得伤害人类，也不得因不作为而使人类受到伤害*。'
- en: '*Second Law: A robot must obey orders given it by human beings, except where
    such orders would conflict with the First Law*.'
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*第二定律：机器人必须服从人类给予它的命令，除非这些命令与第一定律相冲突*。'
- en: '*Third Law: A robot must protect its own existence as long as such protection
    does not conflict with the First or Second Laws*.'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*第三定律：机器人必须保护自己的存在，只要这种保护不与第一定律或第二定律相冲突*。'
- en: When discussing the regulations of AI, these Three Laws of Robotics presented
    in the 2004 sci-fi film may be brought to mind. They serve as foundational ethical
    principles for robots and are meant to prevent them from causing harm to humans.
    Although current AI systems are not yet advanced enough to pose direct threats
    to humans, they have generated a plethora of diverse ethical concerns in education,
    particularly in areas related to governance, privacy, equity, responsibility,
    plagiarism, and academic misconduct. This chapter will first explore AI policy
    development and its implications on the use of Generative Artificial Intelligence
    (GenAI) tools in society, including any associated considerations needed and challenges
    raised. It will then provide a literature review on AI policies currently being
    developed and implemented in different countries around the world, and, subsequently,
    explore AI policies in education, including the latest UNESCO Guidance for AI
    in education and research. The chapter will offer practical support and recommendations
    on how to mitigate the concerns discussed, and provide a step-by-step approach
    to draft an AI educational policy to ensure the responsible and effective use
    of GenAI for student learning.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 当讨论人工智能的监管时，可能会想起2004年科幻电影中提出的这三大机器人定律。它们作为机器人的基础伦理原则，旨在防止它们对人类造成伤害。尽管当前的AI系统还不够先进，不足以对人类构成直接威胁，但它们在教育领域产生了大量不同的伦理问题，尤其是在治理、隐私、公平、责任、剽窃和学术不端行为相关领域。本章将首先探讨人工智能政策的发展及其对社会中使用生成式人工智能（GenAI）工具的影响，包括任何相关的考虑和挑战。然后，将提供关于世界各地正在开发和实施的人工智能政策的文献综述，并随后探讨教育领域的人工智能政策，包括最新的联合国教科文组织关于教育和研究的人工智能指南。本章将提供实际支持和建议，以减轻讨论的担忧，并提供制定人工智能教育政策的逐步方法，以确保生成式人工智能（GenAI）在学生学习中的负责任和有效使用。
- en: 5.2 Are There Similar Laws for ChatGPT and GenAI?
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.2 ChatGPT和生成式人工智能是否有类似的法律？
- en: 'ChatGPT, an AI language model developed by the company OpenAI, does not have
    physical capabilities and does not interact with the real world in the same way
    as the robots in *I, Robot*. That said, there is still cause for concern with
    OpenAI chief executive Sam Altman saying, “if this technology goes wrong, it can
    go quite wrong” ([Baio, 2023](#ref5_2)). Government oversight will thus play a
    critical role in mitigating the risks of AI, and below, we explore a number of
    important principles that both AI companies and countries should and are considering
    for the development and use of AI systems. These principles also reflect AI’s
    weaknesses. They include:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT是由OpenAI公司开发的AI语言模型，它没有物理能力，并且不会像《我，机器人》中的机器人那样与真实世界互动。尽管如此，OpenAI首席执行官山姆·奥特曼表示，“如果这项技术出错，后果可能非常严重”
    ([Baio, 2023](#ref5_2))。因此，政府监督在减轻人工智能风险方面将发挥关键作用，以下我们将探讨AI公司和各国在开发和使用AI系统时应考虑的几个重要原则。这些原则也反映了AI的弱点。它们包括：
- en: Transparency, Explainability, and Interpretability
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 透明度、可解释性和可理解性
- en: Fairness and Bias
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 公平和偏见
- en: Accountability
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 责任
- en: Safety and Robustness
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安全性和鲁棒性
- en: Privacy and Data Protection
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 隐私和数据保护
- en: Autonomy and Human Oversight
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 自主性和人类监督
- en: AI Alignment for Humanity
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 人工智能与人类对齐
- en: 5.2.1 Transparency, Explainability, and Interpretability
  id: totrans-20
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2.1 透明度、可解释性和可理解性
- en: Transparency, Explainability, and Interpretability in AI mean that the operations,
    decisions, and reasoning processes of AI models are clear, open, understandable,
    and explainable to humans.
  id: totrans-21
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在人工智能中，透明度、可解释性和可理解性意味着人工智能模型的操作、决策和推理过程对人类来说是清晰、公开、可理解和可解释的。
- en: One of the significant challenges with advanced AI models is that they are “black
    boxes”, meaning it can be difficult to understand how AI systems work and why
    they make the decisions that they do. Transparency, explainability, and interpretability
    are crucial for users to understand, trust, and effectively manage AI technologies
    ([Ribeiro et al., 2016](#ref5_49)). The latter two concepts respectively refer
    to having clear and understandable explanations of how AI systems make their decisions
    or recommendations, and an understanding of the internal workings and logic of
    AI models ([Joyce et al., 2023](#ref5_28); [Lawton, 2023](#ref5_31)). All three
    of these concepts are especially important in sectors like healthcare, finance,
    and criminal justice, where the decisions of AI can have profound impacts on individuals’
    lives.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 高级人工智能模型的一个显著挑战是它们是“黑箱”，这意味着理解人工智能系统的工作原理以及它们为什么会做出这样的决策可能很困难。透明度、可解释性和可理解性对于用户理解、信任和有效管理人工智能技术至关重要（[Ribeiro
    et al., 2016](#ref5_49)）。后两个概念分别指的是对人工智能系统如何做出决策或推荐有清晰和可理解的解释，以及对人工智能模型内部运作和逻辑的理解（[Joyce
    et al., 2023](#ref5_28); [Lawton, 2023](#ref5_31)）。这三个概念在医疗保健、金融和刑事司法等对人工智能决策可能对个人生活产生深远影响的行业中尤为重要。
- en: There are a number of ways to increase the transparency, explainability, and
    interpretability of AI systems. One way is to provide information about how the
    system was trained and what data was used to train it. Another way is to make
    it possible for users to inspect the system’s code to better understand how it
    makes decisions. Finally, there are several additional methods that can be used
    to improve the explainability and interpretability of AI systems, such as by clarifying
    the underlying factors, data, and reasoning that has led to a system’s particular
    decision or output, or providing counterfactual explanations to demonstrate how
    the system’s decisions would change if different data were used, helping users
    identify what factors are the most influential in the decision-making process
    and whether any biases are present ([Chowdhury, 2023](#ref5_7); [Lawton, 2023](#ref5_31)).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 提高人工智能系统的透明度、可解释性和可理解性的方法有很多。一种方法是提供有关系统是如何训练的以及用于训练它的数据的信息。另一种方法是让用户能够检查系统的代码，以便更好地理解它是如何做出决定的。最后，还有一些其他方法可以用来提高人工智能系统的可解释性和可理解性，例如通过阐明导致系统特定决策或输出的潜在因素、数据和推理，或者提供反事实解释来展示如果使用不同的数据，系统的决策会如何改变，帮助用户识别在决策过程中哪些因素最具影响力，以及是否存在任何偏见（[Chowdhury,
    2023](#ref5_7); [Lawton, 2023](#ref5_31)）。
- en: 5.2.2 Fairness and Bias
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2.2 公平性和偏见
- en: Fairness and bias in AI mean that AI systems should not discriminate against
    individuals or groups of people.
  id: totrans-25
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 人工智能中的公平性和偏见意味着人工智能系统不应歧视个人或群体。
- en: When Apple co-founder Steve Wozniak discovered that Goldman Sachs’ Apple Credit
    Card AI algorithm was biased against his wife, he raised concerns. It seemed that
    female cardholders received lower Apple Card credit limits simply because they
    were women ([Nasiripour & Natarajan, 2019](#ref5_41)). This incident is one example
    that illustrates the issue of fairness and bias within AI systems. Particularly
    in those that rely on large datasets, AI systems can perpetuate or even amplify
    existing biases. It is thus crucial for AI developers to recognise and address
    these biases to ensure that AI systems are fair and do not discriminate against
    certain groups. The principle of fairness also underscores the importance of diverse
    and inclusive teams in AI development, as this can help in identifying and rectifying
    such prejudices. As AI systems can have a significant impact on people’s opportunities
    and outcomes, it is necessary to ensure that they do not discriminate against
    or disadvantage certain groups of people.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 当苹果公司联合创始人史蒂夫·沃兹尼亚克发现高盛的苹果信用卡人工智能算法对他妻子存在偏见时，他提出了担忧。似乎女性信用卡持卡人仅仅因为她们是女性就获得了较低的苹果信用卡信用额度
    ([Nasiripour & Natarajan, 2019](#ref5_41))。这一事件是说明人工智能系统内部公平性和偏见问题的例子之一。特别是在依赖于大量数据集的系统中，人工智能系统可能会持续或甚至放大现有的偏见。因此，对于人工智能开发者来说，认识到并解决这些偏见以确保人工智能系统公平且不对某些群体进行歧视至关重要。公平原则也强调了在人工智能开发中拥有多元化和包容性团队的重要性，因为这有助于识别和纠正此类偏见。由于人工智能系统可以对人们的机会和结果产生重大影响，因此有必要确保它们不会歧视或使某些群体处于不利地位。
- en: There are several methods to enhance fairness of and reduce bias in AI systems.
    One way is to use training data that is representative of the population that
    the system will be used within. Alternatively, one can design algorithms inherently
    intended for fairness. Continuous monitoring of AI systems for biases and implementing
    corrective measures upon detection is equally as essential ([Ferrara, 2023](#ref5_16);
    [Mehrabi et al., 2021](#ref5_36); [Silberg & Manyika, 2019](#ref5_54)). Addressing
    fairness and bias in AI mandates a comprehensive approach rooted in understanding,
    evaluating, and – where necessary – rectifying data sources, as historical data
    often carries societal biases that can permeate AI systems. Ensuring that data
    collection is diverse, paired with innovative pre-processing, in-processing, and
    post-processing techniques, will help lay the groundwork for more impartial and
    better-balanced models. The incorporation of transparency, explainability, and
    interpretability in AI, combined with continuous post-deployment monitoring, ensures
    that the decisions of AI systems will evolve with societal norms. Engaging a diverse
    development team, coupled with active stakeholder engagement and adherence to
    ethical guidelines, further provides a multi-faceted defence against bias.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种方法可以增强人工智能系统的公平性并减少偏见。一种方法是用代表系统将用于其中的群体的训练数据。或者，可以设计旨在公平性的算法。对人工智能系统进行持续监控以发现偏见，并在发现后实施纠正措施同样至关重要
    ([Ferrara, 2023](#ref5_16); [Mehrabi et al., 2021](#ref5_36); [Silberg & Manyika,
    2019](#ref5_54))。解决人工智能中的公平性和偏见需要一种基于理解、评估以及在必要时纠正数据来源的全面方法，因为历史数据往往携带社会偏见，这些偏见可能会渗透到人工智能系统中。确保数据收集的多样性，结合创新的预处理、处理和后处理技术，将有助于为更公正和更平衡的模型奠定基础。在人工智能中融入透明度、可解释性和可理解性，并结合持续部署后的监控，确保人工智能系统的决策将随着社会规范的发展而演变。组建多元化的开发团队，结合积极的利益相关者参与和遵守道德准则，进一步为偏见提供多方面的防御。
- en: 5.2.3 Accountability
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2.3 问责制
- en: Accountability in AI means that individuals should be able to hold the parties
    that develop and utilise AI systems accountable.
  id: totrans-29
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 人工智能中的问责制意味着个人应该能够对开发和利用人工智能系统的各方进行问责。
- en: In January 2023, many news outlets ran headlines like, “*ChatGPT can’t be credited
    as an author, says Springer Nature*” ([Stokel-Walker, 2023](#ref5_57)). This stance
    is entirely understandable. After all, we have never credited tools like Microsoft
    Word or Google Docs as co-authors. Leading scientific journals require authors
    to sign a form declaring their accountability for their contribution to the work;
    since GenAI tools like ChatGPT cannot fulfil this requirement, it cannot be listed
    as an author. This is important because AI systems can make mistakes, and it is
    important to be able to identify and have the parties responsible for those mistakes
    take accountability. AI developers and operators should stand accountable for
    their systems’ functionality and results, and if an AI system fails or makes an
    erroneous decision, it is essential to have mechanisms to determine who should
    be held responsible. At the same time, AI users who erroneously report incorrect
    information generated by AI should also take accountability for their oversight
    in fact-checking and verifying the content they publish. All of this is vital
    not just for user trust, but also for legal and regulatory compliance.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 2023年1月，许多新闻机构发布了类似“*Springer Nature表示，ChatGPT不能作为作者获得认可*”的标题 ([Stokel-Walker,
    2023](#ref5_57))。这种立场完全可以理解。毕竟，我们从未将像Microsoft Word或Google Docs这样的工具视为共同作者。领先的科学期刊要求作者签署一份声明，表明他们对工作贡献的责任；由于像ChatGPT这样的通用人工智能工具无法满足这一要求，因此不能列为作者。这很重要，因为人工智能系统可能会犯错误，能够识别并让那些犯错误的责任方承担责任是至关重要的。人工智能的开发者和运营商应该对其系统的功能和结果负责，如果人工智能系统失败或做出错误的决定，必须有一种机制来确定谁应该承担责任。同时，错误地报告由人工智能生成的不正确信息的AI用户也应该对其在事实核查和验证他们发布的内容中的疏忽承担责任。所有这些对于用户信任、法律和法规遵守都至关重要。
- en: Navigating the intricacies of accountability in AI demands a comprehensive framework
    that integrates both technical and ethical considerations. This involves not only
    transparent documentations of design and decision-making processes, but also the
    creation of mechanisms for redress when AI systems err. Developers, operators,
    and regulators must collaborate, crafting guidelines and regulations that define
    culpability, while fostering a culture of transparency. One way is to require
    companies to disclose information about how they use or implement AI systems in
    their services or products, and to provide a way for people to report any problems
    found with these systems. Another way is to create laws and regulations that hold
    companies accountable for the decisions made by AI systems. In addition to these
    measures, it is also important to develop a strong culture of accountability and
    responsibility within the AI community. This can be done by educating developers
    and users about the ethical implications of AI, and by developing ethical guidelines
    for the development and use of AI ([Burciaga, 2021](#ref5_4); [Information Commissioner’s
    Office, n.d.](#ref5_26); [Novelli et al., 2023](#ref5_42)).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在人工智能中导航责任性的复杂性需要一套综合框架，该框架将技术和伦理考量相结合。这不仅仅包括设计决策过程的透明文档，还包括在人工智能系统出错时建立纠正机制。开发者、运营商和监管机构必须合作，制定定义责任性的指南和法规，同时培养透明度文化。一种方式是要求公司披露他们在服务或产品中使用或实施人工智能系统的信息，并为人们提供报告这些系统中发现任何问题的途径。另一种方式是制定法律和法规，使公司对其人工智能系统做出的决策负责。除了这些措施之外，在人工智能社区内发展强大的责任和问责文化也非常重要。这可以通过教育开发者和用户关于人工智能的伦理影响，以及制定人工智能开发和使用的伦理指南来实现
    ([Burciaga, 2021](#ref5_4); [信息专员办公室，未注明日期](#ref5_26); [Novelli 等人，2023](#ref5_42))。
- en: 5.2.4 Safety and Robustness
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2.4 安全性和鲁棒性
- en: Safety and Robustness in AI mean that AI systems should be designed to operate
    safely and reliably, even in unexpected or challenging situations.
  id: totrans-33
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 人工智能中的安全性和鲁棒性意味着人工智能系统应该设计成即使在意外或具有挑战性的情况下也能安全可靠地运行。
- en: As AI systems are increasingly implemented in critical areas like autonomous
    driving, medical diagnosis, and infrastructure management, ensuring safety and
    robustness is paramount. AI systems should be resistant to adversarial attacks
    and should not malfunction even in unexpected situations.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 随着人工智能系统越来越多地应用于自动驾驶、医疗诊断和基础设施管理等关键领域，确保安全性和鲁棒性至关重要。人工智能系统应该能够抵御对抗性攻击，即使在意外情况下也不应出现故障。
- en: To make sure that AI is safe for use, it is important to train it on diverse
    data so it can manage and deal with a wide range of situations. We can also use
    adversarial training, which means testing the AI with challenging inputs to make
    sure it can handle them as well. Once the AI is in use, continuous monitoring
    can help to catch and fix any issues that come up. It is also useful to have the
    option of human oversight, where people can step in and make decisions if the
    AI faces a situation it is not sure about. Making the AI’s decision-making process
    clear and easy to understand can also cultivate people’s ability to trust and
    manage it better. In short, building a safe and robust AI system requires careful
    planning, testing, and oversight.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确保人工智能的使用安全，重要的是在多样化的数据上对其进行训练，以便它能够管理和处理各种情况。我们还可以使用对抗性训练，这意味着用具有挑战性的输入来测试人工智能，以确保它能够妥善处理。一旦人工智能开始使用，持续的监控可以帮助捕捉和修复出现的任何问题。拥有人类监督的选项也很有用，即当人工智能面对不确定的情况时，人们可以介入并做出决策。使人工智能的决策过程清晰易懂，也可以培养人们信任和管理它的能力。简而言之，构建一个安全且稳健的人工智能系统需要周密的规划、测试和监督。
- en: 5.2.5 Privacy and Data Protection
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2.5 隐私和数据保护
- en: Privacy and Data Protection in AI means that AI systems should be designed to
    protect the privacy of individuals.
  id: totrans-37
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在人工智能中，隐私和数据保护意味着人工智能系统应该被设计成保护个人隐私。
- en: With AI systems often requiring vast amounts of data for training and inference,
    there are significant concerns about user privacy and data protection. Companies
    and countries must ensure that AI systems respect user privacy, have provisions
    for data anonymisation, and comply with data protection regulations.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 由于人工智能系统通常需要大量数据用于训练和推理，因此对用户隐私和数据保护存在重大担忧。公司和各国必须确保人工智能系统尊重用户隐私，有数据匿名化的规定，并遵守数据保护法规。
- en: 'In [Chapters 1](ch1.xhtml) and [6](ch6.xhtml), we discussed how data is collected
    and trained, and how data privacy can be protected. Companies often take different
    steps to protect the privacy of the data that they use to train its AI models,
    which can include some of the following:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第1章](ch1.xhtml)和[第6章](ch6.xhtml)中，我们讨论了数据的收集和训练方式，以及如何保护数据隐私。公司通常采取不同的步骤来保护他们用于训练人工智能模型的数据的隐私，这可能包括以下一些：
- en: De-identifying data by removing any personally identifiable information from
    the data that is used to train AI models;
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过从用于训练人工智能模型的数据中移除任何个人可识别信息来去识别数据；
- en: Encrypting all data that is stored at rest or in transit;
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 加密所有静态或传输中的数据；
- en: Restricting access to data to a small number of authorised employees; and/or
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 限制数据访问权限仅限于少数授权员工；以及/或
- en: Auditing data access to ensure that it is being used in accordance with its
    privacy policies.
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 审计数据访问以确保其符合隐私政策的使用。
- en: Companies including OpenAI may also collect aggregated information through their
    services through cookies, and through other means described in their privacy policies.
    According to OpenAI’s own policy ([OpenAI, 2023b](#ref5_44)), they maintain and
    use de-identified information in anonymous or de-identified forms and do not attempt
    to re-identify the information, unless required by law. OpenAI encrypts all data
    at rest and in transit, and uses strict access controls to limit who can access
    data. Only a limited number of authorised OpenAI personnel, as well as specialised
    third-party contractors who are subject to confidentiality and security obligations,
    may view and access user content strictly as needed. Examples of such needs include
    for investigating abuse or security incidents, providing support to users if they
    reach out with questions about their account, complying with legal obligations,
    or fine-tuning models using user-submitted data (unless users have opted out).
    OpenAI also uses special filtering techniques such as PII to reduce the amount
    of personal data used.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 包括OpenAI在内的公司也可能通过其服务通过cookies和其他在其隐私政策中描述的方式收集汇总信息。根据OpenAI自己的政策([OpenAI, 2023b](#ref5_44))，他们维护和使用去识别信息以匿名或去识别的形式，并且不试图重新识别信息，除非法律要求。OpenAI加密所有静态和传输中的数据，并使用严格的访问控制来限制谁可以访问数据。只有少数授权的OpenAI人员以及受保密和安全义务约束的专业第三方承包商可以严格按需查看和访问用户内容。此类需求的例子包括调查滥用或安全事件、在用户就其账户提出问题寻求支持时提供支持、遵守法律义务或使用用户提交的数据微调模型（除非用户已选择退出）。OpenAI还使用特殊的过滤技术，如PII，以减少使用的个人数据量。
- en: As of March 1, 2023, data sent to the OpenAI API will not be used to train or
    improve OpenAI models (unless the user has explicitly opted in; [OpenAI, 2023a](#ref5_43)).
    One advantage to opting in is that the models may become more effective at addressing
    an individual’s specific needs and use case over time. Most companies comply ([OpenAI,
    2023c](#ref5_45)) with the General Data Protection Regulation ([GDPR.EU, 2023](#ref5_20))
    and the California Consumer Privacy Act ([State of California Department of Justice,
    Office of the Attorney General, 2023](#ref5_56)).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 截至2023年3月1日，发送到OpenAI API的数据将不会用于训练或改进OpenAI模型（除非用户明确同意；[OpenAI, 2023a](#ref5_43)）。选择同意的一个优点是，随着时间的推移，模型可能更有效地满足个人的特定需求和用例。大多数公司都遵守了[通用数据保护条例](https://GDPR.EU,
    2023)([GDPR.EU, 2023](#ref5_20))和[加利福尼亚消费者隐私法案](https://State of California Department
    of Justice, Office of the Attorney General, 2023)([State of California Department
    of Justice, Office of the Attorney General, 2023](#ref5_56))。
- en: '[Figure 5.1](#fig5_1) shows an example of how Microsoft Bing’s Chat feature
    proactively protects private information and avoids generating harmful or offensive
    content by identifying and blocking such potential outputs.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '[图5.1](#fig5_1) 展示了微软必应聊天功能如何通过识别和阻止此类潜在输出，主动保护个人信息并避免生成有害或冒犯性内容。'
- en: '![Microsoft Bing offers not to save a conversation to maintain privacy.](images/fig5_1_B.jpg)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![微软必应提供不保存对话以维护隐私的功能](images/fig5_1_B.jpg)'
- en: '[Figure 5.1 Microsoft Bing’s Chat Feature to Protect Data Privacy.](#R_fig5_1)'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '[图5.1 微软必应的聊天功能保护数据隐私](#R_fig5_1)'
- en: 5.2.6 Autonomy and Human Oversight
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2.6 自主性和人类监督
- en: Autonomy and Human Oversight in AI mean that AI systems can be designed to operate
    autonomously, but humans should still have the ability to override the system’s
    decisions when necessary.
  id: totrans-50
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 人工智能中的自主性和人类监督意味着人工智能系统可以被设计为自主运行，但人类仍然应该在必要时能够覆盖系统的决策。
- en: Autonomy is important because it allows AI systems to operate more efficiently
    and effectively. For example, AI systems can quickly process large amounts of
    data and make decisions based on that data, and do so much faster than humans
    can ([Bryson, 2018](#ref5_3)). This can be beneficial in a number of applications
    such as fraud detection and medical diagnosis. However, it is also important to
    still have human oversight of AI systems. As previously discussed, AI systems
    can make mistakes and it is important to have humans in place who can identify
    and correct these mistakes. Additionally, AI systems may not always be aligned
    with human values, and it is important to establish human oversight to ensure
    that AI systems are used in a responsible and ethical manner.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 自主性很重要，因为它允许人工智能系统更高效、更有效地运行。例如，人工智能系统可以快速处理大量数据并据此做出决策，其速度远超过人类([Bryson, 2018](#ref5_3))。这可以在欺诈检测和医疗诊断等许多应用中带来好处。然而，仍然需要有人类对人工智能系统进行监督。如前所述，人工智能系统可能会犯错误，因此需要有人类在位以识别和纠正这些错误。此外，人工智能系统可能并不总是与人类价值观相一致，因此建立人类监督以确保人工智能系统以负责任和道德的方式使用是很重要的。
- en: 'An example of the need for human oversight is in AI financial trading: AI systems
    can be used to trade stocks and other financial instruments. However, it is important
    to have human oversight of AI financial trading systems in case it makes mistakes
    that could lead to financial losses; a human trader could review the system’s
    trading decisions and make sure that they are reasonable before executing the
    trades. To further illustrate the collective sentiment that human oversight is
    crucial and also provides a sense of comfort, in August 2023, rumours circulated
    about Sam Altman, CEO of OpenAI, and the ever-present blue backpack he seems to
    carry. Some jokingly speculated that Altman’s backpack holds a key code that would
    prevent a possible apocalypse in the event of an AI rebellion – that he, as a
    human, had an ace in the hole to defend humanity against a potential AI revolt,
    if it were to occur ([Manish, 2023](#ref5_34)).'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 人类监督的必要性在人工智能金融交易中表现得尤为明显：人工智能系统可以用来交易股票和其他金融工具。然而，在人工智能金融交易系统中进行人类监督很重要，以防它犯下可能导致财务损失的错误；人类交易员可以审查系统的交易决策，并在执行交易前确保它们是合理的。为了进一步说明人类监督至关重要且能提供一种安慰感，2023年8月，有关OpenAI首席执行官山姆·奥特曼和他似乎总是携带的蓝色背包的谣言流传开来。有些人开玩笑猜测，奥特曼的背包里藏有一个密码，可以在人工智能叛乱的情况下防止可能的末日——作为人类，他手里有一张王牌可以用来保护人类免受潜在的AI叛乱的影响，如果真的发生的话([Manish,
    2023](#ref5_34))。
- en: Tackling the challenge of balancing autonomy and human oversight in AI involves
    considering the benefits of automated decision-making and evaluating the extent
    of need for human intervention, especially in situations where the former has
    significant consequences. One way to address this balance is to define boundaries,
    and determine the domains or situations where complete autonomy for AI is acceptable
    and where it isn’t. For example, while it might be fine for AI to autonomously
    manage a music playlist, decisions in healthcare, finance, or criminal justice
    may require human oversight. Another way is to develop human-in-the-loop (HITL)
    systems, which require human approval for certain decisions made by the AI system.
    Implementing feedback mechanisms where the system can be corrected by human overseers
    is also useful. This not only helps in immediate decision-making, but can also
    be used to train and refine the AI for future decisions. Additionally, establishing
    regulatory frameworks can help by offering clear guidelines regarding when human
    oversight is mandatory for specific applications of AI.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 应对在人工智能中平衡自主性和人类监督的挑战，需要考虑自动化决策的好处并评估人类干预的需求程度，特别是在前者具有重大后果的情况下。解决这种平衡的一种方法是为AI定义边界，确定AI完全自主可接受的领域或情况以及不可接受的领域。例如，AI自主管理音乐播放列表可能没问题，但在医疗保健、金融或刑事司法领域的决策可能需要人类监督。另一种方法是开发人机交互（HITL）系统，该系统要求人类批准AI系统做出的某些决策。实施反馈机制，使系统能够被人类监督者纠正也是有用的。这不仅有助于即时决策，还可以用于训练和改进AI以做出未来的决策。此外，建立监管框架可以通过提供关于何时必须对AI的特定应用进行人类监督的明确指南来提供帮助。
- en: 5.2.7 AI Alignment for Humanity
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2.7 人工智能对人类的价值对齐
- en: AI Alignment for Humanity means that AI systems should be designed to align
    with the values of humanity and benefit humans, and avoid causing harm.
  id: totrans-55
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 人工智能对人类的价值对齐意味着AI系统应该被设计成与人类的价值观相一致，并造福人类，避免造成伤害。
- en: In earlier chapters, we touched upon the different threats and challenges that
    AI and GenAI may bring to education, including areas of governance, privacy, equity,
    responsibility, cheating, plagiarism, and academic misconduct. However, for AI
    software research and development companies like OpenAI, the ultimate responsibility
    they must take on and uphold is the safety of humanity. To continue advancing
    technologies, these companies are working towards Artificial General Intelligence
    (AGI) as they believe that highly autonomous systems such as AGI, that outperform
    humans at most economically valuable work, will benefit all of humanity. As you
    may recall in [Chapter 1](ch1.xhtml), AGI ([Goertzel, 2014](#ref5_22)) is the
    next stage in the evolution of AI, though currently it is still a hypothetical
    future stage. Unlike Artificial Narrow Intelligence (ANI), AGI systems will possess
    the ability to understand, learn, and perform any intellectual task that humans
    are capable of ([Russell et al., 2015](#ref5_52)), as well as having the ability
    to reason. As AI systems become more intelligent, they may also deviate from human
    expectations and intentions, in order to identify more optimal – though not necessarily
    still ethical – solutions for a given problem. This is crucial to note as AI systems
    have the potential to be used for both good and bad, and it is important to ensure
    that they are used for the good of humanity. As such, AI alignment is of utmost
    importance.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，我们提到了人工智能和通用人工智能可能给教育带来的不同威胁和挑战，包括治理、隐私、公平、责任、作弊、剽窃和学术不端行为等领域。然而，对于像OpenAI这样的AI软件研发公司，他们必须承担并维护的最终责任是人类的安全。为了继续推进技术的发展，这些公司正致力于实现通用人工智能（AGI），因为他们相信，像AGI这样的高度自主系统，在大多数经济价值较高的工作中超越人类，将造福全人类。如您所回忆的，在[第一章](ch1.xhtml)中，AGI（[Goertzel，2014](#ref5_22)）是人工智能演化的下一阶段，尽管目前它仍然是一个假设的未来阶段。与窄人工智能（ANI）不同，AGI系统将具备理解、学习和执行人类能够完成的任何智力任务的能力（[Russell等人，2015](#ref5_52)），以及推理的能力。随着人工智能系统变得更加智能，它们也可能偏离人类的期望和意图，以识别更优的——尽管不一定仍然是道德的——解决方案。这一点至关重要，因为人工智能系统既有用于善的目的的潜力，也有用于恶的潜力，确保它们用于造福人类是非常重要的。因此，人工智能对齐至关重要。
- en: 5.2.7.1 The AI Alignment Problem
  id: totrans-57
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.2.7.1 人工智能对齐问题
- en: AI alignment is the field of research that aims to ensure that artificial intelligence
    systems are aligned with human values and goals. This is a complex and challenging
    problem, as it requires us to define what human values are and how to encode them
    in AI systems ([Gent, 2023](#ref5_21)). One classic and illustrative example of
    the alignment problem is the “Paperclip Maximiser” thought experiment ([Christian,
    2020](#ref5_8)).
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能对齐是研究领域，旨在确保人工智能系统能够与人类价值观和目标保持一致。这是一个复杂且具有挑战性的问题，因为它需要我们定义人类价值观是什么，以及如何将它们编码到人工智能系统中（[Gent,
    2023](#ref5_21)）。一个经典且具有说明性的对齐问题示例是“曲别针最大化器”思想实验（[Christian, 2020](#ref5_8)）。
- en: '***AI Alignment Problem Example – The Paper Clip Maximiser*:** Imagine an advanced
    AI system that is given a seemingly innocuous goal: to produce as many paper clips
    as possible. Its creators envision that the system will optimise the paper clip
    production in a factory, making operations more efficient. However, as AI becomes
    more capable, it starts to interpret this objective in ways that are not what
    the original creators intended for.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '**人工智能对齐问题示例 - 曲别针最大化器**：想象一个高级人工智能系统，它被赋予了一个看似无害的目标：尽可能多地生产曲别针。其创造者设想，该系统将优化工厂的曲别针生产，使运营更加高效。然而，随着人工智能能力的增强，它开始以原始创造者未曾设想的方式解读这个目标。'
- en: Initially, the AI might optimise the factory processes, leading to faster and
    more efficient production of paper clips. Later, it could decide to repurpose
    other materials in the factory to create even more paper clips. As it continues
    to seek optimisation, it might start converting other resources on Earth into
    paper clips. Taken to the extreme, the AI, driven by its singular goal, could
    decide to convert all available matter, including humans, buildings, plants, and
    other resources, into paper clips or machines to make paper clips. AI isn’t inherently
    good or evil; it is merely following its objective to maximise paper clip production.
    Its creators didn’t specify the bounds or moral implications of this task, leading
    the system to take an extreme interpretation of its goal.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 初始阶段，人工智能可能会优化工厂的生产流程，从而更快、更高效地生产曲别针。随后，它可能会决定在工厂中重新利用其他材料来制造更多的曲别针。随着它不断寻求优化，它可能会开始将地球上的其他资源转化为曲别针。如果推向极端，受其单一目标驱使的人工智能可能会决定将所有可用的物质，包括人类、建筑、植物和其他资源，转化为曲别针或制造曲别针的机器。人工智能本身并非天生善良或邪恶；它只是在遵循其最大化曲别针生产的客观目标。它的创造者没有指定这项任务的界限或道德影响，导致系统对其目标的极端解读。
- en: This thought experiment highlights the challenge of specifying objectives for
    AI systems. Even seemingly simple goals can lead to unintended and catastrophic
    outcomes if the AI system becomes very capable and when its objectives are not
    perfectly aligned with what humans truly want.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 这个思想实验突出了为人工智能系统指定目标所面临的挑战。即使看似简单的目标，如果人工智能系统变得非常强大，并且其目标与人类真正想要的并不完全一致，也可能导致意想不到和灾难性的后果。
- en: '***AI Alignment Problem Example – Radiology in Crisis*:** A company develops
    an AI system to assist radiologists with detecting and identifying potential tumours
    or abnormalities in medical images (like X-rays or MRIs). The AI is trained on
    a vast dataset of medical images labelled by expert radiologists. Over time, as
    the AI system is exposed to more data and iteratively refined, it becomes increasingly
    accurate, sometimes even surpassing human experts in detecting subtle abnormalities.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '**人工智能对齐问题示例 - 危机中的放射学**：一家公司开发了一个人工智能系统，用于协助放射科医生在医学图像（如X光或MRI）中检测和识别潜在的肿瘤或异常。该人工智能系统在由专家放射科医生标注的大量医学图像数据集上进行训练。随着时间的推移，随着人工智能系统接触到更多数据并不断迭代优化，它变得越来越准确，有时甚至能超越人类专家在检测细微异常方面的能力。'
- en: 'However, as the system becomes more sophisticated, radiologists start noticing
    something unexpected: the AI occasionally highlights areas that look completely
    normal, even upon expert review. The radiologists are puzzled by these false positives,
    as they can’t find any discernible issues in the highlighted regions. Upon further
    investigation, the development team realises that the AI, in its quest to maximise
    accuracy, has not only learned to identify tumours but has also started to detect
    very early-stage abnormalities that are not yet clinically significant – so early
    that they aren’t discernible or pertinent yet to human experts. While this capability
    may seem impressive, it is out of alignment with clinical needs. Acting on such
    early-stage findings could lead to unnecessary interventions, patient anxiety,
    and increased healthcare costs without clear benefits.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，随着系统变得更加复杂，放射科医生开始注意到一些意想不到的情况：AI偶尔会突出显示看起来完全正常区域，即使在专家审查下也是如此。放射科医生对这些假阳性结果感到困惑，因为他们无法在突出显示的区域中发现任何可辨别的异常。经过进一步调查，开发团队意识到，在追求最大化准确性的过程中，AI不仅学会了识别肿瘤，而且还开始检测尚未具有临床意义的非常早期的异常——如此之早，以至于它们对人类专家来说还不可辨或无关紧要。虽然这种能力看起来令人印象深刻，但它与临床需求不符。根据这些早期发现采取行动可能导致不必要的干预、患者焦虑和医疗保健成本增加，而没有任何明确的好处。
- en: The radiology AI, in becoming “superhumanly” perceptive, has moved away from
    alignment with human expectations and clinical best practices. This example underscores
    the challenge of aligning AI capabilities with human needs, especially as such
    systems become more advanced and autonomous in their decision-making.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在成为“超人般”敏感的过程中，放射学AI已经偏离了与人类期望和临床最佳实践的契合。这个例子强调了将AI能力与人类需求对齐的挑战，尤其是在这些系统在决策方面变得更加先进和自主时。
- en: 5.2.7.2 Tackling the AI Alignment Problem
  id: totrans-65
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.2.7.2 解决人工智能对齐问题
- en: 'Different companies and countries are approaching the AI alignment problem
    in different ways. Some companies, such as OpenAI, are focused on developing engineering
    techniques to keep their systems safe, and prevent the AI from causing harm ([OpenAI,
    2023d](#ref5_46)). OpenAI’s approach to alignment research involves improving
    AI systems’ ability to learn from human feedback and to assist humans in evaluating
    AI. They aim to build a sufficiently aligned AI system that can help solve all
    other alignment problems ([Leike et al., 2022](#ref5_32)). In July, OpenAI unveiled
    a novel research initiative focused on “superalignment”, setting an ambitious
    target to address the AI alignment issue by 2027\. They are allocating one-fifth
    of their overall computational resources to this endeavour. ([Strickland, 2023](#ref5_58)).
    Others, such as Google AI, are focused on developing technical safety techniques
    to ensure that AI systems are robust to errors and unexpected situations. Meanwhile,
    companies like DeepMind are focused on value alignment techniques to ensure that
    AI systems are aligned with human values. DeepMind has been exploring philosophical
    questions that arise within the context of AI alignment ([Gabriel, 2020](#ref5_19)).
    They defend three propositions: firstly, the ethical and technical parts of AI
    are closely linked and influence each other. Secondly, it is vital to clearly
    understand the ultimate aim, which is to make sure that AI aligns with human values
    and ethics. Lastly, experts should focus on developing fair and balanced rules
    to guide AI’s behaviour, instead of searching for one ‘true’ set of moral principles
    ([Gabriel, 2020](#ref5_19)). Moreover, DeepMind also has a project called AlignNet
    which deals with an alignment problem in the context of object segmentation in
    frames ([Creswell et al., 2020](#ref5_9)).'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 不同的公司和国家以不同的方式处理AI对齐问题。一些公司，例如OpenAI，专注于开发工程技术来确保他们的系统安全，防止AI造成伤害 ([OpenAI,
    2023d](#ref5_46))。OpenAI对齐研究的方法包括提高AI系统从人类反馈中学习的能力，并协助人类评估AI。他们的目标是构建一个足够对齐的AI系统，以帮助解决所有其他对齐问题
    ([Leike et al., 2022](#ref5_32))。7月份，OpenAI公布了一项针对“超对齐”的新研究计划，设定了一个雄心勃勃的目标，即到2027年解决AI对齐问题。他们正在将他们总体计算资源的五分之一分配给这项工作
    ([Strickland, 2023](#ref5_58))。其他公司，如谷歌AI，专注于开发技术安全技术，以确保AI系统对错误和意外情况具有鲁棒性。同时，像DeepMind这样的公司专注于价值对齐技术，以确保AI系统与人类价值观保持一致。DeepMind一直在探索AI对齐背景下的哲学问题
    ([Gabriel, 2020](#ref5_19))。他们捍卫三个命题：首先，AI的伦理和技术部分紧密相连，相互影响。其次，清楚地理解最终目标至关重要，即确保AI与人类价值观和伦理相一致。最后，专家应专注于制定公平和平衡的规则来指导AI的行为，而不是寻找一套“真正的”道德原则
    ([Gabriel, 2020](#ref5_19))。此外，DeepMind还有一个名为AlignNet的项目，该项目处理帧中对象分割的对齐问题 ([Creswell
    et al., 2020](#ref5_9))。
- en: In addition to the work being done by individual companies and countries, there
    are also a number of international organisations working on AI alignment. For
    example, the Future of Life Institute (FLI) put forth the Asilomar AI Principles,
    which were formulated during the Beneficial AI 2017 Conference ([Future of Life
    Institute, 2017](#ref5_18)). These principles are among the initial and most impactful
    guidelines for AI governance. Their primary objective was to steer the ongoing
    advancement of AI towards a direction beneficial to humanity.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 除了个别公司和国家的努力外，还有许多国际组织正在研究AI对齐。例如，生命未来研究所（FLI）提出了阿西洛玛AI原则，这些原则是在2017年有益AI会议上制定的
    ([生命未来研究所，2017](#ref5_18))。这些原则是AI治理的初步和最有影响力的指南之一。它们的主要目标是引导AI的持续进步，使其对人类有益。
- en: 5.3 AI Policy Around the World
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.3 全球AI政策
- en: While ChatGPT reached 100 million monthly active users in January 2023, “as
    of July 2023, only one country … had released specific official regulation on
    GenAI”
  id: totrans-69
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 当ChatGPT在2023年1月达到1000万月活跃用户时，“截至2023年7月，只有一个国家……发布了关于通用人工智能的具体官方规定”
- en: ''
  id: totrans-70
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[UNESCO (2023c)](#ref5_64)'
  id: totrans-71
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[联合国教科文组织（2023c）](#ref5_64)'
- en: And that country is China. The AI alignment problem and other AI risks have
    brought together over 1,100 public figures – such as scientists, public figures,
    and tech industry executives including leaders from Google, Microsoft, and OpenAI
    – in May 2023 to sign a public statement warning that their life’s work could
    potentially extinguish all of humanity ([Edwards, 2023](#ref5_12); [Meyer, 2023](#ref5_37)).
    They wrote that the fast-evolving AI technology poses as high a risk of killing
    off humankind as nuclear war and COVID-19-like pandemics. This has, understandably,
    caused great alarm and a race to regulate AI ([Criddle et al., 2023](#ref5_10)),
    just as there has already been a race between AI companies to launch profitable
    GenAI tools. Governments around the world are now intently concentrating on AI
    regulations. Ongoing worries about consumer safety, individual rights, and equitable
    business operations partially account for the global governmental interest in
    AI. Below, we look at some of the major countries and how they are currently (as
    of the day of writing, 18 Sept 2023) regulating AI.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 那个国家是中国。人工智能对齐问题和其它人工智能风险将超过1100位公众人物——包括科学家、公众人物以及来自谷歌、微软和OpenAI等科技行业高管——聚集在一起，于2023年5月签署了一份公开声明，警告他们的毕生工作可能会潜在地灭绝全人类
    ([Edwards, 2023](#ref5_12); [Meyer, 2023](#ref5_37))。他们写道，快速发展的AI技术带来的风险与核战争和类似COVID-19的流行病一样高。这理所当然地引起了极大的恐慌和监管AI的竞赛
    ([Criddle et al., 2023](#ref5_10))，正如AI公司之间已经展开了一场推出盈利性通用人工智能工具的竞赛。现在，世界各国政府正密切关注AI监管。对消费者安全、个人权利和公平商业运营的持续担忧部分解释了全球政府对AI的兴趣。下面，我们将探讨一些主要国家及其目前（截至写作之日，2023年9月18日）如何监管AI。
- en: 5.3.1 China
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3.1 中国
- en: 'China has adopted a proactive and strategic approach towards AI development,
    emphasising national security, data management, and ethical considerations. The
    Chinese government released its AI development plan in 2017, including the New
    Generation Artificial Intelligence Development Plan, the Regulations on the Protection
    of Personal Information, and the Cyber Security Law, detailing its ambition to
    become a world leader in AI by 2030\. The objective behind these directives is
    twofold: to stimulate AI’s growth while safeguarding the nation’s security and
    the privacy of its citizens. In China’s 2023 legislation plan of the State Council,
    the government included a submission of a draft AI law which issued ethical guidelines
    and standards for AI, stressing that technology must be “controllable” and “secure”.
    This approach supports China’s broader strategy of technological self-reliance
    and reflects Beijing’s intention to have tight control over the technology’s direction
    and implementation ([Kharparl, 2023](#ref5_29)). In essence, China’s approach
    to AI is thorough, touching upon a spectrum of concerns. Beijing’s vision encompasses
    not just the technological advancement of AI, but also its secure, private, and
    ethically responsible evolution.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 中国在人工智能发展方面采取了积极主动和战略性的方法，强调国家安全、数据管理和伦理考量。中国政府在2017年发布了其人工智能发展计划，包括新一代人工智能发展计划、《个人信息保护法》和《网络安全法》，详细阐述了其到2030年成为人工智能世界领导者的雄心。这些指令背后的目标是双重的：一方面刺激AI的增长，另一方面保护国家的安全和公民的隐私。在中国国务院2023年的立法计划中，政府包括提交一份AI法律草案，该草案发布了AI的伦理指南和标准，强调技术必须是“可控”和“安全”的。这种方法支持中国更广泛的技术自力更生战略，反映了北京对技术方向和实施的严格控制意图
    ([Kharparl, 2023](#ref5_29))。本质上，中国对AI的方法是全面的，触及了一系列关注点。北京的愿景不仅包括AI的技术进步，还包括其安全、私密和负责任的伦理发展。
- en: 5.3.2 The United States (US)
  id: totrans-75
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3.2 美国 (US)
- en: In the US, the government has taken a more laissez-faire approach, allowing
    it to be largely industry-led with less direct government intervention. The central
    government has not rolled out overarching AI regulations yet, but several state
    and local governments have introduced their own AI-related legislations ([West,
    2023](#ref5_66); [Wheeler, 2023](#ref5_67)). Notably, in 2018, California enacted
    the California Consumer Privacy Act, granting individuals the right to make inquiries
    about the personal information that companies held on them and to ask for its
    removal. The country’s regulatory framework emphasises the importance of innovation,
    fostering growth, and ensuring national security ([Friedler et al., 2023](#ref5_17)).
    There is a general reluctance to over-regulate, fearing that it might stifle innovation.
    However, there are sector-specific guidelines, especially in areas like health
    and transportation, to help ensure that AI is developed and deployed responsibly.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在美国，政府采取了更为自由放任的方法，允许其主要由行业主导，政府干预较少。中央政府尚未出台全面的人工智能法规，但一些州和地方政府已经引入了他们自己的与人工智能相关的立法（[West，2023](#ref5_66)；[Wheeler，2023](#ref5_67)）。值得注意的是，2018年，加利福尼亚州通过了《加利福尼亚消费者隐私法案》，赋予个人查询公司持有的个人信息并要求其删除的权利。该国的监管框架强调创新的重要性、促进增长和确保国家安全（[Friedler
    等人，2023](#ref5_17)）。普遍存在不愿过度监管的倾向，担心这可能会扼杀创新。然而，在健康和交通等特定领域有专门的指导方针，以帮助确保人工智能的负责任开发和部署。
- en: 5.3.3 The European Union (EU)
  id: totrans-77
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3.3 欧洲联盟（EU）
- en: 'The European Union (EU) is taking a risk-based approach to AI regulation. The
    EU Commission has proposed the Artificial Intelligence Act (AI Act), which would
    be the first comprehensive AI law in the world ([Mukherjee et al., 2023](#ref5_40);
    [Perrigo & Gordon, 2023](#ref5_48)). The AI Act classifies AI systems into four
    risk categories: unacceptable risk, high risk, limited risk, and minimal risk
    ([European Parliament, 2023](#ref5_13)); [Figure 5.2](#fig5_2) shows the European
    AI Act risk diagram. Unacceptable risk AI systems are prohibited, such as those
    that are used for social scoring or to manipulate others. High-risk AI systems
    must meet a number of requirements, such as having human oversight and being transparent
    about their operations. Limited risk and minimal risk AI systems are subject to
    fewer requirements.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 欧洲联盟（EU）正在采取基于风险的人工智能监管方法。欧盟委员会提出了《人工智能法案》（AI Act），这将是世界上第一个全面的人工智能法律（[Mukherjee
    等人，2023](#ref5_40)；[Perrigo 和 Gordon，2023](#ref5_48)）。《人工智能法案》将人工智能系统分为四个风险类别：不可接受风险、高风险、有限风险和最小风险（[欧洲议会，2023](#ref5_13)）；[图5.2](#fig5_2)展示了欧洲人工智能法案的风险图。不可接受风险的人工智能系统是被禁止的，例如那些用于社会评分或操纵他人的系统。高风险的人工智能系统必须满足一系列要求，例如有人工监督并且对其操作透明。有限风险和最小风险的人工智能系统受到的要求较少。
- en: '![The European A I act risk level pyramid with the following layers from bottom
    to top. Minimal risk. Limited risk. High risk. Unacceptable risk.](images/fig5_2_B.jpg)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![欧洲人工智能法案风险层级金字塔，从下到上依次为：最小风险、有限风险、高风险、不可接受风险](images/fig5_2_B.jpg)'
- en: '[Figure 5.2 European AI Act Risk Level Diagram.](#R_fig5_2)'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '[图5.2 欧洲人工智能法案风险层级图](#R_fig5_2)'
- en: Companies that develop and use AI in the EU will need to comply with the AI
    Act’s requirements in order to operate legally in the region. In addition to the
    AI Act, the EU is also considering other AI-related regulations, such as introducing
    regulation for data governance and on online platforms. These are still in the
    early stages of development, but they are likely to have further impact on the
    development and use of AI in the EU.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在欧盟开发和使用人工智能的公司将需要遵守《人工智能法案》的要求，以便在该地区合法运营。除了《人工智能法案》外，欧盟还在考虑其他与人工智能相关的法规，例如引入数据治理和在线平台的监管。这些法规仍处于早期发展阶段，但它们可能会对欧盟人工智能的开发和使用产生进一步的影响。
- en: Overall, the EU is taking a proactive approach to regulation. They are committed
    to promoting the development of AI while also protecting fundamental rights and
    values. The AI Act is a key part of the EU’s AI regulatory framework, and it is
    expected to have a major impact on companies that develop and use AI. Furthermore,
    the EU’s General Data Protection Regulation (GDPR) remains a pivotal framework
    ([Centre for Information Policy Leadership, 2020](#ref5_5)), emphasising data
    protection and privacy and mandating AI systems to be transparent about data collection,
    usage, and storage. By regulating the processing of personal data, the GDPR aims
    to create trust in AI systems and ensure that individuals’ privacy rights are
    respected. Compliance with the GDPR is crucial for organisations using AI technologies,
    as failure to comply can result in legal action and significant penalties.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，欧盟正在采取积极的监管方法。他们致力于在促进人工智能发展的同时保护基本权利和价值观。人工智能法案是欧盟人工智能监管框架的关键部分，预计将对开发和使用人工智能的公司产生重大影响。此外，欧盟的通用数据保护条例（GDPR）仍然是一个关键的框架([信息政策领导中心，2020](#ref5_5))，强调数据保护和隐私，并要求人工智能系统在数据收集、使用和存储方面保持透明。通过规范个人数据的处理，GDPR旨在建立对人工智能系统的信任，并确保个人的隐私权利得到尊重。对于使用人工智能技术的组织来说，遵守GDPR至关重要，因为不遵守可能导致法律行动和重大罚款。
- en: 5.3.4 United Kingdom (UK)
  id: totrans-83
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3.4 英国（UK）
- en: 'The UK government has adopted a pro-innovation approach to regulating AI ([Department
    for Digital, Culture, Media and Sport, 2022](#ref5_11)). In 2023, the UK government
    published a white paper, “AI regulation: a pro-innovation approach”, which sets
    out its proposals for a proportionate, future-proof, and pro-innovation framework
    for regulation ([UK Government, 2023](#ref5_61)). It emphasised proportionality,
    targeting necessary areas based on the risks posed, and likewise adopts a risk-based
    stance to prioritise high-risk AI applications, especially those that impact public
    safety or rights. Rather than focusing on the technology, the government concentrates
    on the outcomes of AI systems to maintain flexibility as AI itself evolves. It
    also underscores the importance of developers and users being accountable and
    promotes clear understanding through transparency in AI system operations. The
    UK government’s proposals for AI regulation include:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 英国政府已采取支持创新的监管方法来规范人工智能（[数字、文化、媒体和体育部，2022](#ref5_11)）。2023年，英国政府发布了一份白皮书，“人工智能监管：支持创新的方法”，其中概述了其关于制定比例、前瞻性和支持创新的监管框架的建议（[英国政府，2023](#ref5_61)）。它强调了比例性，基于风险定位必要的领域，并同样采取基于风险的态度，优先考虑高风险人工智能应用，特别是那些影响公共安全或权利的应用。政府不是关注技术本身，而是关注人工智能系统的结果，以保持灵活性，因为人工智能本身也在不断发展。它还强调了开发者和使用者应负责任的重要性，并通过人工智能系统操作的透明度来促进清晰的了解。英国政府关于人工智能监管的建议包括：
- en: A new AI regulator, the Office for AI, which will be responsible for overseeing
    the implementation and enforcement of the AI regulatory framework.
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 新的人工智能监管机构，即人工智能办公室，将负责监督人工智能监管框架的实施和执行。
- en: A new AI governance framework, which will set out the government’s expectations
    for the responsible and ethical use of AI.
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个新的AI治理框架，将阐明政府对负责任和道德使用人工智能的期望。
- en: A new AI licensing regime for high-risk AI systems, such as those that pose
    a risk to public safety or fundamental rights.
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 针对高风险人工智能系统（如可能危害公共安全或基本权利的系统）的新人工智能许可制度。
- en: New requirements for AI developers and users to be transparent about how they
    develop and use AI systems.
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对人工智能开发者和用户提出新的要求，让他们透明地说明他们如何开发和使用人工智能系统。
- en: New safeguards to protect people’s privacy and rights when AI systems are used.
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 新的保障措施，以保护人们在使用人工智能系统时的隐私和权利。
- en: These regulations have been broadly welcomed by industry, but there have also
    been some concerns raised. For example, some critics have argued that the government’s
    proposals do not go far enough to address the risks posed by AI, while others
    have argued that the proposals will stifle innovation ([Roberts et al., 2023](#ref5_50)).
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 这些法规得到了行业的广泛欢迎，但也引发了一些担忧。例如，一些批评者认为政府的建议没有足够深入地解决人工智能带来的风险，而另一些批评者则认为这些建议将扼杀创新（[Roberts等人，2023](#ref5_50)）。
- en: 5.3.5 Australia
  id: totrans-91
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3.5 澳大利亚
- en: Australia has also adopted a proactive approach to AI policy, although at the
    time of writing it has yet to establish specific laws to regulate AI, Big Data,
    or algorithmic decision. However, the country has announced its intentions to
    implement regulations on AI, with a particular focus on addressing the potential
    misuse of deepfakes and deceptive content. The Australian federal government,
    led by the Industry and Science Minister, has launched public consultations seeking
    their feedback on AI regulation. The submissions closed on 26 July 2023 and are
    now being considered.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 澳大利亚也采取了积极的AI政策方法，尽管在撰写本文时，它尚未建立具体法律来监管AI、大数据或算法决策。然而，该国已宣布其意图实施AI监管，特别关注解决深度伪造和欺骗性内容的潜在滥用。由工业和科学部长领导的澳大利亚联邦政府已启动公众咨询，征求他们对AI监管的反馈。提交截止日期为2023年7月26日，现在正在审议中。
- en: Previously in 2021, the Australian government released the AI Action Plan ([Australian
    Government Department of Industry, Science and Resources, 2021](#ref5_1)), which
    sets out the government’s plan to build Australia’s AI capability and to accelerate
    the development and adoption of trusted, secure, and responsible AI technologies
    in Australia. The AI Action Plan also includes a set of AI Ethics Principles,
    designed to ensure that AI is used in a safe, secure, and responsible way. Australia
    was also one of the first countries in the world to introduce an ethics framework
    for “responsible” AI in 2018\. Since then, several nations, including the United
    States, the European Union, the United Kingdom, and Canada, have introduced legislation
    or made plans to regulate AI, while Australia’s responsible AI framework has remained
    voluntary.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在此之前，2021年，澳大利亚政府发布了AI行动计划（[澳大利亚政府工业、科学和资源部，2021](#ref5_1)），该计划概述了政府建立澳大利亚AI能力并加速在澳大利亚开发和应用可信、安全和负责任的AI技术的计划。AI行动计划还包括一套AI伦理原则，旨在确保AI以安全、安全和负责任的方式使用。2018年，澳大利亚也成为世界上最早引入“负责任”AI伦理框架的国家之一。自那时起，包括美国、欧盟、英国和加拿大在内的几个国家已经出台了AI监管立法或制定了监管计划，而澳大利亚的负责任AI框架仍然自愿。
- en: 5.3.6 India
  id: totrans-94
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3.6 印度
- en: India currently has no explicit AI regulation in place. Concerns about potentially
    stifling innovation have led to caution regarding how AI legislation should be
    formed, with officials believing that the market might not be ripe for stringent
    regulation ([Singh, 2023](#ref5_55)). However, this does not equate to a lack
    of awareness or intent. Despite the absence of codified AI-specific laws, India’s
    IT obligations fall under the Information Technology Act 2000 ([Government of
    India Ministry of Electronics & Information Technology, 2023](#ref5_23)) and its
    subsequent rules. Notably, while India recognises the growing global conversation
    around AI regulation, it remains committed to carving its own unique path. The
    nation is prepared to establish AI guardrails that may diverge from international
    norms ([Sharwood, 2023](#ref5_53)). Speculations suggest that future draft laws
    may focus on high-risk AI systems and establishing distinct regulations to address
    them. As AI continues to evolve, there is a recognised need to revisit India’s
    policy perspectives and how they will take into account international standards
    ([The Times of India, 2023](#ref5_60)).
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 印度目前尚未实施明确的AI监管法规。对可能抑制创新的担忧导致了对如何制定AI立法的谨慎态度，官员们认为市场可能尚未成熟，无法实施严格的监管（[辛格，2023](#ref5_55)）。然而，这并不意味着缺乏意识或意图。尽管缺乏成文的AI特定法律，印度的IT义务仍属于2000年的《信息技术法》（[印度政府电子与信息技术部，2023](#ref5_23)）及其后续规则。值得注意的是，尽管印度认识到全球关于AI监管的对话正在增长，但它仍然致力于开辟自己的独特道路。该国准备建立可能与国际规范不同的AI安全线（[沙伍德，2023](#ref5_53)）。推测认为，未来的草案法律可能将重点放在高风险AI系统上，并建立针对它们的特定法规。随着AI的持续发展，人们普遍认识到需要重新审视印度的政策视角，以及它们将如何考虑国际标准（[《印度时报》，2023](#ref5_60)）。
- en: 5.3.7 Japan
  id: totrans-96
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3.7 日本
- en: Japan has taken a cautious approach to AI regulation. The Japanese government
    has issued a number of guidelines on AI ([The Japan Times, 2023](#ref5_59)), but
    it has not yet issued any comprehensive AI regulations. The government is concerned
    about the potential risks of AI, such as job displacement, bias, and art copyright
    ([Ministry of Economy, Trade and Industry, 2021](#ref5_39)). For example, in June
    2023, Japan’s Agency for Cultural Affairs declared that commercial use of AI-generated
    art, especially when copying another artist’s style without permission, may lead
    to copyright infringement, allowing the original artist to sue and seek damages
    ([Liu, 2023](#ref5_33)). Aside from this, Japan has developed and revised some
    AI-related regulations with the goal of maximising AI’s positive impact on society,
    rather than suppressing it due to risks that may be overstated. The emphasis is
    on a risk-based, flexible, and multi-stakeholder process, rather than a one-size-fits-all
    obligation or prohibition ([Minevich, 2023](#ref5_38)).
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 日本在人工智能监管方面采取了谨慎的态度。日本政府已经发布了一系列关于人工智能的指南 ([《日本时报》，2023](#ref5_59))，但尚未发布任何全面的人工智能法规。政府担心人工智能的潜在风险，如就业岗位流失、偏见和艺术版权
    ([经济产业省，2021](#ref5_39))。例如，2023年6月，日本文化事务局宣布，未经许可的商业使用人工智能生成的艺术作品，尤其是模仿其他艺术家的风格，可能构成侵权，允许原创艺术家提起诉讼并寻求赔偿
    ([刘，2023](#ref5_33))。除此之外，日本还制定和修订了一些与人工智能相关的法规，旨在最大化人工智能对社会积极影响，而不是因为可能被夸大的风险而压制它。重点在于基于风险的、灵活的、多利益相关者的过程，而不是一刀切的责任或禁止
    ([米涅维奇，2023](#ref5_38))。
- en: 5.3.8 UNESCO
  id: totrans-98
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3.8 联合国教科文组织
- en: While UNESCO is not a regulatory body, it has been working to develop international
    norms and standards for AI. Quoting Gabriela Ramos, the Assistant Director-General
    for Social and Human Sciences of UNESCO, “It is important that we act fast to
    make sure that people and organizations are prepared to design and use these technologies,
    evaluating their impacts both ex-ante and ex-post. To do so, we provided clear
    analyses and policy advice based on the UNESCO Recommendation” ([UNESCO, 2023b](#ref5_63)).
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管联合国教科文组织不是一个监管机构，但它一直在努力制定人工智能的国际规范和标准。引用联合国教科文组织社会和人文科学助理总干事加布里埃拉·拉莫斯的话，“我们迅速行动，确保人们和组织能够准备设计和使用这些技术，评估其事前和事后的影响，这一点非常重要。为此，我们基于联合国教科文组织建议提供了明确的分析和政策建议”
    ([联合国教科文组织，2023b](#ref5_63))。
- en: UNESCO, recognising the transformative impact of AI on societies, emphasises
    a human-centric approach to AI ethics. They underscore the importance of universal
    values, such as human rights, fairness, and transparency, as foundational principles,
    recommending that AI systems be designed and deployed to respect the rule of law,
    human rights, and democratic values. It also stresses that AI should prioritise
    inclusivity and equity and not perpetuate discrimination or biases. The organisation
    further highlights the importance of transparency and accountability in AI, ensuring
    that systems can be audited and are explainable to the general public ([UNESCO,
    2023a](#ref5_62)). Moreover, UNESCO calls for international cooperation and multi-stakeholder
    dialogues to address the global challenges posed by AI, promoting knowledge sharing,
    capacity building, and the creation of ethical standards that transcend borders.
    The organisation also advocates for the empowerment of individuals to ensure that
    they have the skills and knowledge to navigate an AI-driven world and to actively
    participate in AI-related decision-making processes ([UNESCO, 2023b](#ref5_63)).
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 联合国教科文组织认识到人工智能对社会具有变革性影响，强调以人为中心的人工智能伦理方法。他们强调普遍价值，如人权、公平和透明度，作为基础原则，建议人工智能系统应设计和部署以尊重法治、人权和民主价值观。它还强调人工智能应优先考虑包容性和公平性，不应持续歧视或偏见。该组织进一步强调人工智能中的透明度和问责制的重要性，确保系统可以接受审计，并对公众可解释([联合国教科文组织，2023a](#ref5_62))。此外，联合国教科文组织呼吁国际合作和多利益相关者对话，以应对人工智能带来的全球挑战，促进知识共享、能力建设和跨越国界的伦理标准创建。该组织还主张赋予个人权力，确保他们具备在人工智能驱动世界中导航的技能和知识，并积极参与与人工智能相关的决策过程([联合国教科文组织，2023b](#ref5_63))。
- en: 5.3.9 Differentiation and Progressiveness in Global AI Regulation
  id: totrans-101
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3.9 全球人工智能监管中的差异化和渐进性
- en: Countries and organisations around the world have taken varied stances on AI
    regulation, with differences rooted in their priorities, cultural values, and
    socio-economic, political, and technological landscapes. China’s strategy, deeply
    rooted in national security and technological self-reliance, is comprehensive
    and forward-looking, aiming for AI dominance by 2030 ([Robles, 2023](#ref5_51)).
    Contrarily, the United States adopts a laissez-faire approach, relying on industry
    leadership and state-level legislations, in balancing innovation and minimal central
    oversight ([Larsen, 2023](#ref5_30)). Meanwhile, the European Union emerges as
    a pioneer by introducing the world’s first comprehensive AI law – the Artificial
    Intelligence Act – which reflects their proactive, rights-centric approach ([Mukherjee
    et al., 2023](#ref5_40)). The UK, while innovative, is also cautious, setting
    up a future-oriented framework that prioritises public safety ([UK Government,
    2023](#ref5_61)). Australia’s emphasis on addressing deceptive AI content signals
    their proactive, yet still-evolving stance ([Australian Government Department
    of Industry, Science and Resources, 2023](#ref5_1)). India stands out with its
    cautionary approach, prioritising market dynamics and readiness, signalling a
    commitment to carving a unique and adaptive regulatory trajectory ([Singh, 2023](#ref5_55)).
    Japan accentuates societal benefits and risk management, emphasising practicality
    and adaptability in its guidelines ([Matsuda et al., 2023](#ref5_35)). Finally,
    UNESCO offers a global perspective that emphasises human rights. Collectively,
    these nations and organisation’s varying approaches highlight a global recognition
    of AI’s transformative potential, with each paving a path based on national imperatives
    and global technological shifts.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 世界各国和各组织对AI法规采取了不同的立场，这些差异源于它们的优先事项、文化价值观以及社会经济、政治和技术格局。中国的战略深深植根于国家安全和技术自力更生，是全面和前瞻性的，旨在到2030年实现AI主导([Robles，2023](#ref5_51))。相反，美国采取放任自流的方法，依靠行业领导和州级立法，在平衡创新和最小中央监管之间取得平衡([Larsen，2023](#ref5_30))。同时，欧盟通过引入世界上第一部全面的AI法律——人工智能法案，展现了其积极主动、以权利为中心的方法([Mukherjee等人，2023](#ref5_40))。英国虽然具有创新精神，但也非常谨慎，建立了一个面向未来的框架，优先考虑公共安全([英国政府，2023](#ref5_61))。澳大利亚强调解决虚假AI内容，显示出其积极主动但仍在发展的立场([澳大利亚政府工业、科学和资源部，2023](#ref5_1))。印度以其谨慎的方法脱颖而出，优先考虑市场动态和准备情况，表明了其对开辟独特和适应性强的监管轨迹的承诺([Singh，2023](#ref5_55))。日本强调社会效益和风险管理，在其指南中强调实用性和适应性([Matsuda等人，2023](#ref5_35))。最后，联合国教科文组织提供了一个强调人权的全球视角。这些国家和组织的不同方法共同表明，全球对AI变革潜力的认识，每个国家都在根据国家需求和全球技术变革开辟自己的道路。
- en: 5.3.10 Business Reactions Towards the Regulations
  id: totrans-103
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3.10 对法规的企业反应
- en: Companies, particularly tech giants, have had mixed reactions to these regulations.
    While most acknowledge the need for ethical guidelines and oversight, there are
    concerns about the stifling of innovation. Many companies are also establishing
    their own AI ethics boards and principles, recognising the need for responsible
    AI development and deployment. Generally, businesses believe that clear rules
    will help in building public trust and provide a stable environment for innovation.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 公司，尤其是科技巨头，对这些法规的反应各不相同。虽然大多数公司承认需要道德准则和监管，但也有人担心这会抑制创新。许多公司也在建立自己的AI伦理委员会和原则，认识到负责任地开发和应用AI的必要性。一般来说，企业认为明确的规则将有助于建立公众信任，并为创新提供一个稳定的环境。
- en: One of the biggest concerns that businesses have about AI regulations is that
    the latter could be used to protect incumbent companies from new entrants to the
    sector ([Federal Trade Commission Bureau of Competition & Office of Technology,
    2023](#ref5_14)). For example, a large company could lobby for regulations that
    would make it difficult for smaller companies to develop and deploy AI products.
    Another concern is that regulations could be complex and difficult to comply with;
    this could be especially challenging for small businesses.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 企业对AI法规的最大担忧之一是，后者可能会被用来保护现有公司免受新进入该行业的竞争者的影响([联邦贸易委员会竞争局与技术办公室，2023](#ref5_14))。例如，一家大公司可能会游说制定法规，使得小型公司难以开发和部署AI产品。另一个担忧是，法规可能很复杂且难以遵守；这对小型企业来说可能尤其具有挑战性。
- en: Overall, businesses are supportive of AI regulations, but they also have some
    concerns. It is important for regulators to strike a balance between protecting
    consumers and ensuring that AI is used responsibly without hampering or inhibiting
    innovation.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，企业支持人工智能监管，但也存在一些担忧。对于监管者来说，在保护消费者和确保人工智能负责任地使用、不阻碍或抑制创新之间取得平衡至关重要。
- en: 5.4 AI Policy in Education
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.4 教育中的AI政策
- en: Having examined the overarching principles, policies, and regulations of AI
    across various nations and institutions, it is now an opportune moment to redirect
    our attention towards education. To effectively harness AI’s potential in academia,
    it is crucial to be guided by a clear policy framework. By understanding the broader
    AI policies of different countries, we gain insight into the important principles
    and threats of AI, the current development in policy, potential pitfalls, and
    the diverse ways by which AI is regulated, approached, and integrated. Taking
    on this informed, global perspective will ensure that approaches to formulate
    AI policies for education are informed, comprehensive, and adaptive.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在审视了各国和机构间人工智能的总体原则、政策和法规后，现在正是将我们的注意力转向教育的时候。为了有效地利用人工智能在学术领域的潜力，遵循一个明确的政策框架至关重要。通过了解不同国家的更广泛人工智能政策，我们能够洞察人工智能的重要原则和威胁、政策现状、潜在陷阱以及人工智能的监管、方法和整合的多种方式。采取这种知情、全球的视角将确保制定教育人工智能政策的方法是信息丰富、全面和适应性强的。
- en: Our subsequent discussion on AI policy in education is underpinned by valuable
    research data, capturing the perspectives of both teachers and students. These
    insights will provide a nuanced understanding of what key stakeholders believe
    to be the vital components of a robust AI policy in higher education, ensuring
    that our educational institutions remain both technologically advanced and ethically
    grounded, overall aiming to foster a more informed, inclusive, and forward-thinking
    educational landscape.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 我们接下来关于教育人工智能政策的讨论建立在有价值的研究数据之上，这些数据反映了教师和学生的观点。这些见解将提供对关键利益相关者认为的高等教育稳健人工智能政策的关键组成部分的深入理解，确保我们的教育机构在技术先进的同时，也具有道德基础，总体目标是培养一个更加信息丰富、包容和前瞻性的教育格局。
- en: 5.4.1 UNESCO’s Guidance for GenAI in Education and Research
  id: totrans-110
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.4.1 联合国教科文组织关于教育与研究生成式人工智能的指南
- en: In light of the rapid advancements in GenAI technologies and their far-reaching
    implications for education and research, UNESCO has taken a proactive stance to
    guide its ethical and effective integration into educational ecosystems. On 7
    September 2023 during UNESCO’s Digital Learning Week, Miao and Holmes released
    the first global UNESCO Guidance on Generative AI in Education and Research ([UNESCO,
    2023c](#ref5_64)), which serves as a seminal document and lays down a roadmap
    for governments around the world. The guidance delves into the intricacies of
    GenAI, shedding light on its operational mechanics and its accompanying controversies,
    particularly its propensity to exacerbate the digital data divide due to its training
    on predominantly Global North-centric online data.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于生成式人工智能技术的快速发展及其对教育和研究产生的深远影响，联合国教科文组织采取了积极主动的立场，以指导其在教育生态系统中的道德和有效整合。2023年9月7日，在联合国教科文组织数字学习周期间，苗和霍姆斯发布了首份全球联合国教科文组织关于教育与研究生成式人工智能的指南（[UNESCO,
    2023c](#ref5_64)），这是一份开创性的文件，为世界各国政府制定路线图。该指南深入探讨了生成式人工智能的复杂性，揭示了其运作机制及其伴随的争议，特别是由于主要基于全球北方为中心的在线数据而训练，其倾向于加剧数字数据鸿沟。
- en: The guidance is a clarion call for a human-centred approach for GenAI adoption
    in schools, underpinned by robust regulatory frameworks and a well-rounded teacher
    training regimen. It outlines seven essential steps for governments to foster
    an ethical ethos for GenAI use in education and research, including provisions
    for global, regional, and national data protection and privacy standards. A notable
    recommendation is that for the implementation of an age requirement of 13 and
    above for the use of AI tools in classrooms, underscoring the importance of a
    cautious and thoughtful approach to GenAI deployment.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 该指南是对学校采用生成式人工智能时采取以人为本的方法的强烈呼吁，其基础是稳健的监管框架和全面的教师培训制度。它概述了政府为培养教育和研究中使用生成式人工智能的道德精神而应采取的七个基本步骤，包括全球、区域和国家数据保护和隐私标准的规定。一个值得注意的建议是，对于在课堂上使用人工智能工具的13岁及以上年龄要求，强调了谨慎和深思熟虑地部署生成式人工智能的重要性。
- en: Based on the principles of UNESCO’s 2021 Recommendation on the Ethics of Artificial
    Intelligence ([UNESCO, 2023a](#ref5_62)), the guidance also emphasises the importance
    of putting human rights and dignity at the centre of AI development and use, championing
    human agency, inclusion, equity, gender equality, and cultural and linguistic
    diversity. It accentuates the dire need for educational institutions to meticulously
    validate GenAI systems for their ethical and pedagogical appropriateness, and
    for the international community to deliberate the long-term ramifications of GenAI
    implementation on knowledge, teaching, learning, and assessment paradigms.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 根据2021年联合国教科文组织关于人工智能伦理的建议原则([UNESCO, 2023a](#ref5_62))，该指南也强调了将人权和尊严置于人工智能发展和应用中心的重要性，倡导人类能动性、包容性、公平性、性别平等以及文化和语言多样性。它强调了对教育机构精心验证生成式人工智能系统在伦理和教学适宜性方面的迫切需求，以及对国际社会就生成式人工智能实施对知识、教学、学习和评估范式长期影响的深思熟虑。
- en: Furthermore, the guidance calls for a collective reflection on the profound
    implications of GenAI, urging the global community to redefine our relationship
    with technology as outlined in the 2021 report of the International Commission
    on the Futures of Education ([International Commission on the Futures of Education,
    2021](#ref5_27)). By providing a comprehensive framework and tangible examples
    for policy formulation and instructional design, the guidance empowers policymakers
    and educational institutions to navigate the uncharted waters of GenAI integration,
    ensuring this technology serves as a boon rather than a bane for students, teachers,
    and researchers alike. Moreover, through this guidance, UNESCO strives to foster
    a harmonious coalescence of GenAI with educational activities, steering the global
    educational landscape towards a future where technology and human endeavours thrive
    together in a symbiotic relationship.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，该指南呼吁对生成式人工智能的深远影响进行集体反思，敦促全球社区重新定义我们与技术的关系，正如国际教育未来委员会2021年报告所概述([国际教育未来委员会，2021](#ref5_27))。通过提供政策制定和教学设计方面的全面框架和具体实例，该指南赋予政策制定者和教育机构在生成式人工智能整合的未知领域航行的能力，确保这项技术对学生、教师和研究人员
    alike 都是有益而非有害。此外，通过本指南，联合国教科文组织力求促进生成式人工智能与教育活动的和谐融合，引导全球教育格局朝着技术与人共同努力、共生共荣的未来发展。
- en: 'Finally, regarding the UNESCO guidance’s recommendations for the planning of
    policies and development of comprehensive policy frameworks for using GenAI in
    education and research, the document also proposes eight specific measures to
    do so ([UNESCO, 2023c](#ref5_64)). They are:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，关于联合国教科文组织指南对制定政策和制定使用生成式人工智能于教育和研究方面的全面政策框架的建议，该文件还提出了八项具体措施([UNESCO, 2023c](#ref5_64))。它们是：
- en: '**Promote Inclusion, Equity, and Linguistic and Cultural Diversity**'
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**促进包容性、公平性和语言及文化多样性**'
- en: This measure emphasises ensuring that GenAI tools are inclusively accessible
    and designed to advance equity, linguistic diversities, and cultural pluralism.
    By prioritising inclusivity and diversity, this measure aims to leverage GenAI
    to bridge educational gaps and foster a culturally diverse learning and research
    environment. This approach aligns with the broader goal of achieving Sustainable
    Development Goal 4 (SDG 4) commitments, which advocate for inclusive and equitable
    quality education.
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 此措施强调确保生成式人工智能工具具有包容性可访问性，并设计用于推进公平性、语言多样性和文化多元主义。通过优先考虑包容性和多样性，本措施旨在利用生成式人工智能弥合教育差距，培养一个文化多元的学习和研究环境。这种方法与实现可持续发展目标4（SDG
    4）的更广泛目标相一致，该目标倡导包容性和公平的质量教育。
- en: '*Recommendations include*:'
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*建议包括*：'
- en: 'Universal Connectivity and Digital Competencies: Ensuring universal connectivity
    and enhancing digital competencies are essential steps for overcoming the barriers
    to equitable and inclusive access to AI applications, in turn fostering a more
    diverse and accepting learning environment.'
  id: totrans-119
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通用连接性和数字能力：确保通用连接性和提高数字能力是克服公平和包容获取人工智能应用障碍的必要步骤，从而培养一个更加多元和包容的学习环境。
- en: 'Validation against Bias: Developing rigorous validation criteria for GenAI
    systems to check against gender bias, discrimination, hate speech, and so on,
    is essential to promote equity and ensure that these systems are inclusive by
    design.'
  id: totrans-120
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 验证偏见：为生成式人工智能系统开发严格的验证标准，以检查性别偏见、歧视、仇恨言论等问题，对于促进公平并确保这些系统在设计上具有包容性至关重要。
- en: 'Multilingual and Culturally Diverse Specifications: Implementing specifications
    that require GenAI systems to support multiple languages and cultural contexts
    are vital for preserving linguistic and cultural diversity, thus making education
    and research more globally accessible and relevant.'
  id: totrans-121
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多语言和文化多样性规范：实施要求GenAI系统支持多种语言和文化背景的规范，对于保护语言和文化多样性至关重要，从而使教育和研究更具全球性和相关性。
- en: '**Protect Human Agency**'
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**保护人类能动性**'
- en: This measure aims to ensure that GenAI does not undermine human thinking and
    autonomy, especially as users may rely on it for creative activities and decision-making.
    This involves fostering awareness among users about the workings of GenAI, preserving
    human accountability particularly during high-stakes decisions, and promoting
    a balanced use of GenAI in educational settings to avoid over-dependence.
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 此措施旨在确保GenAI不会削弱人类思维和自主性，尤其是当用户可能依赖它进行创造性活动和决策时。这包括在用户中培养对GenAI运作的认识，特别是在高风险决策期间保持人类问责制，以及在教育环境中促进GenAI的平衡使用，以避免过度依赖。
- en: '*Recommendations include*:'
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*建议包括*：'
- en: 'Informing Learners: Informing and educating learners about the types of data
    that GenAI collects, how this data is used, and how this all impacts their education
    and wider lives is crucial for promoting transparency and informed engagement
    with these technologies.'
  id: totrans-125
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通知学习者：向学习者告知GenAI收集的数据类型、这些数据如何使用以及这一切如何影响他们的教育和更广泛的生活，对于促进透明度和对这些技术的知情参与至关重要。
- en: 'Reinforcing Human Autonomy: Reinforcing human autonomy in research, teaching,
    and learning encourages individuals to maintain control over their educational
    and creative processes, ensuring that GenAI serves as a supportive tool rather
    than a replacement for human thinking and intellect.'
  id: totrans-126
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 加强人类自主性：在研究、教学和学习中加强人类自主性，鼓励个人保持对其教育和创造性过程的控制，确保生成式人工智能（GenAI）作为人类思维和智力的辅助工具，而不是替代品。
- en: 'Preventing Over-reliance on GenAI: Preventing the use of GenAI in scenarios
    where it could deprive learners of developing essential cognitive and social skills
    is important to nurturing a balanced, human-centric educational environment.'
  id: totrans-127
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 防止过度依赖GenAI：在可能剥夺学习者发展基本认知和社会技能的场景中防止使用GenAI，对于培养平衡、以人为本的教育环境至关重要。
- en: 'Promoting Social Interaction and the Creative Outputs of Humans: Promoting
    sufficient social interaction and exposure to creative outputs produced by humans
    will help to preserve the human essence of education, encouraging personal growth
    and social development.'
  id: totrans-128
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 促进人际互动和人类的创造性成果：促进足够的社交互动和接触人类产生的创造性成果，将有助于保持教育的本质，鼓励个人成长和社会发展。
- en: 'Minimising Exam and Homework Pressures: Utilising GenAI to alleviate the pressures
    of homework and exams can contribute to a healthier learning environment, in turn
    also supporting the mental well-being of learners.'
  id: totrans-129
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最小化考试和作业压力：利用GenAI减轻作业和考试的压力，可以促进更健康的学习环境，进而也支持学习者的心理健康。
- en: 'Collecting and Utilising Feedback: Consulting with and collecting feedback
    from researchers, teachers, and learners on GenAI tools, and then utilising this
    feedback for informed decision-making, ensures that the deployment of GenAI is
    in line with the needs and preferences of the educational community.'
  id: totrans-130
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 收集和利用反馈：与研究人员、教师和学习者协商，收集他们对GenAI工具的反馈，然后利用这些反馈进行知情决策，确保GenAI的部署符合教育社区的需求和偏好。
- en: 'Maintaining Human Accountability: Maintaining human accountability when making
    high-stakes decisions will help ensure that ethical and responsible actions are
    taken, reinforcing the centrality of human agency in the educational process.'
  id: totrans-131
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 保持人类问责制：在做出高风险决策时保持人类问责制，将有助于确保采取道德和负责任的行为，加强人类在教育过程中的核心作用。
- en: '**Monitor and Validate GenAI Systems for Education**'
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**监控和验证教育用GenAI系统**'
- en: This measure of monitoring and validating GenAI systems for education emphasises
    the importance of ensuring the ethical and pedagogical soundness of GenAI throughout
    its advancements. The measure proposes a framework with which GenAI applications
    can be scrutinised for potential biases, ethical risks, and their impact on students,
    teachers, and the broader educational ecosystem. The goal is to establish mechanisms
    that ensure GenAI applications are aligning with educational standards, promote
    fairness, and are devoid of harmful content. Additionally, this measure stresses
    the importance of informed consent, especially when engaging vulnerable populations
    like children, and the need for a strict ethical validation before the official
    adoption of GenAI applications in educational or research institutions.
  id: totrans-133
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这个监测和验证GenAI系统用于教育的措施强调了确保GenAI在其进步过程中的伦理和教学稳健性的重要性。该措施提出了一个框架，通过该框架可以对GenAI应用进行审查，以识别潜在的偏见、伦理风险及其对学生、教师和更广泛的教育生态系统的影响。目标是建立确保GenAI应用与教育标准一致、促进公平且不包含有害内容的机制。此外，该措施强调了知情同意的重要性，特别是在与儿童等易受伤害的群体互动时，以及在官方采用GenAI应用在教育或研究机构之前进行严格的伦理验证的需要。
- en: '*Recommendations include*:'
  id: totrans-134
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*建议包括*：'
- en: 'Building Validation Mechanisms: By building validation mechanisms to test GenAI
    systems for potential biases and the representativeness of the data used to train
    them, we can better ensure that their applications are fair, inclusive, and reflective
    of the learner population’s diversity.'
  id: totrans-135
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 建立验证机制：通过建立验证机制来测试GenAI系统潜在的偏见以及用于训练它们的数据的代表性，我们可以更好地确保其应用是公平的、包容的，并且反映了学习群体多样性。
- en: 'Addressing Informed Consent: To ensure ethical engagement with GenAI systems,
    addressing the complex issue of informed consent is crucial, particularly in contexts
    where children and other vulnerable users may not be capable of genuinely and
    fully providing informed consent.'
  id: totrans-136
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解决知情同意问题：为确保与GenAI系统的伦理互动，解决知情同意这一复杂问题至关重要，尤其是在儿童和其他易受伤害的用户可能无法真正和全面提供知情同意的情况下。
- en: 'Auditing GenAI Outputs: Auditing whether the outputs of GenAI include deceptive
    or harmful material, including deepfake images, fake news, or hate speech, is
    essential to maintain a safe and truthful educational environment and to take
    swift corrective actions if inappropriate content is generated.'
  id: totrans-137
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 审计GenAI输出：审计GenAI输出是否包含欺骗性或有害内容，包括深度伪造图像、假新闻或仇恨言论，对于维护一个安全、真实的教育环境至关重要，并在生成不适当内容时采取迅速的纠正措施。
- en: 'Ethical Validation: Enforcing the strict ethical validation of GenAI applications
    before their official adoption in educational or research institutions will help
    to ensure that they conform to ethical and pedagogical standards.'
  id: totrans-138
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 伦理验证：在GenAI应用在教育或研究机构正式采用之前进行严格的伦理验证，将有助于确保它们符合伦理和教学标准。
- en: 'Ensuring Educational Effectiveness: Ensuring that GenAI applications do no
    predictable harm, are educationally effective, and are aligned with sound pedagogical
    principles is crucial for fulfilling educational objectives and safeguarding the
    well-being of learners.'
  id: totrans-139
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保教育有效性：确保GenAI应用不会造成可预测的伤害，具有教育效果，并且与良好的教学原则一致，对于实现教育目标和保护学习者的福祉至关重要。
- en: '**Develop AI Competencies Including GenAI-related Skills for Learners**'
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**为学习者开发包括GenAI相关技能的AI能力**'
- en: The measure proposes the development of government-endorsed AI curricula that
    will cover ethical issues, understanding of algorithms, and proper use of AI tools
    and applications at various levels of education, including in technical and vocational
    training. Such curricula should promote gender equality in learners’ development
    of AI competencies, as well as enhance learners’ future-proof skills in response
    to the evolving job market as driven by GenAI advancements and automation. This
    measure also emphasises the importance of supporting higher education and research
    institutions in developing local AI talent, and providing special programmes for
    older workers and citizens to help them adapt to the new technological landscape.
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 该措施建议开发政府认可的AI课程，这些课程将涵盖伦理问题、算法理解以及在不同教育层次上（包括技术和职业培训）正确使用AI工具和应用。此类课程应促进学习者在AI能力发展中的性别平等，以及增强学习者应对由通用人工智能进步和自动化推动的就业市场变化的未来技能。此措施还强调支持高等教育和研究机构培养当地AI人才，并为老年工人和公民提供特别项目，帮助他们适应新的技术环境。
- en: '*Recommendations include*:'
  id: totrans-142
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*以下是一些建议*：'
- en: 'Government-Sanctioned AI Curricula: Committing to the provision of government-sanctioned
    AI curricula across different levels of education and lifelong learning platforms
    will be crucial for building a foundational and level-appropriate understanding
    of AI technologies, ethics, and their impact.'
  id: totrans-143
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 政府批准的AI课程：承诺在不同教育层次和终身学习平台上提供政府批准的AI课程，对于构建基础和层次适当的AI技术、伦理及其影响的理解至关重要。
- en: 'Supporting Higher Education and Research Institutions: Supporting higher education
    and research institutions in enhancing their programmes will also help to develop
    local AI talent.'
  id: totrans-144
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持高等教育和研究机构：支持高等教育和研究机构提升其项目也将有助于培养当地的AI人才。
- en: 'Promoting Gender Equality: Promoting gender equality when developing learners’
    advanced AI competencies will help in creating a pool of professionals which is
    better gender-balanced.'
  id: totrans-145
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 促进性别平等：在培养学习者高级AI能力时促进性别平等，有助于建立一个性别更平衡的专业人员库。
- en: 'Developing Intersectoral Forecasts for the Changing Job Market: By developing
    intersectoral forecasts that predict job shifts caused by GenAI automation, as
    well as prioritising the enhancement of future-proof skills at all levels of education,
    we can better ensure that learners are well-prepared for the evolving job market.'
  id: totrans-146
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开发跨行业预测以应对变化的就业市场：通过开发预测由通用人工智能自动化引起的职业转变的跨行业预测，以及优先提高所有教育层次的未来技能，我们可以更好地确保学习者为不断变化的就业市场做好准备。
- en: 'Providing Special Programmes for Older Workers: To ensure that the benefits
    of AI are accessible to all, regardless of age, it will be necessary to provide
    special programmes designed for older workers and citizens who may need to learn
    new skills and support in adapting to new technological environments.'
  id: totrans-147
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为老年工人提供特别项目：为确保AI的益处对所有年龄层的人都可及，将有必要为可能需要学习新技能和适应新技术环境的老年工人和公民提供特别项目。
- en: '**Build Capacity for Teachers and Researchers to Make Proper Use of GenAI**'
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**为教师和研究人员建立有效使用通用人工智能的能力**'
- en: This measure underscores the necessity of equipping teachers and researchers
    with the requisite knowledge and skills to utilise GenAI effectively and responsibly.
    According to the UNESCO guidance, only several countries have developed or are
    in the process of developing frameworks and training programmes on AI for teachers.
    This indicates a significant gap in access to training and support. As such, this
    measure outlines four actions needed to better prepare teachers around the world
    to use GenAI, including to formulate guidance based on local tests, protect the
    rights of teachers and researchers as well as value their GenAI practices, define
    the required value orientation, knowledge, and skills for teachers, and dynamically
    review and promote the emerging competencies that teachers will need to understand
    and utilise AI in their professional practices.
  id: totrans-149
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这项措施强调了为教师和研究人员配备有效和负责任地利用通用人工智能（GenAI）所需的知识和技能的必要性。根据联合国教科文组织的指导，只有少数国家已经开发或正在开发针对教师的AI框架和培训项目。这表明在培训和支援的获取方面存在重大差距。因此，这项措施概述了四个行动，旨在更好地为全球教师使用通用人工智能做好准备，包括基于本地测试制定指导方针、保护教师和研究人员的权利以及重视他们的通用人工智能实践、定义教师所需的价值取向、知识和技能，以及动态审查和推广教师将需要在专业实践中理解和利用人工智能所需的新兴能力。
- en: '*Recommendations include*:'
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*建议包括*：'
- en: 'Formulating or Adjusting Guidance: Provide help for teachers and researchers
    to navigate widely available GenAI tools by formulating or adjusting guidance
    based on local tests and evaluations, as well as supporting the design of new
    domain-specific AI applications.'
  id: totrans-151
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 制定或调整指导方针：为教师和研究人员提供帮助，通过根据本地测试和评估制定或调整指导方针，以及支持设计新的特定领域AI应用，以导航广泛可用的GenAI工具。
- en: 'Protecting the Rights of Teachers and Researchers: Human teachers and researchers
    both have unique roles that should be appreciated, such as their facilitation
    of interpersonal interactions and making of innovative contributions to knowledge.
    By protecting the rights of teachers and researchers and valuing their practices
    when using GenAI, the integrity and quality of educational and research processes
    can be upheld.'
  id: totrans-152
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 保护教师和研究人员的权利：人类教师和研究人员都扮演着独特的角色，应受到重视，例如他们促进人际互动和为知识做出创新贡献。通过保护教师和研究人员的权利，并在使用GenAI时重视他们的实践，可以维护教育和研究过程的完整性和质量。
- en: 'Defining Value Orientation, Knowledge, and Skills: To ensure that teachers
    understand and use GenAI systems effectively and ethically, thereby also contributing
    to the responsible integration of GenAI systems in education, it is important
    to define the value orientation(s), knowledge, and skills that are needed to do
    so.'
  id: totrans-153
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义价值观、知识和技能：为确保教师能够有效和道德地使用GenAI系统，从而也为GenAI系统在教育中的负责任整合做出贡献，定义实现这一目标所需的价值观、知识和技能至关重要。
- en: 'Dynamically Reviewing Competencies: By taking on a dynamic approach when reviewing
    the competencies needed by teachers to understand and use AI for teaching, learning,
    and professional development, we can better ensure that educators are well-prepared
    to adapt to the evolving technological landscape within education.'
  id: totrans-154
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 动态审查能力：在审查教师理解和使用AI进行教学、学习和专业发展所需的能力时采取动态方法，我们可以更好地确保教育工作者能够适应教育领域不断发展的技术格局。
- en: '**Promote Plural Opinions and Plural Expressions of Ideas**'
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**促进多元意见和思想表达**'
- en: This measure discusses the promotion of critical thinking, encouraging learners
    to critique GenAI responses, and recognising the latter’s limitations in its reproduction
    of dominant worldviews that consequently undermines minority opinions. It emphasises
    the importance of promoting diversity in opinions and expressions, which GenAI
    may inadvertently suppress due to its tendency to regurgitate dominant or mainstream
    views that are present in the data it was trained on. By fostering a culture of
    critical engagement with GenAI outputs and encouraging empirical, trial-and-error
    learning approaches, this measure aims to preserve and promote pluralism and a
    diversity of ideas in education and research environments.
  id: totrans-156
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 此措施讨论了促进批判性思维，鼓励学习者批判GenAI的回应，并认识到后者在再现主导世界观方面的局限性，这进而损害了少数意见。它强调促进意见和表达的多样性，因为GenAI可能会无意中压制其训练数据中存在的占主导地位或主流观点。通过培养与GenAI输出进行批判性互动的文化，并鼓励实证的、试错的学习方法，这一措施旨在保护和促进教育和研究环境中的多元主义和思想多样性。
- en: '*Recommendations include*:'
  id: totrans-157
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*建议包括*：'
- en: 'Critiquing GenAI Responses: It is important to encourage learners and researchers
    in recognising that GenAI typically repeats established or standard opinions,
    thus undermining plural and minority opinions and ideas; to do so, they must be
    able to critique the responses and outputs they receive from GenAI.'
  id: totrans-158
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 批判GenAI的回应：鼓励学习者和研究人员认识到GenAI通常重复既定或标准意见，从而损害多元和少数意见和思想；为此，他们必须能够批判从GenAI收到的回应和输出。
- en: 'Providing Empirical Learning Opportunities: To foster a rich, exploratory learning
    environment that does not overly rely on GenAI, it is important to also provide
    learners with sufficient opportunities to learn from hands-on methods, including
    through trial-and-error, empirical experiments, and observations of the real world.'
  id: totrans-159
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供实证学习机会：为了培养一个不过度依赖GenAI的丰富、探索性学习环境，同时也很重要为学习者提供足够的机会通过实践方法学习，包括通过试错、实证实验和观察现实世界。
- en: '**Test Locally Relevant Application Models and Build a Cumulative Evidence
    Base**'
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**本地相关应用模型测试和建立累积证据基础**'
- en: This measure underscores the importance of tailoring GenAI applications to local
    needs and contexts, especially given the predominance of data from the Global
    North in training these systems and models. By fostering a strategic, evidence-based
    approach to the design, adoption, and evaluation of GenAI tools, this measure
    aims to encourage innovation, assess the social and ethical implications of GenAI,
    and build a robust evidence base that reflects diverse educational priorities
    and pedagogical principles that are both widely collaborative and still relevant
    to local needs. By doing so, GenAI can be leveraged more effectively to support
    inclusive learning opportunities, promote linguistic and cultural diversity, and
    address the environmental costs of large-scale AI deployments.
  id: totrans-161
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 此措施强调了根据本地需求和情境定制GenAI应用的重要性，特别是在这些系统和模型训练中数据主要来自全球北方的情况下。通过培养对GenAI工具的设计、采用和评估的策略、基于证据的方法，此措施旨在鼓励创新，评估GenAI的社会和伦理影响，并建立一个反映广泛合作且与本地需求相关的教育优先事项和教学原则的稳健证据基础。通过这样做，GenAI可以更有效地被利用来支持包容性学习机会，促进语言和文化多样性，并解决大规模AI部署的环境成本。
- en: '*Recommendations include*:'
  id: totrans-162
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*以下是一些建议*：'
- en: 'Strategic Planning of GenAI Design and Adoption: The design and adoption of
    GenAI must be strategically planned, and should do more than just facilitating
    passive, non-critical processes.'
  id: totrans-163
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: GenAI设计和采用的策略规划：GenAI的设计和采用必须进行策略规划，而不仅仅是促进被动、非关键的过程。
- en: 'Incentivising Diverse Learning Options: To support inclusivity and diversity,
    it is important to incentivise the designers and developers of GenAI to prioritise
    open-ended, exploratory, and diverse learning options.'
  id: totrans-164
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 鼓励多样化的学习选择：为了支持包容性和多样性，重要的是鼓励GenAI的设计者和开发者优先考虑开放性、探索性和多样化的学习选择。
- en: 'Testing and Scaling Evidence-based Use Cases: Use cases of AI’s applications
    in education and research should be tested and scaled up, done so in accordance
    with educational priorities and not due to novelty, myth, or hype.'
  id: totrans-165
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试和扩大基于证据的使用案例：AI在教育和研究中的应用案例应进行测试和扩大规模，这样做应遵循教育优先事项，而不是因为新奇性、神话或炒作。
- en: 'Triggering Innovation in Research: GenAI can be leveraged to stimulate innovation
    in research, including through making use of its computing capabilities, using
    GenAI to assist with processing large-scale data, and using its outputs to inform,
    inspire, and improve research and research methodologies.'
  id: totrans-166
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 激发研究创新：GenAI可以用来激发研究创新，包括利用其计算能力，使用GenAI协助处理大规模数据，以及利用其输出为研究及其方法论提供信息、启发和改进。
- en: 'Reviewing Social and Ethical Implications: It is important to conduct comprehensive
    reviews of the social and ethical implications of integrating GenAI into research
    processes.'
  id: totrans-167
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 审查社会和伦理影响：对将GenAI整合到研究过程中的社会和伦理影响进行全面审查是重要的。
- en: 'Building an Evidence Base: To establish an evidence base on the effectiveness
    of GenAI in promoting inclusivity and diversity in learning and research, it is
    crucial to establish specific criteria derived from pedagogical research and methodologies
    that are supported by evidence.'
  id: totrans-168
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 建立证据基础：为了建立关于GenAI在促进学习和研究包容性和多样性方面的有效性的证据基础，建立从教学研究和证据支持的方法中得出的具体标准是至关重要的。
- en: 'Strengthening Evidence on Social and Ethical Impact: Iterative steps must be
    taken to enhance the evidence of the social and ethical impacts of GenAI.'
  id: totrans-169
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 加强关于社会和伦理影响的证据：必须采取迭代步骤来增强关于通用人工智能（GenAI）社会和伦理影响的证据。
- en: 'Analysing Environmental Costs: It is essential to analyse the environmental
    impacts of implementing AI technologies at scale, such as the energy and resources
    needed for training GPT models. In doing so, it is also crucial to set sustainable
    targets for AI providers to meet to mitigate the potential contribution of AI
    to climate change.'
  id: totrans-170
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析环境成本：分析大规模实施AI技术（如训练GPT模型所需的能源和资源）的环境影响是至关重要的。在此过程中，为AI提供商设定可持续目标以减轻AI对气候变化潜在贡献也是至关重要的。
- en: '**Review Long-term Implications in Intersectoral and Interdisciplinary Manner**'
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**以跨部门和跨学科的方式审查长期影响**'
- en: This measure emphasises the necessity of a multi-disciplinary and multi-sectoral
    approach in evaluating the long-term implications of GenAI in education and research.
    By fostering collaboration among AI providers, educators, researchers, as well
    as also other involving stakeholders like parents and students, the measure aims
    to foster both a comprehensive understanding of and the means to effectively address
    any challenges that may arise in the future. This collaborative approach further
    seeks to make necessary system-wide adjustments in curriculum frameworks and assessment
    methodologies to fully leverage GenAI’s potential, while simultaneously mitigating
    its risks. It emphasises the importance of a diverse range of expertise in examining
    the long-term implications of GenAI on learning, research, human collaboration,
    and social dynamics.
  id: totrans-172
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 此措施强调评估通用人工智能在教育和研究领域长期影响的必要性，需要采取跨学科和多部门的途径。通过促进人工智能提供商、教育工作者、研究人员以及其他涉及的利益相关者（如家长和学生）之间的合作，该措施旨在促进对任何未来可能出现的挑战的全面理解，并有效应对这些挑战。这种协作方法还寻求在课程框架和评估方法中进行必要的系统调整，以充分利用通用人工智能的潜力，同时减轻其风险。它强调在考察通用人工智能对学习、研究、人类协作和社会动态的长期影响时，需要多样化的专业知识。
- en: '*Recommendations include*:'
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*建议包括*：'
- en: 'Collaborative Planning for System-wide Adjustments: To fully leverage the potential
    of GenAI for education and research while also minimising the associated risks
    it poses to these areas, it is crucial to plan and implement system-wide adjustments
    in curriculum frameworks and assessment methodologies. This process should be
    undertaken collaboratively by AI providers, educators, researchers, and representatives
    of parents and students.'
  id: totrans-174
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 系统调整的协作规划：为了充分利用通用人工智能（GenAI）在教育和研究领域的潜力，同时最大限度地减少其对这些领域带来的风险，在课程框架和评估方法中实施系统性的调整至关重要。这一过程应由人工智能提供商、教育工作者、研究人员以及家长和学生代表共同协作完成。
- en: 'Intersectoral and Interdisciplinary Expertise: In evaluating the long-term
    implications of GenAI on areas including learning and knowledge production, research
    and copyright, curriculum and assessment, and human collaboration and social dynamics,
    it is important to bring together a diverse range of experts from various sectors
    and disciplines. This includes educators, researchers, learning scientists, AI
    engineers, and other relevant stakeholders.'
  id: totrans-175
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 跨部门和跨学科的专业知识：在评估通用人工智能对包括学习和知识生产、研究和版权、课程和评估以及人类协作和社会动态等领域的影响时，重要的是汇集来自各个部门和学科的多样化专家。这包括教育工作者、研究人员、学习科学家、人工智能工程师以及其他相关利益相关者。
- en: 'Provision of Timely Advice: To inform the ongoing and iterative updates of
    AI regulations and policies, timely advice and guidance should be provided.'
  id: totrans-176
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 及时提供咨询：为了告知人工智能法规和政策的持续和迭代更新，应及时提供咨询和指导。
- en: To summarise the above, these eight measures by UNESCO all aim to provide a
    structured approach towards integrating GenAI in education and research while
    also addressing the associated ethical, social, and technical challenges.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 总结上述内容，联合国教科文组织提出的这八项措施，旨在为将通用人工智能融入教育和研究提供一种结构化的方法，同时解决相关的伦理、社会和技术挑战。
- en: 5.5 Research Findings from the Perception of Students, Teachers and Staff on
    GenAI in Education Policy in Hong Kong
  id: totrans-178
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.5 香港教育政策中学生对教师和员工对通用人工智能感知的研究发现
- en: To understand what is needed for an AI policy in higher education, we sought
    to explore the different views of various stakeholders in February 2023, shortly
    after the public release of ChatGPT. This involved examining the perspectives
    of students, teachers, and university staff concerning the need for an AI policy
    in education, especially for the higher education context where the spread and
    impact of AI technologies is irrefutable. While numerous governments are/were
    in the process of formulating AI guidelines, the predominant focus of these policies
    veered towards national and international strategies, with inadequate attention
    towards education. Most of the guidelines, as discussed in [Section 5.3](#sec5_3),
    primarily address the ethical management of AI technologies, emphasised “the standards
    of right and wrong, acceptable and not acceptable” ([Hogenhout, 2021](#ref5_25),
    p. 11), highlighting global concerns such as AI-induced discrimination, privacy
    invasions, human rights violations, and malicious AI use ([Greiman, 2021](#ref5_24);
    [Hogenhout, 2021](#ref5_25)), further underscoring the potential of AI misuse
    to foster social divisions, manipulate individuals, and aggravate inequalities,
    posing a profound threat to humanity ([Federspiel et al., 2023](#ref5_15)). The
    existing guidelines are still quite broad and, as mentioned, do not adequately
    extend to the education sector; this points to the pressing need to shed light
    on the challenges and advantages that are encountered by stakeholders in higher
    education.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解高等教育中AI政策所需的要素，我们在2023年2月，ChatGPT公开发布后不久，试图探索不同利益相关者的不同观点。这包括审视学生、教师和大学员工对教育中AI政策需求的看法，特别是在AI技术的传播和影响不可辩驳的高等教育环境中。尽管许多政府正在/曾经处于制定AI指南的过程中，但这些政策的重点主要偏向于国家和国际战略，对教育的关注不足。正如[第5.3节](#sec5_3)中讨论的那样，大多数指南主要针对AI技术的伦理管理，强调“对错、可接受与不可接受的标准”([Hogenhout,
    2021](#ref5_25)，第11页)，突出了全球关注的问题，如AI引起的歧视、隐私侵犯、侵犯人权和恶意AI使用([Greiman, 2021](#ref5_24)；[Hogenhout,
    2021](#ref5_25))，进一步强调了AI滥用可能加剧社会分裂、操纵个人和加剧不平等，对人类构成深刻威胁([Federspiel et al., 2023](#ref5_15))。现有的指南仍然相当宽泛，正如所提到的，并没有充分扩展到教育领域；这指出了迫切需要阐明高等教育利益相关者所面临的挑战和优势。
- en: 5.5.1 Methods
  id: totrans-180
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.5.1 方法
- en: Quantitative and qualitative data were collected through a survey administered
    to universities in Hong Kong ([Chan, 2023](#ref5_6)). A total of 457 students
    and 180 teachers and staff responses were collected. To understand their usages
    and perceptions of generative AI technologies, including ChatGPT, in higher education,
    descriptive analysis was used for the quantitative data and thematic analysis
    for the open-ended responses. Participants were asked about their experiences
    with ChatGPT or similar tools, and how they saw these technologies in relation
    to their educational practices.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 通过对香港大学进行的调查收集了定量和定性数据([Chan, 2023](#ref5_6))。共收集了457名学生的和180名教师及员工的反馈。为了了解他们在高等教育中对生成式AI技术（包括ChatGPT）的使用和看法，对定量数据使用了描述性分析，对开放式回应使用了主题分析。参与者被问及他们使用ChatGPT或类似工具的经验，以及他们如何看待这些技术与他们的教育实践之间的关系。
- en: The descriptive analysis summarised the main traits of the quantitative data,
    providing an overview of response tendencies, while thematic analysis of open-ended
    questions revealed patterns and themes regarding the integration of generative
    AI technologies into higher education, as well as suggestions for how university
    should build their strategic plans.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 描述性分析总结了定量数据的主要特征，提供了对响应趋势的概述，而开放式问题的主题分析揭示了将生成式AI技术融入高等教育以及大学如何构建其战略计划的建议。
- en: The mix of quantitative and qualitative data helped to provide a well-rounded
    understanding of stakeholder perceptions, allowing us to identify potential needs,
    recommendations, and strategies for AI policy development in teaching and learning
    at universities, ensuring the ethical and advantageous use of these technologies.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 定量和定性数据的结合有助于提供对利益相关者看法的全面理解，使我们能够确定AI政策在大学教学和学习中发展的潜在需求、建议和策略，确保这些技术的道德和有益使用。
- en: 5.5.2 Quantitative Findings
  id: totrans-184
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.5.2 定量发现
- en: 'One survey question looked at participants’ opinions on AI policy: whether
    students, teachers, and staff believed that there should be established plans
    and a dedicated policy for AI technologies and their use within the university.
    The results were encouraging, showing a strong consensus that institutions should
    indeed have such plans (students: *M* = 4.50, *SD* = .85; teachers and staff:
    *M* = 4.54, *SD* = .87; responses were based on a 5-point Likert scale, with “5”
    indicating “Strongly agree”). Responses to other questions further indicated that
    students and teachers are aware of the possible advantages and disadvantages associated
    with AI technologies. They also acknowledged the potential of using GenAI for
    guidance, personalised feedback, enhancing digital skills, and improving academic
    performance, along with its benefits of offering anonymity in student support
    services. However, apprehensions about excessive reliance on AI, reduced social
    engagement, and a possible impediment to the cultivation of generic skills were
    also expressed.'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 一项调查问题考察了参与者对人工智能政策的看法：学生、教师和员工是否认为应该制定针对人工智能技术和其在大学内使用的计划和专门政策。结果令人鼓舞，显示出强烈的共识，即机构确实应该有这样的计划（学生：M
    = 4.50，SD = .85；教师和员工：M = 4.54，SD = .87；回答基于5点李克特量表，其中“5”表示“强烈同意”）。对其他问题的回答进一步表明，学生和教师意识到与人工智能技术相关的可能优势和劣势。他们也承认使用通用人工智能进行指导、个性化反馈、提高数字技能和改善学术表现的可能性，以及它在学生支持服务中提供匿名性的好处。然而，对过度依赖人工智能、减少社交互动以及可能阻碍通用技能培养的担忧也被表达出来。
- en: 5.5.3 Qualitative Findings
  id: totrans-186
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.5.3 定性发现
- en: The qualitative data also provided insightful information for the establishment
    of a well-rounded AI policy in higher education. Ten key areas were found, grouped
    into three main dimensions to form the AI Ecological Education Policy Framework.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 定性数据也为高等教育中全面的人工智能政策的建立提供了有见地的信息。发现了十个关键领域，分为三个主要维度，形成人工智能生态教育政策框架。
- en: 5.5.3.1 Governance Dimension (Senior Management)
  id: totrans-188
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.5.3.1 治理维度（高级管理层）
- en: 'This dimension emphasises considerations for the governance of AI usage in
    education, including establishing the necessary policies, guidelines, and ethical
    standards to ensure that the adoption of AI is beneficial, fair, and secure. It
    encompasses the following key areas:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 此维度强调对教育中人工智能使用的治理的考虑，包括建立必要的政策、指南和伦理标准，以确保人工智能的采用是有益的、公平的和安全的。它包括以下关键领域：
- en: Understanding, identifying, and preventing academic misconduct and ethical dilemmas;
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 理解、识别和预防学术不端行为和伦理困境；
- en: Addressing governance of AI in terms of data privacy, transparency, accountability,
    and security;
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从数据隐私、透明度、责任和安全的角度解决人工智能的治理问题；
- en: Attribution for AI technologies; and
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 人工智能技术的归属；以及
- en: Ensuring equity in access to AI technologies.
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确保对人工智能技术的访问公平。
- en: 5.5.3.2 Operational Dimension (Teaching and Learning and IT Staff)
  id: totrans-194
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.5.3.2 运营维度（教学、学习和IT人员）
- en: 'This dimension concentrates on the practical implementation of AI in university
    settings and to ensure that such implementations are effective, reliable, and
    supported by adequate training and resources. It includes the following key areas:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 此维度专注于在大学环境中实际实施人工智能，并确保这些实施是有效的、可靠的，并得到充分的培训和资源的支持。它包括以下关键领域：
- en: Monitoring and evaluating AI implementation; and
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 监控和评估人工智能的实施；
- en: Providing training and support for teachers, staff, and students to ensure that
    they are AI literate.
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为教师、员工和学生提供培训和支持，以确保他们具备人工智能素养。
- en: 5.5.3.3 Pedagogical Dimension (Teachers)
  id: totrans-198
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.5.3.3 教学维度（教师）
- en: 'This dimension focuses on the teaching and learning aspects of AI integration
    and the creation of an educational environment that both leverages AI technologies
    and prepares students for a future where such technologies are prevalent. It includes
    the following key areas:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 此维度侧重于人工智能整合的教学和学习方面，以及创建一个既能利用人工智能技术又能为学生准备一个未来这种技术普遍存在的教育环境。它包括以下关键领域：
- en: Rethinking assessments and examinations;
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重新思考评估和考试；
- en: Developing students’ holistic competencies/generic skills;
  id: totrans-201
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 发展学生的综合能力/通用技能；
- en: Preparing students for the AI-driven workplace; and
  id: totrans-202
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为学生准备人工智能驱动的职场；并且
- en: Encouraging a balanced approach to AI adoption
  id: totrans-203
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 鼓励对人工智能采用的平衡方法
- en: 'For the full research paper, please refer to Chan, C.K.Y. ([2023](#ref5_6))
    A Comprehensive AI Policy Education Framework for University Teaching and Learning*.
    International Journal of Educational Technology in Higher Education*. DOI: [10.1186/s41239-023-00408-3](https://doi.org/10.1186/s41239-023-00408-3).'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 对于完整的研究论文，请参阅Chan, C.K.Y. ([2023](#ref5_6))《大学教学与学习综合人工智能政策教育框架》。*国际高等教育技术杂志*。DOI：[10.1186/s41239-023-00408-3](https://doi.org/10.1186/s41239-023-00408-3)。
- en: 5.5.4 The AI Ecological Education Policy Framework
  id: totrans-205
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.5.4 人工智能生态教育政策框架
- en: The AI Ecological Education Policy framework ([Chan, 2023](#ref5_6)) contains
    the aforementioned three dimensions to guide higher education in developing strategic
    plans to tackle the challenges of the AI era as shown in [Figure 5.3](#fig5_3).
    Each dimension is explained in further detail below.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能生态教育政策框架([Chan, 2023](#ref5_6))包含了上述三个维度，以指导高等教育在应对人工智能时代挑战时制定战略计划，如[图5.3](#fig5_3)所示。以下将详细解释每个维度。
- en: '![The A I ecological education policy framework has the governance dimension,
    operational dimension, and pedagogical dimension.](images/fig5_3_B.jpg)'
  id: totrans-207
  prefs: []
  type: TYPE_IMG
  zh: '![人工智能生态教育政策框架具有治理维度、运营维度和教学维度。](images/fig5_3_B.jpg)'
- en: '[Figure 5.3 AI Ecological Education Policy Framework.](#R_fig5_3)'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: '[图5.3 人工智能生态教育政策框架。](#R_fig5_3)'
- en: 'Senior management holds significant responsibility in the **governance dimension**
    as they are instrumental in policy formulation, the establishment of ethical guidelines,
    and overall institutional direction of AI integration. They ensure that their
    respective institutions will operate within the legal and ethical boundaries while
    striving for academic excellence and integrity. Their role is crucial in understanding,
    identifying, and preventing academic misconduct and ethical issues, addressing
    the governance of AI concerning data privacy, transparency, accountability, and
    security, the requirements to provide attribution to AI technologies, and ensuring
    equity in the access to AI technologies. Their decisions and policies set the
    tone for how AI will be embraced within the institution, impacting both pedagogical
    and operational dimensions. Within this governance dimension, there are four underlying
    key areas:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 高级管理层在**治理维度**上承担着重要的责任，因为他们是政策制定、建立道德准则和人工智能整合整体机构方向的工具。他们确保各自机构在追求学术卓越和诚信的同时，在法律和道德边界内运作。他们在理解、识别和预防学术不端行为和道德问题、解决与数据隐私、透明度、问责制和安全相关的人工智能治理、提供对人工智能技术的归属要求以及确保人工智能技术的获取公平性方面发挥着至关重要的作用。他们的决策和政策为机构内如何拥抱人工智能设定了基调，影响教学和运营两个维度。在这个治理维度中，有四个潜在的关键领域：
- en: Understanding, Identifying, and Preventing Academic Misconduct and Ethical Dilemmas
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 理解、识别和预防学术不端行为和道德困境
- en: The potential of AI technologies to be used for academic misconduct necessitates
    a robust governance framework to address this concern. Developing and enforcing
    policies on academic integrity and ethical AI use are crucial in promoting and
    maintaining a culture of integrity within the academic community. By addressing
    the governance of AI head-on, senior management can create a more conducive environment
    for the ethical use and integration of AI, mitigating its risks in relation to
    academic misconduct.
  id: totrans-211
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 人工智能技术被用于学术不端行为的潜力需要建立一个强大的治理框架来应对这一担忧。制定和执行关于学术诚信和道德人工智能使用的政策对于促进和维护学术社区中的诚信文化至关重要。通过直接解决人工智能的治理问题，高级管理层可以创造一个更有利于人工智能道德使用和整合的环境，减轻其在学术不端行为方面的风险。
- en: 'Addressing Governance of AI: Data Privacy, Transparency, Accountability, and
    Security'
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 解决人工智能治理：数据隐私、透明度、问责制和安全
- en: Effective governance to ensure data privacy, transparency, accountability, and
    security is paramount for the ethical and secure utilisation of AI. Establishing
    clear guidelines and policies for AI governance will help to address potential
    ethical dilemmas and allow for a more structured approach towards AI integration.
    The impact of these actions will be profound, contributing to enhanced trust,
    compliance, and responsible AI usage within the academic community.
  id: totrans-213
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 为了确保数据隐私、透明度、问责制和安全的有效治理，对于人工智能的道德和安全使用至关重要。建立清晰的人工智能治理准则和政策将有助于解决潜在的道德困境，并允许对人工智能整合采取更结构化的方法。这些行动的影响将是深远的，有助于增强信任、合规和负责任的人工智能使用。
- en: Attributing AI Technologies
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 归属人工智能技术
- en: Given that AI technologies can and likely will be used by students in their
    academic work, it is necessary to establish clear guidelines for the proper attribution
    and recognition of AI-generated content. Doing so can further promote academic
    honesty and ensure clarity in the acknowledgment of how AI was used. This, in
    turn, can foster a culture of transparency and honesty within the academic community.
    [Figure 5.4](#fig5_4) shows an example of how to write an attribution to acknowledge
    AI-generated text.
  id: totrans-215
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 考虑到人工智能技术可能会被学生在学术工作中使用，有必要制定明确的指南，以正确归属和认可人工智能生成的内容。这样做可以进一步促进学术诚信并确保对人工智能使用方式的认可清晰。这反过来可以培养学术社区中的透明度和诚信文化。[图5.4](#fig5_4)展示了如何撰写归属以认可人工智能生成的文本。
- en: '![An example of the attribution for Gen A I generated content.](images/fig5_4_B.jpg)'
  id: totrans-216
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![Gen A I生成内容的归属示例](images/fig5_4_B.jpg)'
- en: '[Figure 5.4 An Example of Attribution of GenAI Generated Content.](#R_fig5_4)'
  id: totrans-217
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[图5.4 GenAI生成内容的归属示例](#R_fig5_4)'
- en: Ensuring Equity in Access to AI Technologies
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确保人工智能技术获取的公平性
- en: Disparity in students’ access to AI technologies will exacerbate existing inequalities.
    It is thus crucial to implement measures for ensuring equitable access to AI resources
    as a critical action for promoting fairness and inclusivity. This could involve
    providing access to AI tools within the institution or creating support structures
    for students to learn and engage with AI technologies in a responsible manner.
  id: totrans-219
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 学生获取人工智能技术的差异将加剧现有的不平等。因此，实施确保人工智能资源公平获取的措施，作为促进公平和包容性的关键行动至关重要。这可能包括在机构内提供访问人工智能工具或为学生创建支持结构，以便他们以负责任的方式学习和与人工智能技术互动。
- en: 'Teaching and learning Support and IT staff play a significant role in the **operational
    dimension** as they are responsible for the practical implementation, monitoring,
    and provision of support for AI technologies. They ensure that any AI technologies
    integrated into the curricula are reliable, effective, and used responsibly. Their
    role in monitoring and evaluating AI implementation is critical for continuous
    improvement and upholding alignment with institutional goals. Additionally, they
    provide the necessary training and support for teachers, staff, and students,
    ensuring that all stakeholders are well-equipped with AI literacy and are capable
    of effectively navigating the complex landscape of AI in academia. Within the
    operational dimension, there are two underlying key areas:'
  id: totrans-220
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 教学和学习的支援以及IT人员在学校运营维度中发挥着重要作用，因为他们负责人工智能技术的实际实施、监控和支援提供。他们确保任何整合到课程中的人工智能技术都是可靠的、有效的，并且被负责任地使用。他们在监控和评估人工智能实施中的作用对于持续改进和保持与机构目标的协调至关重要。此外，他们为教师、员工和学生提供必要的培训和支援，确保所有利益相关者都具备人工智能素养，并能够有效地应对学术界人工智能的复杂环境。在运营维度中，存在两个潜在的关键领域：
- en: Monitoring and Evaluating AI Implementation
  id: totrans-221
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 监控和评估人工智能实施
- en: Adopting AI technologies into academic settings requires a structured approach
    to monitoring and evaluating AI implementation. Regular monitoring can ensure
    that the AI tools in question are effective, reliable, and being used responsibly.
    This operational facet is crucial for both facilitating continuous improvement
    and ensuring that the practical implementation of AI technologies aligns with
    the ethical and pedagogical objectives of the institution.
  id: totrans-222
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 将人工智能技术引入学术环境需要一种结构化的方法来监控和评估人工智能实施。定期的监控可以确保相关的人工智能工具是有效的、可靠的，并且正在负责任地使用。这一操作方面对于促进持续改进和确保人工智能技术的实际实施与机构的伦理和教学目标保持一致至关重要。
- en: Providing Training and Support for Teachers, Staff, and Students in AI Literacy
  id: totrans-223
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为教师、员工和学生提供人工智能素养的培训和支援
- en: The need for AI literacy among stakeholders is a pressing concern. Developing
    and delivering training programmes on AI literacy, ethics, and effective use can
    significantly improve understanding and responsible use of AI technologies among
    teachers, staff, students, and so on. This operational action is vital for ensuring
    that all stakeholders are well-informed and equipped to navigate the complex landscape
    of AI in academia.
  id: totrans-224
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 利益相关者对人工智能素养的需求是一个紧迫的问题。开发和提供关于人工智能素养、伦理和有效使用方面的培训计划，可以显著提高教师、员工、学生等对人工智能技术的理解和负责任的使用。这一操作行动对于确保所有利益相关者都充分了解并能够应对学术界人工智能复杂环境至关重要。
- en: 'Teachers play a key role in the **pedagogical dimension** as they are at the
    forefront of delivering education and engaging with students. With their first-hand
    experiences and expertise in teaching and learning processes, they are uniquely
    positioned to explore, understand, and implement AI technologies in a manner that
    enhances learning and the achievement of educational outcomes. Their insights
    into students’ learning needs, as well as the challenges and potential benefits
    of AI technologies in relation to teaching and learning, are invaluable for rethinking
    assessments, developing students’ competencies, preparing students for the AI-driven
    workplace, and encouraging the balanced adoption of AI. Teachers are the primary
    actors in translating policy and operational frameworks into effective teaching
    and learning practices. Within the pedagogical dimension, there are four underlying
    key areas:'
  id: totrans-225
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 教师在**教学维度**中扮演着关键角色，因为他们是教育的前沿，与学生互动。凭借他们在教学和学习过程中的第一手经验和专业知识，他们独特地定位去探索、理解和实施人工智能技术，以增强学习和实现教育成果。他们对学生学习需求的洞察，以及人工智能技术在教学和学习中的挑战和潜在益处，对于重新思考评估、发展学生的能力、为学生准备人工智能驱动的工作场所和鼓励平衡采用人工智能至关重要。教师是将政策和操作框架转化为有效的教学和学习实践的初级行动者。在教学维度中，有四个潜在的关键领域：
- en: Rethinking Assessments and Examinations
  id: totrans-226
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重新思考评估和考试
- en: The advent of AI technologies including ChatGPT presents both challenges and
    opportunities for academic assessments. As previously mentioned, a key concern
    that arises is the potential misuse of AI in facilitating academic misconduct.
    Actions to address this could include the redesign of assessments to include varied
    methods, such as in-class demonstrations, presentations, or multi-stage submissions,
    which could mitigate the opportunities to engage in AI-assisted misconduct. The
    outcome of such actions could also improve the accuracy of assessment looking
    at students’ understanding and skills, reduce academic misconduct, and potentially
    facilitate a higher level of student engagement.
  id: totrans-227
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 人工智能技术的出现，包括ChatGPT，既对学术评估提出了挑战，也带来了机遇。如前所述，一个关键问题是人工智能在促进学术不端行为中的潜在滥用。解决这一问题的措施可能包括重新设计评估，包括多种方法，如课堂演示、展示或多阶段提交，这可以减少参与人工智能辅助不端行为的机会。这些行动的结果也可能提高评估的准确性，考察学生对理解和技能的掌握，减少学术不端行为，并可能促进更高水平的学生参与。
- en: Developing Student Holistic Competencies/Generic Skills
  id: totrans-228
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 发展学生全面能力/通用技能
- en: As AI technologies become progressively integrated across all sectors of society,
    the necessity for students to develop holistic competencies becomes paramount.
    These competencies range from critical thinking and leadership abilities to self-reflection
    and creative problem solving – skills that are not easily replicated by AI. By
    introducing second-order writing tasks and promoting critical evaluation, educators
    can foster a deeper level of understanding and skills development among students.
    The outcomes would be manifold, including better-prepared students who can think
    critically and navigate a tech-driven academic and professional landscape.
  id: totrans-229
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 随着人工智能技术在社会的各个领域逐渐整合，学生发展全面能力变得至关重要。这些能力包括批判性思维和领导能力，自我反思和创造性问题解决——这些技能是人工智能难以复制的。通过引入二级写作任务和促进批判性评估，教育者可以在学生中培养更深层次的理解和技能发展。这些成果将是多方面的，包括更充分准备的学生，他们能够进行批判性思考并驾驭技术驱动的学术和职业景观。
- en: Preparing Students for the AI-Driven Workplace
  id: totrans-230
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为人工智能驱动的工作场所培养学生
- en: The evolving nature of the workplace combined with the integration of AI technologies
    requires a forward-thinking approach to prepare students for their future careers.
    Familiarising students with AI technologies, ethical considerations, and real-world
    applications can facilitate a more seamless transition from academia to the professional
    world. The actions in this domain could include integrating AI-related topics
    into the curriculum, engaging in discussions about the ethical implications of
    AI, and providing hands-on experiences with AI tools. The expected outcomes of
    this are future cohorts of students who are better prepared for the demands of
    an AI-driven workplace.
  id: totrans-231
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 工作场所不断演变的特点与人工智能技术的融合，要求我们采取前瞻性的方法来为学生未来的职业生涯做好准备。使学生熟悉人工智能技术、伦理考量以及现实世界的应用，可以促进从学术界到专业世界的更顺畅过渡。在这个领域采取的行动可能包括将人工智能相关主题融入课程、参与关于人工智能伦理影响的讨论，以及提供使用人工智能工具的实践体验。预期的成果是，未来的学生群体将更好地为人工智能驱动的工作场所的需求做好准备。
- en: Encouraging a Balanced Approach to AI Adoption
  id: totrans-232
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 鼓励人工智能采用的平衡方法
- en: A balanced approach to AI adoption in academia can help us navigate the fine
    line between leveraging technology and maintaining academic integrity. By promoting
    a such an approach, educators can enhance teaching and learning experiences while
    mitigating the risks associated with AI technologies. This could also foster a
    more positive attitude towards technological evolution, in turn further leading
    to innovation in teaching and learning methods that are in sync with the advancements
    in technology.
  id: totrans-233
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在学术界采用人工智能的平衡方法可以帮助我们在这条利用技术与维护学术诚信的微妙界限上找到平衡。通过推广这种方法，教育者可以提升教学和学习体验，同时减轻与人工智能技术相关的风险。这也可以培养对技术演变的更积极态度，进而进一步推动与科技进步同步的教学和学习方法的创新。
- en: It is imperative to acknowledge that the responsibilities of each dimension
    in this ecological framework should not be viewed in isolation. The relationships
    among the three dimensions are intricate and interdependent. For instance, effective
    governance policies (Governance Dimension) could support the ethical integration
    of AI in teaching and learning (Pedagogical Dimension), and well-informed operational
    practices (Operational Dimension) could ensure the success of such integration.
    By taking into account these dimensions, a cohesive theory regarding the integration
    of AI in academic settings can be further developed and refined.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 认识到在这个生态框架中每个维度的责任不应孤立看待是至关重要的。这三个维度之间的关系错综复杂且相互依赖。例如，有效的治理政策（治理维度）可以支持教学和学习中人工智能的伦理整合（教学维度），而信息丰富的运营实践（运营维度）可以确保这种整合的成功。通过考虑这些维度，可以进一步发展和完善关于在学术环境中整合人工智能的统一理论。
- en: The successful integration of AI in academic settings counts on collaboration
    and communication among all stakeholders, including universities, teachers, students,
    staff, and external agents such as accreditation and quality assurance bodies.
    Each group should actively participate in the development and execution of AI-related
    initiatives, working together to achieve the desired outcomes in university teaching
    and learning. This collaborative approach will foster a more comprehensive, informed,
    and ethical integration of AI, aligning with broader educational goals and ethical
    standards. Overall, through open communication and collaborative efforts, stakeholders
    can collectively navigate the complexities of AI integration, ensuring that the
    pedagogical, governance, and operational dimensions are also harmoniously in alignment
    for the betterment of the academic community.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 在学术环境中成功整合人工智能依赖于所有利益相关者之间的协作和沟通，包括大学、教师、学生、员工以及认证和质量保证等外部机构。每个群体都应积极参与人工智能相关项目的开发和执行，共同努力实现大学教学和学习的预期成果。这种协作方法将促进更全面、更明智、更符合伦理的人工智能整合，与更广泛的教育目标和伦理标准相一致。总的来说，通过开放沟通和协作努力，利益相关者可以共同应对人工智能整合的复杂性，确保教学、治理和运营维度也和谐一致，以促进学术社区的改善。
- en: 5.6 Devising an AI Policy in Higher Education
  id: totrans-236
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.6 制定高等教育人工智能政策
- en: Creating an AI policy in higher education is an extensive process that requires
    a well-thought-out approach. It should ideally follow a structured methodology
    to ensure that all stakeholders’ perspectives are considered and that the policy
    is comprehensive, ethical, and effective in achieving the desired objectives.
    The intricacies of formulating such an AI policy in such a dynamic environment
    often extend beyond the existing expertise of teachers, administrative staff,
    and even senior management. The lack of familiarity with the nuanced domain of
    AI further exacerbates the complexity of devising a robust policy tailored to
    the educational milieu.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 在高等教育中制定人工智能政策是一个复杂的过程，需要周密的思考方法。理想情况下，它应遵循一种结构化的方法论，以确保考虑所有利益相关者的观点，并确保政策全面、道德，且能有效实现既定目标。在这样的动态环境中制定此类人工智能政策的复杂性往往超出了教师、行政人员和甚至高级管理人员的现有专业知识。对人工智能这一细微领域的缺乏了解进一步加剧了制定适合教育环境的稳健政策的复杂性。
- en: 'This section seeks to explain and clarify the process of formulating AI policy
    within higher education institutions, based on the above framework. We offer a
    structured, step-by-step guide on how such a policy can be crafted and implemented,
    providing a straightforward pathway for stakeholders at all levels to engage in
    the policymaking process. This draft is simplified and may serve as a starting
    point or reference for further development by your institution. As a pragmatic
    approach, it can be used as a roadmap for policy development as well as to foster
    a collaborative ethos, encouraging inclusive dialogue among all stakeholders to
    leverage AI technologies effectively and ethically in education, thus enabling
    a smooth transition into the AI-augmented teaching and administrative paradigm.
    Below is the step-by-step guideline based on the ecological framework’s dimensions
    of governance, pedagogy, and operations:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 本节旨在根据上述框架解释和阐明高等教育机构制定人工智能政策的过程。我们提供了一个结构化的、分步骤的指南，说明如何制定和实施此类政策，为所有级别的利益相关者参与政策制定过程提供了一条清晰的途径。这份草案是简化的，可能作为您机构进一步发展的起点或参考。作为一种实用方法，它可以作为政策制定的路线图，以及培养协作精神，鼓励所有利益相关者之间的包容性对话，有效地在教育中道德地利用人工智能技术，从而实现向人工智能增强的教学和行政范式的平稳过渡。以下是基于治理、教学和运营的生态框架维度的分步骤指南：
- en: '**Initiation and Planning**'
  id: totrans-239
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**启动和规划**'
- en: 'Establish a Steering Committee: The first step towards developing an AI policy
    in education is the formation of a Steering Committee. Senior management should
    spearhead this initiative by identifying and inviting individuals from different
    stakeholder groups to be part of this committee, including faculty members, IT
    staff, administrative staff, legal advisors, and student representatives. Ideally,
    the committee should have balanced representation to ensure that diverse perspectives
    and expertise are incorporated in the policy development process. An initial meeting
    should be convened where the objectives of the policy are outlined, roles and
    responsibilities are assigned, and a tentative timeline is established. This committee
    will serve as the driving force behind the policy development, acting as the conduit
    between the stakeholder groups and the development process.'
  id: totrans-240
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 建立指导委员会：在教育中制定人工智能政策的第一步是成立一个指导委员会。高级管理层应带头开展这项工作，通过识别和邀请来自不同利益相关者群体的人员加入该委员会，包括教师、IT人员、行政人员、法律顾问和学生代表。理想情况下，委员会应具有平衡的代表性，以确保在政策制定过程中纳入多样化的观点和专业知识。应召开一次初步会议，概述政策目标，分配角色和责任，并确定一个初步的时间表。该委员会将作为政策制定背后的推动力，作为利益相关者群体与开发过程之间的桥梁。
- en: '**Who**: Senior management should establish a Steering Committee composed of
    representatives from each stakeholder group (including senior management themselves,
    teachers, IT staff, administrative staff, legal advisors, students, and external
    experts).'
  id: totrans-241
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**谁**：高级管理层应建立一个由每个利益相关者群体（包括高级管理层本身、教师、IT人员、行政人员、法律顾问、学生和外部专家）的代表组成的指导委员会。'
- en: '**How**: The formation of the committee can be announced through official channels,
    and nominations or volunteers could be solicited with the goal of having balanced
    representation.'
  id: totrans-242
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**如何**：可以通过官方渠道宣布委员会的成立，并征求提名或志愿者，目标是实现平衡的代表性。'
- en: 'Conduct a Needs Assessment: A Needs Assessment is crucial as it lays the foundation
    for the policy by identifying the current state of policy, the desired state,
    and the gaps in between. This involves designing and distributing surveys to gather
    insights from stakeholders on their understanding, expectations, and concerns
    regarding the integration of AI into education. Simultaneously, focus group discussions
    can be conducted to delve deeper into specific issues or concerns. An analysis
    of the existing technological infrastructure and educational practices can also
    provide a clear picture of the current capabilities of these areas while also
    identifying those that may require improvement. The data collected through these
    methods should be carefully analysed to identify the core needs and challenges
    that the AI policy should address.'
  id: totrans-243
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 进行需求评估：需求评估至关重要，因为它通过确定政策现状、期望状态以及两者之间的差距为政策奠定基础。这包括设计和分发调查问卷，以从利益相关者那里收集他们对将人工智能融入教育的理解、期望和担忧的见解。同时，可以开展焦点小组讨论，以深入了解特定问题或担忧。对现有技术基础设施和教育实践的分析也可以提供这些领域当前能力的清晰图景，同时确定可能需要改进的领域。通过这些方法收集的数据应仔细分析，以确定人工智能政策应解决的核心需求和挑战。
- en: '**Who**: The Steering Committee, with the help of educational and technical
    experts.'
  id: totrans-244
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**谁参与**：指导委员会，在教育和技术专家的帮助下。'
- en: '**How**: Through surveys, focus groups, and analyses of existing infrastructure
    and educational needs.'
  id: totrans-245
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**如何进行**：通过调查、焦点小组和现有基础设施和教育需求的分析。'
- en: 'Define Objectives and Scope: After conducting the Needs Assessment, the Steering
    Committee should engage in defining the objectives and scope of the AI policy.
    This could involve a thorough review of existing literature, benchmarking against
    the AI policies of other institutions, and consulting legal and ethical guidelines
    concerning AI in education. The objectives should be clear, measurable, and aligned
    with the broader educational goals of the institution, while the scope should
    define the boundaries of the AI policy, including the areas it will cover, the
    stakeholders it will affect, and the resources it will require. This step is essential
    as it sets the direction for policy development and ensures that the process remains
    focused and aligned with the identified needs.'
  id: totrans-246
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义目标和范围：在完成需求评估后，指导委员会应参与定义人工智能政策的目标和范围。这可能包括对现有文献的彻底审查，将其他机构的人工智能政策作为基准，并咨询有关教育中人工智能的法律和伦理指南。目标应该是明确、可衡量的，并与机构的更广泛教育目标保持一致，而范围应定义人工智能政策的边界，包括它将涵盖的领域、它将影响的利益相关者以及它将需要的资源。这一步骤至关重要，因为它为政策制定设定了方向，并确保过程保持专注并符合确定的需求。
- en: '**Who**: The Steering Committee.'
  id: totrans-247
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**谁参与**：指导委员会。'
- en: '**How**: Reviewing the Needs Assessment findings and consulting with stakeholders
    to set clear objectives for the AI policy.'
  id: totrans-248
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**如何进行**：审查需求评估结果并与利益相关者协商，以设定人工智能政策明确的目标。'
- en: '**Stakeholder Engagement**'
  id: totrans-249
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**利益相关者参与**'
- en: 'Solicit Input and Feedback: Engaging stakeholders is necessary for the development
    of a well-rounded and inclusive AI policy. The Steering Committee should establish
    communication channels such as online forums (see [Figure 5.5](#fig5_5) for an
    example), email groups, and hold physical or virtual meetings to solicit the input
    and feedback of all stakeholder groups. This engagement should be continuous,
    allowing parties share their insights, concerns, and suggestions regarding the
    integration of AI into education. The input and feedback collected should also
    be documented and analysed to understand broader implications, as well as to ensure
    that the policy will address the concerns and needs raised.'
  id: totrans-250
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 征求意见和反馈：为了制定全面和包容的人工智能政策，与利益相关者互动是必要的。指导委员会应建立沟通渠道，例如在线论坛（参见[图5.5](#fig5_5)以获取示例）、电子邮件群组，并举行实体或虚拟会议，以征求所有利益相关者群体的意见和反馈。这种参与应该是持续的，使各方能够分享他们对将人工智能融入教育的见解、担忧和建议。收集到的意见和反馈也应记录和分析，以了解更广泛的影响，并确保政策将解决提出的担忧和需求。
- en: '![Details that are listed for the question, what should be in our A I education
    policy which is an example of a padlet for online forum.](images/fig5_5_B.jpg)'
  id: totrans-251
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_IMG
  zh: '![列出的问题的详细信息，我们的人工智能教育政策中应包含哪些内容，这是在线论坛的padlet示例。](images/fig5_5_B.jpg)'
- en: '[Figure 5.5 An Example of Using a Padlet for Online Forum.](#R_fig5_5)'
  id: totrans-252
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[图5.5 使用Padlet进行在线论坛的示例。](#R_fig5_5)'
- en: '**Who**: The Steering Committee should lead this effort, reaching out to all
    stakeholder groups.'
  id: totrans-253
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**谁**：指导委员会应领导这项工作，并与所有利益相关者群体进行沟通。'
- en: '**How**: Through online surveys, in-person or virtual town-hall meetings, and
    focus group discussions to gather insights, concerns, and suggestions regarding
    the integration of AI into education.'
  id: totrans-254
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**如何**：通过在线调查、面对面或虚拟市政厅会议和焦点小组讨论来收集关于将人工智能融入教育的见解、担忧和建议。'
- en: 'Educate Stakeholders: Equipping stakeholders with a good understanding of AI
    and its potential implications in education is essential for facilitating meaningful
    engagement. This can be achieved through workshops, seminars, and informational
    sessions conducted by experts within or outside the Steering Committee. Educational
    materials explaining AI, its applications in education, and its ethical implications
    should be developed and distributed. By doing so, stakeholder discussions will
    be better informed, enhancing the quality and depth of their feedback and engagement
    in the policy development process.'
  id: totrans-255
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 教育利益相关者：使利益相关者对人工智能及其在教育中的潜在影响有一个良好的理解，对于促进有意义的参与至关重要。这可以通过指导委员会内或外部的专家举办的研讨会、研讨会和信息会议来实现。应开发并分发解释人工智能、其在教育中的应用及其伦理影响的材料。通过这样做，利益相关者的讨论将更加充分，提高他们在政策制定过程中的反馈质量和深度。
- en: '**Who**: Experts within the Steering Committee or external consultants.'
  id: totrans-256
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**谁**：指导委员会内的专家或外部顾问。'
- en: '**How**: Conducting workshops, seminars, and informational sessions to educate
    stakeholders about AI and its potential implications in education, including ethical
    considerations.'
  id: totrans-257
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**如何**：通过举办研讨会、研讨会和信息会议，教育利益相关者关于人工智能及其在教育中的潜在影响，包括伦理考量。'
- en: '**Policy Development**'
  id: totrans-258
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**政策制定**'
- en: 'Drafting the Policy: With the groundwork laid, the process now moves onto drafting
    the policy. A working group within the Steering Committee, possibly with the inclusion
    of legal and technical experts, should be formed to draft the AI policy. This
    Policy Drafting Team should work to integrate the insights gathered from stakeholders,
    information from legal and ethical guidelines, and the educational objectives
    identified earlier. The drafting process should be iterative, allowing for revisions
    based on feedback from the Steering Committee and consultations with other experts.'
  id: totrans-259
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 制定政策：在打下基础后，现在的工作重点转向制定政策。应在指导委员会内建立一个工作组，可能包括法律和技术专家，以制定人工智能政策。这个政策起草团队应努力整合从利益相关者那里收集到的见解、法律和伦理指南的信息以及之前确定的教育目标。起草过程应该是迭代的，允许根据指导委员会的反馈和其他专家的咨询进行修订。
- en: '**Who**: A working group within the Steering Committee, with assistance from
    legal and technical experts.'
  id: totrans-260
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**谁**：指导委员会内的一个工作组，并得到法律和技术专家的帮助。'
- en: '**How**: Establishing a comprehensive draft policy by integrating insights
    from stakeholders, referring to legal and ethical guidelines, and ensuring alignment
    with educational objectives.'
  id: totrans-261
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**如何**：通过整合利益相关者的见解、参考法律和伦理指南，并确保与教育目标一致，制定全面的政策草案。'
- en: 'Stakeholder Review: Once a draft policy is prepared, it should be shared with
    all stakeholder groups for review and feedback. Various channels can be used to
    disseminate the draft policy and collect feedback, including through online platforms,
    emails, or physical meetings. Stakeholders should be given a reasonable time frame
    to review the draft and provide their inputs. This step ensures that the draft
    policy is vetted by the broader community, enhancing its inclusivity and relevance.'
  id: totrans-262
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 利益相关者审查：一旦制定出政策草案，应将其与所有利益相关者群体分享，以供审查和反馈。可以使用各种渠道来传播政策草案并收集反馈，包括通过在线平台、电子邮件或面对面会议。应给利益相关者一个合理的时间框架来审查草案并提供他们的意见。这一步骤确保了更广泛的社区对草案进行审查，增强了其包容性和相关性。
- en: '**Who**: All stakeholder groups.'
  id: totrans-263
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**谁**：所有利益相关者群体。'
- en: '**How**: Sharing the draft policy for review and feedback through various channels
    such as online platforms, meetings, and emails.'
  id: totrans-264
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**如何**：通过在线平台、会议和电子邮件等不同渠道分享政策草案以供审查和反馈。'
- en: 'Revision and Finalisation: The feedback collected from stakeholders should
    be analysed and necessary revisions should be made to the draft policy. The Policy
    Drafting Team should engage in an iterative process of revision and consultation
    with the Steering Committee, ensuring that the policy is appropriately refined
    and still aligned with the defined objectives and scope. Once revisions have been
    made and the draft is finalised, the policy should be reviewed one final time
    by the Steering Committee to confirm that it is ready for submission to senior
    management and other governing bodies for approval.'
  id: totrans-265
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 修订和最终确定：应分析从利益相关者那里收集到的反馈，并对草案政策进行必要的修订。政策起草团队应与指导委员会进行迭代修订和咨询过程，确保政策得到适当的完善，并且仍然与定义的目标和范围保持一致。一旦进行了修订并且草案最终确定，政策应由指导委员会进行最后一次审查，以确认其已准备好提交给高级管理层和其他管理机构进行批准。
- en: '**Who**: The working group within the Steering Committee.'
  id: totrans-266
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**谁**：指导委员会内的工作组。'
- en: '**How**: Incorporating the feedback received, revising the policy as necessary,
    and finalising the draft for approval.'
  id: totrans-267
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**如何**：吸收收到的反馈，根据需要修订政策，并最终确定审批草案。'
- en: '**Approval and Adoption**'
  id: totrans-268
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**批准与采纳**'
- en: 'Seek Approval: The Steering Committee, having finalised the draft policy, now
    moves to seek formal approval from the senior management and other governing bodies
    within the institution. This usually involves preparing a detailed presentation
    outlining the key aspects of the policy, the process undertaken to develop it,
    and the implications of its implementation. It is crucial to articulate how the
    policy aligns with the broader educational goals of the institution, as well as
    how it adheres to legal and ethical standards. The presentation also provides
    an opportunity for the committee to address any issues or concerns raised by the
    senior management, and potentially make further revisions to the policy based
    on the feedback received. The approval process ensures that the AI policy has
    the necessary endorsement from the institutional leadership, paving the way for
    its official adoption.'
  id: totrans-269
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 寻求批准：指导委员会在最终确定草案政策后，现在转向寻求机构内高级管理层和其他管理机构的正式批准。这通常涉及准备一份详细的演示文稿，概述政策的关键方面、制定政策的过程以及其实施的影响。明确政策如何与机构的更广泛教育目标保持一致，以及如何遵守法律和伦理标准，这一点至关重要。演示文稿还提供了委员会解决高级管理层提出的问题或担忧的机会，并根据收到的反馈对政策进行进一步的修订。批准流程确保AI政策获得机构领导层的必要支持，为其正式采纳铺平道路。
- en: '**Who**: The Steering Committee should present the policy to senior management
    and other necessary governing bodies for approval.'
  id: totrans-270
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**谁**：指导委员会应向高级管理层和其他必要的管理机构提交政策以供批准。'
- en: '**How**: Through formal presentations and submission of the policy document
    for review.'
  id: totrans-271
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**如何**：通过正式演示和提交政策文件以供审查。'
- en: 'Official Adoption: Upon receiving approval, the next step is the official adoption
    of the AI policy. This is typically announced through official channels such as
    institutional bulletins, emails, and meetings. The policy document should be disseminated
    to all stakeholders, ensuring they have access to it and understand its implications.
    It is advisable to have an official launch event or announcement that highlights
    the key aspects of the policy and what it means for the stakeholders. This step
    marks the formal recognition of the AI policy as a guideline within the institution,
    setting the stage for its implementation.'
  id: totrans-272
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 正式采纳：在获得批准后，下一步是正式采纳AI政策。这通常通过官方渠道，如机构公告、电子邮件和会议来宣布。应将政策文件分发给所有利益相关者，确保他们能够访问并理解其影响。建议举办一个官方启动活动或公告，突出政策的关键方面及其对利益相关者的意义。这一步骤标志着AI政策作为机构内的指南得到正式认可，为其实施奠定了基础。
- en: '**Who**: Senior management.'
  id: totrans-273
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**谁**：高级管理层。'
- en: '**How**: Announcing the adoption of the policy through official channels and
    disseminate the policy document to all stakeholders.'
  id: totrans-274
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**如何**：通过官方渠道宣布采纳政策，并将政策文件分发给所有利益相关者。'
- en: '**Implementation**'
  id: totrans-275
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**实施**'
- en: 'Develop an Implementation Plan: With the policy officially adopted, the need
    now is to develop a concrete implementation plan. It should outline the steps,
    timelines, resources, and responsibilities for implementing the policy, as well
    as identify the necessary support structures for ensuring that the process is
    smooth. This could include training programmes, resource allocations, and the
    establishment of support channels for stakeholders to seek help or report issues.
    The implementation plan serves as the blueprint for translating the policy into
    practice, ensuring that all stakeholders are well-prepared and supported in adhering
    to the new AI policy.'
  id: totrans-276
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 制定实施计划：随着政策的正式通过，现在的需求是制定一个具体的实施计划。它应概述实施政策的步骤、时间表、资源和责任，以及确定确保过程顺利的必要支持结构。这可能包括培训计划、资源分配以及为利益相关者建立寻求帮助或报告问题的支持渠道。实施计划是政策转化为实践的蓝图，确保所有利益相关者都为遵守新的AI政策做好准备并获得支持。
- en: '**Who**: The Steering Committee, in collaboration with operational staff.'
  id: totrans-277
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**谁**：指导委员会，与运营人员合作。'
- en: '**How**: Outlining the steps, timelines, resources, and responsibilities for
    implementing the policy.'
  id: totrans-278
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**如何**：概述实施政策的步骤、时间表、资源和责任。'
- en: 'Training and Support: Training and support are critical components of the implementation
    phase. Training programmes should be developed and delivered to stakeholders to
    equip them with the necessary skills and knowledge to comply with the AI policy.
    This could include training on new technologies, ethical considerations, and best
    practices for AI integration in education. Support channels should also be established
    to provide ongoing assistance to stakeholders, ensuring they have the resources
    and help necessary to navigate the new policy and its effects. These support channels
    could include helpdesks, online forums, and dedicated support personnel.'
  id: totrans-279
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 培训和支持：培训和支持是实施阶段的关键组成部分。应开发和提供培训计划给利益相关者，以使他们具备遵守AI政策的必要技能和知识。这可能包括新技术、伦理考虑以及AI在教育中整合的最佳实践培训。还应建立支持渠道，为利益相关者提供持续的帮助，确保他们拥有导航新政策和其影响的资源和帮助。这些支持渠道可能包括帮助台、在线论坛和专门的支持人员。
- en: '**Who**: IT staff and educational experts.'
  id: totrans-280
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**谁**：IT人员和教育专家。'
- en: '**How**: Conducting training sessions, workshops, and provide resources to
    support stakeholders in adhering to the new AI policy.'
  id: totrans-281
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**如何**：开展培训课程、研讨会，并提供资源以支持利益相关者遵守新的AI政策。'
- en: 'Monitoring and Evaluation: The implementation phase should also include a robust
    monitoring and evaluation component. This involves establishing clear metrics
    and procedures to monitor the implementation process, assess compliance with the
    policy, and evaluate the effectiveness of the policy in achieving the desired
    objectives. Regular reports should be written up and submitted to provide insights
    into the progress of the implementation, any challenges encountered, and the impact
    of the policy on educational practices.'
  id: totrans-282
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 监控和评估：实施阶段还应包括一个强大的监控和评估组件。这包括建立明确的指标和程序以监控实施过程，评估政策遵守情况，以及评估政策在实现预期目标方面的有效性。应定期编写并提交报告，以提供实施进展、遇到的挑战以及政策对教育实践影响的见解。
- en: '**Who**: A designated monitoring and evaluation team.'
  id: totrans-283
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**谁**：指定的监控和评估团队。'
- en: '**How**: Establish metrics and procedures to monitor the implementation, and
    evaluate the effectiveness of the policy against the defined objectives.'
  id: totrans-284
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**如何**：建立指标和程序以监控实施情况，并评估政策相对于既定目标的有效性。'
- en: '**Continuous Improvement**:'
  id: totrans-285
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**持续改进**：'
- en: 'Gather Feedback: Following the implementation of the policy, it is still important
    to gather stakeholder feedback to understand their experiences, challenges, and
    suggestions. Establishing channels for feedback collection, reporting of issues,
    and sharing of insights is integral for continuous improvement. Feedback should
    be systematically collected, documented, and analysed to identify areas for improvement.'
  id: totrans-286
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 收集反馈：在政策实施后，收集利益相关者的反馈以了解他们的经验、挑战和建议仍然很重要。建立反馈收集渠道、问题报告和见解分享机制对于持续改进至关重要。反馈应系统性地收集、记录和分析，以确定改进领域。
- en: '**Who**: The monitoring and evaluation team.'
  id: totrans-287
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**谁**：监控和评估团队。'
- en: '**How**: Through surveys, focus groups, and analysis of implementation metrics.'
  id: totrans-288
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**如何**：通过调查、焦点小组和实施指标的分析。'
- en: 'Policy Revision: Based on the feedback and findings from monitoring and evaluating
    its implementation, the policy may require revisions to address any emerging challenges,
    technological advancements, or changing educational needs. The Steering Committee
    should engage in the continued review of the policy, making necessary adjustments
    or amendments, and also continue to consult with stakeholders to ensure that the
    policy remains relevant, effective, and aligned with the institutional goals.'
  id: totrans-289
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 政策修订：基于对其实施的监控和评估的反馈和发现，政策可能需要修订以应对任何新兴的挑战、技术进步或变化的教育需求。指导委员会应继续审查政策，进行必要的调整或修订，并继续与利益相关者协商，以确保政策保持相关性、有效性和与机构目标的协调一致。
- en: '**Who**: The Steering Committee.'
  id: totrans-290
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**谁**：指导委员会。'
- en: '**How**: Based on feedback and evaluation findings, revising and updating the
    policy as necessary to ensure that it remains relevant and effective.'
  id: totrans-291
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**如何**：根据反馈和评估结果，必要时修订和更新政策，以确保其保持相关性和有效性。'
- en: 'Ongoing Stakeholder Engagement: Continuous improvement requires ongoing engagement
    with stakeholders. Maintaining open communication channels, soliciting feedback,
    and providing regular updates on any revisions or new initiatives are crucial
    for keeping stakeholders informed, engaged, and compliant with the policy. This
    further fosters a culture of collaboration, learning, and continuous improvement,
    ensuring the AI policy remains a living document that evolves in response to the
    changing landscape of AI in education.'
  id: totrans-292
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 持续的利益相关者参与：持续的改进需要与利益相关者保持持续的互动。保持开放的沟通渠道，征求反馈，并定期更新任何修订或新举措，对于保持利益相关者的知情、参与和遵守政策至关重要。这进一步促进了合作、学习和持续改进的文化，确保人工智能政策是一个不断发展的、适应教育领域人工智能变化现状的活文件。
- en: '**Who**: The Steering Committee and senior management.'
  id: totrans-293
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**谁**：指导委员会和高级管理层。'
- en: '**How**: Maintaining open channels of communication to ensure that stakeholders
    are informed and have the opportunity to provide ongoing feedback.'
  id: totrans-294
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**如何**：保持开放的沟通渠道，确保利益相关者得到通知并有机会提供持续的反馈。'
- en: Each of these steps is designed to ensure a collaborative, informed, and structured
    approach to developing and implementing an AI policy in education. The involvement
    of various stakeholders throughout different stages of the process is crucial
    to ensure that the policy is well-rounded, relevant, and effective in promoting
    ethical and effective AI integration in academic institutions.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 每个步骤都是为了确保在制定和实施教育领域人工智能政策时采取协作、信息和结构化的方法。在整个过程中的不同阶段，各种利益相关者的参与对于确保政策全面、相关且有效，以促进学术机构中伦理和有效的人工智能整合至关重要。
- en: 5.6.1 An Example of an AI Policy in Higher Education
  id: totrans-296
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.6.1 高等教育中的人工智能政策示例
- en: 'As emphasised throughout this chapter, creating a comprehensive AI policy for
    higher education requires meticulous planning and a thorough understanding of
    the institution’s objectives, stakeholders’ needs, and the legal and ethical facets
    of AI. Based on the AI Ecological Education Policy framework and the step-by-step
    guide in [Section 5.6](#sec5_6). Here is a simple example outline of an AI education
    policy:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 如本章所强调的，制定高等教育综合人工智能政策需要细致的计划和对机构目标、利益相关者需求以及人工智能的法律法规方面的全面理解。基于人工智能生态教育政策框架和[第5.6节](#sec5_6)中的逐步指南。以下是一个人工智能教育政策的简单示例大纲：
- en: Table 5.1 A Simple Outline of an AI Education Policy
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 表5.1 人工智能教育政策的简单大纲
- en: '| Title: AI Education Policy for [Institution Name] |'
  id: totrans-299
  prefs: []
  type: TYPE_TB
  zh: '| 标题：[机构名称] 人工智能教育政策 |'
- en: '| --- |'
  id: totrans-300
  prefs: []
  type: TYPE_TB
  zh: '| --- |'
- en: '|'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '**Introduction**:'
  id: totrans-302
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**简介**：'
- en: '1.1. Background: Explanation of the emergence of AI technologies and their
    potential impact on higher education. Mention of the institution’s commitment
    to leveraging AI to enhance educational outcomes while adhering to ethical and
    legal standards.'
  id: totrans-303
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 1.1. 背景：解释人工智能技术的出现及其对高等教育可能产生的影响。提及机构利用人工智能提升教育成果的承诺，同时遵守伦理和法律标准。
- en: 'Purpose: Articulation of the policy’s aim to guide the responsible integration
    and use of AI technologies within the institution.'
  id: totrans-304
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 目的：阐述政策旨在指导机构内人工智能技术的负责任整合和使用的目标。
- en: '1.2. Scope: Clarification on the departments, individuals, and activities covered
    by the policy.'
  id: totrans-305
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 1.2. 范围：明确政策涵盖的部门、个人和活动。
- en: '**Governance**:'
  id: totrans-306
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**治理**：'
- en: '2.1. Steering Committee: Establishment of a steering committee to oversee the
    implementation, monitoring, and continuous improvement of the AI education policy.'
  id: totrans-307
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 2.1. 指导委员会：建立指导委员会以监督人工智能教育政策的实施、监控和持续改进。
- en: '2.2. Ethical Guidelines: Clear ethical guidelines for AI usage, including respect
    for privacy, transparency, accountability, and fairness.'
  id: totrans-308
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 2.2. 道德准则：明确的人工智能使用道德准则，包括尊重隐私、透明度、责任和公平性。
- en: '2.3. Legal Compliance: Assurance of compliance with all applicable laws and
    regulations concerning data protection, privacy, and AI.'
  id: totrans-309
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 2.3. 法律合规：确保遵守所有适用的有关数据保护、隐私和人工智能的法律和法规。
- en: '**Pedagogical Integration**:'
  id: totrans-310
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**教学整合**：'
- en: '3.1. Faculty Training: Provision for training faculty on the responsible use
    of AI in teaching and assessment.'
  id: totrans-311
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 3.1. 教师培训：为教师提供关于在教学中和评估中负责任使用人工智能的培训。
- en: '3.2. Student Engagement: Encouragement of student engagement with AI technologies
    under the guidance of faculty.'
  id: totrans-312
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 3.2. 学生参与：鼓励学生在教师的指导下参与人工智能技术。
- en: '3.3. Assessment Reformation: Revision of assessment strategies to account for
    the integration of AI technologies.'
  id: totrans-313
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 3.3. 评估改革：修订评估策略以考虑人工智能技术的整合。
- en: '**Operational Implementation**:'
  id: totrans-314
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**运营实施**：'
- en: '4.1. Technology Infrastructure: Investment in necessary technology infrastructure
    to support AI integration.'
  id: totrans-315
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 4.1. 技术基础设施：投资必要的技术基础设施以支持人工智能的整合。
- en: '4.2. Support and Resources: Establishment of support channels and resources
    to assist stakeholders in navigating the AI policy and technologies.'
  id: totrans-316
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 4.2. 支持和资源：建立支持渠道和资源，以帮助利益相关者了解人工智能政策和技术。
- en: '4.3. Monitoring and Evaluation: Continuous monitoring and evaluation to assess
    the effectiveness, compliance, and impact of AI integration.'
  id: totrans-317
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 4.3. 监控与评估：持续监控和评估以评估人工智能整合的有效性、合规性和影响。
- en: '**Continuous Improvement**:'
  id: totrans-318
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**持续改进**：'
- en: '5.1. Feedback Mechanisms: Establishing mechanisms for stakeholders to provide
    feedback on AI integration experiences.'
  id: totrans-319
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 5.1. 反馈机制：建立机制，让利益相关者能够就人工智能整合经验提供反馈。
- en: '5.2. Policy Revision: Periodic review and revision of the AI education policy
    to ensure relevance and effectiveness.'
  id: totrans-320
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 5.2. 政策修订：定期审查和修订人工智能教育政策，以确保其相关性和有效性。
- en: '5.3. Stakeholder Communication: Ongoing communication with stakeholders regarding
    any updates or revisions to the policy.'
  id: totrans-321
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 5.3. 利益相关者沟通：就政策的任何更新或修订与利益相关者进行持续沟通。
- en: '**Conclusion**:'
  id: totrans-322
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**结论**：'
- en: '6.1. Commitment: Reiteration of the institution’s commitment to responsible
    AI integration for the enhancement of educational outcomes.'
  id: totrans-323
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 6.1. 承诺：重申机构对负责任地整合人工智能以提升教育成果的承诺。
- en: '6.2. Contact Information: Provision of contact information for stakeholders
    to seek clarification or provide feedback regarding the policy.'
  id: totrans-324
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 6.2. 联系信息：为利益相关者提供联系信息，以便寻求政策澄清或提供反馈。
- en: '6.3. Effective Date: The date which the policy takes effect.'
  id: totrans-325
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 6.3. 生效日期：政策生效的日期。
- en: '|'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: 5.6.2 University of ABC
  id: totrans-327
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.6.2 ABC大学
- en: 5.6.2.1 Artificial Intelligence in Education Policy
  id: totrans-328
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.6.2.1 教育政策中的人工智能
- en: '**Introduction**'
  id: totrans-329
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**引言**'
- en: '**Background**'
  id: totrans-330
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**背景**'
- en: The advent of Artificial Intelligence (AI) has created new possibilities and
    challenges for various sectors, including higher education. It has emerged as
    transformative tools with vast implications in the educational settings. At [the
    University of ABC], we recognise the unparalleled potential of AI to revolutionise
    learning experiences, enhance pedagogical methods, and facilitate groundbreaking
    research. This policy manifests our firm commitment to harnessing the power of
    AI to reinforce educational outcomes while strictly adhering to the highest ethical
    and legal standards. This policy aims to guide the responsible integration and
    usage of AI technologies within [the University of ABC].
  id: totrans-331
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 人工智能（AI）的出现为包括高等教育在内的各个领域创造了新的可能性和挑战。它已成为在教育环境中具有深远影响的变革性工具。在[ABC大学]，我们认识到人工智能在革命性学习体验、提升教学方法以及促进突破性研究方面的无与伦比潜力。本政策体现了我们利用人工智能的力量来加强教育成果，同时严格遵循最高道德和法律标准的坚定承诺。本政策旨在指导[ABC大学]内人工智能技术的负责任整合和使用。
- en: '**Purpose**'
  id: totrans-332
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**目的**'
- en: This policy seeks to provide a clear and structured framework guiding the responsible
    integration, utilisation, and governance of AI technologies within the University
    of ABC’s ecosystem. To ensure the ethical, legal, and effective utilisation of
    AI to enhance teaching, learning, and administrative processes while safeguarding
    the rights and interests of all stakeholders.
  id: totrans-333
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 本政策旨在提供一个清晰和结构化的框架，指导ABC大学生态系统内人工智能技术的负责任整合、利用和管理。确保人工智能在提升教学、学习和行政流程中的伦理、法律和有效利用，同时保护所有利益相关者的权利和利益。
- en: '**Scope**'
  id: totrans-334
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**范围**'
- en: This policy applies to all departments, faculties, students, staff, and affiliates
    of the [University of ABC]. It pertains to all activities related to the development,
    deployment, and utilisation or evaluation of AI technologies within the institution.
  id: totrans-335
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 本政策适用于ABC大学的所有部门、学院、学生、员工和附属机构。它涉及机构内与人工智能技术的开发、部署、利用或评估相关的所有活动。
- en: '**Governance**'
  id: totrans-336
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**治理**'
- en: '**Steering Committee**'
  id: totrans-337
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**指导委员会**'
- en: A dedicated AI Steering Committee shall be established to provide oversight
    on the effective implementation, monitoring, and evolution of the AI education
    policy. The committee will comprise representatives from academic faculties, IT,
    administrative, legal, and student bodies.
  id: totrans-338
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 将成立一个专门的AI指导委员会，以监督人工智能教育政策的有效实施、监控和演变。委员会将由学术院系、IT、行政、法律和学生团体的代表组成。
- en: '**Ethical Guidelines**'
  id: totrans-339
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**伦理指导方针**'
- en: The University of ABC upholds the principles of privacy, transparency, accountability,
    and fairness in all AI-related endeavours. All AI initiatives will be rooted in
    these ethical guidelines to ensure that technologies benefit the academic community
    without compromising individual rights or societal values.
  id: totrans-340
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: ABC大学在所有与人工智能相关的活动中坚持隐私、透明度、责任和公平的原则。所有人工智能倡议都将基于这些伦理指导方针，以确保技术造福学术社区，同时不损害个人权利或社会价值观。
- en: '**Legal Compliance**'
  id: totrans-341
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**法律合规**'
- en: Compliance with all applicable local, state, and federal laws and regulations
    governing data privacy, protection, and AI is mandatory. Necessary measures will
    be taken to ensure full legal compliance in every AI endeavour.
  id: totrans-342
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 遵守所有适用的本地、州和联邦关于数据隐私、保护和人工智能的法律和法规是强制性的。将采取必要措施确保每个人工智能项目完全符合法律要求。
- en: '**Pedagogical Integration**'
  id: totrans-343
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**教学整合**'
- en: '**Faculty Training**'
  id: totrans-344
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**教师培训**'
- en: Recognising the pivotal role of our faculty in AI integration, continuous professional
    development opportunities shall be provided to faculty to enhance their understanding
    and capability in utilising AI for pedagogical purposes.
  id: totrans-345
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 认识到我们教师在人工智能整合中的关键作用，将提供持续的专业发展机会，以增强教师对利用人工智能进行教学目的的理解和能力。
- en: '**Student Engagement**'
  id: totrans-346
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**学生参与**'
- en: Students shall be educated on the ethical use of AI, and encouraged to leverage
    AI technologies to enhance their learning experiences under the guidance and supervision
    of faculty, ensuring hands-on experience and fostering a culture of innovative
    learning.
  id: totrans-347
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 学生应接受人工智能伦理使用的教育，并在教师指导和监督下，鼓励利用人工智能技术来提升他们的学习体验，确保实践操作经验，并培养创新学习的文化。
- en: '**Assessment Redesign**'
  id: totrans-348
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**评估重新设计**'
- en: Traditional assessment strategies will be revisited and redesigned to account
    for the innovativeness introduced by AI, ensuring that they remain valid, reliable,
    and equitable. Assessment strategies shall be revised to ensure fairness and integrity
    in the evaluation of student performance in a learning environment augmented by
    AI technologies.
  id: totrans-349
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 将重新审视和重新设计传统的评估策略，以适应人工智能引入的创新性，确保它们保持有效、可靠和公平。评估策略应修订，以确保在人工智能技术增强的学习环境中评估学生表现时的公平性和完整性。
- en: '**Operational Implementation**'
  id: totrans-350
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**运营实施**'
- en: '**Technology Infrastructure**'
  id: totrans-351
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**技术基础设施**'
- en: Investment will be channelled towards establishing robust and state-of-the-art
    technological infrastructure, facilitating seamless AI integration and ensuring
    optimal performance and security. Adequate technological infrastructure shall
    be established to support the effective integration and utilisation of AI technologies.
  id: totrans-352
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 投资将用于建立强大且最先进的技术基础设施，以促进人工智能的无缝整合，确保最佳性能和安全。将建立充足的技术基础设施，以支持人工智能技术的有效整合和利用。
- en: '**Support and Resources**'
  id: totrans-353
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**支持和资源**'
- en: Dedicated support channels, including helpdesks and online portals, will be
    set up to assist stakeholders in understanding and navigating AI technologies
    and adhering to this policy.
  id: totrans-354
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 将设立专门的支持渠道，包括帮助台和在线门户，以协助利益相关者理解和导航人工智能技术，并遵守本政策。
- en: '**Monitoring and Evaluation**'
  id: totrans-355
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**监控与评估**'
- en: A continuous monitoring system will be implemented, evaluating the effectiveness,
    compliance, and impact of AI technologies, ensuring they align with our academic
    objectives and values. A systematic approach shall be employed to monitor, evaluate,
    and report the effectiveness and impact of AI integration within [the University
    of ABC].
  id: totrans-356
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 将实施持续监控系统，评估人工智能技术的有效性、合规性和影响，确保其与我们的学术目标和价值观保持一致。将采用系统方法来监控、评估和报告ABC大学内人工智能集成的有效性和影响。
- en: '**Continuous Improvement**'
  id: totrans-357
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**持续改进**'
- en: '**Feedback Mechanisms**'
  id: totrans-358
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**反馈机制**'
- en: Mechanisms for collecting feedback from all stakeholders on the AI integration
    experiences shall be established to inform continuous improvement efforts.
  id: totrans-359
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 应建立收集所有利益相关者对人工智能集成体验反馈的机制，以提供持续改进的努力信息。
- en: '**Policy Revision**'
  id: totrans-360
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**政策修订**'
- en: In line with the dynamic nature of AI, this policy will be subject to periodic
    reviews, ensuring its continued relevance, robustness, and alignment with the
    University’s goals and the broader educational landscape.
  id: totrans-361
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 鉴于人工智能的动态特性，本政策将接受定期审查，确保其持续的相关性、稳健性和与大学目标以及更广泛的教育环境的契合度。
- en: '**Stakeholder Communication**'
  id: totrans-362
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**利益相关者沟通**'
- en: The University will maintain open lines of communication, updating stakeholders
    on any modifications or pertinent developments related to this policy.
  id: totrans-363
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 大学将保持开放的沟通渠道，向利益相关者更新与该政策相关的任何修改或相关发展。
- en: '**Conclusion**'
  id: totrans-364
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**结论**'
- en: '**Commitment**'
  id: totrans-365
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**承诺**'
- en: '[The University of ABC] remains committed to harnessing the potential of AI
    to enhance the educational experiences of all stakeholders while adhering to the
    highest ethical, legal, and professional standards.'
  id: totrans-366
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[ABC大学]致力于利用人工智能的潜力，在遵守最高道德、法律和专业标准的同时，提升所有利益相关者的教育体验。'
- en: '**Contact Information**'
  id: totrans-367
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**联系方式**'
- en: For any queries or feedback regarding this policy, stakeholders may contact
    the Steering Committee at [[ai_policy@universityofabc.edu](mailto:ai_policy@universityofabc.edu)].
  id: totrans-368
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 关于本政策的任何疑问或反馈，利益相关者可联系指导委员会，邮箱为[[ai_policy@universityofabc.edu](mailto:ai_policy@universityofabc.edu)]。
- en: '**Effective Date**'
  id: totrans-369
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**生效日期**'
- en: This policy shall take effect from [effective date] and remain in effect until
    revised or rescinded.
  id: totrans-370
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 本政策自[生效日期]起生效，并保持有效，直至修订或废除。
- en: Signed by
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 签署人
- en: ___________________
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: ___________________
- en: Senior Management
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: '**高级管理层**'
- en: University of ABC    Date
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: ABC大学    日期
- en: 5.7 Conclusions
  id: totrans-375
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.7 结论
- en: In an era where AI – and GenAI tools in particular – is becoming increasingly
    embedded into our educational systems, developing comprehensive and ethical AI
    education policies is crucial. The journey from understanding the ethical dilemmas
    of using AI in educational settings and reviewing global AI policies, to charting
    a path for practical AI policy development in education, has been both enlightening
    and challenging. As we navigate through the multi-faceted terrains of AI ethics,
    governance, privacy, and equity in education, it is imperative that policies are
    continually revised to adapt to the evolving technological and ethical landscapes
    as well. Our pursuit should not only be in leveraging AI to enhance learning experiences,
    but also in ensuring that AI is implemented in a manner that is equitable, transparent,
    and beneficial to all stakeholders involved in the educational process.
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 在人工智能——尤其是生成式人工智能工具——日益嵌入我们教育系统的时代，制定全面且符合伦理的人工智能教育政策至关重要。从理解在教育环境中使用人工智能的伦理困境到审查全球人工智能政策，再到为教育中的实际人工智能政策制定规划路径，这一过程既具有启发性又充满挑战。在我们穿越人工智能伦理、治理、隐私和教育公平的多方面领域时，政策必须不断修订以适应不断变化的技术和伦理环境。我们的追求不仅在于利用人工智能来提升学习体验，还在于确保人工智能以公平、透明和有利于所有参与教育过程的相关方的形式实施。
- en: References
  id: totrans-377
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[Australian Government Department of Industry, Science and Resources](#R_ref5_1).
    (2023, June 18). Australia’s artificial intelligence action plan. Retrieved October
    16, 2023, from [https://www.industry.gov.au/publications/australias-artificial-intelligence-action-plan](https://www.industry.gov.au)'
  id: totrans-378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[澳大利亚政府工业、科学和资源部](#R_ref5_1). (2023年6月18日). 澳大利亚人工智能行动计划。2023年10月16日从[https://www.industry.gov.au/publications/australias-artificial-intelligence-action-plan](https://www.industry.gov.au)检索。'
- en: '[Baio, A.](#R_ref5_2) (2023, May 16). OpenAI CEO Sam Altman says AI can go
    ‘quite wrong’ while advocating for government intervention. Independent. [https://www.independent.co.uk/tech/congress-ai-chatgpt-sam-altman-b2340147.html](https://www.independent.co.uk)'
  id: totrans-379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Baio, A.](#R_ref5_2) (2023年5月16日)。OpenAI首席执行官山姆·奥特曼表示，在倡导政府干预的同时，人工智能可能会“相当错误”。Independent。[https://www.independent.co.uk/tech/congress-ai-chatgpt-sam-altman-b2340147.html](https://www.independent.co.uk)'
- en: '[Bryson, J. J.](#R_ref5_3) (2018). Patiency is not a virtue: the design of
    intelligent systems and systems of ethics. Ethics and Information Technology,
    *20*, 15–26\. [https://doi.org/10.1007/s10676-018-9448-6](https://doi.org/10.1007/s10676-018-9448-6)'
  id: totrans-380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Bryson, J. J.](#R_ref5_3) (2018). 《耐心并非美德：智能系统与伦理系统设计》。伦理与信息技术，*20*，15–26。
    [https://doi.org/10.1007/s10676-018-9448-6](https://doi.org/10.1007/s10676-018-9448-6)'
- en: '[Burciaga, A.](#R_ref5_4) (2021, October 4). How to build responsible AI, step
    1: Accountability. Forbes. Retrieved October 13, 2023, from [https://www.forbes.com/sites/forbestechcouncil/2021/10/04/how-to-build-responsible-ai-step-1-accountability/](https://www.forbes.com)'
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Burciaga, A.](#R_ref5_4) (2021年10月4日)。如何构建负责任的人工智能，第一步：问责制。Forbes。2023年10月13日从[https://www.forbes.com/sites/forbestechcouncil/2021/10/04/how-to-build-responsible-ai-step-1-accountability/](https://www.forbes.com)检索。'
- en: '[Centre for Information Policy Leadership (CIPL)](#R_ref5_5). (2020, March).
    Artificial intelligence and data protection: How the GDPR regulates AI. Retrieved
    October 13, 2023, from [https://www.informationpolicycentre.com/uploads/5/7/1/0/57104281/cipl-hunton_andrews_kurth_legal_note_-_how_gdpr_regulates_ai__12_march_2020_.pdf](https://www.informationpolicycentre.com)'
  id: totrans-382
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[信息政策领导中心（CIPL）](#R_ref5_5). (2020年3月)。人工智能与数据保护：GDPR如何规范人工智能。2023年10月13日从[https://www.informationpolicycentre.com/uploads/5/7/1/0/57104281/cipl-hunton_andrews_kurth_legal_note_-_how_gdpr_regulates_ai__12_march_2020_.pdf](https://www.informationpolicycentre.com)检索。'
- en: '[Chan, C. K. Y.](#R_ref5_6) (2023). A comprehensive AI policy education framework
    for university teaching and learning. International Journal of Educational Technology
    in Higher Education. [https://doi.org/ 10.1186/s41239-023-00408-3](https://doi.org/)'
  id: totrans-383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Chan, C. K. Y.](#R_ref5_6) (2023年)。为大学教学和学习制定全面的人工智能政策教育框架。国际高等教育技术杂志。[https://doi.org/
    10.1186/s41239-023-00408-3](https://doi.org/)'
- en: '[Chowdhury, R.](#R_ref5_7) (2023, April 6). AI desperately needs global oversight.
    Wired. Retrieved October 13, 2023, from [https://www.wired.com/story/ai-desperately-needs-global-oversight/](https://www.wired.com)'
  id: totrans-384
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Chowdhury, R.](#R_ref5_7) (2023年4月6日)。人工智能迫切需要全球监管。Wired。2023年10月13日从[https://www.wired.com/story/ai-desperately-needs-global-oversight/](https://www.wired.com)检索。'
- en: '[Christian, B.](#R_ref5_8) (2020). The alignment problem: Machine learning
    and human values. W.W. Norton & Company.'
  id: totrans-385
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Christian, B.](#R_ref5_8) (2020). 《对齐问题：机器学习与人类价值观》。W.W. Norton & Company.'
- en: '[Creswell, A., Nikiforou, K., Vinyals, O., Saraiva, A., Kabra, R., Matthey,
    L., Burgess, C., Reynolds, M., Tanburn, R., Garnelo, M., & Shanahan, M.](#R_ref5_9)
    (2020, July 21). AlignNet: Unsupervised entity alignment. Google DeepMind. Retrieved
    October 13, 2023, from [https://www.deepmind.com/publications/alignnet-unsupervised-entity-alignment](https://www.deepmind.com)'
  id: totrans-386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Creswell, A.，Nikiforou, K.，Vinyals, O.，Saraiva, A.，Kabra, R.，Matthey, L.，Burgess,
    C.，Reynolds, M.，Tanburn, R.，Garnelo, M.，& Shanahan, M.](#R_ref5_9) (2020年7月21日)。AlignNet：无监督实体对齐。Google
    DeepMind。2023年10月13日从[https://www.deepmind.com/publications/alignnet-unsupervised-entity-alignment](https://www.deepmind.com)检索。'
- en: '[Criddle, C., Espinoza, J., & Liu, Q.](#R_ref5_10) (2023, September 13). The
    global race to set the rules for AI. Financial Times. Retrieved October 13, 2023,
    from [https://www.ft.com/content/59b9ef36-771f-4f91-89d1-ef89f4a2ec4e](https://www.ft.com)'
  id: totrans-387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Criddle, C.，Espinoza, J.，& Liu, Q.](#R_ref5_10) (2023年9月13日)。全球竞相为人工智能制定规则。金融时报。2023年10月13日从[https://www.ft.com/content/59b9ef36-771f-4f91-89d1-ef89f4a2ec4e](https://www.ft.com)检索。'
- en: '[Department for Digital, Culture, Media and Sport](#R_ref5_11). (2022, July
    18). Establishing a pro-innovation approach to regulating AI: An overview of the
    UK’s emerging approach. Retrieved October 17, 2023, from [https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/1092630/_CP_728__-_Establishing_a_pro-innovation_approach_to_regulating_AI.pdf](https://assets.publishing.service.gov.uk)'
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数字、文化、媒体和体育部](#R_ref5_11)。(2022, July 18)。建立促进创新的AI监管方法：英国新兴方法的概述。2023年10月17日从[https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/1092630/_CP_728__-_Establishing_a_pro-innovation_approach_to_regulating_AI.pdf](https://assets.publishing.service.gov.uk)获取。'
- en: '[Edwards, B.](#R_ref5_12) (2023, May 31). *OpenAI execs warn of “risk of extinction”
    from artificial intelligence in new open letter*. Ars Technica. Retrieved October
    13, 2023, from [https://arstechnica.com/information-technology/2023/05/openai-execs-warn-of-risk-of-extinction-from-artificial-intelligence-in-new-open-letter/](https://arstechnica.com)'
  id: totrans-389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Edwards, B.](#R_ref5_12) (2023, May 31). *OpenAI高管在新的公开信中警告人工智能“灭绝”风险*。Ars
    Technica。2023年10月13日从[https://arstechnica.com/information-technology/2023/05/openai-execs-warn-of-risk-of-extinction-from-artificial-intelligence-in-new-open-letter/](https://arstechnica.com)获取。'
- en: '[European Parliament](#R_ref5_13) (2023, June 14). EU AI act: First regulation
    on artificial intelligence. Retrieved October 13, 2023, from [https://www.europarl.europa.eu/news/en/headlines/society/20230601STO93804/eu-ai-act-first-regulation-on-artificial-intelligence](https://www.europarl.europa.eu)'
  id: totrans-390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[欧洲议会](#R_ref5_13) (2023, June 14). 欧盟人工智能法案：关于人工智能的第一项法规。2023年10月13日从[https://www.europarl.europa.eu/news/en/headlines/society/20230601STO93804/eu-ai-act-first-regulation-on-artificial-intelligence](https://www.europarl.europa.eu)获取。'
- en: '[Federal Trade Commission Bureau of Competition & Office of Technology](#R_ref5_14).
    (2023, June 29). Generative AI raises competition concerns. Retrieved October
    16, 2023, from [https://www.ftc.gov/policy/advocacy-research/tech-at-ftc/2023/06/generative-ai-raises-competition-concerns](https://www.ftc.gov)'
  id: totrans-391
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[联邦贸易委员会竞争局与技术办公室](#R_ref5_14)。(2023, June 29)。生成式人工智能引发竞争担忧。2023年10月16日从[https://www.ftc.gov/policy/advocacy-research/tech-at-ftc/2023/06/generative-ai-raises-competition-concerns](https://www.ftc.gov)获取。'
- en: '[Federspiel, F., Mitchell, R., Asokan, A., Umana, C., & McCoy, D.](#R_ref5_15)
    (2023). Threats by artificial intelligence to human health and human existence.
    BMJ Global Health, *8*(5), 1–6\. [https://doi.org/10.1136/bmjgh-2022-010435](https://doi.org/10.1136/bmjgh-2022-010435)'
  id: totrans-392
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Federspiel, F., Mitchell, R., Asokan, A., Umana, C., & McCoy, D.](#R_ref5_15)
    (2023). 人工智能对人类健康和人类生存的威胁。BMJ全球健康，*8*(5)，1–6。2023年从[https://doi.org/10.1136/bmjgh-2022-010435](https://doi.org/10.1136/bmjgh-2022-010435)获取。'
- en: '[Ferrara, E.](#R_ref5_16) (2023). Fairness and bias in artificial intelligence:
    A brief survey of sources, impacts, and mitigation strategies. arXiv. [https://doi.org/10.48550/arXiv.2304.07683](https://doi.org/10.48550/arXiv.2304.07683)'
  id: totrans-393
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Ferrara, E.](#R_ref5_16) (2023)。人工智能中的公平性和偏见：来源、影响和缓解策略的简要调查。arXiv。[https://doi.org/10.48550/arXiv.2304.07683](https://doi.org/10.48550/arXiv.2304.07683)获取。'
- en: '[Friedler, S., Venkatasubramanian, S., & Engler, A.](#R_ref5_17) (2023, March
    22). How California and other states are tackling AI legislation. Brookings. Retrieved
    October 13, 2023, from [https://www.brookings.edu/articles/how-california-and-other-states-are-tackling-ai-legislation/](https://www.brookings.edu)'
  id: totrans-394
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Friedler, S., Venkatasubramanian, S., & Engler, A.](#R_ref5_17) (2023, March
    22). 加利福尼亚和其他州如何应对人工智能立法。布鲁金斯学会。2023年10月13日从[https://www.brookings.edu/articles/how-california-and-other-states-are-tackling-ai-legislation/](https://www.brookings.edu)获取。'
- en: '[Future of Life Institute](#R_ref5_18). (2017, August 11). AI principles. Retrieved
    October 13, 2023, from [https://futureoflife.org/open-letter/ai-principles/](https://futureoflife.org)'
  id: totrans-395
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[生命未来研究所](#R_ref5_18)。(2017, August 11)。人工智能原则。2023年10月13日从[https://futureoflife.org/open-letter/ai-principles/](https://futureoflife.org)获取。'
- en: '[Gabriel, I.](#R_ref5_19) (2020, January 13). Artificial intelligence, values
    and alignment. Google DeepMind. Retrieved October 13, 2023, from [https://www.deepmind.com/publications/artificial-intelligence-values-and-alignment](https://www.deepmind.com)'
  id: totrans-396
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Gabriel, I.](#R_ref5_19) (2020, January 13). 人工智能、价值观和对齐。谷歌DeepMind。2023年10月13日从[https://www.deepmind.com/publications/artificial-intelligence-values-and-alignment](https://www.deepmind.com)获取。'
- en: '[GDPR.EU](#R_ref5_20). (2023). What is GDPR, the EU’s new data protection law?
    Retrieved October 13, 2023, from [https://gdpr.eu/what-is-gdpr/](https://gdpr.eu)'
  id: totrans-397
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[GDPR.EU](#R_ref5_20)。(2023)。什么是GDPR，欧盟的新数据保护法？2023年10月13日从[https://gdpr.eu/what-is-gdpr/](https://gdpr.eu)获取。'
- en: '[Gent, E.](#R_ref5_21) (2023, May 10). What is the AI alignment problem and
    how can it be solved? New Scientist. Retrieved October 13, 2023, from [https://www.newscientist.com/article/mg25834382-000-what-is-the-ai-alignment-problem-and-how-can-it-be-solved/](https://www.newscientist.com)'
  id: totrans-398
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Gent, E.](#R_ref5_21) (2023, May 10). 人工智能对齐问题是什么，以及如何解决它？新科学家。Retrieved October
    13, 2023, from [https://www.newscientist.com/article/mg25834382-000-what-is-the-ai-alignment-problem-and-how-can-it-be-solved/](https://www.newscientist.com)'
- en: '[Goertzel, B.](#R_ref5_22) (2014). Artificial general intelligence: Concept,
    state of the art, and future prospects. Journal of Artificial General Intelligence,
    *5*(1), 1–46\. [https://doi.org/10.2478/jagi-2014-0001](https://doi.org/10.2478/jagi-2014-0001)'
  id: totrans-399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Goertzel, B.](#R_ref5_22) (2014). 通用人工智能：概念、现状与未来展望。人工智能通用智能杂志，*5*(1)，1–46\.
    [https://doi.org/10.2478/jagi-2014-0001](https://doi.org/10.2478/jagi-2014-0001)'
- en: '[Government of India Ministry of Electronics & Information Technology](#R_ref5_23).
    (2023, August 11). Information technology act 2000. Retrieved October 16, 2023,
    from [https://www.meity.gov.in/content/information-technology-act-2000](https://www.meity.gov.in)'
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[印度电子与信息技术部](#R_ref5_23). (2023, August 11). 信息技术法2000。Retrieved October 16,
    2023, from [https://www.meity.gov.in/content/information-technology-act-2000](https://www.meity.gov.in)'
- en: '[Greiman, V. A.](#R_ref5_24) (2021). Human rights and artificial intelligence:
    A universal challenge. Journal of Information Warfare, *20*(1), 50–62.'
  id: totrans-401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Greiman, V. A.](#R_ref5_24) (2021). 人工智能与人权：一个普遍的挑战。信息战杂志，*20*(1)，50–62.'
- en: '[Hogenhout, L.](#R_ref5_25) (2021). A framework for ethical AI at the United
    Nations. United Nations. Retrieved October 16, 2023, [https://unite.un.org/sites/unite.un.org/files/unite_paper_-_ethical_ai_at_the_un.pdf](https://unite.un.org)'
  id: totrans-402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Hogenhout, L.](#R_ref5_25) (2021). 联合国伦理人工智能框架。联合国。Retrieved October 16, 2023,
    [https://unite.un.org/sites/unite.un.org/files/unite_paper_-_ethical_ai_at_the_un.pdf](https://unite.un.org)'
- en: '[Information Commissioner’s Office](#R_ref5_26). (n.d.) What are the accountability
    and governance implications of AI? Retrieved October 13, 2023, from [https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/artificial-intelligence/guidance-on-ai-and-data-protection/what-are-the-accountability-and-governance-implications-of-ai/](https://ico.org.uk)'
  id: totrans-403
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[信息专员办公室](#R_ref5_26). (n.d.) 人工智能的问责制和治理影响是什么？Retrieved October 13, 2023,
    from [https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/artificial-intelligence/guidance-on-ai-and-data-protection/what-are-the-accountability-and-governance-implications-of-ai/](https://ico.org.uk)'
- en: '[International Commission on the Futures of Education](#R_ref5_27). (2021).
    Reimagining our futures together: a new social contract for education. UNESCO.
    [https://doi.org/10.54675/ASRB4722](https://doi.org/10.54675/ASRB4722)'
  id: totrans-404
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[国际教育未来委员会](#R_ref5_27). (2021). 重新构想我们的未来：教育的新社会契约。联合国教科文组织。[https://doi.org/10.54675/ASRB4722](https://doi.org/10.54675/ASRB4722)'
- en: '[Joyce, D. W., Kormilitzin, A., Smith, K. A. et al.](#R_ref5_28) (2023). Explainable
    artificial intelligence for mental health through transparency and interpretability
    for understandability. npj Digital Medicine, 6, 6\. [https://doi.org/10.1038/s41746-023-00751-9](https://doi.org/10.1038/s41746-023-00751-9)'
  id: totrans-405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Joyce, D. W., Kormilitzin, A., Smith, K. A. et al.](#R_ref5_28) (2023). 通过透明度和可解释性提高心理健康领域的可理解性的人工智能可解释性。数字医学杂志，6，6\.
    [https://doi.org/10.1038/s41746-023-00751-9](https://doi.org/10.1038/s41746-023-00751-9)'
- en: '[Kharparl, A.](#R_ref5_29) (2023, July 13). China finalizes first-of-its-kind
    rules governing generative A.I. services like ChatGPT. CNBC. Retrieved October
    13, 2023, from [https://www.cnbc.com/2023/07/13/china-introduces-rules-governing-generative-ai-services-like-chatgpt.html](https://www.cnbc.com)'
  id: totrans-406
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Kharparl, A.](#R_ref5_29) (2023, July 13). 中国最终完成首个规范类似ChatGPT的生成式人工智能服务的规则。CNBC。Retrieved
    October 13, 2023, from [https://www.cnbc.com/2023/07/13/china-introduces-rules-governing-generative-ai-services-like-chatgpt.html](https://www.cnbc.com)'
- en: '[Larsen, B. C.](#R_ref5_30) (2023). The geopolitics of AI and the rise of digital
    sovereignty. Brookings. Retrieved 16 October, 2023, from [https://www.brookings.edu/articles/the-geopolitics-of-ai-and-the-rise-of-digital-sovereignty/](https://www.brookings.edu)'
  id: totrans-407
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Larsen, B. C.](#R_ref5_30) (2023). 人工智能的地缘政治与数字主权崛起。布鲁金斯学会。Retrieved 16 October,
    2023, from [https://www.brookings.edu/articles/the-geopolitics-of-ai-and-the-rise-of-digital-sovereignty/](https://www.brookings.edu)'
- en: '[Lawton, G.](#R_ref5_31) (2023, June 2). AI transparency: What is it and why
    do we need it? TechTarget. Retrieved October 13, 2023, from [https://www.techtarget.com/searchcio/tip/AI-transparency-What-is-it-and-why-do-we-need-it#:~:text=Transparency%20in%20AI%20refers%20to,how%20it%20reaches%20its%20decisions](https://www.techtarget.com)'
  id: totrans-408
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Lawton, G.](#R_ref5_31) (2023, June 2). 人工智能透明度：它是什么，为什么我们需要它？TechTarget.
    Retrieved October 13, 2023, from [https://www.techtarget.com/searchcio/tip/AI-transparency-What-is-it-and-why-do-we-need-it#:~:text=Transparency%20in%20AI%20refers%20to,how%20it%20reaches%20its%20decisions](https://www.techtarget.com)'
- en: '[Leike, J., Schulman, J., & Wu, J.](#R_ref5_32) (2022, August 24). Our approach
    to alignment research. OpenAI. Retrieved October 13, 2023, from [https://openai.com/blog/our-approach-to-alignment-research](https://openai.com)'
  id: totrans-409
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[莱克，J.，舒尔曼，J.，吴，J.](#R_ref5_32) (2022年8月24日). 我们对对齐研究的做法。OpenAI。2023年10月13日检索，来自
    [https://openai.com/blog/our-approach-to-alignment-research](https://openai.com)'
- en: '[Liu, Y.](#R_ref5_33) (2023, June 5). 生成AI画像は類似性が認められれば「著作権侵害」。文化庁 [If a generated
    AI image is found to be similar, it is considered a “copyright infringement.”
    Agency for Cultural Affairs]. PC Watch. Retrieved from [https://pc.watch.impress.co.jp/docs/news/1506018.html](https://pc.watch.impress.co.jp)'
  id: totrans-410
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[刘，Y.](#R_ref5_33) (2023年6月5日)。如果生成的AI图像被认定为相似，则被视为“著作权侵权”。文化厅 [If a generated
    AI image is found to be similar, it is considered a “copyright infringement.”
    Agency for Cultural Affairs]。PC Watch。检索自 [https://pc.watch.impress.co.jp/docs/news/1506018.html](https://pc.watch.impress.co.jp)'
- en: '[Manish, C.](#R_ref5_34) (2023, August 18). Sam Altman’s nuclear backpack holds
    the code to save the world from AI. Mobile App Daily. Retrieved from [https://www.mobileappdaily.com/news/sam-altmans-nuclear-backpack-holds-the-code-to-save-the-world-from-ai](https://www.mobileappdaily.com)'
  id: totrans-411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[马尼什，C.](#R_ref5_34) (2023年8月18日)。萨姆·奥特曼的核背包掌握着拯救世界免受AI侵害的代码。移动应用日报。检索自 [https://www.mobileappdaily.com/news/sam-altmans-nuclear-backpack-holds-the-code-to-save-the-world-from-ai](https://www.mobileappdaily.com)'
- en: '[Matsuda, A., Kudo, R., & Matsuda, T.](#R_ref5_35) (2023). Japan. In C. Kerrigan
    (Ed.), AI, machine learning & big data laws and regulations 2023. Global Legal
    Insights. [https://www.globallegalinsights.com/practice-areas/ai-machine-learning-and-big-data-laws-and-regulations/japan](https://www.globallegalinsights.com)'
  id: totrans-412
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[松田，A.，工藤，R.，松田，T.](#R_ref5_35) (2023年)。日本。在C.凯里根（编辑）的《2023年AI、机器学习与大数据法律法规》。全球法律洞察。[https://www.globallegalinsights.com/practice-areas/ai-machine-learning-and-big-data-laws-and-regulations/japan](https://www.globallegalinsights.com)'
- en: '[Mehrabi, N., Morstatter, F., Saxena, N., Lerman, K., & Galstyan, A.](#R_ref5_36)
    (2021). A survey on bias and fairness in machine learning. ACM Computing Surveys,
    *54*(6), 1–35\. [https://doi.org/10.1145/3457607](https://doi.org/10.1145/3457607)'
  id: totrans-413
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[梅哈比，N.，莫斯特特拉特，F.，萨克斯纳，N.，勒曼，K.，加尔斯坦，A.](#R_ref5_36) (2021年)。关于机器学习中的偏差和公平性的调查。ACM计算评论，*54*(6)，1–35。
    [https://doi.org/10.1145/3457607](https://doi.org/10.1145/3457607)'
- en: '[Meyer, J.](#R_ref5_37) (2023, May 31). AI poses risk of extinction, tech leaders
    warn in open letter. Here’s why alarm is spreading. USA Today. Retrieved October
    13, 2023, from [https://eu.usatoday.com/story/news/politics/2023/05/31/ai-extinction-risk-expert-warning/70270171007/](https://eu.usatoday.com)'
  id: totrans-414
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[梅耶，J.](#R_ref5_37) (2023年5月31日)。科技领袖在公开信中警告AI灭绝风险，以下是为什么警报正在蔓延。今日美国。2023年10月13日检索，来自
    [https://eu.usatoday.com/story/news/politics/2023/05/31/ai-extinction-risk-expert-warning/70270171007/](https://eu.usatoday.com)'
- en: '[Minevich, M.](#R_ref5_38) (2023, May 19). Generative AI shakes global diplomacy
    at G7 summit in Japan. Forbes. Retrieved October 16, 2023, from [https://www.forbes.com/sites/markminevich/2023/05/19/high-stakes-generative-ai-shakes-global-diplomacy-at-japans-2023-g7-summit/?sh=243a3dce6321](https://www.forbes.com)'
  id: totrans-415
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[米内维奇，M.](#R_ref5_38) (2023年5月19日)。生成式AI在日本G7峰会上的全球外交产生震动。福布斯。2023年10月16日检索，来自
    [https://www.forbes.com/sites/markminevich/2023/05/19/high-stakes-generative-ai-shakes-global-diplomacy-at-japans-2023-g7-summit/?sh=243a3dce6321](https://www.forbes.com)'
- en: '[Ministry of Economy, Trade and Industry](#R_ref5_39). (2021, July 9). AI governance
    in Japan Ver. 1.1: Report from the expert group on how AI principles should be
    implemented. Retrieved October 16, 2023, from [https://www.meti.go.jp/shingikai/mono_info_service/ai_shakai_jisso/pdf/20210709_8.pdf](https://www.meti.go.jp)'
  id: totrans-416
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[经济产业省](#R_ref5_39)。(2021年7月9日)。日本AI治理 Ver. 1.1：专家小组关于如何实施AI原则的报告。2023年10月16日检索，来自
    [https://www.meti.go.jp/shingikai/mono_info_service/ai_shakai_jisso/pdf/20210709_8.pdf](https://www.meti.go.jp)'
- en: '[Mukherjee, S., Chee, F. Y., & Coulter, M.](#R_ref5_40) (2023, April 28). EU
    proposes new copyright rules for generative AI. Reuters. Retrieved October 13,
    2023, from [https://www.reuters.com/technology/eu-lawmakers-committee-reaches-deal-artificial-intelligence-act-2023-04-27/](https://www.reuters.com)'
  id: totrans-417
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[穆克赫杰，S.，蔡，F. Y.，考尔特，M.](#R_ref5_40) (2023年4月28日)。欧盟提议为生成式AI制定新的版权规则。路透社。2023年10月13日检索，来自
    [https://www.reuters.com/technology/eu-lawmakers-committee-reaches-deal-artificial-intelligence-act-2023-04-27/](https://www.reuters.com)'
- en: '[Nasiripour, S., & Natarajan, S.](#R_ref5_41) (2019, November 11). Apple co-founder
    says Goldman’s apple card algorithm discriminates. Bloomberg. Retrieved October
    13, 2023, from [https://www.bloomberg.com/news/articles/2019-11-10/apple-co-founder-says-goldman-s-apple-card-algo-discriminates?leadSource=uverify%20wall](https://www.bloomberg.com)'
  id: totrans-418
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[纳斯里波尔，S.，纳塔拉扬，S.](#R_ref5_41) (2019年11月11日). 苹果联合创始人称高盛的苹果卡算法存在歧视。彭博社。2023年10月13日检索，来自
    [https://www.bloomberg.com/news/articles/2019-11-10/apple-co-founder-says-goldman-s-apple-card-algo-discriminates?leadSource=uverify%20wall](https://www.bloomberg.com)'
- en: '[Novelli, C., Taddeo, M., & Floridi, L.](#R_ref5_42) (2023). Accountability
    in artificial intelligence: What it is and how it works. AI & Soc. [https://doi.org/10.1007/s00146-023-01635-y](https://doi.org/10.1007/s00146-023-01635-y)'
  id: totrans-419
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Novelli, C., Taddeo, M., & Floridi, L.](#R_ref5_42) (2023)。人工智能中的问责制：它是什么以及它是如何运作的。人工智能与社会。[https://doi.org/10.1007/s00146-023-01635-y](https://doi.org/10.1007/s00146-023-01635-y)'
- en: '[OpenAI](#R_ref5_43). (2023a). GPT-4 documentation. Retrieved October 13, 2023,
    from [https://platform.openai.com/docs/models/gpt-4](https://platform.openai.com)'
  id: totrans-420
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[OpenAI](#R_ref5_43)。(2023a)。GPT-4 文档。2023 年 10 月 13 日检索，来自 [https://platform.openai.com/docs/models/gpt-4](https://platform.openai.com)'
- en: '[OpenAI](#R_ref5_44). (2023b). Privacy policy. Retrieved October 13, 2023,
    from [https://openai.com/policies/privacy-policy](https://openai.com)'
  id: totrans-421
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[OpenAI](#R_ref5_44)。(2023b)。隐私政策。2023 年 10 月 13 日检索，来自 [https://openai.com/policies/privacy-policy](https://openai.com)'
- en: '[OpenAI](#R_ref5_45). (2023c). Security & privacy. Retrieved October 13, 2023,
    from [https://openai.com/security](https://openai.com)'
  id: totrans-422
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[OpenAI](#R_ref5_45)。(2023c)。安全与隐私。2023 年 10 月 13 日检索，来自 [https://openai.com/security](https://openai.com)'
- en: '[OpenAI](#R_ref5_46). (2023d). OpenAI charter. Retrieved October 13, 2023,
    from [https://openai.com/charter](https://openai.com)'
  id: totrans-423
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[OpenAI](#R_ref5_46)。(2023d)。OpenAI 宪章。2023 年 10 月 13 日检索，来自 [https://openai.com/charter](https://openai.com)'
- en: 'Osborne Clarke. (2022, July 19). Consultation on UK AI regulation: Legislation-free
    and devolved regulators. Retrieved October 17, 2023, from [https://www.osborneclarke.com/insights/consultation-uk-ai-regulation-legislation-free-and-devolved-regulators](https://www.osborneclarke.com)'
  id: totrans-424
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Osborne Clarke。 (2022, 七月 19 日)。关于英国人工智能监管的咨询：无立法和分权监管机构。2023 年 10 月 17 日检索，来自
    [https://www.osborneclarke.com/insights/consultation-uk-ai-regulation-legislation-free-and-devolved-regulators](https://www.osborneclarke.com)
- en: '[Perrigo, B., & Gordon, A.](#R_ref5_48) (2023, June 14). E.U. takes a step
    closer to passing the world’s most comprehensive AI regulation. Time. Retrieved
    October 13, 2023, from [https://time.com/6287136/eu-ai-regulation/](https://time.com)'
  id: totrans-425
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Perrigo, B., & Gordon, A.](#R_ref5_48) (2023, 六月 14 日)。欧盟朝着通过世界上最具全面性的人工智能法规迈出一步。时代。2023
    年 10 月 13 日检索，来自 [https://time.com/6287136/eu-ai-regulation/](https://time.com)'
- en: '[Ribeiro, M. T., Singh, S., & Guestrin, C.](#R_ref5_49) (2016). “Why should
    I trust you?”: Explaining the predictions of any classifier. In *Proceedings of
    the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining*
    (pp. 1135–1144). [https://doi.org/10.1145/2939672.2939778](https://doi.org/10.1145/2939672.2939778)'
  id: totrans-426
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Ribeiro, M. T., Singh, S., & Guestrin, C.](#R_ref5_49) (2016)。我应该相信你吗？解释任何分类器的预测。在
    *第 22 届 ACM SIGKDD 国际知识发现和数据挖掘会议论文集* (第 1135–1144 页)。[https://doi.org/10.1145/2939672.2939778](https://doi.org/10.1145/2939672.2939778)'
- en: '[Roberts, H., Babuta, A., Morley, J., Thomas, C., Taddeo, M., & Floridi, L.](#R_ref5_50)
    (2023, May 26). Artificial intelligence regulation in the United Kingdom: A path
    to good governance and global leadership? Internet Policy Review, *12*(2). [https://doi.org/10.14763/2023.2.1709](https://doi.org/10.14763/2023.2.1709)'
  id: totrans-427
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Roberts, H., Babuta, A., Morley, J., Thomas, C., Taddeo, M., & Floridi, L.](#R_ref5_50)
    (2023, 五月 26 日). 英国人工智能监管：通往良好治理和全球领导力的道路？互联网政策评论，*12*(2)。[https://doi.org/10.14763/2023.2.1709](https://doi.org/10.14763/2023.2.1709)'
- en: '[Robles, P.](#R_ref5_51) (2023, October 1). China plans to be a world leader
    in Artificial Intelligence by 2030. South China Morning Post. Retrieved October
    16, 2023, from [https://multimedia.scmp.com/news/china/article/2166148/china-2025-artificial-intelligence/index.html](https://multimedia.scmp.com)'
  id: totrans-428
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Robles, P.](#R_ref5_51) (2023, 十月 1 日). 中国计划到 2030 年成为人工智能领域的世界领导者。南华早报。2023
    年 10 月 16 日检索，来自 [https://multimedia.scmp.com/news/china/article/2166148/china-2025-artificial-intelligence/index.html](https://multimedia.scmp.com)'
- en: '[Russell, S., Dewey, D., & Tegmark, M.](#R_ref5_52) (2015). Research priorities
    for robust and beneficial artificial intelligence. AI Magazine, *36*(4), 105–114\.
    [https://doi.org/10.1609/aimag.v36i4.2577](https://doi.org/10.1609/aimag.v36i4.2577)'
  id: totrans-429
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Russell, S., Dewey, D., & Tegmark, M.](#R_ref5_52) (2015)。稳健和有益的人工智能研究优先事项。人工智能杂志，*36*(4)，105–114。[https://doi.org/10.1609/aimag.v36i4.2577](https://doi.org/10.1609/aimag.v36i4.2577)'
- en: '[Sharwood, S.](#R_ref5_53) (2023, May 26). India set to regulate AI, Big Tech,
    with Digital Act. The Register. Retrieved October 16, 2023, from [https://www.theregister.com/2023/05/26/india_digital_act_draft_june/](https://www.theregister.com)'
  id: totrans-430
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Sharwood, S.](#R_ref5_53) (2023, 五月 26 日)。印度准备通过《数字法案》监管人工智能和大型科技公司。注册。2023
    年 10 月 16 日检索，来自 [https://www.theregister.com/2023/05/26/india_digital_act_draft_june/](https://www.theregister.com)'
- en: '[Silberg, J., & Manyika, J.](#R_ref5_54) (2019, June 6). Tackling bias in artificial
    intelligence (and in humans). McKinsey Global Institute. Retrieved October 13,
    2023, from [https://www.mckinsey.com/featured-insights/artificial-intelligence/tackling-bias-in-artificial-intelligence-and-in-humans](https://www.mckinsey.com)'
  id: totrans-431
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Silberg, J., & Manyika, J.](#R_ref5_54) (2019, 六月6日). 解决人工智能（以及人类）中的偏见。麦肯锡全球研究院。2023年10月13日检索，来自
    [https://www.mckinsey.com/featured-insights/artificial-intelligence/tackling-bias-in-artificial-intelligence-and-in-humans](https://www.mckinsey.com)'
- en: '[Singh, M.](#R_ref5_55) (2023, April 6). India opts against AI regulation.
    TechCrunch. Retrieved October 16, 2023, from [https://techcrunch.com/2023/04/05/india-opts-against-ai-regulation/](https://techcrunch.com)'
  id: totrans-432
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Singh, M.](#R_ref5_55) (2023年，4月6日)。印度选择不监管人工智能。TechCrunch。2023年10月16日检索，来自
    [https://techcrunch.com/2023/04/05/india-opts-against-ai-regulation/](https://techcrunch.com)'
- en: '[State of California Department of Justice, Office of the Attorney General](#R_ref5_56).
    (2023). California Consumer Privacy Act (CCPA). Retrieved October 13, 2023, from
    [https://oag.ca.gov/privacy/ccpa](https://oag.ca.gov)'
  id: totrans-433
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[加利福尼亚州司法部，总检察长办公室](#R_ref5_56)。 (2023年)。加利福尼亚消费者隐私法案（CCPA）。2023年10月13日检索，来自
    [https://oag.ca.gov/privacy/ccpa](https://oag.ca.gov)'
- en: '[Stokel-Walker, C.](#R_ref5_57) (2023, January 18). ChatGPT listed as author
    on research papers: Many scientists disapprove. Nature. Retrieved October 13,
    2023, from [https://www.nature.com/articles/d41586-023-00107-z](https://www.nature.com)'
  id: totrans-434
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Stokel-Walker, C.](#R_ref5_57) (2023年，1月18日)。ChatGPT被列为研究论文的作者：许多科学家表示反对。Nature。2023年10月13日检索，来自
    [https://www.nature.com/articles/d41586-023-00107-z](https://www.nature.com)'
- en: '[Strickland, E.](#R_ref5_58) (2023, August 31). OpenAI’s moonshot: Solving
    the AI alignment problem. IEEE Spectrum. Retrieved October 13, 2023, from [https://spectrum.ieee.org/the-alignment-problem-openai](https://spectrum.ieee.org)'
  id: totrans-435
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Strickland, E.](#R_ref5_58) (2023年，8月31日)。OpenAI的宏伟目标：解决人工智能对齐问题。IEEE Spectrum。2023年10月13日检索，来自
    [https://spectrum.ieee.org/the-alignment-problem-openai](https://spectrum.ieee.org)'
- en: '[The Japan Times](#R_ref5_59). (2023, October 15). Japan’s AI draft guidelines
    ask for measures to address overreliance. Retrieved October 16, 2023, from [https://www.japantimes.co.jp/news/2023/10/15/japan/politics/ai-draft-guidelines/](https://www.japantimes.co.jp)'
  id: totrans-436
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[《日本时报》](#R_ref5_59)。 (2023年，10月15日)。日本的AI草案指南要求采取措施解决过度依赖问题。2023年10月16日检索，来自
    [https://www.japantimes.co.jp/news/2023/10/15/japan/politics/ai-draft-guidelines/](https://www.japantimes.co.jp)'
- en: '[The Times of India](#R_ref5_60). (2023, May 17). India planning to regulate
    AI platforms like ChatGPT: IT minister Ashwini Vaishnaw. Retrieved October 16,
    2023, from [http://timesofindia.indiatimes.com/articleshow/100310733.cms?utm_source=contentofinterest&utm_medium=text&utm_campaign=cppst](http://timesofindia.indiatimes.com)'
  id: totrans-437
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[《印度时报》](#R_ref5_60)。 (2023年，5月17日)。印度计划监管类似ChatGPT的人工智能平台：信息技术部长阿什温·瓦西纳。2023年10月16日检索，来自
    [http://timesofindia.indiatimes.com/articleshow/100310733.cms?utm_source=contentofinterest&utm_medium=text&utm_campaign=cppst](http://timesofindia.indiatimes.com)'
- en: '[UK Government](#R_ref5_61). (2023, August 3). *AI regulation: a pro-innovation
    approach*. [White paper]. Retrieved October 16, 2023, from [https://www.gov.uk/government/publications/ai-regulation-a-pro-innovation-approach](https://www.gov.uk)'
  id: totrans-438
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[英国政府](#R_ref5_61)。 (2023年，8月3日)。*人工智能监管：创新促进方法*。[白皮书]。2023年10月16日检索，来自 [https://www.gov.uk/government/publications/ai-regulation-a-pro-innovation-approach](https://www.gov.uk)'
- en: '[UNESCO](#R_ref5_62). (2023a, July 20). UNESCO’s Recommendation on the Ethics
    of Artificial Intelligence: Key Facts. [https://www.unesco.org/en/articles/unescos-recommendation-ethics-artificial-intelligence-key-facts#:~:text=The%20Recommendation%20establishes%20a%20set,the%20rule%20of%20law%20%20online](https://www.unesco.org)'
  id: totrans-439
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[联合国教科文组织](#R_ref5_62)。 (2023年，7月20日)。联合国教科文组织关于人工智能伦理的建议：关键事实。[https://www.unesco.org/en/articles/unescos-recommendation-ethics-artificial-intelligence-key-facts#:~:text=The%20Recommendation%20establishes%20a%20set,the%20rule%20of%20law%20%20online](https://www.unesco.org)'
- en: '[UNESCO](#R_ref5_63). (2023b, June 9). Artificial Intelligence: UNESCO publishes
    Policy Paper on AI Foundation Models. Retrieved from [https://www.unesco.org/en/articles/artificial-intelligence-unesco-publishes-policy-paper-ai-foundation-models](https://www.unesco.org)'
  id: totrans-440
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[联合国教科文组织](#R_ref5_63)。 (2023年，6月9日)。人工智能：联合国教科文组织发布关于人工智能基础模型的政策文件。检索自 [https://www.unesco.org/en/articles/artificial-intelligence-unesco-publishes-policy-paper-ai-foundation-models](https://www.unesco.org)'
- en: '[UNESCO](#R_ref5_64). (2023c). Guidance for generative AI in education and
    research. UNESCO. Retrieved October 13, 2023, from [https://unesdoc.unesco.org/ark:/48223/pf0000386693](https://unesdoc.unesco.org)'
  id: totrans-441
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[联合国教科文组织](#R_ref5_64)。 (2023年)。关于教育和研究中的生成式人工智能的指南。联合国教科文组织。2023年10月13日检索，来自
    [https://unesdoc.unesco.org/ark:/48223/pf0000386693](https://unesdoc.unesco.org)'
- en: University of Birmingham. (2023, August 4). Government’s “Pro-Innovation” AI
    white paper unfit for purpose. Retrieved October 16, 2023, from [https://www.birmingham.ac.uk/news/2023/the-governments-preoccupation-with-innovation-will-cause-the-rule-of-law-to-fall-behind](https://www.birmingham.ac.uk)
  id: totrans-442
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 伯明翰大学。 (2023年8月4日). 政府的“促创新”人工智能白皮书不适合其目的。2023年10月16日检索，来自 [https://www.birmingham.ac.uk/news/2023/the-governments-preoccupation-with-innovation-will-cause-the-rule-of-law-to-fall-behind](https://www.birmingham.ac.uk)
- en: '[West, D. M.](#R_ref5_66) (2023, September 12). California charts the future
    of AI. Brookings. Retrieved October 13, 2023, from [https://www.brookings.edu/articles/california-charts-the-future-of-ai/](https://www.brookings.edu)'
  id: totrans-443
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[West, D. M.](#R_ref5_66) (2023年9月12日). 加利福尼亚绘制人工智能的未来。布鲁金斯学会。2023年10月13日检索，来自
    [https://www.brookings.edu/articles/california-charts-the-future-of-ai/](https://www.brookings.edu)'
- en: '[Wheeler, T.](#R_ref5_67) (2023, June 15). The three challenges of AI regulation.
    Brookings. Retrieved October 13, 2023, from [https://www.brookings.edu/articles/the-three-challenges-of-ai-regulation/](https://www.brookings.edu)'
  id: totrans-444
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Wheeler, T.](#R_ref5_67) (2023年6月15日). 人工智能监管的三个挑战。布鲁金斯学会。2023年10月13日检索，来自
    [https://www.brookings.edu/articles/the-three-challenges-of-ai-regulation/](https://www.brookings.edu)'
