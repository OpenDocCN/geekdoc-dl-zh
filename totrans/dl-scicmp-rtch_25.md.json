["```r\nlibrary(torch)\nlibrary(luz)\n\nlibrary(purrr)\nlibrary(readr)\nlibrary(dplyr)\n\nuci <- \"https://archive.ics.uci.edu\"\nds_path <- \"ml/machine-learning-databases/heart-disease\"\nds_file <- \"processed.cleveland.data\"\n\ndownload.file(\n file.path(uci, ds_path, ds_file),\n destfile = \"resources/tabular-heart.csv\"\n)\n\nheart_df <- read_csv(\n \"resources/tabular-heart.csv\",\n col_names = c(\n \"age\", \n # 1 = male; 0 = female\n \"sex\", \n # chest pain type\n # (1 = typical angina, 2 = atypical angina,\n #  3 = non-anginal pain, 4 = asymptomatic)\n \"pain_type\", \n # in mm Hg on admission\n \"resting_blood_pressure\", \n # serum cholesterol in mg/dl\n \"chol\", \n # > 120 mg/dl, true (1) or false (0)\n \"fasting_blood_sugar\", \n # 0 = normal, 1 = ST-T wave abnormality\n # (T wave inversions and/or ST elevation\n # or depression of > 0.05 mV),\n # 2 = probable or definite left ventricular\n # hypertrophy by Estes' criteria\n \"rest_ecg\", \n # during exercise\n \"max_heart_rate\", \n # exercise induced angina (1 = yes, 0 = no),\n \"ex_induced_angina\",\n # ST depression induced by exercise relative to rest \n \"old_peak\", \n # slope of the peak exercise ST segment\n # (1 = upsloping, 2 = flat, 3 = downsloping) \n \"slope\", \n # number of major vessels (0-3) colored by fluoroscopy\n \"ca\", \n # 3 = normal; 6 = fixed defect; 7 = reversible defect\n \"thal\", \n # 1-4 = yes; 0 = no\n \"heart_disease\" \n ),\n na = \"?\")\n```", "```r\nwhich(is.na(heart_df), arr.ind = TRUE)\n```", "```r\n row col\n[1,] 167  12\n[2,] 193  12\n[3,] 288  12\n[4,] 303  12\n[5,]  88  13\n[6,] 267  13\n```", "```r\nheart_df %>% group_by(thal) %>% summarise(n())\n```", "```r\ntibble: 4 × 2\nthal `n()`\n<dbl> <int>\n  1      3   166\n  2      6    18\n  3      7   117\n  4     NA     2\n```", "```r\nheart_df %>% group_by(ca) %>% summarise(n())\n```", "```r\nA tibble: 5 × 2\nca `n()`\n<dbl> <int>\n  1     0   176\n  2     1    65\n  3     2    38\n  4     3    20\n  5    NA     4\n```", "```r\nnnf_one_hot(\n torch_tensor(\n heart_df$slope,\n dtype = torch_long()\n )\n) %>% print(n = 5)\n```", "```r\ntorch_tensor\n 0  0  1\n 0  1  0\n 0  1  0\n 0  0  1\n 1  0  0\n... [the output was truncated (use n=-1 to disable)]\n[ CPULongType{303,3} ]\n```", "```r\nheart_dataset <- dataset(\n initialize = function(df) {\n self$x_cat <- self$get_categorical(df)\n self$x_num <- self$get_numerical(df)\n self$y <- self$get_target(df)\n },\n .getitem = function(i) {\n x_cat <- self$x_cat[i, ]\n x_num <- self$x_num[i, ]\n y <- self$y[i]\n list(x = list(x_cat, x_num), y = y)\n },\n .length = function() {\n dim(self$y)[1]\n },\n get_target = function(df) {\n heart_disease <- ifelse(df$heart_disease > 0, 1, 0)\n heart_disease\n },\n get_numerical = function(df) {\n df %>%\n select(\n -(c(\n heart_disease, pain_type,\n rest_ecg, slope, ca, thal\n ))\n ) %>%\n mutate(across(.fns = scale)) %>%\n as.matrix()\n },\n get_categorical = function(df) {\n df$ca <- ifelse(is.na(df$ca), 999, df$ca)\n df$thal <- ifelse(is.na(df$thal), 999, df$thal)\n df %>%\n select(\n pain_type, rest_ecg, slope, ca, thal\n ) %>%\n mutate(\n across(.fns = compose(as.integer, as.factor))\n ) %>%\n as.matrix()\n }\n)\n```", "```r\nds <- heart_dataset(heart_df)\nds[1]\n```", "```r\n$x\n$x[[1]]\npain_type  rest_ecg     slope        ca      thal \n        1         3         3         1         2 \n\n$x[[2]]\n                   age                    sex \n            0.94715962             0.68506916 \nresting_blood_pressure                   chol \n            0.75627397            -0.26446281 \n   fasting_blood_sugar         max_heart_rate \n            2.39048352             0.01716893 \n     ex_induced_angina               old_peak \n           -0.69548004             1.08554229 \n\n$y\n[1] 0\n```", "```r\ntrain_indices <- sample(\n 1:nrow(heart_df), size = floor(0.8 * nrow(heart_df)))\nvalid_indices <- setdiff(\n 1:nrow(heart_df), train_indices)\n\ntrain_ds <- dataset_subset(ds, train_indices)\ntrain_dl <- train_ds %>% \n dataloader(batch_size = 256, shuffle = TRUE)\n\nvalid_ds <- dataset_subset(ds, valid_indices)\nvalid_dl <- valid_ds %>% \n dataloader(batch_size = 256, shuffle = FALSE)\n```", "```r\none <- torch_tensor(c(1.555, 0.21, -3.33, 0.0007, 0.07))\ntwo <- torch_tensor(c(0.33, -0.03, -2.177, 1.1, 0.0005))\nthree <- torch_tensor(c(-0.33, 2.99, 1.77, 1.08, 3.001))\n```", "```r\nnnf_cosine_similarity(\n torch_ones(2),\n torch_ones(2) * 2.5,\n dim = 1\n)\n```", "```r\ntorch_tensor\n1\n[ CPUFloatType{} ]\n```", "```r\nnnf_cosine_similarity(\n torch_ones(2),\n -1.5 * torch_ones(2),\n dim = 1\n)\n```", "```r\ntorch_tensor\n-1\n[ CPUFloatType{} ]\n```", "```r\nnnf_cosine_similarity(\n torch_tensor(c(1, 0)),\n torch_tensor(c(0, 1)),\n dim = 1\n)\n```", "```r\ntorch_tensor\n0\n[ CPUFloatType{} ]\n```", "```r\nnnf_cosine_similarity(one, two, dim = 1)\nnnf_cosine_similarity(one, three, dim = 1)\nnnf_cosine_similarity(two, three, dim = 1)\n```", "```r\ntorch_tensor\n0.855909\n[ CPUFloatType{} ]\n\ntorch_tensor\n-0.319886\n[ CPUFloatType{} ]\n\ntorch_tensor\n-0.245948\n[ CPUFloatType{} ]\n```", "```r\nmodule <- nn_embedding(num_embeddings = 3, embedding_dim = 5)\nmodule$weight\n```", "```r\ntorch_tensor\n 2.3271  0.0894  0.6558 -0.5836 -0.1074\n 0.0367  0.1822 -0.0446  0.2059 -0.7540\n-0.7577 -1.7773 -0.6619  1.2884  0.3946\n[ CPUFloatType{3,5} ][ requires_grad = TRUE ]\n```", "```r\n# slope\nmodule(ds[1]$x[[1]][3])\n```", "```r\ntorch_tensor\n-0.7577 -1.7773 -0.6619  1.2884  0.3946\n[ CPUFloatType{1,5} ][ grad_fn = <EmbeddingBackward0> ]\n```", "```r\nembedding_module <- nn_module(\n initialize = function(cardinalities, embedding_dim) {\n self$embeddings <- nn_module_list(\n lapply(\n cardinalities,\n function(x) {\n nn_embedding(\n num_embeddings = x, embedding_dim = embedding_dim\n )\n }\n )\n )\n },\n forward = function(x) {\n embedded <- vector(\n mode = \"list\",\n length = length(self$embeddings)\n )\n for (i in 1:length(self$embeddings)) {\n embedded[[i]] <- self$embeddings[[i]](x[, i])\n }\n torch_cat(embedded, dim = 2)\n }\n)\n```", "```r\nmodel <- nn_module(\n initialize = function(cardinalities,\n num_numerical,\n embedding_dim,\n fc1_dim,\n fc2_dim) {\n self$embedder <- embedding_module(\n cardinalities,\n embedding_dim\n )\n self$fc1 <- nn_linear(\n embedding_dim * length(cardinalities) + num_numerical,\n fc1_dim\n )\n self$drop1 <- nn_dropout(p = 0.7)\n self$fc2 <- nn_linear(fc1_dim, fc2_dim)\n self$drop2 <- nn_dropout(p = 0.7)\n self$output <- nn_linear(fc2_dim, 1)\n },\n forward = function(x) {\n embedded <- self$embedder(x[[1]])\n all <- torch_cat(list(embedded, x[[2]]), dim = 2)\n score <- all %>%\n self$fc1() %>%\n nnf_relu() %>%\n self$drop1() %>%\n self$fc2() %>%\n nnf_relu() %>%\n self$drop2() %>%\n self$output()\n score[, 1]\n }\n)\n```", "```r\n# cardinalities of categorical features\ncardinalities <- heart_df %>%\n select(pain_type, rest_ecg, slope, ca, thal) %>%\n mutate(across(.fns = as.factor)) %>%\n summarise(across(.fns = nlevels))\n\n# cardinalities of categorical features,\n# adjusted for presence of NAs in ca and thal\ncardinalities <- cardinalities + c(0, 0, 0, 1, 1) \n\n# number of numerical features\nnum_numerical <- ncol(heart_df) - length(cardinalities) - 1\n\nembedding_dim <- 7\n\nfc1_dim <- 32\nfc2_dim <- 32\n```", "```r\nfitted <- model %>%\n setup(\n optimizer = optim_adam,\n loss = nn_bce_with_logits_loss(),\n metrics = luz_metric_binary_accuracy_with_logits()\n ) %>%\n set_hparams(\n cardinalities = cardinalities,\n num_numerical = num_numerical,\n embedding_dim = embedding_dim,\n fc1_dim = fc1_dim, fc2_dim\n ) %>%\n set_opt_hparams(lr = 0.001) %>%\n fit(train_dl,\n epochs = 200,\n valid_data = valid_dl,\n callbacks = list(\n luz_callback_early_stopping(patience = 10)\n ),\n verbose = TRUE\n )\n```", "```r\n# Epoch 1/200\n# Train metrics: Loss: 0.7445 - Acc: 0.4091\n# Valid metrics: Loss: 0.6988 - Acc: 0.541\n# Epoch 2/200\n# Train metrics: Loss: 0.7036 - Acc: 0.5248\n# Valid metrics: Loss: 0.6966 - Acc: 0.5246\n# Epoch 3/200\n# Train metrics: Loss: 0.7029 - Acc: 0.5124\n# Valid metrics: Loss: 0.6946 - Acc: 0.5082\n# ...\n# ...\n# Epoch 124/200\n# Train metrics: Loss: 0.3884 - Acc: 0.8512\n# Valid metrics: Loss: 0.4026 - Acc: 0.8525\n# Epoch 125/200\n# Train metrics: Loss: 0.3961 - Acc: 0.8471\n# Valid metrics: Loss: 0.4023 - Acc: 0.8525\n# Epoch 126/200\n# Train metrics: Loss: 0.359 - Acc: 0.8554\n# Valid metrics: Loss: 0.4019 - Acc: 0.8525\n# Early stopping at epoch 126 of 200\n```", "```r\nfitted %>% plot()\n```", "```r\nembedding_weights <- vector(mode = \"list\")\n\nfor (i in 1:length(fitted$model$embedder$embeddings)) {\n embedding_weights[[i]] <-\n fitted$model$embedder$embeddings[[i]]$\n parameters$weight$to(device = \"cpu\")\n}\n\nslope_weights <- embedding_weights[[3]]\nslope_weights\n```", "```r\ntorch_tensor\n-0.9226 -1.0282  0.8935  0.3152  0.5481  0.8376  0.9990\n 0.0604  0.1904  0.6788  0.8542  0.8007  1.5226 -0.1789\n 1.2504 -0.0827 -0.7259  1.2885 -1.7847  0.1813  0.4418\n[ CPUFloatType{3,7} ][ requires_grad = TRUE ]\n```", "```r\npca <- prcomp(slope_weights, center = TRUE, scale = TRUE)\npca\n```", "```r\nStandard deviations (1, .., p=3):\n[1] 2.138539e+00 1.557771e+00 2.173695e-16\n\nRotation (n x k) = (7 x 3):\n            PC1         PC2         PC3\n[1,]  0.4650931 -0.06650143  0.18974889\n[2,]  0.2915618 -0.50187753  0.42034629\n[3,] -0.4539313 -0.15412668  0.46092035\n[4,]  0.4562585 -0.14058058 -0.16106015\n[5,] -0.4203277 -0.28128658  0.29209764\n[6,] -0.2903728 -0.50317497 -0.68060609\n[7,] -0.1531762  0.60652402  0.01925451\n```", "```r\n(pca$sdev^2 / sum(pca$sdev^2)) %>% round(2)\n```", "```r\n[1] 0.65 0.35 0.00\n```", "```r\nbiplot(pca)\n```", "```r\npca$x\n```", "```r\n PC1        PC2           PC3\n[1,] -1.9164879  1.1343079  1.783213e-17\n[2,] -0.3903307 -1.7761457  6.993398e-16\n[3,]  2.3068187  0.6418377 -4.977644e-16\n```", "```r\nlibrary(ggplot2)\nlibrary(ggrepel)\n\nslopes <- c(\"up\", \"flat\", \"down\")\n\npca$x[, 1:2] %>%\n as.data.frame() %>%\n mutate(class = slopes) %>%\n ggplot(aes(x = PC1, y = PC2)) +\n geom_point() +\n geom_label_repel(aes(label = class)) +\n coord_cartesian(\n xlim = c(-2.5, 2.5),\n ylim = c(-2.5, 2.5)\n ) +\n theme(aspect.ratio = 1) +\n theme_classic()\n```"]