["```py\n# Load the anime titles with genres, synopsis, producers, etc\n# there are 16,206 titles\npre_merged_anime = pd.read_csv('../data/anime/pre_merged_anime.csv')\n\n# Load the ratings given by users who have **completed** an anime\n# there are 57,633,278 ratings!\nrating_complete = pd.read_csv('../data/anime/rating_complete.csv')\n\nimport numpy as np\n\n# split the ratings into an 90/10 train/test split\nrating_complete_train, rating_complete_test = \\\n              np.split(rating_complete.sample(frac=1, random_state=42), \n                       [int(.9*len(rating_complete))])\n```", "```py\ngiven: user, k=3\npromoted_animes = all anime titles that the user gave a score of 9 or a 10\n\nrelevant_animes = []\nfor each promoted_anime in promoted_animes:\n    add k animes to relevant_animes with the highest cosine similiarty to promoted_anime along with the cosine score\n\n# relevant_animes should now have k * (however many animes were in promoted_animes)\n\n# Calculate a weighted score of each unique relevant anime given how many times it appears in the list and itâ€™s similarity to promoted animes\n\nfinal_relevant_animes = the top k animes with the highest weighted cosine/occurrence score\n```", "```py\nfinal_relevant_animes = {\n  'text-embedding-ada-002': { '6351': 0.921, '1723': 0.908, '2167': 0.905 },\n  'paraphrase-distilroberta-base-v1': { '17835': 0.594, '33970': 0.589,  '1723': 0.586 }\n}\n```", "```py\ndef clean_text(text):\n    # Remove non-printable characters\n    text = ''.join(filter(lambda x: x in string.printable, text))\n    # Replace multiple whitespace characters with a single space\n    text = re.sub(r'\\s{2,}', ' ', text).strip()\n    return text.strip()\n\ndef get_anime_description(anime_row):\n    \"\"\"\n    Generates a custom description for an anime title based on various features from the input data.\n\n    :param anime_row: A row from the MyAnimeList dataset containing relevant anime information.\n    :return: A formatted string containing a custom description of the anime.\n    \"\"\"\n\n...\n    description = (\n        f\"{anime_row['Name']} is a {anime_type}.\\n\"\n... #  NOTE I omitting over a dozen other rows here for brevity\n        f\"Its genres are {anime_row['Genres']}\\n\"\n    )\n    return clean_text(description)\n\n# Create a new column in our merged anime dataframe for our new descriptions\npre_merged_anime['generated_description'] = pre_merged_anime.apply(get_anime_description, axis=1)\n```", "```py\nfrom sentence_transformers import SentenceTransformer\n\n# Load a pre-trained SBERT model\nmodel = SentenceTransformer('paraphrase-distilroberta-base-v1')\nmodel.max_seq_length = 384     # Truncate long documents to 384 tokens\nmodel\n```", "```py\n# Create a DataLoader for the examples\ntrain_dataloader = DataLoader(\n    train_examples,\n    batch_size=16,\n    shuffle=True\n)\n\n...\n\n# Create a DataLoader for the validation examples\nval_dataloader = DataLoader(\n    all_examples_val,\n    batch_size=16,\n    shuffle=True\n)\n\n# Use the CosineSimilarityLoss from Sentence Transformers\nloss = losses.CosineSimilarityLoss(model=model)\n\n# Set the number of epochs for training\nnum_epochs = 5\n\n# Calculate warmup steps using 10% of the training data\nwarmup_steps = int(len(train_dataloader) * num_epochs * 0.1)\n\n# Create the evaluator using validation data\nevaluator = evaluation.EmbeddingSimilarityEvaluator(\n    val_sentences1,  # List of first anime descriptions in each pair from validation data\n    val_sentences2,  # List of second anime descriptions in each pair from validation data\n    val_scores       # List of corresponding cosine similarity labels for validation data\n)\n\n# get initial metrics\nmodel.evaluate(evaluator)  # initial embedding similarity score: **0.0202**\n\n# Configure the training process\nmodel.fit(\n    # Set the training objective with the train dataloader and loss function\n    train_objectives=[(train_dataloader, loss)],\n    epochs=num_epochs,  # set the number of epochs\n    warmup_steps=warmup_steps,  # Set the warmup steps\n    evaluator=evaluator,  # Set the evaluator for validation during training\n    output_path=\"anime_encoder\"  # Set the output path for saving the fine-tuned model\n)\n\n# get final metrics\nmodel.evaluate(evaluator)  # final embedding similarity score:   **0.8628**\n```"]