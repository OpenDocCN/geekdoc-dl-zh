["```py\n`import  os from  openai  import OpenAI import  sys from  dotenv  import load_dotenv, find_dotenv  # Add the path to access project modules sys.path.append('../..')  # Load environment variables from the .env file load_dotenv(find_dotenv())  # Initialize the OpenAI client using environment variables client = OpenAI()` \n```", "```py\n`from  langchain.text_splitter  import CharacterTextSplitter  # Define chunk size and overlap for splitting chunk_size = 26 chunk_overlap = 4  # Initialize a CharacterTextSplitter character_text_splitter = CharacterTextSplitter(     chunk_size=chunk_size,     chunk_overlap=chunk_overlap )` \n```", "```py\n`from  langchain.text_splitter  import RecursiveCharacterTextSplitter  # Initialize a RecursiveCharacterTextSplitter recursive_character_text_splitter = RecursiveCharacterTextSplitter(     chunk_size=chunk_size,     chunk_overlap=chunk_overlap )` \n```", "```py\n`# A simple alphabet string example alphabet_text = 'abcdefghijklmnopqrstuvwxyz'  # Try splitting the alphabet string with both splitters recursive_character_text_splitter.split_text(alphabet_text) character_text_splitter.split_text(alphabet_text, separator=' ')` \n```", "```py\n`# A class that splits text into chunks based on character count. class  CharacterTextSplitter:     def  __init__(self, chunk_size, chunk_overlap=0):   \"\"\"  Initialize the splitter with the given chunk size and overlap.   Args:  - chunk_size: Number of characters each chunk should contain.  - chunk_overlap: Number of characters to overlap between neighboring chunks.  \"\"\"         self.chunk_size = chunk_size         self.chunk_overlap = chunk_overlap      def  split_text(self, text):   \"\"\"  Split the given text into chunks according to the configured size and overlap.   Args:  - text: The string to split.   Returns:  A list of text chunks.  \"\"\"         chunks = []         start_index = 0          # Continue splitting until the end of the text is reached.         while start_index < len(text):             end_index = start_index + self.chunk_size             chunks.append(text[start_index:end_index])             # Advance start index for the next chunk accounting for overlap.             start_index = end_index - self.chunk_overlap         return chunks  # Extend CharacterTextSplitter with recursive splitting capabilities. class  RecursiveCharacterTextSplitter(CharacterTextSplitter):     def  split_text(self, text, max_depth=10, current_depth=0):   \"\"\"  Recursively split text into smaller chunks until each chunk is below the  size threshold or the maximum recursion depth is reached.   Args:  - text: The string to split.  - max_depth: Maximum recursion depth to prevent infinite recursion.  - current_depth: Current recursion depth.   Returns:  A list of text chunks.  \"\"\"         # Base case: if max depth reached or text already below threshold, return as-is.         if current_depth == max_depth or len(text) <= self.chunk_size:             return [text]         else:             # Split into two halves and recurse on each.             mid_point = len(text) // 2             first_half = text[:mid_point]             second_half = text[mid_point:]             return self.split_text(first_half, max_depth, current_depth + 1) + \\                    self.split_text(second_half, max_depth, current_depth + 1)  # Example usage of the above classes:  # Define chunk size and overlap for splitting. chunk_size = 26 chunk_overlap = 4  # Initialize the CharacterTextSplitter with the specified size and overlap. character_text_splitter = CharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)  # Initialize the RecursiveCharacterTextSplitter with the specified size. recursive_character_text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size)  # Example text to split. alphabet_text = 'abcdefghijklmnopqrstuvwxyz'  # Use both splitters and store results. recursive_chunks = recursive_character_text_splitter.split_text(alphabet_text) simple_chunks = character_text_splitter.split_text(alphabet_text)  # Print results from the recursive splitter. print(\"Recursive splitter chunks:\") for chunk in recursive_chunks:     print(chunk)  # Print results from the simple splitter. print(\"\\nSimple splitter chunks:\") for chunk in simple_chunks:     print(chunk)` \n```", "```py\n`# A sample complex text complex_text = \"\"\"When writing documents, writers will use document structure to group content... Sentences have a period at the end, but also, have a space.\"\"\"  # Apply recursive splitting with configured chunk size and separators recursive_character_text_splitter = RecursiveCharacterTextSplitter(     chunk_size=450,     chunk_overlap=0,      separators=[\"\\n\\n\", \"\\n\", \" \", \"\"] ) recursive_character_text_splitter.split_text(complex_text)` \n```", "```py\n`from  langchain.text_splitter  import TokenTextSplitter  # Initialize a TokenTextSplitter token_text_splitter = TokenTextSplitter(chunk_size=10, chunk_overlap=0)  # Split document pages by tokens document_chunks_by_tokens = token_text_splitter.split_documents(pages)` \n```", "```py\n`from  langchain.text_splitter  import MarkdownHeaderTextSplitter  # Define the headings to split on in a Markdown document markdown_headers = [     (\"#\", \"Header 1\"),     (\"##\", \"Header 2\"), ]  # Initialize a MarkdownHeaderTextSplitter markdown_header_text_splitter = MarkdownHeaderTextSplitter(     headers_to_split_on=markdown_headers )  # Split a real Markdown document while preserving heading metadata markdown_document_splits = markdown_header_text_splitter.split_text(markdown_document_content)` \n```"]