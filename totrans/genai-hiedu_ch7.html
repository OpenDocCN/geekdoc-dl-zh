<?xml version="1.0" encoding="utf-8"?><!DOCTYPE html []>
<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops" xml:lang="en" lang="en">
<head>
<title>7 The Future of Artificial Intelligence in Education</title>
<link rel="stylesheet" type="text/css" href="template.css"/></head>
<body epub:type="bodymatter">
<section epub:type="chapter" role="doc-chapter">
<header>
<h1 id="h1"><span epub:type="pagebreak" id="p240" aria-label=" page 240. " role="doc-pagebreak"/><span class="chnum" epub:type="ordinal">7 </span><span class="chtitle">The Future of Artificial Intelligence in Education</span></h1>
<p class="doi">DOI: <a href="https://dx.doi.org/10.4324/9781003459026-7" aria-label="D.O.I. link to this document.">10.4324/9781003459026-7</a></p></header>
<blockquote epub:type="epigraph" role="doc-epigraph">
<p>For most events that will unfold in the world, we speculate that AI won&#x2019;t be able to predict the future any better than humans, and that is an important thing to remember.</p>
<p class="byLine"><span epub:type="credit" role="doc-credit">Tom Colloton</span></p></blockquote>
<section epub:type="introduction" role="doc-introduction">
<h2 id="sec7_1"><span epub:type="ordinal">7.1 </span>Introduction</h2>
<p>Throughout this book, we have discussed AI in education and Generative AI (GenAI), providing an overview of its history and details of the technology. We have presented the need for AI literacy and how GenAI can influence curriculum design, assessment, and educational policy. We have provided frameworks for defining and guiding changes in these areas with the goal of ensuring that desired outcomes are best achieved. We have also provided insight into why GenAI has reached a point where it will have a transformative impact on education, as well as how educational institutions and policymakers should respond.</p>
<p>In this chapter, we speculate about what the future might hold. We look at the broader picture of social norms as well as the roles and positions of governments, employers, and AI product companies, to help guide our perspective. We recap the changes that have already taken place both within and outside of education. Finally, we look at the future for educational institutions and how the broader picture will influence the adoption of this technology in education.</p></section>
<section aria-labelledby="sec7_2">
<h2 id="sec7_2"><span epub:type="ordinal">7.2 </span>Previous Technology Adoption</h2>
<p>Social norms influence our everyday behaviour. They can impact anything from the time that we eat to the clothes we wear, or to the use of our mobile phones. A society cannot function successfully for long without such social norms influencing individual behaviour, and in turn facilitating cohesion and order (<a href="#ref7_20" id="R_ref7_20" epub:type="biblioref" role="doc-biblioref">Rachlinski, 2000</a>). By examining the adoption of previous innovations in society, we may be able to uncover a model for how AI and GenAI adoption could be similarly influenced by, or even reshape, our social norms.</p>
<p>If we look back at the adoption of the personal computer (PC) in the 1980s and 1990s, it was initially a small, yet sizeable group of people who were the early users (yes, the nerds!). It was not until much later that such adoption increased. One could argue that PCs were initially not hugely useful to the average person until after the Internet reached a point where it catered to a sufficiently broad set of interests. In the early days of the PC, playing computer games and writing simple software were not yet of interest to the majority; moreover, the widespread need for tools like spreadsheets and word processors only arose when <span epub:type="pagebreak" id="p241" aria-label=" page 241. " role="doc-pagebreak"/>they reached a relatively high level of regular use among the general population. This was assisted, or perhaps driven, by the need for these tools and related skills in the work environment. Eventually, they also became a necessity in the educational system. How many people submitted handwritten reports in the 1990s for their degree courses, compared to the current number of people submitting reports in this format?</p>
<p>In 2019, around 47% of households worldwide were reported to have a computer (<a href="#ref7_22" id="R_ref7_22" epub:type="biblioref" role="doc-biblioref">Statista PCs, 2019</a>); this may not seem like a very large percentage, but it was possibly impacted by the introduction of smartphones. According to Statista, in 2020, 78% of the world&#x2019;s population owned a smartphone; in 2016, it was less than half (<a href="#ref7_21" id="R_ref7_21" epub:type="biblioref" role="doc-biblioref">Statista Mobiles, 2019</a>). Here, we see a much more rapid and broader adoption of smartphones by people across the socio-economic landscape. The rise of smartphones has been, in part, due to their usefulness, personal nature, handheld-sized convenience akin to having a PC in your pocket, and the huge variety of options available in terms of cost and style.</p></section>
<section aria-labelledby="sec7_3">
<h2 id="sec7_3"><span epub:type="ordinal">7.3 </span>Predictions on General GenAI Implications</h2>
<p>GenAI adoption will be impacted by how it is generally used in the broader society. At the moment, GenAI is at the beginning of its lifecycle, but there are already significant segments of the population that are embracing and using this technology, from professionals and technology enthusiasts, all the way to kids.</p>
<section aria-labelledby="sec7_3_1">
<h3 id="sec7_3_1"><span epub:type="ordinal">7.3.1 </span>GenAI Adoption by General Population</h3>
<p>Unlike the initially slow uptake of PCs, which had to be supplemented by software like spreadsheets to appeal to businesses, and fast Internet connections to appeal to the wider public, GenAI stands out for its immediate readiness for use without the necessity for additional tools or technologies. However, despite its broad array of capabilities, <b>we predict</b> that GenAI won&#x2019;t resonate with as wide a proportion of society as mobile phones and smartphone technology have. <b>We predict</b> that the primary users of AI will be the more educated members of society, regardless of their economic backgrounds, with a significant proportion being younger individuals. Still, <b>we predict</b> GenAI will be rapidly adopted by society, spanning most social and economic groups, and also expect that a wide variety of useful GenAI tools will be available and accessible (e.g., at zero or low cost options). <b>We predict</b> that there will be a high diversity of GenAI offerings, including chatbots, personal assistants, and a seamless integration of GenAI into word processing and text editors similar to how spell or grammar checkers are now integrated into these tools. With this broad range of applications, <b>we also predict</b> that it will be challenging to accurately measure the usage, availability, and penetration of GenAI.</p></section>
<section aria-labelledby="sec7_3_2">
<h3 id="sec7_3_2"><span epub:type="ordinal">7.3.2 </span>Job Impact</h3>
<p>Numerous predictions have been made regarding the impact of AI and GenAI on the job market, as illustrated by a report from Goldman Sachs (<a href="#ref7_3" id="R_ref7_3" epub:type="biblioref" role="doc-biblioref">Briggs &#x0026; Kodnani, 2023a</a>). This has been highlighted in numerous news headlines, with Forbes stating that &#x201C;Goldman Sachs predicts 300 million jobs will be lost or degraded by artificial intelligence&#x201D; (<a href="#ref7_12" id="R_ref7_12" epub:type="biblioref" role="doc-biblioref">Kelly, 2023</a>). Conversely, another headline for an article about the same Goldman Sachs report read, &#x201C;Generative AI could raise global GDP by 7%&#x201D; (<a href="#ref7_4" id="R_ref7_4" epub:type="biblioref" role="doc-biblioref">Briggs &#x0026; Kodnani, 2023b</a>). This exemplifies how news media can spin the same information to create either positive or <span epub:type="pagebreak" id="p242" aria-label=" page 242. " role="doc-pagebreak"/>negative impressions among their audiences. <b>We predict</b> that significant &#x2018;drama&#x2019; will unfold regarding the impact of AI, particularly on jobs and the job market.</p>
<p>Certain companies and even entire specific industries will experience these impacts more intensely. For instance, Stack Overflow &#x2013; a site dedicated to supporting software development professionals &#x2013; announced a layoff of up to 28% of their staff in the latter half of 2023 (<a href="#ref7_9" id="R_ref7_9" epub:type="biblioref" role="doc-biblioref">Davis, 2023</a>). Concurrently, they unveiled their own AI offering (<a href="#ref7_6" id="R_ref7_6" epub:type="biblioref" role="doc-biblioref">Chandrasekar, 2023</a>) and a plan to charge AI companies for data usage (<a href="#ref7_8" id="R_ref7_8" epub:type="biblioref" role="doc-biblioref">Dave, 2023</a>). While the layoffs may appear sudden and extreme, it is worth noting that Stack Overflow had conducted a significant hiring round about 12 months prior; at that time, many other tech companies were reducing staff numbers due to the general economic climate. Thus, not all these staff losses can be directly attributed to GenAI.</p>
<p>The Goldman Sachs report estimated that AI automation would impact work tasks in numerous sectors across the US and Europe, affecting 46% of work in the Office and Administrative Support sector, 44% of Legal, 37% of Architecture and Engineering, and 36% of the Life, Physical, and Social Science areas (<a href="#ref7_3" epub:type="biblioref" role="doc-biblioref">Briggs &#x0026; Kodnani, 2023a</a>). The report also emphasised that AI technologies still require human intervention and guidance, indicating that not all roles within these sectors would be affected equally. It pointed out that work capable of being automated by AI would be more prevalent in developed markets than in emerging ones, with Japan, Israel, and Hong Kong being the most highly impacted. The report further underscored that any new jobs created would constitute the bulk of employment growth during such a transition into greater automation of tasks. For instance, of the current US employment rate, only 40% are in occupations that have existed since 1940, while 60% are in occupations that emerged thereafter.</p>
<p>The reality is that GenAI currently serves more as an assistance tool, enabling individuals to perform their jobs more efficiently. GenAI still requires human intervention for direction, purpose, and to drive it towards useful, helpful, and productive outcomes. This can be taken to mean that the rise of GenAI will not necessarily jeopardise anyone&#x2019;s jobs &#x2013; only the individual working that job, who will need to keep up to date with the necessary skills and knowledge to best leverage GenAI for their work &#x2013; and that, overall, it will likely be perceived to have a positive impact. It could mean that companies, whose employees have already begun to use GenAI to assist with their responsibilities, will not need to hire extra people for a new project as the existing team &#x2013; with the help of GenAI &#x2013; can manage the additional workload.</p>
<p>As such, <b>our prediction</b> is that any negative impacts on employment will neither slow nor significantly affect GenAI adoption. <b>We also predict</b> that GenAI will impact roles in the knowledge-based economy more than, say, manual labour-based roles, and that those in these knowledge-based jobs are more likely to be the early users of GenAI. This results in the impacted workforce being in a better position, due to their relatively high level of education, to adapt to the new reality more than ever before. These changes will be hard to measure, and the impact on key job numbers will not be obvious, similar to the case of the &#x2018;The Great Attrition&#x2019; during the pandemic in the US (<a href="#ref7_10" id="R_ref7_10" epub:type="biblioref" role="doc-biblioref">Ellingrud et al., 2023</a>). <b>We predict</b> that, ultimately, there will be an increase in the number of people employed in the knowledge economy due to the additional roles, companies, and needs that currently do not even exist, growing vastly more than the consolidation that will happen on existing roles due to efficiencies allowed by AI. <b>We also predict</b> that the knowledge economy of the future will involve a much stronger mix of holistic competencies together with knowledge skills than previously.</p>
<p><span epub:type="pagebreak" id="p243" aria-label=" page 243. " role="doc-pagebreak"/>Currently, many industries are embracing GenAI, from software development companies to legal services firms. Their adoption of this technology is happening rapidly, especially in smaller organisations. Larger organisations, on the other hand, are proceeding more cautiously due to concerns surrounding commercial privacy, trust, and risk. They need to understand the legal risks and potential liabilities given the novelty of this technology and the areas of law that it may touch. For example, could they, through their use of GenAI models, potentially have liabilities due to copyright issues arising from how the model is trained by its developers (e.g., the copyright issue of using Harry Potter works by OpenAI in their products; <a href="#ref7_25" id="R_ref7_25" epub:type="biblioref" role="doc-biblioref">Usman, 2023</a>)? Still, despite the slower pace of integration among larger organisations, it seems that their full embracing of GenAI will just be a matter of time. This could be expedited if AI product companies address enterprise concerns with specific offerings that cater to their risk appetite, or if these enterprises become more comfortable with the risks involved, drawing from their previous experiences with technologies like cloud computing or outsourcing services.</p>
<p><b>We predict</b> that the rising trend of GenAI adoption in the corporate world will continue, with the use of AI and GenAI becoming an expected skill and capability for a broad variety of roles within organisations. It may even become a fundamental and widely required competence, akin to how essential basic computer skills are nowadays, and eventually become a set of skills that people are presumed to have by the time they enter the workplace. Until that point, it is likely that job descriptions will continue to specify the experience and proficiency expected for specific roles, with regard to particular GenAI tools and uses. In smaller organisations and start-ups, these key expectations may be more pronounced. This shift in skills requirements will not only affect the employment of new graduates, but also impact existing job roles at all levels. As such, <b>we predict</b> a change in expectations for individuals filling roles, especially within the knowledge economy, as they begin to integrate GenAI into their work; moreover, while they will become more capable, less manpower will be needed over time for existing role types and the skill mix for those roles will evolve, for example, with a greater emphasis on holistic competencies such as teamwork, leadership skills, critical thinking. Different and new types of roles will also emerge, such as &#x2018;AI Engineers&#x2019;, &#x2018;Head of Conversational AI&#x2019;, &#x2018;AI Ethicists&#x2019;, &#x2018;Human&#x2013;Machines Teaming Manager&#x2019;, &#x2018;Digital Detox Therapist&#x2019;, &#x2018;AI Personality Designers&#x2019;, &#x2018;AI Dating Assistants&#x2019;, and &#x2018;Responsible AI Content Safety Managers&#x2019;. These anticipated titles prompt us to think about how existing roles may evolve, as well as how new roles that were never considered before will come into existence.</p>
<p><b>We also predict</b> a scenario within organisations where employees who embrace AI and GenAI technologies will demonstrate and assert their adaptability to the evolving technological landscape, thus increasing their likelihood of long-term job retention. Newly created roles will have inherent expectations for proficiency in AI and GenAI; this shift will enable organisations to adjust their staffing profiles accordingly, to fully leverage the enhanced productivity and competencies of their AI and GenAI-empowered employees.</p></section>
<section aria-labelledby="sec7_3_3">
<h3 id="sec7_3_3"><span epub:type="ordinal">7.3.3 </span>AI Safety Impact &#x2013; Adoption</h3>
<p>People now know more about data privacy issues due to the rise of big data leaks, such as at Yahoo in 2013 where 3 billion accounts were affected (<a href="#ref7_1" id="R_ref7_1" epub:type="biblioref" role="doc-biblioref">BBC, 2017</a>). Similarly, LinkedIn had a data leak in 2021 affecting 700 million accounts (<a href="#ref7_23" id="R_ref7_23" epub:type="biblioref" role="doc-biblioref">Taylor, 2021</a>), and <span epub:type="pagebreak" id="p244" aria-label=" page 244. " role="doc-pagebreak"/>Facebook had one in 2019 affecting 533 million accounts (<a href="#ref7_27" id="R_ref7_27" epub:type="biblioref" role="doc-biblioref">Wong, 2021</a>). Despite such leaks and the Facebook&#x2013;Cambridge Analytica scandal, where user data was shared without permission and used in controversial ways during the 2016 US presidential election (<a href="#ref7_26" id="R_ref7_26" epub:type="biblioref" role="doc-biblioref">Wong, 2019</a>), people still continue to use these platforms and share their personal information online.</p>
<p>There may be a point where people will say that enough is enough with the sharing or misuse of their data, but right now, it does not seem like we are there yet. Concerns with data safety and privacy could be a wild card that might affect how people use and interact with GenAI, but it might also only affect the kind of GenAI they choose to use, perhaps shaping a preference for embedded personalised GenAI assistants on smartphones that does not pass any personal details over the network.</p>
<p>It is likely that, at first, people will trust the information that GenAI provides them, even on controversial topics. It is in the interest of AI developer and product companies to have high adoption rates and appeal to as many people as possible, across all walks of life. Much effort has been, and will continue to be, put into measuring people&#x2019;s acceptance and use of AI products and services. This acceptance and use of AI can also be taken into account when measuring AI safety, or as a simple proxy measure for the appropriateness of AI alignment, the more people accepting it or using it the better the AI alignment. This may very well hide the complexities of the situation such as competitive pressures driving people to use the technology regardless of alignment or acceptance at an individual level.</p>
<p><b>We predict</b> that even with concerns like privacy and data security, people will still continue to use AI technologies, though some will look to AI platforms, tools, and offerings that provide much higher guarantees regarding safeguards to the above issues.</p></section>
<section aria-labelledby="sec7_3_4">
<h3 id="sec7_3_4"><span epub:type="ordinal">7.3.4 </span>AI Safety Impact &#x2013; Post-Adoption</h3>
<p>Examining AI safety is crucial not only during the initial adoption phase, but also after its integration into society. This is because there will be a shift in the motivations of AI product companies once their products attain a substantial user base. As AI gains widespread trust and usage, entities such as corporations and governmental bodies may attempt to leverage AI to influence public opinion. This manipulation could stem from various motives, such as altering societal norms or pursuing financial gains. Here are two examples to explain this better:</p>
<aside epub:type="tip" role="doc-tip" class="box ruled">
<h3 id="box7_1">Example 1</h3>
<ul class="disc">
<li><b>Question:</b> A user asks an AI for suggestions on the best phones to buy within a certain budget.</li>
<li><b>Answer:</b> The AI provides a list of phones, but only includes brands that have paid fees to promote their products to the AI&#x2019;s development company.</li>
<li><b>Issue:</b> The user is unaware that there are other good options available within their budget from brands that didn&#x2019;t pay for promotion. The AI&#x2019;s suggestion is biased, but the user might still trust it because they don&#x2019;t know about the behind-the-scenes deals.</li></ul></aside>
<aside epub:type="tip" role="doc-tip" class="box ruled">
<h3 id="box7_2"><span epub:type="pagebreak" id="p245" aria-label=" page 245. " role="doc-pagebreak"/>Example 2</h3>
<ul class="disc">
<li><b>Question:</b> A user asks an AI for information about recycling centres in their area.</li>
<li><b>Answer:</b> The AI only provides information about government-approved recycling centres and omits some local, privately-run centres.</li>
<li><b>Issue:</b> The AI&#x2019;s response is skewed towards official government resources, which may not always be in the best interests of the user who may be looking for all available options. The user might miss out on closer or better privately-run centres because the AI didn&#x2019;t provide complete information.</li></ul></aside>
<p>The provided examples, though hypothetical and crafted for illustrative purposes, reflect genuine concerns observed with existing search engine technology and social media platforms, where certain results are downplayed due to undisclosed influences like political or financial factors. The detection of such biases will pose significant challenges for the general population. Once enough people start using AI, the goals of companies that develop AI products may change. Moreover, people may find it hard to switch to different AI products even if they are aware of problems with the one they are currently using. Such situations are a real threat of AI, and more realistic than hypothetical scenarios like the &#x2018;Skynet Judgment Day&#x2019; from <i>The Terminator</i>.</p>
<p><b>We predict</b> that AI safety and AI alignment will only be viewed differently in the future and only be taken much more seriously by the public when the negative impacts become widespread and difficult to resolve.</p></section>
<section aria-labelledby="sec7_3_5">
<h3 id="sec7_3_5"><span epub:type="ordinal">7.3.5 </span>Impact from Governments</h3>
<p>The availability of the GenAI tools within specific geographical regions, for commercial, geopolitical, or even reasons due to local legal requirements, will have an impact on how GenAI will be adopted. For example, similar to the way that technologies like cryptocurrencies have been banned or highly restricted in many jurisdictions, if a country prohibits the use of these technologies, it will impact the assimilation of said technology in that region or area.</p>
<p>It is clear that AI is currently viewed as something that will provide a competitive advantage across the national, regional, and geopolitical levels. It is thus unlikely that most governments will introduce complete restrictions on AI and related technologies. However, given the very different set of approaches employed around the world, the guardrails being provided will have varying impacts on the types and speeds of AI development.</p>
<p><a href="ch5.xhtml">Chapter 5</a> described some of the completed and in-progress work in relation to governmental policies for AI, providing an overview of the different approaches undertaken. In China, the focus has been on national security; in the EU, the focus has been on a risk-based approach; meanwhile, the US is currently taking a much more laissez-faire approach. In a more laissez-faire regime, for example, you would expect a greater mix of commercial approaches, as well as a wide range of industries choosing to utilise AI and variations in the extent to which they do so. However, for a risk-based approach, you would expect little development of AI in high-risk categories where it is highly regulated or not allowed, such as toys, aviation, cars, medical devices, and lifts; or you would expect the cost of the technology in these areas to be significantly more expensive due to the regulatory overhead.</p>
<p><b><span epub:type="pagebreak" id="p246" aria-label=" page 246. " role="doc-pagebreak"/>We predict</b> that regulation will be highly varied and that the impacts of this will be difficult to predict, especially given the connectedness of the global economy. However, the adoption of AI and GenAI, in particular, will not be significantly impacted, nor will the speeds of their technological advancements. It is likely that regulation will be highly adaptive in trying to balance the potential benefits and risks of the technology with other considerations, including the geopolitical situation, and competitiveness at national and regional levels.</p>
<p><b>We predict</b> that future regulations and policies will not address issues related to how AI is trained, such as the selection or vetting of training datasets, how filtering is guided, and how AI makes decisions in terms of the underlying algorithms. The actual regulations and policies introduced will not help to address the portability concerns that would otherwise enable users to easily switch between different AI products. In addition, the introduced regulations and policies will not be able to prevent a few big players from controlling the whole industry. Once those big players are established, <b>we predict</b> that policymakers and these big players will intensely resist any attempts to alter their centralised control.</p></section>
<section aria-labelledby="sec7_3_6">
<h3 id="sec7_3_6"><span epub:type="ordinal">7.3.6 </span>AI Development Companies</h3>
<p>Companies including OpenAI, Microsoft, Meta, Alphabet/Google, and Anthropic are at the forefront of creating and developing AI and GenAI technologies. There is a clear demand for what they offer, yet there is still untapped potential for more personalised GenAI applications and open source AI models. Emerging companies like Tiny Corp and Mistral AI are stepping in to address these areas. The competition in this sector is fierce, with new players, including Mistral AI, gaining considerable momentum within short periods of time (<a href="#ref7_2" id="R_ref7_2" epub:type="biblioref" role="doc-biblioref">Bradshaw &#x0026; Abboud, 2023</a>), and established players like Meta revising their strategies towards more commercially open licences for their GenAI models (<a href="#ref7_15" id="R_ref7_15" epub:type="biblioref" role="doc-biblioref">Moreno, 2023</a>). It is also worth remembering that most of these services are currently offered in beta (Anthropic Claude), for research purposes only (OpenAI until about Feb 2023), as experiments (Google Bard), or for entertainment purposes only (Bing, as per its terms of use, section 9).</p>
<p>A significant hurdle that these companies face arises from legal challenges, particularly from owners of content that is used by AI developer and product companies to train their models. Numerous lawsuits have already been launched, including Case 1:23-cv-08292 filed in the District Court for the Southern District of New York on behalf of various authors alleging copyright infringement (<a href="#ref7_7" id="R_ref7_7" epub:type="biblioref" role="doc-biblioref">Creamer, 2023</a>). The outcome of such cases could be pivotal, potentially requiring retraining of AI models from scratch, let alone the financial repercussions. The latest news from some of the biggest players in AI development include their commitment to take responsibility and indemnity for the content generated by their AI products. Several companies are actively addressing the legal implications arising from the use of AI technologies, particularly concerning copyright infringements. Microsoft, for instance, has expressed its commitment to addressing legal concerns of its Copilot tool, aiming to provide clarity and confidence to users of this tool when generating code (<a href="#ref7_14" id="R_ref7_14" epub:type="biblioref" role="doc-biblioref">Microsoft, 2023</a>). Similarly, Adobe has taken a proactive stance by offering copyright indemnification for users of its Firefly AI-based image app, in order to protect users from potential legal claims related to copyright infringements (<a href="#ref7_11" id="R_ref7_11" epub:type="biblioref" role="doc-biblioref">Gold, 2023</a>). Google has also joined in by pledging to defend users of its GenAI technologies against copyright claims, thereby providing a safeguard while also promoting the responsible AI use (<a href="#ref7_5" id="R_ref7_5" epub:type="biblioref" role="doc-biblioref">Brittain, 2023</a>). These initiatives reflect the growing recognition among AI developers and product companies of the legal intricacies of AI use, and a collective move towards creating a more secure legal environment for users and developers alike.</p>
<p><span epub:type="pagebreak" id="p247" aria-label=" page 247. " role="doc-pagebreak"/>AI product companies have considerable influence on regulatory frameworks. They are also often consulted to ensure that proposed regulations are sensible and will not unduly hinder technological advancement and competitiveness. <b>We predict</b> that regulatory changes are unlikely to significantly impede the broader AI and GenAI industry.</p>
<p>AI developers and product providers are swiftly advancing their strategies to capture both market and mind share. At the same time, new companies are emerging at an accelerated pace thanks to substantial capital infusion from investors. These dynamics signify a diverse array of companies, business models, and funding, all of which will propel the advancement of AI and GenAI products for a period of time. In the past, some social media firms, for example, delayed their monetisation strategies until they have secured a significant market share; in contrast, the path to commercialisation for AI and GenAI companies appears to be more straightforward. They can initiate revenue generation early on through direct subscriptions, and later benefit from advertisers or other revenue streams that want to target these subscribers. <b>We predict</b> a continuous influx of funding into AI and GenAI developers and product providers, which will contribute to the continuous drive for technological advancements. This will initially result in innovation across many different companies and areas, but we will eventually see consolidation around a few key providers which will have amassed a very significant advantage in subscriber numbers.</p>
<p>The need for hardware and training data could be a challenge for these companies. However, such companies are actively working towards strategies to best use the resources they have, figuring out the right balance between model size and the amount of training data needed, and how the quality of data, the algorithms used, and the designs of AI models will impact hardware requirements and the usefulness of the developed model. While concerns about hardware availability may still be present, <b>we predict</b> it will not significantly slow down the growth of AI and GenAI products. Hardware and environmental concerns will likely prompt developers and product providers to engineer more efficient and potentially smaller models (compared to the current largest 1.8T models) for widespread use.</p>
<p><b>We predict</b> that AI and GenAI product companies will continue to grow and offer a wide range of products. Even though a few big players are expected to take the lead, we believe that some new and creative start-ups will later join the mainstream with their own unique offerings. Advancements in technology and the variety of products available will keep services affordable for most people, although there may be some trade-offs; for example, providers may require users to consent to the use of their customer data for future training purposes. Geopolitical factors will still influence the availability of services and the types of services offered in specific locations.</p></section></section>
<section aria-labelledby="sec7_4">
<h2 id="sec7_4"><span epub:type="ordinal">7.4 </span>Predictions on GenAI&#x2019;s Implications in Higher Education</h2>
<p>The following sections discuss our views on what the future may hold for higher educational institutions. AI and GenAI are not the first technologies with the potential for significant impact; calculators, PCs, the Internet, and, more recently, smartphones, have all had substantial influences. It is worth doing some reflection to better understand and establish the content relevant to the potential implications of AI and GenAI on education.</p>
<section aria-labelledby="sec7_4_1">
<h3 id="sec7_4_1"><span epub:type="ordinal">7.4.1 </span>Pedagogy and Assessment in Higher Education</h3>
<p>The wave of AI and GenAI technologies is not only transforming the operational landscape of various industries, but also &#x2013; as mentioned &#x2013; significantly impacting the expectations of <span epub:type="pagebreak" id="p248" aria-label=" page 248. " role="doc-pagebreak"/>employers for their prospective employees, especially those fresh out of university. Employers are likely to prioritise candidates who possess good foundational understanding and proficiency in using and applying these technologies. AI literacy, encompassing knowledge of the basics of AI, its applications, ethical implications, and the ability to interact with or even develop GenAI solutions, will become a desirable, if not essential, qualification for job applicants.</p>
<p>For university students, <b>we predict</b> that employers will seek candidates who are AI literate. Consequently, AI literacy training will be incorporated into the latter&#x2019;s undergraduate education. As the rising demand for AI literacy across the job market reverberates back to educational institutions, universities may feel the impetus to revise and update their curricula to include comprehensive AI and GenAI education, ensuring their students are well prepared and competitive in the job market after graduation. As such, <b>we predict</b> that universities will need to, and will, adapt accordingly to introduce these tools into their curricula. <b>We predict</b> that these changes will happen gradually; initially, this will be done on an ad-hoc, teacher-by-teacher basis with light integration, perhaps following earlier iterations of institutional policies regarding AI and GenAI. However, <b>we predict</b> that most institutions will fund and facilitate a broader approach towards the deeper integration of these technologies into programme curricula, though seeing the impact of this will take more time.</p>
<p>The potential impact of AI and GenAI on assessment within higher education also signifies a shift towards more technologically-driven, personalised, and innovative assessment strategies. However, the extent and nature of this change are likely to vary considerably across different institutions and regions, based on a myriad of factors, including institutional priorities, regulatory frameworks, and the societal acceptance of AI-driven educational practices.</p>
<p>The transition towards more authentic and innovative assessment approaches, as facilitated by GenAI, presents an intriguing opportunity. However, the extent to which we should embrace such new methodologies, and for institutions to identify what will be effective, practical, and feasible, are far from clear. Institutions may navigate this transition at different paces and with varying degrees of enthusiasm, largely influenced by local educational policies, societal acceptance, and the internal readiness for change. With this in mind, <b>we predict</b> that the changes to assessment will be highly varied between institutions as well as between regions. Some will make minimal changes as required and driven by social attitudes and the goal of upholding fairness. Some will revert back to proctored exams. Some will use this opportunity to make further institutional-wide changes and push towards more authentic, innovative, and GenAI-partnered assessment approaches as per the recommendations presented in this book.</p>
<p><b>We predict</b> that private higher education institutions will adopt these technologies in a more deliberate manner with a specific focus on incorporating them into their curriculum and assessments. They will position this to be a significant distinguisher between themselves and public institutions, especially in earlier stages of GenAI adoption across the sector. Moreover, they will experiment with the approaches used, particularly with assessment, and it will be interesting to see the results they achieve. We further believe that there is a significant probability that they will generate real, measurable benefits from these changes.</p>
<p><b>We also predict</b> that the institutions that demonstrate agility in introducing AI and GenAI into their curriculums and assessment methodologies will be best positioned to take advantage of the broader industry changes and advancements relating to these technologies. There will be a large cohort of the existing workforce looking to quickly prove their AI and GenAI skills, seeking to obtain certifications from suitable higher educational <span epub:type="pagebreak" id="p249" aria-label=" page 249. " role="doc-pagebreak"/>institutions as a way to demonstrate their ability and commitment to current and future employers. Astute institutions should seize the expanding wave of AI consumerism, proactively forging a path into this domain. By doing so, they can provide valuable opportunities for students to immerse in, and emerge proficient from, the AI-centric educational paradigm that will be increasingly demanded in the market.</p></section>
<section aria-labelledby="sec7_4_2">
<h3 id="sec7_4_2"><span epub:type="ordinal">7.4.2 </span>Research in Higher Education</h3>
<p>The advent of AI and GenAI significantly expands the resources available to postgraduate students, their supervisors, and examiners. Students can leverage these tools to act as advisors and mentors to enhance their understanding in their chosen research areas. They can employ GenAI to summarise papers, grasp key concepts, connect ideas with theories, and come to better understand how these theories relate to their own research. GenAI can also help students in the writing process, handling tasks including reference formatting, grammar, spelling, and enhancing clarity and academic writing styles. Supervisors, too, can utilise these tools to swiftly review research proposals or draft theses. Specialised AI or GenAI models can help look over research work in great detail, ensuring the appropriateness of methodological details, the accuracy and suitability of the data analyses used, and even the depth and insightfulness of analytical findings. Examiners and reviewers can similarly benefit as well, where GenAI can be used to examine thoroughness in literature reviews and assess the novelty of presented findings.</p>
<p>Overall, AI and GenAI enables everyone involved in research processes to save time, increase efficiency, and enhance the quality of their work. The adoption and extent of GenAI utilisation will largely depend on institutional policies concerning such technology. <b>We predict</b> that higher education institutions will move towards giving strong support for GenAI adoption and work to implement measures to uphold academic integrity, such as by requiring declarations of GenAI use and promoting users&#x2019; self-regulation using an honour system. <b>We predict</b> that institutions resistant to this will likely face significant pressure from all stakeholders to take action, potentially impacting their ability to attract research candidates if the institution is perceived as lagging behind in modern research approaches. <b>We predict</b> that there may be interesting challenges for supervisors and institutions to achieve cross-institutional consistency. This may lead to regional or specific agreements made between certain groups of institutions in order to establish consistency and an interoperable set of policies that allow for easier cross-institution collaboration.</p></section>
<section aria-labelledby="sec7_4_3">
<h3 id="sec7_4_3"><span epub:type="ordinal">7.4.3 </span>Drafting Funding Proposals</h3>
<p>Just as with research, AI and GenAI can substantially aid in the process of drafting grant applications. <a href="#ref7_19" id="R_ref7_19" epub:type="biblioref" role="doc-biblioref">Parrilla (2023)</a> provides an overview of the process, highlighting how GenAI can drastically cut down on the workload that is otherwise cumbersome for all parties involved in writing and reviewing the proposal. In his article, Parrilla contemplates whether grant proposal systems can be simplified by eliminating certain components from the proposal content, thereby reducing the chances of exploiting GenAI to write these sections. However, considering that most grant funds come from public resources or charitable organisations, transparency and auditability remain crucial, even many years after the completion of the proposed and undertaken research.</p>
<p>As GenAI can also assist grant reviewers in addressing critical queries such as the novelty of the application and the credentials of the Primary Investigator (PI), <b>we predict</b> that <span epub:type="pagebreak" id="p250" aria-label=" page 250. " role="doc-pagebreak"/>GenAI will not simplify the grant application process itself, but instead will enhance the quality and efficiency of the process for both the PIs and the reviewers.</p></section>
<section aria-labelledby="sec7_4_4">
<h3 id="sec7_4_4"><span epub:type="ordinal">7.4.4 </span>Submitting and Reviewing Journal Articles</h3>
<p>Different journals have adopted varying standards in relation to GenAI use and attribution. For example, Nature (<a href="#ref7_16" id="R_ref7_16" epub:type="biblioref" role="doc-biblioref">Nature Editorial, 2023a</a>; <a href="#ref7_17" id="R_ref7_17" epub:type="biblioref" role="doc-biblioref">Nature Editorial, 2023b</a>; <a href="#ref7_18" id="R_ref7_18" epub:type="biblioref" role="doc-biblioref">Nature Portfolio, 2023</a>) permits text generation under certain conditions while disallowing image and video generation. When generating text, how the tool was used to do so must be well-documented and all sources must be accurately cited. Moreover, they do not permit listing the GenAI tool as an author or co-author of the article or paper, as authors have specified responsibilities and declarations to make, which the tool cannot fulfil or perform.</p>
<p>The Lancet (<a href="#ref7_24" id="R_ref7_24" epub:type="biblioref" role="doc-biblioref">The Lancet Microbe, 2023</a>), on the other hand, restricts authors&#x2019; GenAI usage to only &#x201C;improving the readability and language of the work&#x201D; without substituting researcher tasks, including producing scientific insights, analysing and interpreting data, and drawing scientific conclusions. The author(s) must assume ultimate responsibility and disclose any use of AI or AI-assisted technologies in their work. Many other journals have not yet established specific, formal policies regarding the appropriate and admissible use of GenAI technologies.</p>
<p>Given the benefits of GenAI for researchers and academics, as well as the emergence of increasingly specialised AI tools and models for academic purposes, <b>we predict</b> a rise in GenAI usage, leading to pressure to permit their use. This, in turn, will prompt the expansion of journal criteria to outline when it is necessary to declare the usage of these technologies. <b>We predict</b> that these tools will be highly utilised by authors, editors, and reviewers alike, potentially aiding a shift from emphasis on traditional, peer-reviewed, and high-impact factor journals to alternative solutions that provide and measure real impacts in research. These alternative solutions are likely to better align with objectives to achieve greater transparency and openness in the review process, moving towards an approach that emphasises more on scientific validation, impact, and reproducibility, as opposed to the current focus on peer opinions.</p>
<p><b>We predict</b> that the transition from peer review to reviews for transparency and scientific validation will occur in phases, with a clear threshold likely to be seen when a more significant shift takes place. This moment may be triggered by the release of a specialised AI or GenAI model developed for research and academic purposes, with capabilities substantially surpassing its predecessors. A scenario could arise where new AI or GenAI models are capable of identifying validity issues in existing peer-reviewed publications that have thus far been held as correct, using them to then invalidate other findings.</p>
<p>Furthermore, <b>we predict</b> that AI and GenAI capabilities will create more groundbreaking discoveries, AI and GenAI have great potential to fast-track research discoveries.</p></section></section>
<section aria-labelledby="sec7_5">
<h2 id="sec7_5"><span epub:type="ordinal">7.5 </span>Can AI or GenAI Predict the Future?</h2>
<p>Having provided our predications in the previous sections, we now ask the question: How well can an LLM &#x2013; a tool that predicts the next words/tokens &#x2013; do in predicting the future?</p>
<section aria-labelledby="sec7_5_1">
<h3 id="sec7_5_1"><span epub:type="pagebreak" id="p251" aria-label=" page 251. " role="doc-pagebreak"/><span epub:type="ordinal">7.5.1 </span>What did OpenAI ChatGPT Say?</h3>
<table id="tableu7_1">
<thead>
<tr>
<th scope="col" class="center">User</th>
<th scope="col" class="left">Can you give me a few predictions about how GenAI will impact Education over the next 5 to 10 years?</th></tr></thead>
<tbody>
<tr>
<td class="center">OpenAI ChatGPT GPT-4</td>
<td class="left">Certainly. While I cannot predict the future with certainty, based on current trends and the potential of generalised artificial intelligence (GenAI) technology, I can make some educated speculations. Here are a few predictions regarding the impact of GenAI on education over the next 5 to 10 years:
<ol type="1">
<li><b>Personalised Learning</b>: GenAI systems can adapt to individual student needs, learning styles, and paces. This could allow for a more personalised educational experience where content is delivered based on the student&#x2019;s current understanding and preferences. For instance, if a student struggles with algebra but excels in geometry, the AI could tailor lessons accordingly.</li>
<li><b>Virtual Teaching Assistants</b>: GenAI might serve as teaching assistants, helping to answer student questions, grade assignments with immediate feedback, and even manage administrative tasks for teachers. These virtual assistants can be available 24/7, providing support outside of traditional classroom hours.</li>
<li><b>Interactive Simulations</b>: GenAI can help in creating dynamic and realistic simulations for complex subjects. For instance, biology students could explore a virtual cell, while history students could experience historical events firsthand. This immersive learning could lead to a deeper understanding of subjects.</li>
<li><b>Global Classrooms</b>: With AI-driven language translation and adaptive content delivery, students from around the world can join the same virtual classroom, regardless of language or background. This fosters a more inclusive and diverse learning environment.</li>
<li><b>Continuous Assessment</b>: Instead of periodic testing, GenAI can continuously evaluate a student&#x2019;s understanding and adjust lesson plans in real-time. This would minimise the pressures of high-stakes testing and focus on steady, ongoing progress.</li>
<li><b>Skill Gap Identification</b>: GenAI can identify areas where students are struggling and suggest targeted resources or exercises. This could be especially useful in higher education and vocational training, ensuring students graduate with the necessary skills.</li>
<li><b>Accessibility and Inclusion</b>: For students with disabilities or learning differences, GenAI can tailor resources to fit their unique needs, making education more accessible and inclusive.</li>
<li><b>Lifelong Learning</b>: As the job landscape continues to evolve, GenAI can help adult learners adapt by identifying skill gaps and providing resources to fill them, facilitating continuous professional development.</li>
<li><b>Efficiency in Administration</b>: On the administrative side, GenAI could automate many of the tasks associated with running an educational institution, from scheduling to resource allocation, leading to cost savings and more efficient operations.</li>
<li><b>Ethical and Bias Concerns</b>: As with any technology, there will be concerns about how GenAI is used in education. Issues such as data privacy, potential biases in algorithms, and over-reliance on technology will be at the forefront of discussions. It will be crucial for educational institutions and regulators to address these concerns proactively.</li></ol>Remember, these are speculative and the actual impact of AI on education will depend on various factors, including technological advancements, policy regulations, social acceptance, and ethical considerations. The integration of AI in education offers promising opportunities but also presents challenges and ethical dilemmas that need to be thoughtfully addressed.</td></tr></tbody></table></section>
<section aria-labelledby="sec7_5_2">
<h3 id="sec7_5_2"><span epub:type="pagebreak" id="p252" aria-label=" page 252. " role="doc-pagebreak"/><span epub:type="ordinal">7.5.2 </span>What did Google Bard Say?</h3>
<table id="tableu7_2">
<thead>
<tr>
<th scope="col" class="center">User</th>
<th scope="col" class="left">Can you give me a few predictions about how GenAI will impact Education over the next 5 to 10 years?</th></tr></thead>
<tbody>
<tr>
<td class="center">Google Bard</td>
<td class="left">Here are a few predictions about how GenAI will impact education over the next 5 to 10 years:
<ul class="disc">
<li>Personalised learning: GenAI can be used to create personalised learning experiences for each student. This could include adapting the curriculum to the student&#x2019;s individual needs and interests, providing real-time feedback, and offering personalised tutoring support.</li>
<li>More engaging learning experiences: GenAI can be used to create more engaging and interactive learning experiences. For example, GenAI can be used to create virtual worlds, simulations, and games that can help students learn in a more immersive and hands-on way.</li>
<li>Increased access to education: GenAI can help to increase access to education for everyone, regardless of their location or circumstances. For example, GenAI can be used to develop educational tools and resources that can be used in low-resource settings or to provide personalised learning support to students with special needs.</li>
<li>New skills and knowledge: GenAI will create new demands for skills and knowledge in the workforce. This means that education will need to adapt to prepare students for the jobs of the future. For example, schools may need to focus more on teaching students critical thinking, problem-solving, and creativity skills.</li></ul>Here are some specific examples of how GenAI could be used In education:
<ul class="disc">
<li>AI-powered tutors: AI-powered tutors could provide students with personalised instruction and feedback, 24/7.</li>
<li>AI-generated learning content: AI could be used to generate personalised learning content for each student, based on their individual needs and interests.</li>
<li>AI-powered assessment tools: AI could be used to develop assessment tools that can provide more accurate and timely feedback to students.</li>
<li>AI-powered virtual learning environments: AI could be used to create virtual learning environments that allow students to learn in a more immersive and hands-on way.</li></ul>Overall, GenAI has the potential to revolutionise education. It can help us to create more personalised, engaging, and accessible learning experiences for all students. It can also help us to prepare students for the jobs of the future.<p>However, it is important to note that GenAI is still under development. There are some challenges that need to be addressed before GenAI can be widely adopted in education. For example, we need to make sure that AI-powered educational tools are fair and unbiased, and that they are aligned with our educational values. We also need to make sure that teachers are properly trained on how to use AI-powered educational tools effectively.</p></td></tr></tbody></table></section>
<section aria-labelledby="sec7_5_3">
<h3 id="sec7_5_3"><span epub:type="pagebreak" id="p253" aria-label=" page 253. " role="doc-pagebreak"/><span epub:type="ordinal">7.5.3 </span>What did Microsoft Bing Chat Say?</h3>
<table id="tableu7_3">
<thead>
<tr>
<th scope="col" class="center">User</th>
<th scope="col" class="left">Can you give me a few predictions about how GenAI will impact Education over the next 5 to 10 years?</th></tr></thead>
<tbody>
<tr>
<td class="center">Microsoft Bing Chat</td>
<td class="left">Generative AI is a major force that sectors from manufacturing to healthcare must respond to, but the sector perhaps most at risk of disruption is education <a href="#list7_6_1"><sup>1</sup></a>. Generative AI is not necessarily a death knell for education, but educators must be taught how to engage with it effectively <a href="#list7_6_1"><sup>1</sup></a>. More than 90% of teachers said they had never had any training in or even advice on how to use generative AI in school <a href="#list7_6_1"><sup>1</sup></a>. To ensure it is a net benefit to society and the education sector, we must stop being afraid of this technology and instead think hard about how to use it best <a href="#list7_6_1"><sup>1</sup></a>.<p>Generative AI has the potential to disrupt or augment how we think and act. It could modify present and future generations&#x2019; cognition because human socialisation and organic, human pedagogies are being replaced with artificial tutors and automated feedback loops <a href="#list7_6_1"><sup>1</sup></a>. However, young people know that information can be found online. Students today risk being criticised for using their phones to look up answers online on Wikipedia, not because the answer is wrong, but because they used the internet to find it. Trying to stop them from accessing it is problematic, to say the least <a href="#list7_6_1"><sup>1</sup></a>.</p><p>As generative AI becomes more widespread, accessible and easy to use, it will continue to impact the way we engage in teaching, learning, and assessment in higher education <a href="#list7_6_2"><sup>2</sup></a>. UCL has opted to promote ethical and transparent engagement with GenAI tools rather than seek to ban them <a href="#list7_6_2"><sup>2</sup></a>. In this paper, the authors explore the impact of generative AI (GenAI) on assessing student work in further education contexts. As GenAI becomes widely adopted, it engenders potential risks to assessment, such as false evidence of learning, student vulnerability to academic integrity injustice, and implications for independent learning and creativity <a href="#list7_6_3"><sup>3</sup></a>. This study explores university students&#x2019; perceptions of generative AI (GenAI) technologies, such as ChatGPT, in higher education, focusing on familiarity, their willingness to engage, potential benefits and challenges, and effective integration <a href="#list7_6_4"><sup>4</sup></a>.</p><p>It&#x2019;s important to note that these are just a few examples of how GenAI could impact education over the next 5-10 years. The possibilities are endless!</p><p>Learn more:</p>
<ol type="1">
<li id="list7_6_1"><a href="http://weforum.org">weforum.org</a></li>
<li id="list7_6_2"><a href="http://ucl.ac.uk">ucl.ac.uk</a></li>
<li id="list7_6_3"><a href="http://studiolab.ide.tudelft.nl">studiolab.ide.tudelft.nl</a></li>
<li id="list7_6_4"><a href="http://educationaltechnologyjournal.springeropen.com">educationaltechnologyjournal.springeropen.com</a></li>
<li id="list7_6_5"><a href="http://unesco.org">unesco.org</a></li></ol></td></tr></tbody></table></section></section>
<section epub:type="conclusion" role="doc-conclusion">
<h2 id="sec7_6"><span epub:type="ordinal">7.6 </span>Conclusion</h2>
<p>GenAI has numerous applications, ranging from assisting with everyday tasks to more specialised areas of use. The usefulness of GenAI will drive the adoption of this technology in society, eventually becoming part of the social norm, similar to how we perceive smartphones today.</p>
<p>Industry is adapting, and will continue to adopt and adapt, to GenAI and the benefits and challenges it comes with. Generally speaking, employees who do so quickly will be able to benefit more from the momentum, and new employees at all levels will need to acquire <span epub:type="pagebreak" id="p254" aria-label=" page 254. " role="doc-pagebreak"/>the skills in GenAI use and literacy. In particular, the integration of GenAI into roles and industries within the knowledge economy &#x2013; where the creation, acquisition, and application of knowledge and information drive economic growth and development &#x2013; will put pressure on educational institutions to incorporate GenAI skills and capabilities within the curriculum so that new graduates are prepared for the real world.</p>
<p>Government regulations will vary from region to region; however, in general, the potential for advancement and innovation in technology and leadership afforded by AI means that under-regulation is more probable than over-regulation. In cases where over-regulation occurs, there will likely be considerable pressure to quickly lessen or revert the constraints.</p>
<p>In university education, the greatest pressure will be to adjust to the changing marketplace and societal expectations, ensuring that graduates are ready and equipped with the necessary skills to effectively utilise these tools once they enter the job market. Changes in assessment will be needed, to align with the changing landscape and to ensure fairness. Postgraduate students will adopt these technologies in their research and work, subject to individual institutional policies.</p>
<p>In the case of research, the biggest impact will be felt in the practices of peer-reviewed journals. There is potential for the development of specialised AI tools and models that will assist authors, editors, and reviewers, as well as drive change in the industry towards greater transparency and openness, putting greater emphasis on scientific validation, impact, and verification rather than on peer opinion.</p>
<p>As these changes occur, it is likely that there will be considerable &#x2018;drama&#x2019; at times as workforces change, as the technology is used in unexpected ways, as new discoveries are made, or as issues are detected with already-published works. Sometimes the disruptions will be justified; however, most of the time, it will be a storm in a teacup given the overall landscape and changes on the horizon for humanity.</p>
<p>Finally, <b>we speculate</b> that AI <i>won&#x2019;t</i> be able to predict the future any better than humans can for most events that will unfold in the world, and this is an important thing to remember. We should not trust AI any more than a trusted friend who is not an expert. Even blind trust in an expert is not advisable; we need to use our judgement and sharpen our critical thinking skills to make informed decisions. With that being said, we will wait and observe with keen interest to see if any of these predictions come to fruition, and whether they were foreseen by our own speculative efforts or perhaps through the predictive capabilities of GenAI.</p></section>
<section class="reference" epub:type="bibliography" role="doc-bibliography">
<h2 id="r7_1">References</h2>
<ul>
<li id="ref7_1" epub:type="biblioentry"><a href="#R_ref7_1" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">BBC</a>. (2017, October 3). Yahoo 2013 data breach hit &#x2018;all three billion accounts&#x2019;. Retrieved from <a href="https://www.bbc.com">https://www.bbc.com/news/business-41493494</a></li>
<li id="ref7_2" epub:type="biblioentry"><a href="#R_ref7_2" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Bradshaw, T. &#x0026; Abboud, L.</a> (2023, October 22). <i>Four-week-old AI start-up raises record &#x20AC;105mn in European push</i>. Financial Times. Retrieved from <a href="https://www.ft.com">https://www.ft.com/</a></li>
<li id="ref7_3" epub:type="biblioentry"><a href="#R_ref7_3" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Briggs, J., &#x0026; Kodnani, D.</a> (2023a, March 26). The potentially large effects of artificial intelligence on economic growth. Retrieved form <a href="https://www.ansa.it">https://www.ansa.it/documents/1680080409454_ert.pdf</a></li>
<li id="ref7_4" epub:type="biblioentry"><a href="#R_ref7_4" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Briggs, J., &#x0026; Kodnani, D.</a> (2023b, April 5). <cite>Generative AI could raise global GDP by 7%</cite>. Goldman Sachs. Retrieved from <a href="https://www.goldmansachs.com">https://www.goldmansachs.com/intelligence/pages/generative-ai-could-raise-global-gdp-by-7-percent.html</a></li>
<li id="ref7_5" epub:type="biblioentry"><a href="#R_ref7_5" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Brittain, B.</a> (2023, Oct 13). <i>Google to defend generative AI users from copyright claims</i>. Reuters. Retrieved from <a href="https://www.reuters.com">https://www.reuters.com/technology/google-defend-generative-ai-users-copyright-claims-2023-10-12/</a></li>
<li id="ref7_6" epub:type="biblioentry"><a href="#R_ref7_6" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Chandrasekar, P.</a> (2023, July 27). <cite>Announcing OverflowAI</cite>. Stack Overflow Blog. Retrieved from <a href="https://stackoverflow.blog">https://stackoverflow.blog/2023/07/27/announcing-overflowai/</a></li>
<li id="ref7_7" epub:type="biblioentry"><span epub:type="pagebreak" id="p255" aria-label=" page 255. " role="doc-pagebreak"/><a href="#R_ref7_7" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Creamer, E.</a> (2023, July 5). <cite>Authors file a lawsuit against OpenAI for unlawfully &#x2018;ingesting&#x2019; their books</cite>. The Guardian. Retrieved from <a href="https://www.theguardian.com">https://www.theguardian.com/books/2023/jul/05/authors-file-a-lawsuit-against-openai-for-unlawfully-ingesting-their-books</a></li>
<li id="ref7_8" epub:type="biblioentry"><a href="#R_ref7_8" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Dave, P.</a> (2023, April 20). <cite>Stack overflow will charge AI giants for training data</cite>. Wired. Retrieved from <a href="https://www.wired.com">https://www.wired.com/story/stack-overflow-will-charge-ai-giants-for-training-data/</a></li>
<li id="ref7_9" epub:type="biblioentry"><a href="#R_ref7_9" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Davis, W.</a> (2023, October 16). Stack Overflow layoff AI profitability. <cite>The Verge</cite>. Retrieved from <a href="https://www.theverge.com">https://www.theverge.com/2023/10/16/23919004/stack-overflow-layoff-ai-profitability</a></li>
<li id="ref7_10" epub:type="biblioentry"><a href="#R_ref7_10" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Ellingrud, K., Sanghvi, S., Dandona, G. S., Madgavkar, A., Chui, M., White, O., &#x0026; Hasebe, P.</a> (2023, July 26). <i>Generative AI and the future of work in America</i>. McKinsey Global Institute. Retrieved from <a href="https://www.mckinsey.com">https://www.mckinsey.com/mgi/our-research/generative-ai-and-the-future-of-work-in-america</a></li>
<li id="ref7_11" epub:type="biblioentry"><a href="#R_ref7_11" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Gold, J.</a> (2023, June 8). <cite>Adobe offers copyright indemnification for Firefly AI-based image app users</cite>. Computerworld. Retrieved from <a href="https://www.computerworld.com">https://www.computerworld.com/article/3699053/adobe-offers-copyright-indemnification-for-firefly-ai-based-image-app-users.html</a></li>
<li id="ref7_12" epub:type="biblioentry"><a href="#R_ref7_12" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Kelly, J.</a> (2023, March 31). <cite>Goldman Sachs predicts 300 million jobs will be lost or degraded by artificial intelligence</cite>. Forbes. Retrieved from <a href="https://www.forbes.com">https://www.forbes.com/sites/jackkelly/2023/03/31/goldman-sachs-predicts-300-million-jobs-will-be-lost-or-degraded-by-artificial-intelligence/</a></li>
<li id="ref7_13" epub:type="biblioentry">Majewska, D. Rushton, N. &#x0026; Shaw, S. (2022). <cite>How did we get here? Timelines showing changes to maths education in England and the United States</cite>. Cambridge University Press &#x0026; Assessment.</li>
<li id="ref7_14" epub:type="biblioentry"><a href="#R_ref7_14" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Microsoft</a>. (2023, September 7). <cite>Our copyright commitment and legal concerns with copilot</cite>. Microsoft on the Issues. Retrieved from <a href="https://blogs.microsoft.com">https://blogs.microsoft.com/on-the-issues/2023/09/07/copilot-copyright-commitment-ai-legal-concerns/</a></li>
<li id="ref7_15" epub:type="biblioentry"><a href="#R_ref7_15" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Moreno, J.</a> (2023, April 26). <i>Zuckerberg says Meta will add generative AI to all its products</i>. Forbes. Retrieved from <a href="https://www.forbes.com">https://www.forbes.com/sites/johanmoreno/2023/04/26/zuckerberg-says-meta-will-add-generative-ai-to-all-its-products/</a></li>
<li id="ref7_16" epub:type="biblioentry"><a href="#R_ref7_16" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Nature Editorial</a>. (2023a, June 7). Why Nature will not allow the use of generative AI in images and video. <cite>Nature</cite>. Retrieved from <a href="https://www.nature.com">https://www.nature.com/articles/d41586-023-01546-4</a></li>
<li id="ref7_17" epub:type="biblioentry"><a href="#R_ref7_17" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Nature Editorial</a>. (2023b, January 24). Tools such as ChatGPT threaten transparent science; Here are our ground rules for their use. <cite>Nature</cite>. Retrieved from <a href="https://www.nature.com">https://www.nature.com/articles/d41586-023-00191-1</a></li>
<li id="ref7_18" epub:type="biblioentry"><a href="#R_ref7_18" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Nature Portfolio</a>. (2023). Editorial policies: Artificial intelligence (AI). <cite>Nature</cite>. Retrieved October 15, 2023, from <a href="https://www.nature.com">https://www.nature.com/nature-portfolio/editorial-policies/ai</a></li>
<li id="ref7_19" epub:type="biblioentry"><a href="#R_ref7_19" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Parrilla, J. M.</a> (2023, October 13). ChatGPT use shows that the grant-application system is broken. <cite>Nature</cite>. Retrieved from <a href="https://www.nature.com">https://www.nature.com/articles/d41586-023-03238-5</a></li>
<li id="ref7_20" epub:type="biblioentry"><a href="#R_ref7_20" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Jeffrey J. Rachlinski</a>, The limits of social norms, 74 Chi.-Kent L. Rev. 1537 (2000). Retrieved from <a href="https://scholarship.kentlaw.iit.edu">https://scholarship.kentlaw.iit.edu/cklawreview/vol74/iss4/6</a></li>
<li id="ref7_21" epub:type="biblioentry"><a href="#R_ref7_21" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Statista Mobiles</a>. (2019). <a href="https://www.statista.com">https://www.statista.com/statistics/263437/global-smartphone-sales-to-end-users-since-2007/</a></li>
<li id="ref7_22" epub:type="biblioentry"><a href="#R_ref7_22" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Statista PCs</a>. (2019). Retrieved from <a href="https://www.statista.com">https://www.statista.com/statistics/748551/worldwide-households-with-computer/</a></li>
<li id="ref7_23" epub:type="biblioentry"><a href="#R_ref7_23" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Taylor, S.</a> (2021, June 27). New LinkedIn data leak leaves 700 million users exposed. <cite>RestorePrivacy</cite>. Retrieved from <a href="https://restoreprivacy.com">https://restoreprivacy.com/linkedin-data-leak-700-million-users/</a></li>
<li id="ref7_24" epub:type="biblioentry"><a href="#R_ref7_24" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">The Lancet Microbe</a>. (2023, June). Information for authors. <cite>The Lancet</cite>. Retrieved from <a href="https://www.thelancet.com">https://www.thelancet.com/pb-assets/Lancet/authors/tlmicro-info-for-authors-1686637130753.pdf</a></li>
<li id="ref7_25" epub:type="biblioentry"><a href="#R_ref7_25" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Usman, R.</a> (2023, August 16). Magic and copyright: ChatGPT&#x2019;s mischief with Harry Potter gets tricky. <cite>Digital Information World</cite>. Retrieved from <a href="https://www.digitalinformationworld.com">https://www.digitalinformationworld.com/2023/08/magic-and-copyright-chatgpts-mischief.html</a></li>
<li id="ref7_26" epub:type="biblioentry"><a href="#R_ref7_26" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Wong, J. C.</a> (2019, Mar 18). The Cambridge Analytica scandal changed the world &#x2013; But it didn&#x2019;t change Facebook. <cite>The Guardian</cite>. Retrieved from <a href="https://www.theguardian.com">https://www.theguardian.com/technology/2019/mar/17/the-cambridge-analytica-scandal-changed-the-world-but-it-didnt-change-facebook</a></li>
<li id="ref7_27" epub:type="biblioentry"><a href="#R_ref7_27" epub:type="backlink" role="doc-backlink" aria-label=" This link returns to its first in-text citation. ">Wong, J. C.</a> (2021, April 6). What really caused Facebook&#x2019;s 500M-user data leak? <cite>Wired</cite>. Retrieved from <a href="https://www.wired.com">https://www.wired.com/story/facebook-data-leak-500-million-users-phone-numbers/</a></li></ul></section></section></body></html>