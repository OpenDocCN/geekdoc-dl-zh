<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Answers 3.2</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Answers 3.2</h1>
<blockquote>原文：<a href="https://boramorka.github.io/LLM-Book/en/CHAPTER-3/Answers%203.2/">https://boramorka.github.io/LLM-Book/en/CHAPTER-3/Answers%203.2/</a></blockquote>
                
                  


  
  



<h2 id="theory">Theory</h2>
<ol>
<li>Kubeflow Pipelines automate ML workflows, providing reproducibility and saving time through efficient management of complex pipelines.</li>
<li>The <code>dsl</code> module provides decorators and classes for defining components and pipeline structure, while the <code>compiler</code> is responsible for compiling the pipeline into a format executable by the Kubeflow engine.</li>
<li><code>FutureWarning</code> messages can be selectively suppressed to improve log readability; at the same time, it is important to keep track of documentation changes and update the code accordingly.</li>
<li>Clearly defined interfaces and component reusability simplify integration, increasing modularity and overall system efficiency.</li>
<li>The <code>@dsl.component</code> decorator marks a function as a pipeline component, which is an isolated, reusable step within the workflow.</li>
<li>Invoking a component returns a <code>PipelineTask</code> object, which represents a runtime instance of the pipeline step and is used to pass data between components.</li>
<li>A component’s output is passed via the <code>.output</code> attribute of the <code>PipelineTask</code> object.</li>
<li>Using named arguments improves code clarity and helps prevent errors, especially when working with many input parameters.</li>
<li>When chaining components in a pipeline, you must pass one component’s <code>.output</code> as the input to another to ensure a correct data flow.</li>
<li>A pipeline is declared with the <code>@dsl.pipeline</code> decorator and is responsible for orchestrating components. Important aspects include the execution environment and proper handling of outputs.</li>
<li>Pipeline compilation is the process of converting its Python definition into a YAML file, which can then be uploaded and run in the target Kubeflow environment.</li>
<li>Reusing ready‑made pipelines (e.g., PEFT for PaLM 2) significantly speeds up development and helps maintain best practices.</li>
<li>Model versioning is critical for MLOps, ensuring reproducibility and auditability. For example, you can add the date and time to the model name.</li>
<li>Pipeline arguments set input data and configuration for fine‑tuning, which is crucial for correct execution.</li>
<li>Automation and orchestration in Kubeflow improve efficiency and scalability, but require careful planning and a deep understanding of components and data flow.</li>
</ol>
<h2 id="practice">Practice</h2>
<p>Solutions for the tasks:</p>
<h3 id="1-setting-up-the-kubeflow-pipelines-sdk">1. Setting up the Kubeflow Pipelines SDK</h3>
<div class="highlight"><pre><span/><code><span class="c1"># Import the required modules from the Kubeflow Pipelines SDK</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">kfp</span><span class="w"> </span><span class="kn">import</span> <span class="n">dsl</span><span class="p">,</span> <span class="n">compiler</span>

<span class="c1"># Suppress FutureWarning messages from the Kubeflow Pipelines SDK</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">"ignore"</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="ne">FutureWarning</span><span class="p">,</span> <span class="n">module</span><span class="o">=</span><span class="s1">'kfp.*'</span><span class="p">)</span>
</code></pre></div>
<p>This script imports <code>dsl</code> and <code>compiler</code>, and suppresses <code>FutureWarning</code> messages from <code>kfp.*</code> modules.</p>
<h3 id="2-defining-a-simple-pipeline-component">2. Defining a simple pipeline component</h3>
<div class="highlight"><pre><span/><code><span class="kn">from</span><span class="w"> </span><span class="nn">kfp</span><span class="w"> </span><span class="kn">import</span> <span class="n">dsl</span>

<span class="c1"># Define a simple component that adds two numbers</span>
<span class="nd">@dsl</span><span class="o">.</span><span class="n">component</span>
<span class="k">def</span><span class="w"> </span><span class="nf">add_numbers</span><span class="p">(</span><span class="n">num1</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">num2</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">num1</span> <span class="o">+</span> <span class="n">num2</span>
</code></pre></div>
<p>The component function <code>add_numbers</code>, marked with the <code>@dsl.component</code> decorator, accepts two integers and returns their sum.</p>
<h3 id="3-suppressing-specific-warnings">3. Suppressing specific warnings</h3>
<div class="highlight"><pre><span/><code><span class="kn">import</span><span class="w"> </span><span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">"ignore"</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="ne">DeprecationWarning</span><span class="p">)</span>
</code></pre></div>
<p>This script suppresses <code>DeprecationWarning</code> for all modules.</p>
<h3 id="4-linking-components-in-a-pipeline">4. Linking components in a pipeline</h3>
<div class="highlight"><pre><span/><code><span class="kn">from</span><span class="w"> </span><span class="nn">kfp</span><span class="w"> </span><span class="kn">import</span> <span class="n">dsl</span>

<span class="c1"># Component that generates a fixed number</span>
<span class="nd">@dsl</span><span class="o">.</span><span class="n">component</span>
<span class="k">def</span><span class="w"> </span><span class="nf">generate_number</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
    <span class="k">return</span> <span class="mi">42</span>

<span class="c1"># Component that doubles the input number</span>
<span class="nd">@dsl</span><span class="o">.</span><span class="n">component</span>
<span class="k">def</span><span class="w"> </span><span class="nf">double_number</span><span class="p">(</span><span class="n">input_number</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">input_number</span> <span class="o">*</span> <span class="mi">2</span>

<span class="c1"># Define a pipeline that connects two components</span>
<span class="nd">@dsl</span><span class="o">.</span><span class="n">pipeline</span><span class="p">(</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">"Number doubling pipeline"</span><span class="p">,</span>
    <span class="n">description</span><span class="o">=</span><span class="s2">"A pipeline that generates a number and doubles it."</span>
<span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">number_doubling_pipeline</span><span class="p">():</span>
    <span class="c1"># Step 1: Generate a number</span>
    <span class="n">generated_number_task</span> <span class="o">=</span> <span class="n">generate_number</span><span class="p">()</span>

    <span class="c1"># Step 2: Double the generated number</span>
    <span class="n">double_number_task</span> <span class="o">=</span> <span class="n">double_number</span><span class="p">(</span><span class="n">input_number</span><span class="o">=</span><span class="n">generated_number_task</span><span class="o">.</span><span class="n">output</span><span class="p">)</span>
</code></pre></div>
<p>The pipeline consists of two components: <code>generate_number</code>, which generates a fixed number, and <code>double_number</code>, which doubles the input. The connection is made by passing the first component’s <code>.output</code> as the input to the second.</p>
<h3 id="5-compiling-and-preparing-the-pipeline-for-execution">5. Compiling and preparing the pipeline for execution</h3>
<div class="highlight"><pre><span/><code><span class="kn">from</span><span class="w"> </span><span class="nn">kfp</span><span class="w"> </span><span class="kn">import</span> <span class="n">compiler</span>

<span class="c1"># Assume the pipeline definition is named number_doubling_pipeline</span>
<span class="n">pipeline_func</span> <span class="o">=</span> <span class="n">number_doubling_pipeline</span>

<span class="c1"># Compile the pipeline</span>
<span class="n">compiler</span><span class="o">.</span><span class="n">Compiler</span><span class="p">()</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
    <span class="n">pipeline_func</span><span class="o">=</span><span class="n">pipeline_func</span><span class="p">,</span>
    <span class="n">package_path</span><span class="o">=</span><span class="s1">'number_doubling_pipeline.yaml'</span>
<span class="p">)</span>
</code></pre></div>
<p>The pipeline is compiled into the <code>number_doubling_pipeline.yaml</code> file, which can be uploaded and run in the Kubeflow environment.</p>
<h3 id="6-working-with-pipelinetask-objects">6. Working with <code>PipelineTask</code> objects</h3>
<div class="highlight"><pre><span/><code><span class="c1"># This is a hypothetical function that cannot be executed as‑is. It is intended to illustrate the concept.</span>
<span class="k">def</span><span class="w"> </span><span class="nf">handle_pipeline_task</span><span class="p">():</span>
    <span class="c1"># Hypothetical call to a component function named my_component</span>
    <span class="c1"># In a real scenario, this should occur inside a pipeline function</span>
    <span class="n">task</span> <span class="o">=</span> <span class="n">my_component</span><span class="p">(</span><span class="n">param1</span><span class="o">=</span><span class="s2">"value"</span><span class="p">)</span>

    <span class="c1"># Access the component’s output</span>
    <span class="c1"># This line is illustrative and typically used to pass outputs between components in a pipeline</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">task</span><span class="o">.</span><span class="n">output</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">"Accessing the component output:"</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span>

<span class="c1"># Note: In real usage, my_component would be defined as a Kubeflow Pipeline component,</span>
<span class="c1"># and task manipulations should occur within the context of a pipeline function.</span>
</code></pre></div>
<p>The example shows that invoking a component returns a <code>PipelineTask</code> object, and its result is accessed via <code>task.output</code>. In practice, such objects are manipulated inside a pipeline function.</p>
<h3 id="7-handling-errors-in-pipeline-definitions">7. Handling errors in pipeline definitions</h3>
<div class="highlight"><pre><span/><code><span class="kn">from</span><span class="w"> </span><span class="nn">kfp</span><span class="w"> </span><span class="kn">import</span> <span class="n">dsl</span>

<span class="c1"># Incorrect pipeline definition</span>
<span class="nd">@dsl</span><span class="o">.</span><span class="n">pipeline</span><span class="p">(</span>
    <span class="n">name</span><span class="o">=</span><span class="s1">'Incorrect Pipeline'</span><span class="p">,</span>
    <span class="n">description</span><span class="o">=</span><span class="s1">'An example that attempts to return a PipelineTask object directly.'</span>
<span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">incorrect_pipeline_example</span><span class="p">():</span>
    <span class="nd">@dsl</span><span class="o">.</span><span class="n">component</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">generate_number</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">42</span>

    <span class="n">generated_number_task</span> <span class="o">=</span> <span class="n">generate_number</span><span class="p">()</span>
    <span class="c1"># Incorrect attempt to return a PipelineTask object directly</span>
    <span class="k">return</span> <span class="n">generated_number_task</span>  <span class="c1"># This will cause an error</span>

<span class="c1"># Correct pipeline definition</span>
<span class="nd">@dsl</span><span class="o">.</span><span class="n">pipeline</span><span class="p">(</span>
    <span class="n">name</span><span class="o">=</span><span class="s1">'Correct Pipeline'</span><span class="p">,</span>
    <span class="n">description</span><span class="o">=</span><span class="s1">'A corrected example that does not attempt to return a PipelineTask object.'</span>
<span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">correct_pipeline_example</span><span class="p">():</span>
    <span class="nd">@dsl</span><span class="o">.</span><span class="n">component</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">generate_number</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">42</span>

    <span class="n">generated_number_task</span> <span class="o">=</span> <span class="n">generate_number</span><span class="p">()</span>
    <span class="c1"># Correct approach: do not attempt to return a PipelineTask directly from a pipeline function.</span>
    <span class="c1"># A pipeline function should not return anything.</span>

<span class="c1"># Explanation: a pipeline function orchestrates steps and data flow, but does not return data directly.</span>
<span class="c1"># Attempting to return a PipelineTask from a pipeline function is incorrect, because the pipeline definition</span>
<span class="c1"># should describe component structure and dependencies, not process data directly.</span>
<span class="c1"># The corrected version removes the return statement, which matches the expected behavior of pipeline functions.</span>
</code></pre></div>
<h3 id="8-automating-data-preparation-for-model-training">8. Automating data preparation for model training</h3>
<div class="highlight"><pre><span/><code><span class="kn">import</span><span class="w"> </span><span class="nn">json</span>

<span class="c1"># Simulated data preparation for model training</span>
<span class="k">def</span><span class="w"> </span><span class="nf">preprocess_data</span><span class="p">(</span><span class="n">input_file_path</span><span class="p">,</span> <span class="n">output_file_path</span><span class="p">):</span>
    <span class="c1"># Read data from a JSON file</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">input_file_path</span><span class="p">,</span> <span class="s1">'r'</span><span class="p">)</span> <span class="k">as</span> <span class="n">infile</span><span class="p">:</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">infile</span><span class="p">)</span>

    <span class="c1"># Perform a simple transformation: filter data</span>
    <span class="c1"># For illustration, assume we only need items meeting a certain condition</span>
    <span class="c1"># Example: filter items where the value of "useful" is True</span>
    <span class="n">filtered_data</span> <span class="o">=</span> <span class="p">[</span><span class="n">item</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">data</span> <span class="k">if</span> <span class="n">item</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"useful"</span><span class="p">,</span> <span class="kc">False</span><span class="p">)]</span>

    <span class="c1"># Save the transformed data to another JSON file</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">output_file_path</span><span class="p">,</span> <span class="s1">'w'</span><span class="p">)</span> <span class="k">as</span> <span class="n">outfile</span><span class="p">:</span>
        <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">filtered_data</span><span class="p">,</span> <span class="n">outfile</span><span class="p">,</span> <span class="n">indent</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

<span class="c1"># Example usage</span>
<span class="n">preprocess_data</span><span class="p">(</span><span class="s1">'input_data.json'</span><span class="p">,</span> <span class="s1">'processed_data.json'</span><span class="p">)</span>

<span class="c1"># Note: This script assumes the file 'input_data.json' exists in the current directory</span>
<span class="c1"># and will save processed data to 'processed_data.json'.</span>
<span class="c1"># In a real scenario, paths and transformation logic should be adjusted to your requirements.</span>
</code></pre></div>
<p>This script demonstrates a simple data preparation process: reading data from a JSON file, transforming it (filtering by a condition), and saving the processed data to another JSON file. This type of task can be encapsulated in a Kubeflow Pipeline component to automate data preparation steps in ML training workflows.</p>
<h3 id="9-implementing-model-versioning-in-a-pipeline">9. Implementing model versioning in a pipeline</h3>
<div class="highlight"><pre><span/><code><span class="kn">from</span><span class="w"> </span><span class="nn">datetime</span><span class="w"> </span><span class="kn">import</span> <span class="n">datetime</span>

<span class="k">def</span><span class="w"> </span><span class="nf">generate_model_name</span><span class="p">(</span><span class="n">base_model_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="c1"># Generate a timestamp in the format "YYYYMMDD-HHMMSS"</span>
    <span class="n">timestamp</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="s2">"%Y%m</span><span class="si">%d</span><span class="s2">-%H%M%S"</span><span class="p">)</span>
    <span class="c1"># Append the timestamp to the base model name to create a unique name</span>
    <span class="n">model_name</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">base_model_name</span><span class="si">}</span><span class="s2">-</span><span class="si">{</span><span class="n">timestamp</span><span class="si">}</span><span class="s2">"</span>
    <span class="k">return</span> <span class="n">model_name</span>

<span class="c1"># Example usage</span>
<span class="n">base_model_name</span> <span class="o">=</span> <span class="s2">"my_model"</span>
<span class="n">model_name</span> <span class="o">=</span> <span class="n">generate_model_name</span><span class="p">(</span><span class="n">base_model_name</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Generated model name:"</span><span class="p">,</span> <span class="n">model_name</span><span class="p">)</span>

<span class="c1"># This function generates a unique model name by appending the current date and time to the base model name.</span>
<span class="c1"># This practice helps with model versioning, making it easier to track and manage different model versions in ML operations.</span>
</code></pre></div>
<h3 id="10-parameterizing-and-executing-a-kubeflow-pipeline">10. Parameterizing and executing a Kubeflow pipeline</h3>
<p>For the purpose of this task, assume we are working in an environment with access to a Kubeflow Pipeline execution API. Since execution details vary by platform and API version, the following script is a hypothetical example based on common patterns.</p>
<div class="highlight"><pre><span/><code><span class="c1"># Assume the necessary imports and configuration for interacting with the execution environment are present</span>

<span class="k">def</span><span class="w"> </span><span class="nf">submit_pipeline_execution</span><span class="p">(</span><span class="n">compiled_pipeline_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">pipeline_arguments</span><span class="p">:</span> <span class="nb">dict</span><span class="p">):</span>
    <span class="c1"># Placeholder for the API/SDK method to submit a pipeline for execution</span>
    <span class="c1"># In a real scenario, this would use the Kubeflow Pipelines SDK or a cloud provider SDK</span>
    <span class="c1"># For example, using the Kubeflow Pipelines SDK or a cloud service like Google Cloud AI Platform Pipelines</span>

    <span class="c1"># Assume a function `submit_pipeline_job` exists and can be used to submit</span>
    <span class="c1"># This function would be part of the SDK or the environment’s API</span>
    <span class="n">submit_pipeline_job</span><span class="p">(</span><span class="n">compiled_pipeline_path</span><span class="p">,</span> <span class="n">pipeline_arguments</span><span class="p">)</span>

<span class="c1"># Example pipeline arguments</span>
<span class="n">pipeline_arguments</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">"recipient_name"</span><span class="p">:</span> <span class="s2">"Alice"</span>
<span class="p">}</span>

<span class="c1"># Path to the compiled Kubeflow pipeline YAML file</span>
<span class="n">compiled_pipeline_path</span> <span class="o">=</span> <span class="s2">"path_to_compiled_pipeline.yaml"</span>

<span class="c1"># Submit the pipeline for execution</span>
<span class="n">submit_pipeline_execution</span><span class="p">(</span><span class="n">compiled_pipeline_path</span><span class="p">,</span> <span class="n">pipeline_arguments</span><span class="p">)</span>

<span class="c1"># Note: This example assumes a `submit_pipeline_job` function exists, which will be specific</span>
<span class="c1"># to the environment’s API or SDK. In a real implementation, replace this placeholder</span>
<span class="c1"># with actual code that interacts with the Kubeflow Pipelines API or a managed service API, such as Google Cloud AI Platform.</span>
</code></pre></div>
<p>This script describes how to parameterize and submit a compiled Kubeflow pipeline for execution, assuming an appropriate API or SDK method is available (<code>submit_pipeline_job</code> in this hypothetical example). The actual submission method depends on your execution environment or cloud provider.</p>












                
                  
</body>
</html>