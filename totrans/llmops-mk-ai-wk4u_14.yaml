- en: 2.3 Deep Dive into Text Splitting
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2.3 深入探讨文本分割
- en: 原文：[https://boramorka.github.io/LLM-Book/en/CHAPTER-2/2.3%20Deep%20Dive%20into%20Text%20Splitting/](https://boramorka.github.io/LLM-Book/en/CHAPTER-2/2.3%20Deep%20Dive%20into%20Text%20Splitting/)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://boramorka.github.io/LLM-Book/en/CHAPTER-2/2.3%20Deep%20Dive%20into%20Text%20Splitting/](https://boramorka.github.io/LLM-Book/en/CHAPTER-2/2.3%20Deep%20Dive%20into%20Text%20Splitting/)
- en: 'Splitting (segmentation) happens after loading data into a “document” format
    but before indexing or storage. The goal is to produce semantically meaningful
    chunks that work well for search and analytics without breaking meaning at the
    boundaries. Two parameters matter most: chunk size and overlap. Size is measured
    in characters or tokens (larger chunks carry more context; smaller ones are easier
    to process). Overlap is the “handoff” between neighboring chunks that helps maintain
    coherence. LangChain provides several strategies: character- and token-based splitting,
    a recursive approach that follows a hierarchy of separators (paragraphs → sentences
    → words), plus specialized splitters for code and Markdown that respect syntax
    and headings. There are also two modes of operation — Create Documents (accepts
    a list of raw text and returns chunked documents) and Split Documents (splits
    previously loaded documents) — so choose based on whether you are working with
    strings or with document objects. In practice, CharacterTextSplitter (simple character-based
    splitting when semantics are less critical) and TokenTextSplitter (token-based
    splitting to fit LLM limits) are the most common. When structure matters, a recursive
    splitter that follows the hierarchy is very helpful. Among the specialized options
    are LanguageTextSplitter for code and MarkdownHeaderTextSplitter for splitting
    by headings while preserving this structure in metadata.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 分割（分段）发生在将数据加载到“文档”格式之后，但在索引或存储之前。目标是产生具有语义意义的块，这些块对搜索和数据分析很有用，同时不会在边界处破坏意义。最重要的两个参数是块大小和重叠。大小以字符或标记衡量（较大的块携带更多上下文；较小的块更容易处理）。重叠是相邻块之间的“交接”，有助于保持连贯。LangChain提供了几种策略：基于字符和标记的分割，遵循分隔符层次结构的递归方法，以及针对代码和Markdown的专用分割器，这些分割器尊重语法和标题。还有两种操作模式——创建文档（接受原始文本列表并返回分割文档）和分割文档（分割先前加载的文档）——因此根据您是否处理字符串或文档对象进行选择。在实践中，CharacterTextSplitter（当语义不太重要时的简单基于字符的分割）和TokenTextSplitter（基于标记的分割以适应LLM限制）是最常见的。当结构很重要时，遵循层次结构的递归分割器非常有帮助。在专用选项中包括LanguageTextSplitter用于代码和MarkdownHeaderTextSplitter用于通过标题进行分割，同时保留此结构在元数据中。
- en: 'Before applying splitters, it’s useful to quickly set up the environment: imports,
    API keys, and dependencies.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在应用分割器之前，快速设置环境是有用的：导入、API密钥和依赖项。
- en: '[PRE0]'
  id: totrans-4
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Splitting strategy strongly affects search and analytics quality, so tune parameters
    to preserve relevance and coherence. The basic choices are CharacterTextSplitter
    and RecursiveCharacterTextSplitter; select based on your data’s structure and
    nature. Below are compact examples: first, a simple splitter with optional overlap
    to help maintain context,'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 分割策略强烈影响搜索和数据分析质量，因此调整参数以保留相关性和连贯性。基本选择是CharacterTextSplitter和RecursiveCharacterTextSplitter；根据您数据的结构和性质进行选择。下面是紧凑的示例：首先，一个简单的分割器，具有可选的重叠以帮助保持上下文，
- en: '[PRE1]'
  id: totrans-6
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: and then a recursive splitter which, for “general” texts, more carefully preserves
    semantics by following a hierarchy of separators—from paragraphs to sentences
    to words.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 然后是一个递归分割器，对于“通用”文本，通过遵循分隔符的层次结构更仔细地保留语义——从段落到句子到单词。
- en: '[PRE2]'
  id: totrans-8
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Next come a few practical examples. Start with simple strings,
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是一些实际示例。从简单的字符串开始，
- en: '[PRE3]'
  id: totrans-10
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: and then look under the hood with a minimal splitter implementation and its
    behavior on basic inputs.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 然后查看最小分割器实现及其在基本输入上的行为。
- en: '[PRE4]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The example above illustrates how splitting behaves on basic strings—with and
    without explicit separators. Now consider two advanced techniques. First, handling
    more complex text where it’s helpful to explicitly set a hierarchy of separators
    and a chunk size:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的例子说明了在基本字符串上分割的行为——有和无显式分隔符。现在考虑两种高级技术。首先，处理更复杂的文本，其中显式设置分隔符的层次结构和块大小是有帮助的：
- en: '[PRE5]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'This produces coherent chunks that respect the document’s internal structure.
    Second, token-based splitting, where the LLM context window is defined in tokens
    and limits must be strictly observed:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 这会产生尊重文档内部结构的连贯块。其次，基于标记的分割，其中LLM上下文窗口由标记定义，并且必须严格遵守限制：
- en: '[PRE6]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: And finally, splitting by Markdown headings, where the document’s logical organization
    guides segmentation and the detected headings are preserved in chunk metadata.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，通过Markdown标题进行分割，其中文档的逻辑组织指导了分割，并且检测到的标题在块元数据中得到了保留。
- en: '[PRE7]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'A few quick recommendations: preserve semantics and account for the source
    document’s structure; manage overlap—just enough to maintain coherence without
    unnecessary redundancy; use and enrich metadata to improve context during retrieval
    and answering.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 一些快速的建议：保留语义并考虑源文档的结构；管理重叠——只需足够维持连贯性，避免不必要的冗余；使用并丰富元数据以改善检索和回答时的上下文。
- en: Theory Questions
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理论问题
- en: What is the goal of document splitting?
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 文档分割的目标是什么？
- en: How does chunk size affect processing?
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 块大小如何影响处理？
- en: Why is overlap needed and how does it help analysis?
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为什么需要重叠，以及它如何帮助分析？
- en: How do `CharacterTextSplitter` and `TokenTextSplitter` differ, and where are
    they used?
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`CharacterTextSplitter`和`TokenTextSplitter`有何不同，它们在哪里使用？'
- en: What is a recursive splitter and how does it differ from basic ones?
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 递归分割器是什么，它与基本分割器有何不同？
- en: Which specialized splitters exist for code and Markdown, and what are their
    benefits?
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于代码和Markdown，存在哪些专门的分割器，它们的优点是什么？
- en: What is required to set up the environment before splitting?
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在分割之前需要设置哪些环境？
- en: List the pros and cons of `RecursiveCharacterTextSplitter` and the parameters
    that are important to tune.
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 列出`RecursiveCharacterTextSplitter`的优点和缺点，以及需要调整的重要参数。
- en: What does the “alphabet” example demonstrate when comparing simple and recursive
    approaches?
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当比较简单和递归方法时，“字母表”示例展示了什么？
- en: What should you pay attention to when choosing between characters and tokens
    for LLMs?
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在选择LLMs的字符和标记时，你应该注意什么？
- en: How does splitting by Markdown headings preserve logical structure and why is
    that important?
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过Markdown标题分割如何保留逻辑结构，为什么那很重要？
- en: What best practices help preserve semantics and manage overlap?
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 哪些最佳实践有助于保留语义和管理重叠？
- en: Practical Tasks
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实践任务
- en: Write a function `split_by_char(text, chunk_size)` that returns a list of fixed-size
    chunks.
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编写一个函数`split_by_char(text, chunk_size)`，该函数返回一个固定大小的块列表。
- en: Add a `chunk_overlap` parameter to `split_by_char` and implement overlapping.
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将`chunk_overlap`参数添加到`split_by_char`中并实现重叠。
- en: Implement a class `TokenTextSplitter(chunk_size, chunk_overlap)` with a `split_text`
    method that splits text by tokens (tokens separated by spaces).
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实现一个类`TokenTextSplitter(chunk_size, chunk_overlap)`，它有一个`split_text`方法，通过标记（由空格分隔的标记）分割文本。
- en: Write a function `recursive_split(text, max_chunk_size, separators)` that recursively
    splits text using a given list of separators.
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编写一个函数`recursive_split(text, max_chunk_size, separators)`，该函数通过给定的分隔符列表递归地分割文本。
- en: Implement a class `MarkdownHeaderTextSplitter(headers_to_split_on)` with a `split_text`
    method that splits Markdown by the specified headings and returns chunks with
    the corresponding metadata.
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实现一个类`MarkdownHeaderTextSplitter(headers_to_split_on)`，它有一个`split_text`方法，通过指定的标题分割Markdown，并返回带有相应元数据的块。
