- en: 1.5 The Power of Prompt Chaining
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://boramorka.github.io/LLM-Book/en/CHAPTER-1/1.5%20The%20Power%20of%20Prompt%20Chaining/](https://boramorka.github.io/LLM-Book/en/CHAPTER-1/1.5%20The%20Power%20of%20Prompt%20Chaining/)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Prompt chaining solves complex tasks through a sequence of simple, interconnected
    steps. Instead of one “monolithic” request, you build a chain of small prompts:
    each step solves a specific subtask and prepares context for the next. This reduces
    errors, makes model behavior more controllable, and increases observability: it’s
    easier to see where and why a mistake happened and to intervene precisely. It’s
    like cooking a complex dish step by step or using modular architecture in software
    — it’s always easier to debug and maintain a series of small, clear operations
    than a single spaghetti‑like step.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Practical benefits are clear: you can orchestrate the workflow by checkpointing
    state at each step and adapting the next step to the previous result; save context
    and budget, since long prompts cost more while each chain step uses only the minimum
    needed; reduce errors by isolating the problem; and load only relevant information,
    respecting LLM context limits. Methodologically, this means decomposing the task,
    explicitly managing state between steps, designing each prompt for a narrow focus,
    adding tools for loading and pre‑processing data, and dynamically injecting only
    the context fragments needed right now. Best practices are simple: don’t overcomplicate
    when a single prompt suffices; be clear; keep and update external context; think
    about efficiency (quality, cost, latency); and test the chain end to end.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Below is a sequential example that assembles an end‑to‑end scenario: entity
    extraction, querying a simple “database”, parsing JSON, and composing a user‑facing
    answer — then tying it all together into a single support flow.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Now extract entities from a user request. The first step sets the task and output
    format in a system instruction. The user input is bounded by delimiters, which
    makes it easier to control data boundaries and pass the result along the chain.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, plug in a data source and find the specific products or categories. Even
    an in‑memory “database” demonstrates the idea: extract entities → move to structured
    data → prepare facts for the answer.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: On the next step, convert JSON strings that the model might return during entity
    extraction into Python objects for downstream chain steps.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Finally, compose a concise user‑facing answer from the resulting structures.
    You can swap this formatting layer for templates, localization, or generation
    tuned to your UX.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'We’ll finish with an end‑to‑end support scenario: first detect interest in
    photography, then provide troubleshooting, clarify warranty coverage, and end
    with accessory recommendations — four steps in one chain, each building on the
    previous result.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'In the end, prompt chaining gives you a robust and understandable workflow:
    it saves context and budget, localizes errors more precisely, and preserves flexibility
    to tailor the answer to the user’s task.'
  prefs: []
  type: TYPE_NORMAL
- en: Theory Questions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: What is prompt chaining and how does it differ from using one long prompt?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Provide two analogies and explain how they map to chaining.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How does chaining help manage workflow?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Where do the savings come from when using chaining?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How does chaining reduce errors on complex tasks?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Why is dynamic data loading useful given LLM context limits?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Describe a step‑by‑step methodology for chaining and the role of each step.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: List best practices that ensure chaining efficiency.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Which libraries are used in the example and for what?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How does the system message guide the model’s answer?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the role of the product database, and how do you query it?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Why convert JSON strings to Python objects, and how?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How does formatting answers from processed data improve service quality?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How does the end‑to‑end scenario demonstrate adapting to user needs via chaining?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Practical Tasks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Implement `retrieve_model_response` with `model`, `temperature`, and `max_tokens`
    parameters.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Show an entity‑extraction example using a system instruction.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a mini product database and functions to query by name or category.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Implement JSON‑to‑Python list conversion with error handling.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Write `generate_response_from_data` that formats a data list into a user‑friendly
    answer.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compose an end‑to‑end support scenario (query → troubleshooting → warranty →
    recommendations) based on the functions above.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
