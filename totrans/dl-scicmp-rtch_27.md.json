["```r\nlibrary(torch)\nlibrary(torchaudio)\nlibrary(luz)\n\nds <- speechcommand_dataset(\n root = \"~/.torch-datasets\", \n url = \"speech_commands_v0.01\",\n download = TRUE\n)\n\nds$classes\n```", "```r\n[1]  \"bed\"    \"bird\"   \"cat\"    \"dog\"    \"down\"   \"eight\"\n[7]  \"five\"   \"four\"   \"go\"     \"happy\"  \"house\"  \"left\"\n[32] \" marvin\" \"nine\"   \"no\"     \"off\"    \"on\"     \"one\"\n[19] \"right\"  \"seven\" \"sheila\" \"six\"    \"stop\"   \"three\"\n[25]  \"tree\"   \"two\"    \"up\"     \"wow\"    \"yes\"    \"zero\" \n```", "```r\nsample <- ds[2000]\ndim(sample$waveform)\n```", "```r\n[1]     1 16000\n```", "```r\nsample$sample_rate\n```", "```r\n[1] 16000\n```", "```r\nsample$label\nsample$label_index\n```", "```r\n[1] \"bird\"\ntorch_tensor\n2\n[ CPULongType{} ]\n```", "```r\nlibrary(ggplot2)\n\ndf <- data.frame(\n x = 1:length(sample$waveform[1]),\n y = as.numeric(sample$waveform[1])\n )\n\nggplot(df, aes(x = x, y = y)) +\n geom_line(size = 0.3) +\n ggtitle(\n paste0(\n \"The spoken word \\\"\", sample$label, \"\\\": Sound wave\"\n )\n ) +\n xlab(\"time\") +\n ylab(\"amplitude\") +\n theme_minimal()\n```", "```r\ndft <- torch_fft_fft(sample$waveform)\ndim(dft)\n```", "```r\n[1]     1 16000\n```", "```r\nmag <- torch_abs(dft[1, ])\n\ndf <- data.frame(\n x = 1:(length(sample$waveform[1]) / 2),\n y = as.numeric(mag[1:8000])\n)\n\nggplot(df, aes(x = x, y = y)) +\n geom_line(size = 0.3) +\n ggtitle(\n paste0(\n \"The spoken word \\\"\",\n sample$label,\n \"\\\": Discrete Fourier Transform\"\n )\n ) +\n xlab(\"frequency\") +\n ylab(\"magnitude\") +\n theme_minimal()\n```", "```r\nfft_size <- 512\nwindow_size <- 512\npower <- 0.5\n\nspectrogram <- transform_spectrogram(\n n_fft = fft_size,\n win_length = window_size,\n normalized = TRUE,\n power = power\n)\n\nspec <- spectrogram(sample$waveform)$squeeze()\ndim(spec)\n```", "```r\n[1]   257 63\n```", "```r\nbins <- 1:dim(spec)[1]\nfreqs <- bins / (fft_size / 2 + 1) * sample$sample_rate \nlog_freqs <- log10(freqs)\n\nframes <- 1:(dim(spec)[2])\nseconds <- (frames / dim(spec)[2]) *\n (dim(sample$waveform$squeeze())[1] / sample$sample_rate)\n\nimage(x = as.numeric(seconds),\n y = log_freqs,\n z = t(as.matrix(spec)),\n ylab = 'log frequency [Hz]',\n xlab = 'time [s]',\n col = hcl.colors(12, palette = \"Light grays\")\n)\nmain <- paste0(\"Spectrogram, window size = \", window_size)\nsub <- \"Magnitude (square root)\"\nmtext(side = 3, line = 2, at = 0, adj = 0, cex = 1.3, main)\nmtext(side = 3, line = 1, at = 0, adj = 0, cex = 1, sub)\n```", "```r\nspectrogram_dataset <- dataset(\n inherit = speechcommand_dataset,\n initialize = function(...,\n pad_to = 16000,\n sampling_rate = 16000,\n n_fft = 512,\n window_size_seconds = 0.03,\n window_stride_seconds = 0.01,\n # power = 2 is default for\n # transform_spectrogram()\n # we stay with the default for now,\n # but will make use of this option later\n power = 2,\n # this too will be explained later\n n_mels = 0) {\n self$pad_to <- pad_to\n self$window_size_samples <- sampling_rate *\n window_size_seconds\n self$window_stride_samples <- sampling_rate *\n window_stride_seconds\n self$power <- power\n if (n_mels == 0) {\n self$spectrogram <- transform_spectrogram(\n n_fft = n_fft,\n win_length = self$window_size_samples,\n hop_length = self$window_stride_samples,\n normalized = TRUE,\n power = self$power\n )\n } else {\n self$spectrogram <- transform_mel_spectrogram(\n n_fft = n_fft,\n win_length = self$window_size_samples,\n hop_length = self$window_stride_samples,\n normalized = TRUE,\n power = self$power,\n n_mels = n_mels\n )\n }\n super$initialize(...)\n },\n .getitem = function(i) {\n item <- super$.getitem(i)\n\n x <- item$waveform\n # make sure all samples have the same length (57)\n # shorter ones will be padded,\n # longer ones will be truncated\n x <- nnf_pad(x, pad = c(0, self$pad_to - dim(x)[2]))\n x <- x %>% self$spectrogram()\n\n if (is.null(self$power)) {\n # there is an additional dimension now,\n # in position 4,\n # that we want to appear in front\n # (as a second channel)\n x <- x$squeeze()$permute(c(3, 1, 2))\n }\n\n y <- item$label_index\n list(x = x, y = y)\n }\n)\n```", "```r\nds <- spectrogram_dataset(\n root = \"~/.torch-datasets\",\n url = \"speech_commands_v0.01\",\n download = TRUE\n)\n\ndim(ds[1]$x)\nds[1]$y\n```", "```r\n[1]   1 257 101\ntorch_tensor\n1\n[ CPULongType{} ]\n```", "```r\ntrain_ids <- sample(\n 1:length(ds),\n size = 0.6 * length(ds)\n)\nvalid_ids <- sample(\n setdiff(\n 1:length(ds),\n train_ids\n ),\n size = 0.2 * length(ds)\n)\ntest_ids <- setdiff(\n 1:length(ds),\n union(train_ids, valid_ids)\n)\n\nbatch_size <- 128\n\ntrain_ds <- dataset_subset(ds, indices = train_ids)\ntrain_dl <- dataloader(\n train_ds,\n batch_size = batch_size, shuffle = TRUE\n)\n\nvalid_ds <- dataset_subset(ds, indices = valid_ids)\nvalid_dl <- dataloader(\n valid_ds,\n batch_size = batch_size\n)\n\ntest_ds <- dataset_subset(ds, indices = test_ids)\ntest_dl <- dataloader(test_ds, batch_size = 64)\n\nb <- train_dl %>%\n dataloader_make_iter() %>%\n dataloader_next()\n\ndim(b$x)\n```", "```r\n[1] 128   1 257 101\n```", "```r\nmodel <- nn_module(\n initialize = function() {\n self$features <- nn_sequential(\n nn_conv2d(1, 32, kernel_size = 3),\n nn_batch_norm2d(32),\n nn_relu(),\n nn_max_pool2d(kernel_size = 2),\n nn_dropout2d(p = 0.2),\n nn_conv2d(32, 64, kernel_size = 3),\n nn_batch_norm2d(64),\n nn_relu(),\n nn_max_pool2d(kernel_size = 2),\n nn_dropout2d(p = 0.2),\n nn_conv2d(64, 128, kernel_size = 3),\n nn_batch_norm2d(128),\n nn_relu(),\n nn_max_pool2d(kernel_size = 2),\n nn_dropout2d(p = 0.2),\n nn_conv2d(128, 256, kernel_size = 3),\n nn_batch_norm2d(256),\n nn_relu(),\n nn_max_pool2d(kernel_size = 2),\n nn_dropout2d(p = 0.2),\n nn_conv2d(256, 512, kernel_size = 3),\n nn_batch_norm2d(512),\n nn_relu(),\n nn_adaptive_avg_pool2d(c(1, 1)),\n nn_dropout2d(p = 0.2)\n )\n\n self$classifier <- nn_sequential(\n nn_linear(512, 512),\n nn_batch_norm1d(512),\n nn_relu(),\n nn_dropout(p = 0.5),\n nn_linear(512, 30)\n )\n },\n forward = function(x) {\n x <- self$features(x)$squeeze()\n x <- self$classifier(x)\n x\n }\n)\n```", "```r\nmodel <- model %>%\n setup(\n loss = nn_cross_entropy_loss(),\n optimizer = optim_adam,\n metrics = list(luz_metric_accuracy())\n )\n\nrates_and_losses <- model %>%\n lr_finder(train_dl)\nrates_and_losses %>% plot()\n```", "```r\nfitted <- model %>%\n fit(train_dl,\n epochs = 50, valid_data = valid_dl,\n callbacks = list(\n luz_callback_early_stopping(patience = 3),\n luz_callback_lr_scheduler(\n lr_one_cycle,\n max_lr = 1e-2,\n epochs = 50,\n steps_per_epoch = length(train_dl),\n call_on = \"on_batch_end\"\n ),\n luz_callback_model_checkpoint(path = \"models_baseline/\"),\n luz_callback_csv_logger(\"logs_baseline.csv\")\n ),\n verbose = TRUE\n )\n\nplot(fitted)\n```", "```r\n\"epoch\",\"set\",\"loss\",\"acc\"\n\n1,\"train\",3.34194613126368,0.0687577255871446\n1,\"valid\",3.08480389211692,0.137438195302843\n2,\"train\",2.87943273042542,0.161155747836836\n2,\"valid\",2.54789054393768,0.260275030902349\n3,\"train\",2.42715575726204,0.279048207663782\n3,\"valid\",2.08232365753136,0.417567985166873\n...\n...\n30,\"train\",0.397343056799929,0.880098887515451\n30,\"valid\",0.3777267414273,0.895395550061805\n31,\"train\",0.395276123743042,0.880073135558302\n31,\"valid\",0.375300966641482,0.895781829419036\n32,\"train\",0.387298851523524,0.880691182529872\n32,\"valid\",0.379925572989034,0.89323238566131\n```", "```r\nevaluate(fitted, test_dl)\n```", "```r\nloss: 0.3776\nacc: 0.8898\n```", "```r\npreds_baseline <- predict(fitted, test_dl)\npreds_baseline <-\n torch_argmax(preds_baseline, dim = 2) %>%\n as.numeric()\n\ntest_dl <- dataloader(\n test_ds,\n batch_size = length(test_ds)\n)\nb <- test_dl %>%\n dataloader_make_iter() %>%\n dataloader_next()\ntargets_baseline <- b$y$to(device = \"cpu\") %>%\n as.numeric()\n\ndf_baseline <- data.frame(\n preds = preds_baseline,\n targets = targets_baseline\n)\n\nclasses <- speechcommand_ds$classes\n\ndf <- df_baseline %>%\n mutate(correct = preds == targets) %>%\n mutate(\n preds = classes[preds],\n targets = classes[targets]\n ) %>%\n count(preds, targets, correct)\n\nlibrary(alluvial)\nalluvial(\n df %>% select(preds, targets),\n freq = df$n,\n col = ifelse(df$correct, \"#d1d1d1\", \"#aaaaaa\"),\n border = ifelse(df$correct, \"#d1d1d1\", \"#aaaaaa\"),\n hide = df$n < nrow(df_baseline) / 1000\n)\n```", "```r\nfb <- functional_create_fb_matrix(\n n_freqs = 257,\n f_min = 0,\n f_max = 8000,\n n_mels = 16,\n sample_rate = 16000\n)\ndim(fb)\n```", "```r\n[1] 257  16\n```", "```r\ndf <- as_tibble(as.matrix(fb)) %>%\n rowid_to_column(\"x\")\n\ndf %>%\n pivot_longer(!x) %>%\n ggplot(\n aes(x = x, y = value, color = name, group = name)\n ) +\n geom_line() +\n xlab(\"Fourier coefficient\") +\n ylab(\"Contribution to Mel coefficient\") +\n theme_minimal() +\n theme(legend.position = \"None\")\n```", "```r\nsample_spec <- ds[2000]$x\nwin_31 <- sample_spec[1, , 31]\n\nmel_31 <- win_31$unsqueeze(2) %>%\n functional_mel_scale(n_mel = 128)\n\ndf <- data.frame(\n coefficient = 1:128,\n fourier = as.numeric(win_31[1:128]),\n mel = as.numeric(mel_31)\n)\n\ndf %>%\n pivot_longer(\n !coefficient,\n names_to = \"type\", values_to = \"magnitude\"\n ) %>%\n ggplot(\n aes(x = coefficient, y = magnitude, color = type)\n ) +\n geom_line() +\n theme_minimal()\n```", "```r\nfb <- functional_create_fb_matrix(\n n_freqs = 257,\n f_min = 0,\n f_max = 8000,\n n_mels = 128,\n sample_rate = 16000\n)\n\n(fb$t()$matmul(win_31) - mel_31[1, , 1]) %>%\n torch_max()\n```", "```r\ntorch_tensor\n5.96046e-08\n[ CPUFloatType{} ]\n```", "```r\nds <- spectrogram_dataset(\n root = \"~/.torch-datasets\",\n url = \"speech_commands_v0.01\",\n download = TRUE,\n n_mels = 128\n)\n```", "```r\n\"epoch\",\"set\",\"loss\",\"acc\"\n1,\"train\",3.35417570164001,0.0639678615574784\n1,\"valid\",3.03987254348456,0.142228059332509\n2,\"train\",2.6629929004931,0.220874536464771\n2,\"valid\",2.20017999761245,0.367815203955501\n3,\"train\",2.03871287512623,0.400262669962917\n3,\"valid\",1.56310861835293,0.559100741656366\n...\n...\n17,\"train\",0.534631294167899,0.838715492377421\n17,\"valid\",0.524456901585355,0.854063658838072\n18,\"train\",0.526362751336659,0.840801400906469\n18,\"valid\",0.58039141460961,0.839076019777503\n19,\"train\",0.511069792840216,0.847059126493613\n19,\"valid\",0.511746386686961,0.858544499381953\n```", "```r\nevaluate(fitted, test_dl)\n```", "```r\nloss: 0.5081\nacc: 0.8555\n```", "```r\nds <- spectrogram_dataset(\n root = \"~/.torch-datasets\",\n url = \"speech_commands_v0.01\",\n download = TRUE,\n power = NULL\n)\n\ndim(ds[1]$x)\n```", "```r\n[1]   2 257 101\n```", "```r\nmodel <- nn_module(\n initialize = function() {\n self$features <- nn_sequential(\n nn_conv2d(2, 32, kernel_size = 3),\n nn_batch_norm2d(32),\n nn_relu(),\n nn_max_pool2d(kernel_size = 2),\n nn_dropout2d(p = 0.2),\n nn_conv2d(32, 64, kernel_size = 3),\n nn_batch_norm2d(64),\n nn_relu(),\n nn_max_pool2d(kernel_size = 2),\n nn_dropout2d(p = 0.2),\n nn_conv2d(64, 128, kernel_size = 3),\n nn_batch_norm2d(128),\n nn_relu(),\n nn_max_pool2d(kernel_size = 2),\n nn_dropout2d(p = 0.2),\n nn_conv2d(128, 256, kernel_size = 3),\n nn_batch_norm2d(256),\n nn_relu(),\n nn_max_pool2d(kernel_size = 2),\n nn_dropout2d(p = 0.2),\n nn_conv2d(256, 512, kernel_size = 3),\n nn_batch_norm2d(512),\n nn_relu(),\n nn_adaptive_avg_pool2d(c(1, 1)),\n nn_dropout2d(p = 0.2)\n )\n\n self$classifier <- nn_sequential(\n nn_linear(512, 512),\n nn_batch_norm1d(512),\n nn_relu(),\n nn_dropout(p = 0.5),\n nn_linear(512, 30)\n )\n },\n forward = function(x) {\n x <- self$features(x)$squeeze()\n x <- self$classifier(x)\n x\n }\n)\n```", "```r\n\"epoch\",\"set\",\"loss\",\"acc\"\n1,\"train\",3.09768574611813,0.12396992171405\n1,\"valid\",2.52993751740923,0.284378862793572\n2,\"train\",2.26747255972008,0.333642356819118\n2,\"valid\",1.66693911248562,0.540791100123609\n3,\"train\",1.62294889937818,0.518464153275649\n3,\"valid\",1.11740599192825,0.704882571075402\n...\n...\n38,\"train\",0.18717994078312,0.943809229501442\n38,\"valid\",0.23587799138006,0.936418417799753\n39,\"train\",0.19338578602993,0.942882159044087\n39,\"valid\",0.230597475945365,0.939431396786156\n40,\"train\",0.190593419024368,0.942727647301195\n40,\"valid\",0.243536252455384,0.936186650185414\n```", "```r\nevaluate(fitted, test_dl)\n```", "```r\nloss: 0.2373\nacc: 0.9324\n```"]