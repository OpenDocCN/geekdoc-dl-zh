- en: 6 生成式人工智能背后的技术
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'DOI: [10.4324/9781003459026-6](https://dx.doi.org/10.4324/9781003459026-6)'
  prefs: []
  type: TYPE_NORMAL
- en: 大型集中式人工智能模型让人们感到惊讶。个人、便携和安全的AI将使每个人都变得非凡。
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 托姆·科洛顿
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 6.1 简介
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 本章的目标是使读者对生成式人工智能（GenAI）背后的技术有一个更清晰的理解。虽然本书主要关注高等教育中的GenAI，但我们认识到，一些读者可能对GenAI的“黑箱”感兴趣。因此，我们将深入探讨其历史、过程、方法和GenAI的基础技术。在这项探索中，读者将遇到在人工智能（AI）领域常用的术语。
  prefs: []
  type: TYPE_NORMAL
- en: 在本章中，我们将讨论生成式人工智能模型，以下将简称为“模型”。至关重要的是不要将这些模型与其他书中提到的其他类型的模型混淆，例如评估模型。当代的生成式人工智能系统主要采用深度神经网络（DNN）作为其模型的基础方法。如图6.1所示，DNN是一种人工神经网络（ANN）。使用人工神经网络（ANNs）的概念在AI中有着深厚的根源，它从对生物大脑功能的研究中汲取灵感。我们将更深入地探讨这一历史，提供引领到当今最先进模型的前置背景。如图6.1所示，生成式人工智能及其各种模型类型，包括大型语言模型（LLMs）和扩散模型等文本到图像模型，都位于深度学习人工神经网络（ANNs）的领域内。
  prefs: []
  type: TYPE_NORMAL
- en: '![人工智能类别包括人工智能、机器学习、人工神经网络、深度学习和生成式人工智能，后者包括LLM和文本到图像。](images/fig6_1_B.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '[图6.1 人工智能分类。](#R_fig6_1)'
  prefs: []
  type: TYPE_NORMAL
- en: '**人工神经网络（ANNs）**是受人类大脑结构和功能启发的计算模型。它们由相互连接的节点组成，称为神经元，通过加权连接处理和传输信息。ANNs被设计用来从输入数据中学习和识别模式，这使得它们在诸如计算机视觉、自然语言处理和机器人学等领域的分类、预测和决策等任务中非常有用。本章将深入探讨支撑这些能力的过程和技术。'
  prefs: []
  type: TYPE_NORMAL
- en: 神经网络存储经验和利用它们进行预测的精确机制仍然有些神秘。这种难以捉摸的性质导致一些人将它们的运作描述为“魔法”，因为其完整的复杂性以及潜在的局限性尚未完全被理解。本章将尝试分享关于这些模型如何工作已知和尚未理解的内容。
  prefs: []
  type: TYPE_NORMAL
- en: 本章涉及检查目前流行且广泛使用的特定GenAI解决方案。它将详细探讨这些特定示例，同时参考更广泛的方法。通过将具体示例与一般概念并置，我们旨在为非专业人士提供一个比仅仅泛泛而谈该主题更为深刻的视角。
  prefs: []
  type: TYPE_NORMAL
- en: 本章的结构旨在促进逐步理解，尽可能在早期概念的基础上构建后续概念。然而，有些主题是相互关联的，需要更多的迭代方法，而不是纯粹的信息线性阅读，因此建议从头到尾阅读本章，然后重新阅读以获得对这些需要更多迭代方法的概念的更深入理解。
  prefs: []
  type: TYPE_NORMAL
- en: 本章的结构概述如下：
  prefs: []
  type: TYPE_NORMAL
- en: '**历史**。本节探讨了人工神经网络（ANNs）的历史，早期的工作以及一些最近的进展。'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**创建模型**。本节旨在提供一个全面的理解，了解模型是如何运作的，以及其创建过程中涉及到的各种步骤。它考察了模型创建的各个阶段：从收集大量数据到设计结构和考虑；训练阶段；以及测试模型的质量、性能和安全。'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**模型和生态系统**。本节探讨了模型的使用方式以及围绕它们建立起来的生态系统，允许人们以不同的方式与模型互动，并允许模型与其环境互动。'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**最先进的模型**。本节旨在概述一些目前被认为是最先进的流行模型。它考察了这些模型的应用，讨论了它们的设计方法，并对其优缺点进行了评论。'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**结论**。本节总结了GenAI的关键点，并反思了其当前应用的边界。'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 6.2 历史
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 接下来的几节将按时间顺序介绍人工神经网络（ANNs）的历史。你可能会遇到一些尚未讨论或详细阐述的术语，例如人工神经元或细胞的细节、人工神经网络中的连接性、层的概念以及权重和偏差的作用。然而，这些复杂性将在适当的时候得到解决。最初，我们的重点是提供一个这些概念如何发展的时间顺序概述。稍后，我们将深入探讨细节，强调那些至今仍相关的方面，同时使用当代术语。
  prefs: []
  type: TYPE_NORMAL
- en: 人工智能研究的历史可以理解为几种不同方法或“阵营”之间不断演变的相互作用。这些不同的方法通常反映了人工智能创始人多样化的知识背景，并受到可用技术、主流科学范式和更广泛的社会趋势的影响。其中两个阵营是符号主义者和连接主义者。
  prefs: []
  type: TYPE_NORMAL
- en: 符号主义者认为，通过操纵符号和规则可以获得智能。他们的方法包括基于逻辑的系统、基于规则的专家系统和语义网络。这个阵营中的关键人物包括约翰·麦卡锡、马文·明斯基和赫伯特·西蒙。他们的主要焦点是确定理解、逻辑和推理的基本规则如何在机器中表达，以及这些基本规则包含什么。
  prefs: []
  type: TYPE_NORMAL
- en: 连接主义者认为，智能是从简单单元相互连接的网络中产生的，这些单元通常被称为细胞或神经元。他们的方法以神经网络和深度神经网络为例，包括RNN（循环神经网络）、CNN（卷积神经网络）和Transformer等多样化的架构。这个阵营中的知名人物包括弗兰克·罗森布拉特、杰弗里·辛顿、杨立昆、詹姆斯·鲁梅尔哈特和詹姆斯·麦克莱兰德。他们的主要焦点是确定机器如何学习必要的规则，如何训练该机器，以及如何构建其架构以促进学习，使其尽可能全面。
  prefs: []
  type: TYPE_NORMAL
- en: 我们将在稍后更详细地讨论这两个阵营。
  prefs: []
  type: TYPE_NORMAL
- en: 重要的是要认识到，在这次讨论的范围之外，人工智能的其他领域也取得了进步。[图6.2](#fig6_2)展示了人工智能在游戏中的应用；值得注意的是，许多这些里程碑直到最近才使用ANN（人工神经网络）。在特定情况下，例如国际象棋，有人争论ANN是否甚至能够与基于规则的途径相匹配，尤其是在它被认为是一个“已解决”的游戏的情况下。在此背景下，我们的主要焦点是ANN，因此是ANN在自然语言处理（NLP）、图像识别和生成以及某些游戏场景中表现优异的挑战类型。尽管如此，人工智能涵盖了一个广泛的领域，其中许多领域至关重要；然而，并非所有内容都会在这里讨论。
  prefs: []
  type: TYPE_NORMAL
- en: '![从1947年到2023年的时间线，展示了人工智能和游戏的发展。](images/fig6_2_B.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '[图6.2 人工智能和游戏时间线](#R_fig6_2)'
  prefs: []
  type: TYPE_NORMAL
- en: 当我们踏上探索人工智能（AI）丰富历史的旅程，并密切关注ANN时，了解这个领域的演变阶段非常重要。这次旅程不仅简化了我们的理解，而且提供了一个有组织的视角，通过这个视角我们可以欣赏人工智能所经历的里程碑、挑战和快速创新。因此，历史被划分为三个阶段。
  prefs: []
  type: TYPE_NORMAL
- en: '**创世阶段（1940年代–1980年代）**：这是人工智能的诞生。在这一时期，奠定了基础理念。将这些视为人工智能的奠基年份，先驱们为舞台搭建，开发了最初的算法和概念。这一时期许多想法成为了后来创新的基础。参见[图6.4](#fig6_4)了解创世阶段的关键里程碑。![从1947年到2023年的硬件发展时间线以及从1947年到2033年的人工智能时期时间线](images/fig6_3_B.jpg)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[图6.3 人工智能时期和硬件发展](#R_fig6_3)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![关于创世阶段和出版物及模型的时间线，从1947年到1994年](images/fig6_4_B.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: '[图6.4 创世阶段（1940年代至1980年代）- 出版物和模型](#R_fig6_4)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**成熟阶段（1980年代–2010年代）**：在诞生之后，人工智能经历了一个成长和成熟的过程。在这一时期，创世阶段的基础理念得到了细化、扩展并在各种应用中得到实施。概念变得更加清晰，工具也更加复杂。这是一个探索、巩固和实际应用的时代。参见[图6.5](#fig6_5)了解成熟阶段的关键里程碑。![关于成熟阶段和出版物及模型的时间线，从1980年到2010年](images/fig6_5_B.jpg)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[图6.5 成熟阶段（1980年代至2010年代）- 出版物和模型](#R_fig6_5)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**加速阶段（2010年代–2030年代）**：进入当前时代，我们看到人工智能的能力和应用发生了爆炸式增长。得益于计算能力的提升、数据可用性的增加和算法的改进，人工智能，尤其是人工神经网络，现在正以前所未有的速度发展，我们预计这种趋势将持续相当长一段时间。这一阶段捕捉了创新的风暴，以及人工智能对我们生活的几乎每一个方面的变革性影响。在这一阶段的末期，我们预计人工智能将被整合并应用于社会。目前尚不清楚这个画面将是什么样子，但对这个未来的期待推动了当前的研究和应用努力。关于未来可能的样子，我们邀请您阅读[第7章](ch7.xhtml)中的一些预测。参见[图6.6](#fig6_6)了解加速阶段的关键里程碑。![关于加速阶段和出版物及模型的时间线，从2010年到2023年](images/fig6_6_B.jpg)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[图6.6 加速阶段（2010年代至2030年代）- 出版物和模型](#R_fig6_6)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 通过将人工智能和人工神经网络的历史划分为这三个不同的阶段，读者将更容易消化信息，理解当前人工智能发展的背景，并快速参考最近和最相关的进步，这些进步塑造了我们与技术的日常互动。
  prefs: []
  type: TYPE_NORMAL
- en: '[图6.3](#fig6_3)有助于描绘这些阶段以及它们与人工智能历史中通常提到的时期（如人工智能寒冬和人工智能繁荣时期）的关系。它还突出了促进该领域进步的一些关键硬件进步。以下各节将分别讨论这些阶段。'
  prefs: []
  type: TYPE_NORMAL
- en: 随着我们深入到每个阶段，我们将揭示那些使人工智能成为今天如此强大力量的故事、挑战、突破和先驱。
  prefs: []
  type: TYPE_NORMAL
- en: 6.2.1 创世阶段（1940年代–1980年代）
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 6.2.1.1 新研究领域
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 在人工智能的最早阶段，人们希望构建能够通过学习解决问题的机器，类似于大脑的工作方式。这种方法与明确编程机器解决特定问题的方法在本质上不同。为了构建这些机器，科学家们研究了动物大脑，以了解其生物模型。这可以从[McCulloch和Pitts
    (1943)](#ref6_42)关于建模神经元的作品中看出，也可以从[Hebb (1949)](#ref6_24)关于赫布学习的工作中看出。这些作品，以及神经生理学和心理学领域的其他人的贡献，被数学、统计理论、信息科学和计算机科学（当时信息科学和计算机科学都处于起步阶段）领域的人所使用。
  prefs: []
  type: TYPE_NORMAL
- en: 考虑到这些生物模型的可获得性和在这些领域进行的广泛研究，预测迅速解决那些显式编程难以解决的问题（如模式识别、推理、语言的理解和使用）似乎是合理的。
  prefs: []
  type: TYPE_NORMAL
- en: 6.2.1.2 符号主义者
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 1955年，麦卡锡与Marvin Minsky、Nathaniel Rochester和Claude Shannon共同起草了一份提案，提议在1956年夏天在达特茅斯学院举办研讨会。这次研讨会的首要目标是：
  prefs: []
  type: TYPE_NORMAL
- en: 将尝试找出如何让机器使用语言、形成抽象和概念、解决目前仅限于人类解决的问题，并自我改进。
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ([麦卡锡等人，1955](#ref6_40)，第1页)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 这个研讨会被广泛认为是人工智能作为正式学术学科的诞生。达特茅斯研讨会是首次使用“人工智能”一词的场合，这个术语是由麦卡锡本人提出的。
  prefs: []
  type: TYPE_NORMAL
- en: 达特茅斯与会者的乐观情绪很高。他们真诚地相信，通过夏天的专注努力，他们可以取得重大进展，实现机器智能。这在很大程度上反映了20世纪50年代普遍存在的对技术和计算机的乐观态度。他们认为，现有的计算能力应该足以完成他们的任务。他们认为的主要挑战，正如他们所看到的，是开发适当的算法和程序指令来指导机器。
  prefs: []
  type: TYPE_NORMAL
- en: 这个群体受到了后来被称为“符号主义”的人工智能学派的影响很大。正如所提到的，符号主义者认为智能源于符号的操作，并且可以通过基于规则的系统和形式推理来实现。这与其他范式形成鲜明对比，例如试图复制神经网络联结主义方法和从达尔文过程汲取灵感的进化方法。
  prefs: []
  type: TYPE_NORMAL
- en: 这种符号主义方法体现在早期的AI项目中，如逻辑理论家和通用问题求解器，它们旨在通过符号操作模拟人类解决问题的能力。
  prefs: []
  type: TYPE_NORMAL
- en: 回顾过去，尽管达特茅斯研讨会没有在短短一个夏天内实现其宏伟目标，但它标志着一个新的、变革性领域的发展。这次活动催化了研究，并为人工智能设定了多年的方向。尽管我们现在认识到实现类似人类的AI的挑战比McCarthy及其同事最初想象的要复杂得多，但他们的愿景、雄心和基础工作为人工智能领域奠定了基础。
  prefs: []
  type: TYPE_NORMAL
- en: 6.2.1.3 联结主义者
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 人工智能的联结主义者，通常与人工神经网络（ANNs）的开发和研究相关联，从人脑错综复杂的神经元网络中汲取灵感来设计计算模型。这些模型旨在模拟大脑识别模式、处理信息和从经验中学习的能力。与依赖于显式规则做出决策的传统符号人工智能不同，联结主义采用自下而上的方法。通过调整众多简单处理节点（类似于神经元）之间的连接（或权重），联结主义者相信复杂的认知可以自然地产生。自从它们诞生以来，ANNs和联结主义范式就经历了热情和怀疑的浪潮。然而，随着近年来计算能力和算法技术的进步，联结主义已经成为人工智能许多突破性成就的核心，尤其是在深度学习和图像、语音识别等领域。
  prefs: []
  type: TYPE_NORMAL
- en: 在人工智能的早期，天际线上出现了一线希望的曙光，人们相信“神经网络”可能正是解决人工智能一些最令人困惑问题的答案。其中就包括一个引人入胜的问题：“如何安排一组假设的神经元以形成概念？”像Uttley、Rashevsky及其团队，Farley和Clark这对搭档，以及Pitts、McCulloch、Minsky、Rochester和Holland等先驱学者都沉迷于破解这个谜团。尽管他们做出了广泛而多样的贡献，但共识始终是：该领域迫切需要更多的理论深度（[McCarthy等，1955](#ref6_40)）。
  prefs: []
  type: TYPE_NORMAL
- en: 人工神经网络(ANNs)的遗产与人工智能的历史紧密相连。这些网络可能看起来很现代，但它们自人工智能诞生以来一直是人工智能研究的基础。标志性的达特茅斯夏季项目确实是一个里程碑，但在此事件之前，麦卡洛克和他的同事们就已经进入了神经领域。他们的1943年出版物《神经活动内在逻辑的逻辑演算》([McCulloch
    et al., 1943](#ref6_42))提出了一种前卫的观点：神经元可以用简单的开关来模拟，当以独特的排列连接时，可以复制图灵机的逻辑。
  prefs: []
  type: TYPE_NORMAL
- en: 然而，直到1958年，感知器这个现在与人工智能同义的术语才诞生。1958年，弗兰克·罗森布拉特在他的论文中提到了它([Rosenblatt, 1958](#ref6_58))。想象一下，它就像一个拥有不同部分协同工作的微型大脑，类似于现代的ANNs。这个微型大脑有不同类型的单元，被称为S单元、A单元和R单元，它们构成了一个基本的两层网络。尽管在当时，人们认为它是一个“三层网络”。罗森布拉特称之为“光感知器”，它被设计用来识别照片中的物体，如圆形和矩形([Rosenblatt,
    1957](#ref6_57))。
  prefs: []
  type: TYPE_NORMAL
- en: 20世纪60年代，感知器的蓝图被采纳并扩展。 Widrow 和 Hoff 创造了 ADALINE ([Widrow, 1960](#ref6_81))
    和 MADALINE ([Widrow, 1962](#ref6_82))，采用新颖的算法来微调权重和偏差，为现代前馈网络奠定了基础。Block 和他的团队([Block
    et al., 1962](#ref6_8))向感知器模型添加了一层，将其推进到深度神经网络领域。他们的模型旨在进行更广泛的目标分类，然而，训练这个改进的网络很困难，因为当时还没有好的方法来纠正多层网络中的错误。
  prefs: []
  type: TYPE_NORMAL
- en: 然而，到了1969年，一个警示故事出现了。明斯基和其他人出版了《感知器：计算几何导论》([Minsky & Papert, 1988](#ref6_45))，强调了感知器的数学局限性。这本书特别审视了单层感知器，并对它在解决复杂挑战中的潜力表示怀疑。
  prefs: []
  type: TYPE_NORMAL
- en: 1985年，鲁梅尔哈特和他的团队介绍了一种新技术，帮助教授多层机器。这种方法在学习过程中纠正错误，为我们现在所说的深度学习打开了大门。尽管如此，我们还没有足够强大的计算机来充分利用这项新技术。值得注意的是，保罗·韦伯斯更早的博士论文([Werbos,
    1974](#ref6_80))已经预见了鲁梅尔哈特的工作，为反向传播奠定了基础。
  prefs: []
  type: TYPE_NORMAL
- en: 令人好奇的是，明斯基和帕佩特在他们早期书籍的扩展版中([Minsky & Papert, 1988](#ref6_45))，批判性地回顾了诸如鲁梅尔哈特和麦克莱兰德所取得的进步。尽管他们承认了进步，但他们认为这些主张，尤其是关于梯度下降效率和广义delta规则的主张，被过度夸大了。这些辩论和意见分歧提醒我们，像韦泽鲍姆这样的思想家在20世纪70年代发出的谨慎警告（参见下一节关于哲学问题的内容），警告人们不要过早地过于兴奋。
  prefs: []
  type: TYPE_NORMAL
- en: 随着时间的推移，即使有了像这种新的教学方法——反向传播这样的进步，人工神经网络的大希望也开始消退。这导致了被称为“人工智能冬天”的时期，人们对人工智能失去了兴趣，没有在人工智能上投入太多。但，就像往常一样，在寒冷的冬天之后，事情在春天往往会再次回暖。
  prefs: []
  type: TYPE_NORMAL
- en: 6.2.1.4 哲学和伦理考虑
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 6.2.1.4.1 图灵测试 – 艾伦·图灵
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 关于机器能否思考的哲学问题在早期就出现了。1950年，艾伦·图灵在他的论文“计算机与智能”([Turing, 1950](#ref6_73))中讨论了这个问题。图灵没有直接问“机器能思考吗？”而是提出了一个替代方法。他建议一个游戏，他称之为“模仿游戏”。这个游戏衡量了机器欺骗审问者的可能性与真实人做同样事情的概率，仅依靠问答格式中的书面交流。这个挑战随后成为著名的图灵测试。
  prefs: []
  type: TYPE_NORMAL
- en: 6.2.1.4.2 机器人三大定律 – 艾萨克·阿西莫夫
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 在关于机器智能的伦理考虑的相关发展中，科幻作家和生物化学教授艾萨克·阿西莫夫在1942年提出了“机器人三大定律”。这些定律出现在他的短篇小说“Runaround”中，这是“我，机器人”系列的一部分([Asimov,
    1950](#ref6_4))，如[第5章](ch5.xhtml)中提到的。
  prefs: []
  type: TYPE_NORMAL
- en: 机器人不得伤害人类，或者，通过不作为，让人类受到伤害。
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 机器人必须服从人类给予它的命令，除非这些命令与第一定律相冲突。
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 机器人必须保护自己的存在，只要这种保护不与第一或第二定律相冲突。
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 6.2.1.4.3 计算机力量与人类理性 – 约瑟夫·韦泽鲍姆
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '约瑟夫·韦泽鲍姆，ELIZA聊天机器人的创造者，以及《计算机力量与人类理性：从判断到计算》(*Computer Power and Human Reason:
    From Judgment to Calculation*, [1976](#ref6_78))的作者，越来越警惕计算机技术的扩张影响。他认为机器不应该处理需要真正同情心的任务，强调它们无法行使人类判断力，区分单纯的决策和真正的选择。'
  prefs: []
  type: TYPE_NORMAL
- en: 在20世纪70年代，对计算机复制人类思维的怀疑情绪很普遍。许多人认为，人工智能界做出了过于雄心勃勃的承诺。在他的书中，Weizenbaum深入探讨了人工智能被过度炒作的期望以及人们与人工智能系统形成的令人不安的情感纽带。他还表达了对社会日益依赖技术的担忧。正如我们将看到的，这些雄心勃勃的声明将继续成为人工智能世界的主要辩论话题。
  prefs: []
  type: TYPE_NORMAL
- en: 6.2.1.4.4 控制论之父 – 诺伯特·维纳
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '此外，常被称为“控制论之父”的诺伯特·维纳（Norbert Wiener）在他的著作《上帝与哥莱姆，公司：关于控制论对宗教的影响的几点评论》（“God
    & Golem, Inc.: A Comment on Certain Points where Cybernetics Impinges on Religion”）([Wiener,
    1966](#ref6_83))中表达了对自动化可能带来意外后果的担忧。他提出，一旦我们能够有效地复制人类的决策过程，对这些创新的管理就必须极端谨慎。为了说明这一点，他引用了《猴爪》的故事，强调在不完全理解的情况下掌握权力可能导致灾难性的后果。'
  prefs: []
  type: TYPE_NORMAL
- en: 从20世纪40年代到80年代，人工智能领域经历了一段令人兴奋的旅程，为未来创新奠定了坚实的基础。人工神经网络（ANNs）的本质受到了我们大脑中神经元复杂网络的启发，这得益于像麦卡洛克（McCulloch）和皮茨（Pitts）这样的先驱者的开创性工作。随着岁月的推移，这种生物灵感与数学和统计严谨性的织锦交织在一起，确立了定义人工神经元如何在网络中交互和协作的证明和公式。到20世纪80年代，这项基础工作以反向传播和梯度下降等突破性学习技术的形式结出了果实。这些机制优化了ANNs的训练，使它们能够改进其性能并解决复杂问题。与此同时，这个时代也以深刻的哲学内省为标志，质疑人工智能的边界、它与意识的关系以及围绕其潜力的伦理问题。到20世纪80年代末，人工智能领域已经具备了必要的基石，为随后发生的转型做好了准备，包括像理查德·费曼（Richard
    Feynman）讨论的量子计算机概念（[Feynman, 1982](#ref6_17)），这些可能还有很长的路要走才能将它们的益处带给人工智能。
  prefs: []
  type: TYPE_NORMAL
- en: 6.2.2 成熟阶段（1980年代至2010年代）
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 在1980年代和2010年代之间，人工神经网络（ANNs）既面临挑战，也取得了关键性的进步。由于持续存在的问题，如梯度消失问题，对ANNs的初始热情已经减弱，但20世纪80年代带来了对领域复兴至关重要的关键创新。
  prefs: []
  type: TYPE_NORMAL
- en: Rumelhart、Hinton和Williams在1986年引入反向传播算法是一个里程碑式的事件(Rumelhart et al., [1986a](#ref6_61),
    [1986b](#ref6_62), [1986c](#ref6_63))。该算法优化了多层感知器的权重，激发了人们对人工神经网络的新一轮兴趣和研究。在此之后，该领域的领军人物LeCun、Bengio和Hinton做出了重大贡献。他们在这一阶段的工作为深度学习和下一个时代的变革性变化奠定了基础([Goodfellow
    et al., 2016](#ref6_22))。
  prefs: []
  type: TYPE_NORMAL
- en: 在20世纪90年代，神经网络的应用取得了重要进展。研究人员找到了将它们用于复杂数据分析的方法([Breiman, 2001](#ref6_9))，通过降低其复杂性来简化数据([Hinton
    et al., 2006](#ref6_27))，以及改进算法以获得更好的性能([Friedman, 2002](#ref6_18))。他们还开发了新的训练和管理神经网络的技术，如基于能量的模型([Ackley
    et al., 1985](#ref6_1))，并引入了新的神经网络细胞类型，例如长短期记忆(LSTM)，以解决梯度问题([Hochreiter & Schmidhuber,
    1997](#ref6_28))。此外，研究人员对支持向量机(SVM)和核方法有了更好的理解，这提高了鲁棒预测模型的创建([Wahba et al., 2002](#ref6_75))。随着LeCun的卷积神经网络(CNNs)在图像识别([LeCun
    et al., 1989](#ref6_37))和循环神经网络(RNNs)在序列数据([Hochreiter & Schmidhuber, 1997](#ref6_28))的引入，人工神经网络(ANNs)的巨大潜力逐渐被认识到。
  prefs: []
  type: TYPE_NORMAL
- en: 然而，深度人工神经网络的全部潜力受到了计算限制和全面标记数据集稀缺性的制约。尽管存在这些障碍，成熟阶段对于嵌入人工神经网络的重要性以及为随后加速阶段的重大进展奠定基础至关重要。
  prefs: []
  type: TYPE_NORMAL
- en: 6.2.3 加速阶段（2010年代至2030年代）
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 2010年代初，随着更大数据集的发展、计算能力的提升——尤其是GPU的计算能力，以及创新算法的推动，人工神经网络经历了重大的转变。在这方面，一篇引人注目的论文是Le等人撰写的“使用大规模无监督学习构建高级特征”，展示了精炼算法在推动人工神经网络能力方面的优势([Le
    et al., 2011](#ref6_36))。
  prefs: []
  type: TYPE_NORMAL
- en: 在这个时期，深度学习这一神经网络的高级应用领域成为了焦点。像Geoffrey Hinton、Yann LeCun和Yoshua Bengio这样的知名人物在这些演变中发挥了关键作用（Goodfellow等人，2016年[#ref6_22]）。一个突破性的时刻是AlexNet的创建，这是在Geoffrey
    Hinton的指导下，由Alex Krizhevsky设计的卷积神经网络（CNN）。2012年，AlexNet在图像识别基准ImageNet竞赛中取得了无与伦比的成绩，这被许多人称为“ImageNet时刻”（Krizhevsky等人，2012年[#ref6_33]）。
  prefs: []
  type: TYPE_NORMAL
- en: 这样的成功激励了整个科技行业。像谷歌和Facebook这样的公司不仅采用了神经网络研究，而且还做出了重大贡献。例如，谷歌在推荐系统方面的方法在“Wide
    & Deep Learning for Recommender Systems”一文中得到了阐述（Cheng等人，2016年[#ref6_12]），而Facebook通过神经网络在文本理解和用户建模方面取得了进展，如他们的研究所示（Joulin等人，2016年[#ref6_31]；Kaur等人，2021年[#ref6_32]）。
  prefs: []
  type: TYPE_NORMAL
- en: 随着这个十年的发展，神经网络的用途变得更加多样化。循环神经网络（RNNs），尤其是它们演化的形式，长短期记忆网络（LSTMs），成为处理序列数据的首选，并在自然语言处理和时间序列分析中找到了应用（Hochreiter等人，1997年[#ref6_28]）。同时，由Ian
    Goodfellow引入的生成对抗网络（GANs）改变了生成模型，使得图像合成和风格迁移等壮举成为可能（Goodfellow等人，2014年[#ref6_23]）。
  prefs: []
  type: TYPE_NORMAL
- en: 到2010年代末，Transformer架构的引入，如“Attention Is All You Need”论文中描述的，标志着另一个范式转变，尤其是在自然语言处理（NLP）领域。这篇论文为BERT和GPT变体等模型奠定了基础，包括OpenAI的ChatGPT-3.5和GPT
    4.0，重新定义了文本理解和生成（Vaswani等人，2017年[#ref6_74]）。
  prefs: []
  type: TYPE_NORMAL
- en: 随着2020年代的到来，神经网络（ANNs）的推动力不断增强。在少样本学习和自监督学习等领域取得的突破标志着该领域的持续进步。然而，随着人工智能能力的提升，伦理和社会问题也随之而来。这些问题在2023年3月未来生命研究所发布的公开信中得到了强调，该信呼吁暂停开发比GPT-4更先进的模型，并强调了需要采取更反思的方法来应对人工智能的快速进步（未来生命研究所，[2023a](#ref6_19)，[2023b](#ref6_20)）。
  prefs: []
  type: TYPE_NORMAL
- en: 尽管通往通用人工智能（AGI）或甚至人工超级智能（ASI）的道路仍然存在争议，但AI对社会和人类将产生的变革性作用是毋庸置疑的。此外，这种变革性作用很可能会因未来的进步而进一步加剧。正如理查德·费曼的命题，量子计算机可能在模拟复杂系统方面超越经典计算机([费曼，1982](#ref6_17))，这可能会将AI引向其下一个时代。确实，像实现量子霸权这样的里程碑，即量子设备超越其经典对应物，预示着一个未来，在那里AI潜力的界限可能会被重新定义([Arute等人，2019](#ref6_3))。
  prefs: []
  type: TYPE_NORMAL
- en: 6.3 创建模型
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 现在我们已经详细介绍了人工神经网络（ANNs）的历史，我们将把注意力转向创建GenAI模型的过程。这次讨论将侧重于最近的方法，并深入探讨在历史概述中先前概述的术语和进展。随着我们深入到模型创建和理解的探讨中，你将认识到在早期历史部分提到的某些关键人物和进展。
  prefs: []
  type: TYPE_NORMAL
- en: '[图6.7](#fig6_7)展示了创建模型的基本步骤。这个过程包括基础模型的训练和测试，然后进行微调。基础模型是一个初始的、未经训练的具有通用目的的模型（即）从数据中学习。许多基础模型经过微调以适应特定应用。例如，LLaMA-2（大型语言模型Meta
    AI）基础模型经过微调以实现聊天功能，从而产生了被称为LLaMA-2-chat的精细调整模型。这种微调涉及在特定数据上进一步训练基础模型，以实现更专门的目的，例如作为聊天机器人来回答用户查询或与用户进行对话。'
  prefs: []
  type: TYPE_NORMAL
- en: '![展示创建模型更大图景的模型图](images/fig6_7_B.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '[图6.7 创建模型 – 大图景](#R_fig6_7)'
  prefs: []
  type: TYPE_NORMAL
- en: 创建模型涉及的步骤包括：
  prefs: []
  type: TYPE_NORMAL
- en: 训练数据
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 数据收集和准备
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 数据集定制
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 基础模型
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 模型设计和结构化
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 模型训练
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 模型测试
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 微调
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 微调数据集定制
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 模型微调训练
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 模型测试
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 部署和使用
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 模型部署
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 模型监控
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 模型使用（又称推理）
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 微调可以采用各种训练技术，包括带有人类反馈的强化学习（RLHF），这将在下文讨论。以下各节将涵盖这些领域，以提供对这些内容的理解。
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.1 训练数据
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 综合模型创建过程的初始步骤是数据收集和准备。现代深度神经网络（DNNs），尤其是大型语言模型（LLMs），需要大量的训练数据。虽然有一些知名的数据源可用，但一些公司维护他们自己的独特存储库。像Meta、Google和Microsoft这样的知名实体由于提供多样化的服务，拥有大量的数据。同时，像OpenAI这样的公司已经涉足开发他们自己的数据源解决方案，例如网络爬虫工具GPTbot，它从网络上收集公开可访问的数据供OpenAI使用。
  prefs: []
  type: TYPE_NORMAL
- en: 在初步获取后，数据集可能需要进一步精炼以提高质量或更好地与特定模型的预期结果相匹配。收集和准备的过程通常与数据集定制交织在一起，尤其是在组织直接获取数据而不是依赖外部提供的数据集时。
  prefs: []
  type: TYPE_NORMAL
- en: 认识到数据收集、准备和定制阶段固有的复杂性和复杂性至关重要。为了更清晰地理解这些过程，将使用几个广泛使用的数据源作为例子进行更深入的探讨。
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.1.1 文本数据 – Common Crawl
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Common Crawl（见[https://commoncrawl.org/](https://commoncrawl.org)）([Patel, 2020](#ref6_49)）是一个定期提供数十亿网页数据转储的组织，通常每年6到12次。虽然它有一些可以追溯到2008年的数据，但自2011年以来，输出更加一致。Common
    Crawl使用一种称为爬虫机器人的工具来访问网页内容。爬虫机器人从一个URL列表开始，检索这些网页的内容。此外，它还可以识别网页内的其他URL（即指向不同网站的链接）并追踪这些链接以访问那些页面。对于每个访问的页面，爬虫机器人保存内容并识别其他要追踪的链接，向外扩展，就像蜘蛛网一样，涵盖其他URL。
  prefs: []
  type: TYPE_NORMAL
- en: CCBot，通常被称为通用爬虫机器人，为每一轮迭代处理候选URL数据库。它根据爬取过程中的发现更新此数据库中的新URL。虽然URL集合很大，但它们并没有经过严格的审查、组织或管理。因此，获得的数据质量可能差异很大，包括多种语言的内容。令人惊讶的是，一次爬取的输出与下一次爬取之间的重叠非常小。例如，2023年2月和6月的数据转储之间的重叠仅为大约1%（见[https://commoncrawl.github.io/cc-crawl-statistics/plots/crawloverlap](https://commoncrawl.github.io))）。
  prefs: []
  type: TYPE_NORMAL
- en: 每次发布的提供数据量确实令人震惊。例如，2023年6月的发布（CC-MAIN-2023-23）包含100个段。每个段包含800个WARC（大约1.1 GB压缩）、WAT（大约285
    MB压缩）和WET（大约115 MB压缩）格式的文件。包括各种元数据，2023年6月发布的压缩总大小约为120 TB。文本数据的压缩比有利，范围在3到5倍之间，导致未压缩大小约为580
    TB。然而，并非所有用户都需要每个格式。有些人可能只关注WET格式（纯文本），未压缩时仅占约26 TB。
  prefs: []
  type: TYPE_NORMAL
- en: Common Crawl的输出在内容和质量上都有所不同。当训练大型语言模型（LLM）时，这些数据会进行进一步的处理和清理，以提高其质量。专门设计的工具，如CCNet
    ([Wenzek等人，2019](#ref6_79))，可以帮助处理这些问题，尤其是在处理来自Common Crawl的输出时。例如，这些工具可以重新结构化文件，解压缩它们，并将它们分成碎片。然后，每个网页条目都存放在一个特定格式的‘json’文件中。数据去重发生在段落级别，并执行语言检测，使不同语言可以分别排序到不同的数据集中。其中一些步骤很复杂。以语言检测功能为例：它使用另一个语言模型fastText
    ([https://fasttext.cc/](https://fasttext.cc))，该模型在维基百科、Tatoeba和SETimes等替代数据源上预先训练，以识别Common
    Crawl输出的语言。[图6.8](#fig6_8)展示了数据收集和后处理阶段的复杂性。
  prefs: []
  type: TYPE_NORMAL
- en: '![一个类似于流程图的图表，展示了数据收集和定制管道中的过程。](images/fig6_8_B.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '[图6.8 数据收集和定制管道。](#R_fig6_8)'
  prefs: []
  type: TYPE_NORMAL
- en: 这并不是结束；其他模型也可以进行进一步的处理。例如，可以评估数据质量，并根据质量分数，具体数据可以被保留或从数据集中移除。在这种方式下使用的一个模型是5-gram
    Kneser-Ney模型，它使用困惑度度量来比较来自Common Crawl的输入与另一个被认为质量更高的来源，例如维基百科。
  prefs: []
  type: TYPE_NORMAL
- en: 困惑度是衡量特定段落内文本可预测性的度量。困惑度越高，模型越感到惊讶（或困惑），这表明在这个数据定制管道中的质量越低。如果某个段落的困惑度超过了一个特定的阈值，那么这个段落可能会从数据集中移除，目的是提高数据集的整体质量。你可能还记得，困惑度也用于[第4.7节](ch4.xhtml#sec4_7)中的GenAI文本检测。
  prefs: []
  type: TYPE_NORMAL
- en: 由于涉及的数据量巨大，执行这些预处理模型所需的复杂任务，以及定制过程在需要大量专业知识来构建和管理的专业数据处理环境中进行的事实，进行这项任务的成本相当高。
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.1.2 文本数据 – Colossal Clean Crawled Corpus (C4)
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Colossal Clean Crawled Corpus (C4)数据集来源于Common Crawl提供的存档（[Raffel等人，2023](#ref6_54)）。这个数据集经过各种过滤和格式化过程，以产生与使用TensorFlow运行时开发的模型兼容的版本。TensorFlow是构建和训练模型的重要且广泛使用的工具。过滤过程包括诸如去重和移除敏感词等任务。
  prefs: []
  type: TYPE_NORMAL
- en: 最初，谷歌创建了C4数据集用于自身使用。虽然他们提供了一份描述和一些工具，可以从Common Crawl输入中生成数据集，但他们并没有发布实际的数据集。认识到这个数据集的价值，另一家组织，艾伦人工智能研究所（参见[https://allenai.org/](https://allenai.org)；由已故的保罗·G·艾伦创立，微软的联合创始人），重新制作了C4数据集。他们与一家名为Hugging
    Face的公司（参见[https://huggingface.co/](https://huggingface.co)）合作，托管并使这个数据集对所有用户可访问。
  prefs: []
  type: TYPE_NORMAL
- en: 重新创建C4数据集不仅成本高昂（计算成本估计在数百到数千美元之间），而且还需要大量的专业知识和知识。
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.1.3 图像数据 – LAION-5B
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: LAION-5B图像数据集（参见[https://laion.ai/blog/laion-5b/](https://laion.ai)）([Schuhmann等人，2022](#ref6_67)）是一个为最先进（SOTA）模型训练设计的当代数据集。其主要目标是提供一个开放且易于访问的数据集，用于文本到图像模型训练。该数据集包含58.5亿个过滤的图像-文本对，其中23.2亿个是英语。
  prefs: []
  type: TYPE_NORMAL
- en: 这个数据集的基础是Common Crawl，从中提取了图像URL，随后使用现有的OpenAI CLIP（对比语言-图像预训练）模型进行了过滤（[Radford等人，2021](#ref6_50)）。这个过程产生了一个包含以下内容的数据库：a)
    23.2亿个英语图像-文本示例，b) 22.6亿个多语言示例，以及c) 12.7亿个与任何特定语言无关的示例（例如，与地点、产品等相关）。值得注意的是，这个数据集比其他类似的数据集要广泛得多。通过使其公开可访问，它促进了更大的透明度，特别是在与公开来源的大图像数据集相关的伦理考量方面。
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.1.4 图像数据 – LabelMe
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: LabelMe 数据集（见 [http://labelme.csail.mit.edu/](http://labelme.csail.mit.edu)）([Russell
    等人，2007](#ref6_64)；[Oliva，2001](#ref6_47)）的主要目标是提供一个在线标注工具，用于构建计算机视觉研究的图像数据集。用户可以注册账户，贡献标注，然后访问数据集进行他们的研究。这种方法促进了大量图像和标注的积累。重要的是，这些标注不仅仅是标签；用户可以在图像中定位并指定单个对象。因此，背景中的汽车、前景中的人、建筑物、道路以及图像中任何其他可见的组件都可以被明确标注。
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.1.5 其他来源
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 其他常用来源包括来自 GitHub 的数据存档，其中包含多种编程语言的开源软件实现；来自维基百科的存档，这是一个在线百科全书；来自 Project Gutenberg
    的发布，该网站托管超过 70,000 本不再受版权保护的书籍；以及来自“The Pile”的内容，这是一个由 22 个较小的数据集组成的混合体，最近因与版权书籍相关的问题而引起争议。
  prefs: []
  type: TYPE_NORMAL
- en: 存在着几个其他值得注意的数据源。例如，特斯拉拥有一个广泛的与驾驶相关的视频数据库，它利用这个数据库来训练其自动驾驶系统。ImageNet ([https://www.image-net.org/](https://www.image-net.org))
    提供了超过一百万张图片的庞大集合，每张图片都标有与图片内容相对应的名词；这个资源在推进计算机视觉和深度学习研究方面发挥了关键作用。另一个重要的来源是 COCO（上下文中的常见物体），它提供了用于训练的图像数据。CelebA
    作为名人图像的存储库，特别适用于面部识别任务。此外，还有专注于音频的数据集，如用于音乐的 MIDI 数据集；用于语音相关任务的 VCTK 数据集；以及用于视频动作识别的
    UCF101 数据集。
  prefs: []
  type: TYPE_NORMAL
- en: Google 提供了一个搜索各种类型数据集的有价值工具，可通过 [https://datasetsearch.research.google.com/](https://datasetsearch.research.google.com)
    访问。无论需要哪种特定数据集，都可能存在类似的集合，这个搜索工具旨在简化发现过程。
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.1.6 其他数据定制
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 每个这些数据集都有其从原始数据源获取、准备数据存档以及进一步处理以定制数据集以适应特定训练任务的方法。这些准备和定制步骤可能涉及与上述描述相似的过滤，但也可以包括不同类型的过滤和内容编辑以达到特定的目标。
  prefs: []
  type: TYPE_NORMAL
- en: 这种定制化的一个重要方面是按照最适合特定模型和预期训练策略的方式组织数据。模型的设计和结构，以及各种训练方法，将在后续章节中详细阐述。尽管如此，这些因素在确定必要的数据准备和定制化过程中起着至关重要的作用。
  prefs: []
  type: TYPE_NORMAL
- en: 一种常见的定制化涉及确保数据输入的大小与模型设计相匹配。这取决于模型处理的数据类型，无论是基于文本的输入还是基于图像的输入。对于语言模型，典型的输入大小包括可以作为一个单一单元输入系统的段落，通常大约有512个标记。标记类似于单词，我们将在稍后进行更详细的讨论。这些输入要么被分割，要么被填充以确保它们适合模型。随后，这些输入通常被分组到批次中，可能的大小为16、32或64。这些批次在训练期间通常独立处理，这有助于模型并行流的输入。所有批次的集合构成一个epoch，模型可能需要经过这些epochs的多次迭代以最大化训练效益。重要的是，在每个epoch迭代之间，批次通常会被随机打乱，以防止模型对序列做出未经证实的假设学习。
  prefs: []
  type: TYPE_NORMAL
- en: 最后一个考虑因素是将数据集划分为训练集和验证集。这一步骤对于确保模型准确无误且不会过度训练（或过度拟合）至关重要。过度拟合是指模型对训练数据学得很好，但在使用训练集以外的数据集进行测试时表现不佳。简而言之，它没有很好地推广。通常，数据集按照70%到30%的比例划分为训练集和测试集，测试集随机选择以避免与替代选择方法相关的问题。数据集的测试部分用于评估机器学习模型对新、未见数据的推广能力。虽然训练数据用于训练模型，但测试数据作为模型在训练期间从未见过的独立示例集。
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.2 模型设计和结构
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 显然，模型的设计和结构是一个复杂的话题，需要深厚的AI、深度神经网络以及相关的统计和数学概念的经验和理解。
  prefs: []
  type: TYPE_NORMAL
- en: 后续章节将探讨模型设计及其细微细节的关键考虑因素。正如所述，目标是提供影响模型的因素及其内部运作的见解。这将使读者能够深入了解特定主题或探索支撑这些设计考虑因素背后的统计和数学概念，这些内容我们在这本书中并未探讨。
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.2.1 人工神经元 – 权重、偏置和激活函数
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 人工神经元是具有输入和输出的简单结构。虽然可以有任意数量的输入，但输出是一个单一值。尽管输入可以变化，但它们会汇聚以产生这个单一的输出值。神经元通常被描绘为一个基本的圆圈，其中相关的输入和输出被展示出来，如图[图6.9](#fig6_9)所示。这种图形表示是一种基本类型的前馈细胞。为了更深入地理解神经元，可以深入了解细胞内部，如图[图6.9](#fig6_9)所示。
  prefs: []
  type: TYPE_NORMAL
- en: '![提供关于前馈细胞详尽信息的图表](images/fig6_9_B.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '[图6.9 前馈细胞](#R_fig6_9)'
  prefs: []
  type: TYPE_NORMAL
- en: 这引入了一些重要的概念：
  prefs: []
  type: TYPE_NORMAL
- en: '**权重**。每个权重只是一个数字；每个输入到神经元中的都有一个权重（数字）。这个数字的值在模型训练过程中会变化。一旦训练完成，它就是固定的。'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**偏置**。这只是一个数字，每个神经元都有一个。这个数字的值在模型训练过程中会变化。一旦训练完成，它就是固定的。'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**激活函数**。这是一种特殊的数学函数，有助于提高输出的有用性。有许多不同类型的激活函数。一些流行的类型包括sigmoid（用于旧模型，如长短期记忆网络），Tanh（用于旧模型，如序列到序列模型的隐藏层），ReLu（用于GPT3），和SwiGLU（用于LLaMA）。'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 在这种情况下，输入信号（表示为x[i]，它是一个数值）被乘以该输入对应的权重（w[i]）。对所有输入进行这种乘法运算，然后将结果相加（实际上得到的是乘积的总和）。随后，加上偏置（b），然后将得到的数值传递给激活函数。这个激活函数处理给定的值，产生一个也是数值的输出。如果这个神经元连接到多个其他神经元，那么从这个神经元发出的相同输出值将被传输到所有相互连接的神经元。因此，可以将神经元概念化为对一组输入值进行数学运算以产生输出值的操作，而这个数学运算是由另一组称为权重和偏置的值所指导的。
  prefs: []
  type: TYPE_NORMAL
- en: 这些权重和偏差将在模型训练的上下文中被重新审视。总的来说，它们被称为模型的参数。这是模型“记住”或存储信息的方式；这些数值包含了模型在训练阶段识别出的模式，并且可以随后用于做出预测。通常，模型会根据其拥有的参数数量进行基准测试，这源于假设参数数量越多，能力越强。然而，除了参数数量之外，还有其他几个因素会影响模型的有效性。这些包括所使用训练数据的质量、层数及其互连，以及部署的内部函数，如激活函数或乘积之和。
  prefs: []
  type: TYPE_NORMAL
- en: Meta AI的LLaMA-2（大型语言模型Meta AI）有几种尺寸变体：7B、13B和70B，其中‘B’代表十亿参数。OpenAI的ChatGPT-3.5拥有175B参数。虽然ChatGPT-4.0的尺寸尚未官方公布，但据推测其包含大约1.8T参数，其中‘T’代表万亿。Google的LaMDA（用于对话应用的语言模型）拥有高达137B参数。相比之下，Google的PaLM-2（路径语言模型）据报道有大约340B参数。最初，Google的BARD聊天机器人基于LaMDA，但由于后者在推理能力上的优越性，后来转向了PaLM-2。这些尺寸提供了一些关于SOTA模型中涉及细胞数量的指示。
  prefs: []
  type: TYPE_NORMAL
- en: '[图6.10](#fig6_10) 展示了一种称为循环单元的不同类型的人工神经元。'
  prefs: []
  type: TYPE_NORMAL
- en: '![提供关于循环单元详尽和详细信息的一个图表。](images/fig6_10_B.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '[图6.10 循环单元。](#R_fig6_10)'
  prefs: []
  type: TYPE_NORMAL
- en: 如[图6.10](#fig6_10) 所示，这种结构与前馈单元非常相似，但有一个显著的区别，即它包含内部反馈。在这种安排中，前一个迭代（t-1）的输出被重新引入作为当前（t）输入流的一个额外输入。这个输入（h[t-1]）乘以其指定的权重（w[h]）以贡献当前的输出。本质上，这种类型的单元具有对先前输出的记忆，这有助于计算当前的输出。这些循环单元是之前提到的循环神经网络（RNN）模型的基本组成部分。
  prefs: []
  type: TYPE_NORMAL
- en: 存在许多不同类型的细胞，之前提到的一种是长短期记忆（LSTM）单元，但这两个具体的例子应该能给出涉及内容的概览。
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.3 模型层和连接
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 这些人工神经元，也称为细胞或节点，可以按层连接在一起。人工智能中的神经网络由按层组织的节点组成，每个节点都与下一层的其他节点相连。这些连接通常被称为突触。[图6.11](#fig6_11)
    说明了深度神经网络的一些常见结构，通常包括一个输入层、一个输出层和多个中间隐藏层。
  prefs: []
  type: TYPE_NORMAL
- en: '![具有输入层、三个隐藏层和输出层的深度神经网络](images/fig6_11_B.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '[图6.11 深度神经网络](#R_fig6_11)'
  prefs: []
  type: TYPE_NORMAL
- en: 每层的节点数量可以不同，连接也不一定需要链接到下一层的每个节点，尽管这是一种典型安排。要使网络被认为是“深度”的，它必须包含至少三个隐藏层。在计算层数时，包括隐藏层和输出层。在提供的示例中，深度神经网络由四层组成。
  prefs: []
  type: TYPE_NORMAL
- en: 在不同层的输入和节点数量上存在灵活性。以下图表([图6.12](#fig6_12))展示了各种方法。
  prefs: []
  type: TYPE_NORMAL
- en: '![展示深度神经网络可能存在变化的三个不同深度神经网络](images/fig6_12_B.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '[图6.12 深度神经网络变化](#R_fig6_12)'
  prefs: []
  type: TYPE_NORMAL
- en: '[图6.12](#fig6_12) 以抽象的方式概述了深度神经网络的外观。'
  prefs: []
  type: TYPE_NORMAL
- en: 设计和构建模型的一个重要方面是选择要使用的细胞类型；确定哪些细胞类型适合特定的层；决定要包含的层数；以及定义输入、隐藏和输出层中每个层的节点数量。
  prefs: []
  type: TYPE_NORMAL
- en: 某些模型能力针对的是处理的数据类型，例如文本或图像。这些特性将主要在最常见的用例（如大型语言模型（LLMs）、文本到图像模型或多模态模型（支持包括文本、图像、音频、视频等多种数据类型的输入和输出））的背景下进行讨论。例如，一个模型可能促进文本输入并生成文本输出，或者根据用户请求生成图像输出。相反，它也可以接受图像输入并产生描述性文本作为输出。
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.4 关键模型能力
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 以下部分将探讨针对特定数据类型（无论是文本还是图像）设计的模型的关键能力。本节将帮助您了解输入到模型中实际发生了什么，以及模型在训练和推理（训练后的正常用户交互）期间如何处理该输入。
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.4.1 文本 – 分词
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 在深入具体细节之前，理解输入的本质是至关重要的。在LLM的背景下，输入和输出都由文本组成。让我们首先考察这个场景。
  prefs: []
  type: TYPE_NORMAL
- en: 将文本（无论是您输入的文本还是训练数据）转换为实际模型输入需要几个上游处理步骤。这个过程的第一步被称为分词。分词涉及将文本分解成标记。例如，当使用GPT-3分词器时，句子“Can
    you provide a summary of the novel the count of monte cristo”会被分词成以下标记（[图6.13](#fig6_13)）
  prefs: []
  type: TYPE_NORMAL
- en: '![以下句子的分词示例。你能提供《基督山伯爵》的摘要吗？](images/fig6_13_B.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '[图6.13 分词示例1.](#R_fig6_13)'
  prefs: []
  type: TYPE_NORMAL
- en: 如您在[图6.13](#fig6_13)中可以看到，有几个需要注意的点：
  prefs: []
  type: TYPE_NORMAL
- en: 空格包含在单词中（位于单词的开头）。
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 单词主要被分割成不同的标记。
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 有时单词可以被分割成多个标记（例如，‘mon’和‘te’）。
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 如果您将字符串稍微改为“Can you provide a summary of the novel, ‘The Count of Monte Cristo,’”那么这个分词器的标记将是（[图6.14](#fig6_14)）。
  prefs: []
  type: TYPE_NORMAL
- en: '![以下句子的另一个分词示例。你能提供《基督山伯爵》的摘要吗？](images/fig6_14_B.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '[图6.14 分词示例2.](#R_fig6_14)'
  prefs: []
  type: TYPE_NORMAL
- en: 如您在[图6.14](#fig6_14)中可以看到，标点符号和大小写的变化已经影响了分词过程。
  prefs: []
  type: TYPE_NORMAL
- en: 可以提供给模型的输入大小有限，称为上下文窗口。这个限制限制了可以同时传递给模型的标记数量。例如，在Meta的LLaMA-2模型中，上下文窗口是4096个标记；而在ChatGPT-3.0中，它是2048个标记。然而，在ChatGPT-4中，上下文窗口是32k个标记。
  prefs: []
  type: TYPE_NORMAL
- en: 分词方法（包括单词、部分单词、字母、标点符号处理等）是模型设计的重要组成部分，可能需要针对不同语言采取不同的策略。
  prefs: []
  type: TYPE_NORMAL
- en: 当您考虑模型使用的上下文学习方法（即基于输入的学习）时，上下文窗口大小很重要。有几个方法可以使用。
  prefs: []
  type: TYPE_NORMAL
- en: 零样本学习：在这种方法中，只有您输入的提示被作为输入提供给模型。
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 少样本学习：在这种方法中，多个示例和您提供的特定提示都作为输入发送给模型。示例的数量可以从1个到32个不等。
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 在少样本学习的情况下，示例可能会使用掉许多标记，从而为实际执行的提示留下较少的标记，因此，在少样本学习被视为重要的情况下，需要更大的上下文窗口。同样，如果输入本身很大，例如全文文档，也需要更大的上下文窗口。
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.4.2 文本 – 编码
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 分词的一个目的就是将输入映射到一个已知的可能选项集合。在英语语言和上述分词方法的情况下，基于GPT-3的分词设计，大约有50,000个可能的令牌。
  prefs: []
  type: TYPE_NORMAL
- en: 将这50,000个可能的分词值想象成矩阵的垂直列，将实际输入令牌想象成该矩阵的水平行。这将允许将输入映射到数字（一或零），就像编码机制一样。
  prefs: []
  type: TYPE_NORMAL
- en: 矩阵将包含一个‘1’在对应于输入中每个令牌位置的列中，并且根据其在输入文本序列中的位置，这个‘1’将位于适当的行中。该行中的所有其他列都将为‘0’。这已在[图6.15](#fig6_15)中展示。如果输入令牌的数量少于上下文窗口，剩余的列将填充为‘0’。
  prefs: []
  type: TYPE_NORMAL
- en: '![一个已经被分词的句子及其相关的编码矩阵](images/fig6_15_B.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '[图6.15 编码矩阵](#R_fig6_15)'
  prefs: []
  type: TYPE_NORMAL
- en: 这种编码方法允许将提示作为数字矩阵输入传递给模型。由于模型只能处理数字，这种编码是使用模型所需的预处理的关键部分。
  prefs: []
  type: TYPE_NORMAL
- en: 令牌的顺序也很重要。除了矩阵中的令牌值之外，每个令牌在序列中的位置也很重要，并且可以通过模型从提供的输入中识别出来。
  prefs: []
  type: TYPE_NORMAL
- en: 这种将分类变量（令牌或单词）映射到简单矩阵的方法是一种称为“独热编码”的编码类型。然而，还有更复杂的方法可用。这种编码代表了一个固定、基于规则的过程。这些决策对于模型设计和结构至关重要。
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.4.3 文本 – 嵌入
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 一旦令牌以矩阵格式呈现于LLM的Transformer架构中，下一步就是嵌入。这就是矩阵输入被映射到每个令牌和每个令牌位置的向量表示。
  prefs: []
  type: TYPE_NORMAL
- en: 将矩阵中令牌条目映射到向量的过程是一个学习到的表示。换句话说，通过训练，模型学习如何在这个空间中定位向量，以便它们之间的几何关系反映了对应令牌之间的语义关系。例如，动物类型可能会“靠近”（它们的向量具有相似值），或者具有相似意义的单词可能会出现在彼此附近。
  prefs: []
  type: TYPE_NORMAL
- en: 换句话说，LLM 中的嵌入是捕获单词或短语本质的数值表示。而不是将单词视为孤立的单元，嵌入将它们转换成高维空间中的向量，其中相似的单词彼此更接近。这使得模型能够理解上下文和意义，使文本生成更加连贯和上下文相关。例如，将嵌入视为在城市的独特地址（高维空间）中为单词提供地址。因此，虽然“猫”这个词可能住在某个地址，但意义相似的“小猫”就会住在附近（换句话说，会有相似的数值）。当模型需要生成文本时，它使用这些地址（数值相似值）来找到最适合上下文的单词，确保句子有意义。
  prefs: []
  type: TYPE_NORMAL
- en: 如果你没有掌握嵌入过程的细节，不要担心。要记住的关键点是这是一个学习过程；嵌入层有权重和偏差，就像其他层一样，并且通过学习过程，这些权重和偏差值会更新。这个学习过程将在下面更详细地解释。
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.4.4 文本 – 注意力
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 论文《Attention is all you need》（[Vaswani 等人，2017](#ref6_74)）强调了注意力在模型设计和结构中的重要性。注意力机制使模型能够识别句子或段落中单词之间的长距离（远程）依赖关系。这与人类在听某人说话或阅读文本时如何处理这个问题类似。我们分析当前上下文之前的内容，并将其与我们当前处理的内容联系起来，试图形成一个连贯的心理图景。这个注意力机制的关键组成部分是“注意力头”。
  prefs: []
  type: TYPE_NORMAL
- en: 该模型旨在计算输入中每个单词的注意力分数，无论是句子还是段落，以便理解每个单词的相对重要性。通常，存在多个注意力头，每个头计算自己的分数。类似于嵌入，这些分数是从与每个注意力头相关的三个参数的权重中学习的，所谓的“查询”、“键”和“值”参数，通常称为矩阵
    W[q]、W[k] 和 W[v]。不同的注意力头并行处理输入，然后将注意力分数集合并集以创建该标记的新表示。拥有多个注意力头允许模型学习到更全面的标记之间的关系集。例如，一个头可能学会关注句法关系，如主谓一致，而另一个头可能学会捕捉语义关系，如同义。
  prefs: []
  type: TYPE_NORMAL
- en: 以句子‘The cat sat on the mat.’为例。使用单个注意力头时，它可能会关注‘cat’和‘sat’之间的关系，捕捉主谓关系。然而，当使用多个注意力头时，另一个可能会关注‘sat’和‘mat’之间的关系，捕捉动宾关系，而另一个可能会强调‘on’和‘mat’之间的关系，捕捉介词和宾语之间的关系。
  prefs: []
  type: TYPE_NORMAL
- en: 正如所述，这些分数和每个注意力头的焦点是在训练过程中学习的。设计者不会将特定的头分配给特定的能力；这是完全动态的，并在训练过程中学习。这似乎有些令人惊讶，也许令人难以置信，但这确实发生了。在数百万个训练示例中，模型学会了为特定目的专门化特定的注意力头。这是模型的一个涌现特征。训练过程的随机性鼓励头之间的多样性，使得不同的头承担具体但不同的目的。
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.4.5 文本 – 下一个单词预测 学习目标
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 我们已经看到，模型中的某些层专注于寻找单词之间的关系（嵌入），而另一些层则专注于理解输入中最重要单词的内容（注意力）。模型中的其他层将专注于预测文本中的下一个单词。如果到目前为止的输入是‘我去过’，那么模型正在尝试预测下一个单词是什么，比如说它预测了‘market’，但实际上是‘school’，那么它将调整模型中的权重和偏差，以便在将来更好地预测。然后它将再次尝试在‘我去过学校’中预测下一个单词，并且可能会预测‘to’，这是正确的。然后它预测‘pick’，这也是正确的，然后它预测‘up’，这也是正确的，然后它预测‘my’，这又正确。然后它预测的下一个单词是‘kids’，但实际单词是‘books’。它再次更新权重和偏差，试图在将来更好地预测。这给模型提供了输入‘我去过学校去取我的书’。随着它不断学习，它也会更新嵌入和注意力层，以改善这些层。
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.4.6 图像 – 预处理
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 这就是输入图像被准备并归一化或标准化以输入模型的过程。输入图像可能是一个JPEG或GIF，需要转换为标准格式。这种转换不仅包括改变格式，还包括调整其他细节，例如图像的大小（宽度、高度和纵横比）、图像的分辨率和色彩空间。根据复杂程度，可能涉及图像旋转以确保其正确方向。
  prefs: []
  type: TYPE_NORMAL
- en: 预处理的一部分涉及张量（向量的矩阵）转换，这与文本模型中讨论的编码类似。在图像的情况下，这个过程相对容易，因为图像自然地具有高度和宽度的像素集合的二进制表示，每个像素都有颜色值，如红色（R）、绿色（G）和蓝色（B）。因此，转换涉及为这些像素坐标和RGB值创建张量或向量矩阵。这也在[第1.8节](ch1.xhtml#sec1_8)
    [图1.4](ch1.xhtml#fig1_4)中有所涉及。
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.4.7 图像 – 编码
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 图像编码类似于基于文本的模型的嵌入。然而，与在文本模型中使用的嵌入层不同，图像模型通常使用卷积层。这些层学习图像内容之间的关系，有助于提取模型特征。
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.4.8 图像 – 扩散学习目标
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 模型被呈现一个编码后的图像以及该图像的文本描述。正向扩散是一个模型通过改变一些像素的颜色，逐渐向图像中引入噪声，使图片变得模糊的过程。这种噪声是逐步添加的，直到图像变得无法识别，类似于未调谐的电视屏幕。这可以在[第1.8节](ch1.xhtml#sec1_8)
    [图1.6](ch1.xhtml#fig1_6)中看到。
  prefs: []
  type: TYPE_NORMAL
- en: 相反，反向扩散是一个模型从图像中去除噪声的过程，逐渐将其恢复到原始、可识别的形式。
  prefs: []
  type: TYPE_NORMAL
- en: 这些正向和反向扩散过程教会模型如何通过去除噪声来生成一个它有文本描述的图像。当被要求仅基于文本描述创建图像时，模型可以利用这种学习从具有随机噪声的初始图像中去除噪声，从而生成一个之前不存在的全新图像。
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.4.9 超参数
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 超参数是设计者在设计和训练过程中必须选择和调整的模型特定控制。与模型参数不同，模型参数在学习过程中由模型自身自动调整，而超参数仅由模型的设计者调整。
  prefs: []
  type: TYPE_NORMAL
- en: 这些超参数涵盖了模型各个方面的一个广泛范围，包括学习率、批量大小、训练轮数、影响所使用激活函数的因素、dropout率等。在这个阶段，设计者必须确定这些超参数的最佳值。
  prefs: []
  type: TYPE_NORMAL
- en: 有时，超参数会暴露给模型的最终用户，以帮助控制模型的行为。一个这样的例子是“温度”超参数，它控制预测的可重复性。较低的值意味着更多的随机性，而较高的值则意味着更少的随机性和更多的一致性。
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.5 基础模型训练
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 到目前为止，我们已经概述了整体情况，包括数据的收集和准备，以及模型设计和结构化方面的不同方面。在本节中，我们专注于基础模型训练，通常称为预训练。
  prefs: []
  type: TYPE_NORMAL
- en: 基础模型是一个作为通用模型构建和最初训练的模型，它不是另一个模型的专门化。微调模型是一个基础模型（或另一个微调模型），它针对特定目的进行了专门化。
  prefs: []
  type: TYPE_NORMAL
- en: “预训练”或“预训练”一词指的是在模型成为通用基础模型之前发生的训练。
  prefs: []
  type: TYPE_NORMAL
- en: 当训练一个基础模型（也称为预训练）时，可能会发生不同类型的训练，这些训练类型会影响发生的学习的类型。以下章节将深入探讨这些不同类型的学习和相关的训练过程。
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.5.1 监督学习
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 当训练数据包括数据和允许模型确定其预测是否正确的标签时，就会发生监督学习。例如，如果训练数据涉及文本某个部分的情感，它将包括与每个文本部分相关的情感描述。当模型正在训练并预测文本的情感时，它可以参考提供的标签来评估其预测的准确性。然后，它将调整模型中的参数以增强未来的预测。
  prefs: []
  type: TYPE_NORMAL
- en: 另一个例子是当模型处理包含动物的图像时。在这种情况下，训练数据包括许多动物的图片，每张图片都附有描述所描绘动物类型的标签。模型可以利用这些训练数据和标签来做出预测并优化其预测。
  prefs: []
  type: TYPE_NORMAL
- en: 另一个例子涉及一个旨在提高图像分辨率的模型。在这种情况下，训练数据包括同一图片的低分辨率图像和更高分辨率的图像。模型可以预测更高分辨率图像可能的样子，并使用提供的更高分辨率图像来调整其预测以进行改进。
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.5.2 自监督学习
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 自监督学习是一种模型使用未标记输入来监督其自身学习的方法。例如，如果输入是“我爱AI”，而模型的目的是预测下一个单词，它可以使用“我爱xxxx”来预测“我有”。然后，它可以根据后续输入“我爱”，检查该预测是否正确，并调整其未来的预测。这是LLMs学习中最常见的方法，因为来自Common
    Crawl等来源的数据可以相对容易地用于为预测下一个单词的模型（如LLMs）创建自监督训练集。
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.5.3 无监督学习
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 无监督学习是一种训练类型，其中数据被提供给模型，而没有任何关于预期内容的特定知识，没有任何“标签”，或者不使用自监督学习方法。这种学习在特定场景中可能很有用，例如聚类，它涉及识别相关项目（簇）的组。
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.5.4 基于人类反馈的强化学习（RLHF）
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 基于人类反馈的强化学习（RLHF）在难以指定所需行为或模型需要学习细微或复杂策略的领域特别有益。它已被应用于训练跨越各个领域的模型，包括游戏（如围棋）、对话系统和机器人技术。
  prefs: []
  type: TYPE_NORMAL
- en: 与RLHF相关的一个挑战是，它可能既耗时又昂贵，因为它需要人类评估者的持续参与。此外，它可能需要精心设计，以确保收集到的反馈是有信息的，并且人类判断中的偏见不会过度影响模型的行为。
  prefs: []
  type: TYPE_NORMAL
- en: RLHF（基于人类反馈的强化学习）范式充当了传统监督学习（模型从固定数据集的标记示例中学习）和强化学习（模型通过与环境的交互来最大化奖励信号并因此强烈倾向于人类反馈选项）之间的桥梁。
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.5.5 学习
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 本节将更详细地探讨学习过程。到目前为止，学习已被讨论，但没有详细的解释。已经提到，模型会做出预测，例如在LLM的情况下预测下一个单词，然后比较预测值和预期值（通过自监督、监督或强化学习），然后根据需要调整模型。还提到，模型的参数，即权重和偏差，是学习过程中进行调整的数字。
  prefs: []
  type: TYPE_NORMAL
- en: 我们理解，模型对世界的理解源于其结构（包括嵌入、注意力和其他层）及其参数值（权重和偏差）的结合。最初，在基础模型开始训练之前，权重被设置为某个值。通常，这个值是随机的，有时为零。然后，在训练过程中调整这个值。我们已经讨论过，训练数据被分组到批次中。现在，让我们探讨学习过程如何与这些批次紧密相连，以及批次大小的重要性。对于每个批次，以下过程发生：
  prefs: []
  type: TYPE_NORMAL
- en: 前向传播。这是将批次中的数据通过神经网络进行“前向”传递的地方。模型逐个单词或图像地对批次中的每个项目进行预测。它记录下所做的预测和实际值。
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 损失计算。损失计算涉及模型将其预测值与实际预期值进行比较。为此使用损失函数。在大型语言模型（LLMs）中，常见的损失函数是分类交叉熵，而图像生成模型通常使用生成对抗损失等损失函数。这些损失函数量化了实际值与预测值之间每个单词或图像的差异。然后，这些输入的量化值在整个批处理中平均，从而得到可用于下一步的平均损失值。
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 反向传播，也称为反向传播算法([Werbos, 1974](#ref6_80)，以及[Rumelhart 等人，1985](#ref6_60))。步骤1和2对批处理中的每个项目都会执行，损失计算步骤在整个批处理中维护一个运行平均损失。然后基于这个平均损失值执行反向传播。这涉及到计算模型中每个参数相对于损失的梯度。即使一句话可能被完美预测，其他句子中的错误也会对梯度产生影响，并指导参数更新。重要的是要记住，模型由许多层组成，每层有众多细胞或神经元，而这些细胞或神经元都有多个需要调整的权重和偏差。基于平均损失的梯度计算，将影响水平（有时称为责任或奖励）分配给模型中每个权重和偏差，以反映预测值与实际值之间的误差。
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 调整。调整每一层中每个神经元的权重和偏差。现在模型已经为模型中的每个参数分配了责任或奖励水平，它可以在批处理结束时调整这些参数。
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 这就是神经网络学习的本质：做出预测，估计误差，为模型中的每个参数分配一个误差的责备或奖励水平，并调整模型中的每个参数。在数百万或数十亿个标记符中，模型开始展现出专业化和改进的行为。嵌入层学习，使得相关词汇能够以反映它们之间关系的方式分组；相似的词汇会靠得很近，不同的词汇则会相隔甚远。注意力层学习，每个注意力头都专门以某种方式形成，使得词汇之间更远的关系得以形成，例如主语和动作之间的关系。其他层也贡献于词汇、语言概念和现实世界概念之间的整体关系。从这些不同的学习和形成的模式和关系中，模型获得了类似于对世界及其事物之间关系的“理解”。这种学习和理解的大部分是从模型训练所使用的大量数据以及允许不同部分专注于特定方面的模型结构中涌现出来的。这也是人类难以理解模型真正工作原理的原因之一；通常有数十亿个参数，这些参数可以在数百万或数十亿，甚至万亿个标记符上进行训练，而人类并不擅长理解如此庞大的数据量和数字是如何相互作用，从而产生这种涌现能力。
  prefs: []
  type: TYPE_NORMAL
- en: 应该记住，这种理解纯粹与所提供的训练数据相关。它缺乏人类所拥有的那种理解。人类理解物理定律，并从他们的经验中吸取教训来评估情况。他们根据这种理解调整他们的反应。人类还有基于信念的规则，他们使用这些规则来调整他们的反应和行动。然而，类似LLM这样的东西只有它所训练的数据，并没有这些其他的学习方法。人类擅长从相对较少的例子中学习，并从中获得丰富的见解。AI模型需要大量的数据才能开始发展有用的涌现行为。
  prefs: []
  type: TYPE_NORMAL
- en: 虽然不同，但学习过程多少有点像孩子的学习过程；首先在幼儿园、小学和中学接受广泛的教育，这就像是一个基础模型的预训练；然后在大学专注于特定学科或专业，如计算机科学，这就像是我们后面更详细讨论的微调。
  prefs: []
  type: TYPE_NORMAL
- en: 在学习过程的最初阶段，模型一无所知；换句话说，权重和偏差的值尚未设置为适当的值。通常，在这个阶段，模型会将权重和偏差设置为随机值，然后训练过程将按照描述进行调整。这有点像出生时我们假设孩子对世界一无所知，但随着他们成长需要学习。
  prefs: []
  type: TYPE_NORMAL
- en: 深度神经网络的概念受到了人类大脑和动物大脑的启发。我们可以看到有一些相似的概念，但我们也可以看到它们非常不同，有些人可能会说它们在运作方式上有根本性的不同。
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.6 基础模型测试
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 一旦模型被训练，下一步就是测试模型以评估其有用性。测试模型可能是一项复杂的任务。通常，数据集首先被分成训练数据和测试数据，如前所述。训练数据用于训练模型，然后测试集用于评估模型的表现有多好。
  prefs: []
  type: TYPE_NORMAL
- en: 需要记住的一个重要事情是，在训练过程中，模型参数在每个批次之后都会更新。然而，在测试过程中，模型参数保持不变。测试的目标是了解模型的表现。如果模型参数持续变化，将使得测试性能变得不可能，因为每次测试都会影响性能，而且测试将无法重复。
  prefs: []
  type: TYPE_NORMAL
- en: 使用数据的一部分进行测试，例如20%，有助于模型创建团队理解模型的表现。然而，这并不适用于与其他人比较或解释模型的表现，因为他们对涉及到的测试数据、预测的难度级别、测试范围等没有任何了解。这就是标准测试基准发挥作用的地方。下一节将探讨常用的不同基准。
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.6.1 测试基准
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 存在着大量的测试基准，每年都会有更多针对特定目的或提供增强效益的基准被引入。这些基准通常集中在特定的任务或更广泛的领域。
  prefs: []
  type: TYPE_NORMAL
- en: 基准测试通常提供评估协议（规则）和用于评估模型的标准数据集。这个标准数据集确保不同的模型以统一的方式进行评估，使得不同模型之间的比较有意义。标准数据集通常分为训练集和测试集，以确保一致的训练和测试。有时，这些数据集还会进一步分割成验证集。通常，模型将在训练集上训练，使用验证集进行微调，并最终使用测试集进行测试。有时，基准测试的创建者可能会保留测试集，要求模型开发者提交他们的模型进行评估。这种策略旨在防止模型在测试数据上训练，这在基准测试评估期间会给予模型不公平的优势。
  prefs: []
  type: TYPE_NORMAL
- en: 评估协议概述了测试目标的关键细节，包括如何根据每个测试组件的结果计算分数。这个分数通常作为对比两个模型的直接单一指标。有时，基准测试的创建者或相关社区将建立排行榜，显示每个测试模型的排名分数，便于比较。这样的排行榜也可能包括一个人类基线分数，这是通过人类参与者平均分数得出的。这种添加可以提供上下文，帮助用户欣赏模型的表现。在许多基准测试中，模型超越人类平均分数并不罕见。
  prefs: []
  type: TYPE_NORMAL
- en: 下面是一些常见的基准测试示例，按其焦点领域分类。这应该提供对每个基准的全面理解，突出其优势和局限性。分组领域不是严格的，基准测试可能会根据特定上下文下的不同标题进行展示，特别是对于覆盖更广泛领域的更通用基准测试。
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.6.2 常识推理基准测试
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 6.3.6.2.1 BoolQ ([Clark 等人，2018](#ref6_15))
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: BoolQ，代表布尔问题，是一个问答数据集，它涉及根据给定的文本段落确定提供的陈述是真是假。目标是使用段落中的信息回答一个二元（是/否）问题。基准测试包括大约9,400个训练示例、3,200个验证示例和3,200个测试示例。
  prefs: []
  type: TYPE_NORMAL
- en: 下面是数据集的结构：
  prefs: []
  type: TYPE_NORMAL
- en: '**段落**：包含回答给定问题所需信息的文本片段。'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**问题**：基于段落的是/否问题。'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**标签**：一个二元标签，表示根据段落，问题的答案是“是”还是“否”。'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: BoolQ上模型的性能通常使用准确率来评估，准确率是正确答案占总示例数的比例。
  prefs: []
  type: TYPE_NORMAL
- en: BoolQ数据集以几种方式挑战模型：
  prefs: []
  type: TYPE_NORMAL
- en: '**阅读理解**：模型必须能够准确提取和理解段落中的信息，以正确回答问题。'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**二分类**：模型需要将答案分类为两个类别之一：是或否。'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**推理**：有时，答案可能没有在段落中明确陈述，需要模型根据可用信息进行推理。'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 通过在 BoolQ 等数据集上进行测试，研究人员可以评估语言模型理解并从文本中提取相关信息以准确回答问题的能力。
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.6.2.2 PIQA ([Bisk 等人，2020](#ref6_7))
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: PIQA 基准测试，即物理智能问答（Physical Intelligence Question Answering），是一个旨在测试系统对日常物理推理理解的测试数据集。它由
    Bisk 等人在他们 2020 年的论文中引入。基准测试包含大约 16,100 个训练示例、1,800 个验证示例和 3,000 个测试示例。
  prefs: []
  type: TYPE_NORMAL
- en: 在这个基准测试中，问题以这种方式提出，需要模型展示对物理世界的常识性理解，以提供准确的答案。
  prefs: []
  type: TYPE_NORMAL
- en: 这里是 PIQA 中数据结构的组织方式：
  prefs: []
  type: TYPE_NORMAL
- en: '**问题**：通常涉及日常物理推理方面的问题。这可能包括关于物质状态、简单机械、物体运动等问题。'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**答案**：问题的正确答案，通常是一个句子或短语，解释推理或为提出的问题提供解决方案。'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: PIQA 基准测试中模型的性能通常基于产生的答案的准确性来评估。这个准确性指标检查模型的答案是否与正确答案匹配，或者它是否提供了对提出问题的逻辑等价解决方案。
  prefs: []
  type: TYPE_NORMAL
- en: PIQA 是一个具有挑战性的数据集，因为它要求模型具备对物理原理的常识性理解，并将这种理解应用于新情境。它作为评估 AI 系统能够以类似于人类的方式推理物理世界熟练程度的手段。
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.6.2.3 SIQA ([Sap 等人，2019](#ref6_66))
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 社会智能问答（SIQA）基准测试是在 Maarten Sap 等人于 2019 年发表的一篇论文中引入的。这个数据集旨在评估在社交情境中 AI 模型的常识推理能力。目标是确定模型在理解和推理社交场景方面的熟练程度，这对于开发能够与人类自然有效地互动的
    AI 系统至关重要。基准测试包含大约 33,400 个训练示例、1,900 个验证示例和 2,000 个测试示例。
  prefs: []
  type: TYPE_NORMAL
- en: SIQA 数据集包含关于社交情境的问题。每个问题都与三个可能的答案配对：一个正确答案和两个错误答案。
  prefs: []
  type: TYPE_NORMAL
- en: '**情境**：对社交情况的描述。'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**问题**：与上下文中提供的社会情境相关的问题。'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**答案**：提供了三个可能的答案，一个正确和两个错误。'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: SIQA 的性能通常使用准确率等指标来评估，该指标衡量正确回答的问题占总提出问题的比例。通过分析答案选择背后的推理以及模型展现的社会理解，可以更深入地了解模型的性能。
  prefs: []
  type: TYPE_NORMAL
- en: 这个基准测试帮助研究人员评估他们的模型在理解、解释和回应社会情境方面的熟练程度，这是朝着开发更具有社会意识的 AI 系统迈出的重要一步。
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.6.2.4 SWAG ([Zellers 等人，2018](#ref6_84))
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: SWAG（具有对抗性生成的情境）是一个旨在评估基于常识推理的语料库。它旨在衡量系统对句子中描述的日常情境进行推理的能力。基准测试提供了一个部分可观察的场景，目标是预测四个选项中最可能的后续情况。基准测试包含大约
    73,000 个训练示例，20,000 个验证示例和 20,000 个测试示例。
  prefs: []
  type: TYPE_NORMAL
- en: 这里是如何构建 SWAG 语料库的：
  prefs: []
  type: TYPE_NORMAL
- en: '**前提句子**：这是一个给定的陈述或情况，它设定了一个场景。'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**结尾选项**：为每个场景提供了四个可能的结尾。'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**正确结尾**：在四个结尾中，其中一个被标记为场景的正确或最可能的后续情况。'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 任务是根据提供的前提选择最可能的结尾。
  prefs: []
  type: TYPE_NORMAL
- en: 该语料库包含关于基于情境的多项选择题，其中模型被期望从四个选项中选择最可能的后续情况。SWAG 的创造者采用了一种新颖的对抗性过滤技术来构建该语料库。这确保了干扰（错误）答案具有挑战性，并且仅基于表面的文本模式无法轻易与正确答案区分开来。
  prefs: []
  type: TYPE_NORMAL
- en: 模型的任务是，根据前提条件选择最可能的结尾（在这种情况下，选项 d）。
  prefs: []
  type: TYPE_NORMAL
- en: 在使用 SWAG 评估模型时，测量模型选择正确结尾的准确率。因此，这个基准测试提供了一个评估系统在基于常识、真实世界场景背景下的推理能力的方法。
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.6.2.5 HellaSwag ([Zellers 等人，2019](#ref6_85))
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: HellaSwag 是一个基准语料库，用于评估机器学习模型在执行常识推理方面的能力。它可以被视为 SWAG 基准测试的扩展或更具有挑战性的版本。基准测试包含大约
    39,000 个训练示例，10,000 个验证示例和 20,000 个测试示例。
  prefs: []
  type: TYPE_NORMAL
- en: 这里有一个详细的分解：
  prefs: []
  type: TYPE_NORMAL
- en: '**前提**：与SWAG类似，HellaSwag从一个描述特定场景的前提开始。然而，HellaSwag中的前提通常更为复杂和可能具有歧义。'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**结尾选项**：对于每个前提，提供四个可能的延续。这些延续通常被设计为具有误导性或非显而易见，从而挑战模型的推理能力。'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**正确结尾**：在四个延续中，有一个被标记为基于前提中描述的场景的正确或最可能的延续。'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 在这个基准中，机器学习模型的主要目标是根据提供的前提选择最可能的延续。
  prefs: []
  type: TYPE_NORMAL
- en: HellaSwag的创造者采用了一种更复杂的过程来生成延续中的具有挑战性的干扰选项。他们使用一个大型语言模型（LLM）自动生成看似合理但实际上错误的干扰延续。这种方法使得HellaSwag成为一个特别具有挑战性的基准，因为干扰选项被设计为对模型和可能的人类评估者都具有误导性。
  prefs: []
  type: TYPE_NORMAL
- en: 模型的任务是选择最可能的结尾（在这种情况下，选项C）。模型在这个任务上的准确性将表明其通过复杂、现实场景并可能存在误导性信息进行推理的能力。
  prefs: []
  type: TYPE_NORMAL
- en: HellaSwag被设计为一个具有挑战性的基准，以推动模型在常识推理和理解细微的现实场景方面的边界。
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.6.2.6 WinoGrande ([Sakaguchi等人，2019](#ref6_65))
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: WinoGrande是一个大规模数据集，旨在评估机器学习模型解决Winograd Schema挑战的能力。Winograd Schema挑战是一种常识推理任务，测试模型在句子中解决代词引用的能力。该基准包括大约9,200个训练示例，1,200个验证示例和1,700个测试示例。
  prefs: []
  type: TYPE_NORMAL
- en: WinoGrande提供了大量的示例，以提供对模型在类似任务上性能的更稳健的统计评估。WinoGrande中的示例被精心设计，以尽可能减少差异，这意味着句子措辞的微小变化可以改变正确答案。这种设计旨在测试模型对细微语言和上下文信息的掌握。WinoGrande采用对抗过滤方法来确保数据集中示例的质量和挑战水平。这种方法有助于排除过于简单或存在多个可能正确答案的示例。使用WinoGrande的模型的主要任务是澄清句子中的模糊代词引用，例如确定代词所指的具体实体。
  prefs: []
  type: TYPE_NORMAL
- en: 这个例子中的挑战来自于句子中“它”的模糊指代。模型的任务是根据句子中提供的上下文信息确定“它”指的是什么。
  prefs: []
  type: TYPE_NORMAL
- en: WinoGrande基准旨在提供对模型常识推理能力和对细微语言掌握的更严格评估。它被设计为一个具有挑战性的基准，旨在推动模型在常识推理和理解自然语言方面的能力边界。
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.6.2.7 ARC Easy and Challenge ([Clark et al., 2018](#ref6_15))
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: ARC数据集代表AI2 Reasoning Challenge，由艾伦人工智能研究所（AI2）开发。该数据集旨在评估机器学习模型回答需要推理和理解多个句子的问题的能力。ARC数据集分为两个子集：ARC-Easy和ARC-Challenge。
  prefs: []
  type: TYPE_NORMAL
- en: '**ARC-Easy**（2,200个训练样本，500个验证样本，2,300个测试样本）：'
  prefs: []
  type: TYPE_NORMAL
- en: 这个数据集部分包含相对容易回答的问题。这些问题可能不需要深入的推理，可能可以通过简单的事实检索或更简单的推理来解决。
  prefs: []
  type: TYPE_NORMAL
- en: '**ARC-Challenge**（1,100个训练样本，290个验证样本，1,100个测试样本）：'
  prefs: []
  type: TYPE_NORMAL
- en: 这个子集包含更具挑战性的问题，这些问题旨在需要更高级的推理才能正确回答。ARC-Challenge中的问题预计对当前机器学习模型来说将是困难的，旨在推动AI系统在推理方面的边界。
  prefs: []
  type: TYPE_NORMAL
- en: ARC数据集中的每个示例都包含一个问题、一组可能的答案选项和正确答案。问题以多项选择题的形式呈现。这种格式允许通过检查模型是否选择了正确答案来获得清晰的评估指标。这些问题覆盖了广泛的主题，主要在科学领域。它们来源于真实的3至9年级科学考试，旨在用对人类来说容易但对机器来说困难的问题挑战模型。ARC-Easy和ARC-Challenge子集都是设计来需要外部知识才能正确回答的，超越了问题本身提供的信息。
  prefs: []
  type: TYPE_NORMAL
- en: '**ARC-Easy 示例**：'
  prefs: []
  type: TYPE_NORMAL
- en: '**问题**：“植物从大气中吸收哪种气体进行光合作用？”'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**答案**：'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 氧气
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 氮
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 二氧化碳
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 氢
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**正确答案是** c) 二氧化碳。'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ARC-Challenge 示例**：'
  prefs: []
  type: TYPE_NORMAL
- en: '**问题**：“如果一个生活在沙漠中的植物进化出刺而不是叶子，这种适应的最可能原因是什么？”'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**答案**：'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 为了吸引更多昆虫进行授粉
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 为了减少通过蒸腾作用的水分损失
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 为了捕获更多阳光进行光合作用
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 使植物更容易捕捉猎物
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**正确答案是** b) 为了减少通过蒸腾作用的水分损失。'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 除了 ARC 数据集，还提供了一个包含回答问题所需信息的文本语料库。这个语料库可以用来训练模型使用外部信息来回答问题。
  prefs: []
  type: TYPE_NORMAL
- en: 应该注意的是，文本语料库是非结构化的；每个句子可能涉及完全不同的主题（例如，上面引用的句子涉及洪水，接着是光合作用，然后是关于火星神的引用）。被评估的模型可能需要从文本语料库的不同位置组合项目来回答特定且特别具有挑战性的问题。在上面的例子中，至少有五个不同的文本语料库区域是相关或可能相关的。自然地，模型可以借鉴其其他训练数据，而不仅仅是与基准相关的语料库，来回答问题。
  prefs: []
  type: TYPE_NORMAL
- en: ARC 数据集的主要目标是鼓励开发新的模型，这些模型能够以类似于人类的方式推理和理解文本，尤其是在教育或科学环境中。ARC-Easy 和 ARC-Challenge
    之间的区别允许在不同难度的水平上评估模型，从而推进机器推理的最新进展。
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.6.3 问答基准
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 6.3.6.3.1 OpenBookQA ([Mihaylov 等人，2018](#ref6_43))
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: OpenBookQA 是一个旨在评估机器学习模型基于少量事实（称为“开放书籍”）回答问题的能力的基准。这个“开放书籍”包含了一系列事实，这些事实应该足以回答数据集中的问题。目标是测试模型对这些事实进行推理和结合信息以准确回答问题的能力。该基准大约有
    4,900 个训练示例，大约 500 个验证示例和 500 个测试示例。开放书籍包含大约 1,300 个条目或事实。
  prefs: []
  type: TYPE_NORMAL
- en: 每个问题都附带四个答案选项，其中只有一个正确。这些问题设计成可以通过 Open Book 中提供的事实来回答，尽管可能还需要一些外部常识。这些问题覆盖了各种主题，旨在测试各种推理形式，包括检索、比较、空间推理、时间推理、因果关系等。评估通常基于模型在提供的选项中选择正确答案的准确性。
  prefs: []
  type: TYPE_NORMAL
- en: OpenBookQA 被研究人员用来评估和比较不同的问答模型。它特别有助于评估模型如何有效地利用有限的事实来回答广泛的问题。
  prefs: []
  type: TYPE_NORMAL
- en: OpenBookQA 基准提供了一个受控的环境来评估机器学习模型如何有效地利用一组事实来回答需要一定推理或信息综合水平的问题。
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.6.3.2 Natural Questions ([Kwiatkowski 等人，2019](#ref6_34))
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 自然问题（NQ）基准，由Kwiatkowski等人于2019年引入，旨在评估模型根据给定文档的内容回答现实世界问题的能力。在这个基准中，每个示例都包含一个问题以及一个维基百科页面，任务是识别页面中回答问题的特定文本范围，或指出没有答案。完整数据集为42Gb，但提供了一个简化的数据集，大约为4Gb。
  prefs: []
  type: TYPE_NORMAL
- en: 这个任务紧密模拟了现实世界场景，其中用户根据他们正在查看的文档或网页提出问题。例如，一个问题可能是：“埃菲尔铁塔何时完工？”给定一个关于埃菲尔铁塔的维基百科页面，正确的回答应该是识别文本范围“1889年完工”作为答案。这个基准很重要，因为它要求模型有效地处理各种自然语言问题，并从相关文档中提取精确答案，展示了它们的理解和信息检索能力。
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.6.3.3 TriviaQA ([Joshi et al., 2017](#ref6_30))
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: TriviaQA是由Joshi等人于2017年引入的，是一个旨在评估模型在回答常识问题能力上的基准。数据集包含来自常识爱好者的问答对以及提供答案支持信息的证据文档。目标是让模型能够使用相关文档中的信息准确回答问题。它包含超过650K个问答-证据三元组。
  prefs: []
  type: TYPE_NORMAL
- en: 在TriviaQA中，问题根据它们来源的来源进行分组，并根据是否与证据文档进行过交叉核对，将它们分类为已验证或未验证。证据文档来自各种来源，如维基百科、网页或书籍，这些提供了良好的语言多样性和复杂性。
  prefs: []
  type: TYPE_NORMAL
- en: TriviaQA的一个示例问题可能是：
  prefs: []
  type: TYPE_NORMAL
- en: '**问题**：“意大利北部的河流是什么？” **答案**：“波河”。'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**证据**：链接到维基百科，也许还有另一个来源的链接'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 在这个基准中，模型不仅要提供正确的答案，还要展示对支持文档中证明答案的上下文和证据的理解。这个基准挑战模型在阅读理解、知识提取以及处理正式和非正式文本混合的能力，使其成为衡量模型处理现实世界、开放域问答场景能力的一个稳健指标。
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.6.3.4 SQuAD v1.1 ([Rajpurkar et al., 2016](#ref6_56)) 和 2.0 ([Rajpurkar
    et al., 2018](#ref6_55))
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 斯坦福问答数据集（SQuAD 1.1）是一个包含10万个众包问答对的集合 ([Rajpurkar et al., 2016](#ref6_56))。
  prefs: []
  type: TYPE_NORMAL
- en: 斯坦福问答数据集（SQuAD）是评估机器阅读和问答（QA）系统性能的一个公认的基准。在这个基准中，模型被提供一段文本，然后要求根据该文本的内容回答问题。
  prefs: []
  type: TYPE_NORMAL
- en: SQuAD包括两个主要版本：SQuAD 1.1和SQuAD 2.0。在SQuAD 1.1中，重点是回答那些答案肯定存在于提供的段落中的问题。另一方面，SQuAD
    2.0包括那些答案可能或可能不在段落中的问题，从而挑战模型确定何时所需回答问题的信息缺失。
  prefs: []
  type: TYPE_NORMAL
- en: 以下是一个来自SQuAD 1.1的例子：
  prefs: []
  type: TYPE_NORMAL
- en: '**段落**： “超级碗50是一场美国橄榄球比赛，用以确定2015赛季国家橄榄球联盟（NFL）的冠军。美国橄榄球联盟（AFC）冠军丹佛野马队以24-10击败国家橄榄球联盟（NFC）冠军卡罗来纳黑豹队，赢得了他们的第三个超级碗冠军。”'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**问题**： “哪个NFL球队赢得了超级碗50？”'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**答案**： “丹佛野马”'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 以下是一个来自SQuAD 2.0的例子：
  prefs: []
  type: TYPE_NORMAL
- en: '**段落**：如上所述'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**问题**： “超级碗50的MVP是谁？”'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**答案**：在这种情况下，段落没有提供回答问题的所需信息，因此正确的回答应该是指出答案不在段落中。'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: SQuAD一直是评估和比较不同问答系统的一个关键基准，并在自然语言处理（NLP）社区中激发了大量研究。
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.6.4 阅读理解基准
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 6.3.6.4.1 RACE阅读理解基准 ([Lai等人，2017](#ref6_35))
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: RACE（从考试中读取理解，ReAding Comprehension from Examinations）数据集是一个大规模的阅读理解数据集，收集自中国的英语考试，旨在为3至12年级的学生使用。该基准旨在在一个更具挑战性和现实的环境中评估机器理解模型，因为它包括多种多样的题目类型和主题。
  prefs: []
  type: TYPE_NORMAL
- en: 该数据集分为两个子集：RACE-M，它包括中学考试问题，和RACE-H，它包括高中考试问题。
  prefs: []
  type: TYPE_NORMAL
- en: 在RACE基准中，问题和段落的结构格式如下：
  prefs: []
  type: TYPE_NORMAL
- en: 提供一段文本，这可能是一篇叙述、一篇文章或一段对话。
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 与段落相关的多项选择题被呈现出来，每个问题都有四个选项。
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 以下是一个受RACE数据集中可能找到的问题类型启发的简化例子：
  prefs: []
  type: TYPE_NORMAL
- en: '**段落**： “1920年，美国妇女通过美国宪法的第19修正案的批准赢得了投票权。这是妇女选举权运动者多年斗争和积极活动的结果，她们相信妇女应该享有平等的投票权。”'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**问题**： “美国宪法的第19修正案赋予了什么？”'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**答案**：'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 妇女工作的权利
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 妇女选举权
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 奴隶制的废除
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 所得税的设立
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**正确答案**: b) 妇女选举权'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 在这个例子中，文章提供了回答多项选择题所需的信息。模型的任务是充分理解文章，以便从提供的选项中选择正确答案。在现实世界的场景中，RACE中的问题可能更具挑战性，文章更长且更复杂，这使得它成为评估阅读理解模型的强大基准。
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.6.5 数学推理基准
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 6.3.6.5.1 MATH ([Hendrycks et al., 2021](#ref6_26))
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Hendrycks等人于2021年引入的MATH（数学推理数据集）基准旨在评估机器学习模型的数学推理能力。该数据集包含需要各种推理和理解水平才能解决的问题。这些问题覆盖了广泛的主题和难度级别，这使得它成为评估模型如何处理抽象数学推理和符号操作的挑战性基准。该数据集包含12,500个具有挑战性的竞赛数学问题（7,500个训练，5,000个测试）。MATH中的每个问题都有一个完整的逐步解决方案，可用于教会模型生成答案推导和解释。
  prefs: []
  type: TYPE_NORMAL
- en: MATH数据集中的问题被分为几个主题，包括代数、微积分、几何、测量、数论、概率和统计学。每个问题都附有逐步解决方案，旨在帮助评估模型生成最终答案以及中间步骤和解释的能力。
  prefs: []
  type: TYPE_NORMAL
- en: 这里是一个受MATH数据集中可能找到的问题启发的简化示例：
  prefs: []
  type: TYPE_NORMAL
- en: '**问题**: “简化表达式：(x² + 2x + 1) + (2x² + 3x + 2)”'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**逐步解决方案**: “首先，我们将同类项相加。我们首先处理含有x²的项：x² + 2x² = 3x²；接下来，我们将含有x的项相加：2x + 3x
    = 5x；最后，我们将常数项相加：1 + 2 = 3；将所有这些加在一起，我们得到：3x + 2 + 5x + 3'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**最终答案**: 3x² + 5x + 3'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 在这个问题中，模型需要识别多项式表达式的结构并执行适当的操作以简化表达式。逐步解决方案对于理解模型的推理过程至关重要。
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.6.5.2 GSM8k ([Cobbe et al., 2021](#ref6_16))
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: GSM8K（小学数学）包含高质量的初级数学问题。这些问题是由人类问题编写者创建的。该数据集分为7,400个训练问题和1,300个测试问题。这些问题需要2到8步来解决，解决方案涉及使用基本算术运算执行一系列基本计算以得到最终答案。这个基准来自Cobbe等人在OpenAI的研究。
  prefs: []
  type: TYPE_NORMAL
- en: 该基准的一个目标是为了帮助模型创建者促进研究，并允许他们使用不同的方法来衡量他们在这种多步骤数学问题上的模型性能，即使是高参数的现代基于transformer的模型也难以解决。
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.6.6 代码生成基准
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 6.3.6.6.1 HumanEval ([陈等，2021](#ref6_11))
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: HumanEval基准由OpenAI在陈等人的论文中引入，旨在评估语言模型的问题解决能力。基准包括一个任务数据集（约160个），其中每个任务都是一个用Python编写的函数问题，模型必须通过根据给定的输入预测函数的输出来解决。这些问题被设计成需要数学、逻辑或其他形式的常识推理。
  prefs: []
  type: TYPE_NORMAL
- en: 在HumanEval中，任务被制定成对人类来说容易解决但对机器模型具有挑战性的形式，旨在弥合人类与机器问题解决能力之间的差距。任务不受特定领域或类型的限制，可以涵盖一系列主题和难度级别。它们可以包括各种类型的问题，如数学计算、字符串操作或基于逻辑的谜题。
  prefs: []
  type: TYPE_NORMAL
- en: 这里是一个来自HumanEval的示例任务：
  prefs: []
  type: TYPE_NORMAL
- en: 模型应该生成Python代码来解决注释中描述的问题。在这种情况下，它可能生成如下内容：
  prefs: []
  type: TYPE_NORMAL
- en: HumanEval基准的主要目标是推动模型在问题解决和推理方面的能力。该基准可用于评估不同的模型，并了解它们理解和生成正确且高效的代码来解决给定问题的能力。
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.6.6.2 MBPP ([奥斯汀等，2021](#ref6_5))
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: MBPP（大多数基本编程问题）基准包括大约970个Python编程问题，旨在由初级程序员解决，涵盖了编程基础、标准库功能等。每个问题包括任务描述、代码解决方案和3个自动测试案例。
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.6.7 多任务语言理解基准
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 6.3.6.7.1 GLUE ([王等，2018](#ref6_77))
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: GLUE（通用语言理解评估）包括九个NLU（自然语言理解）任务，涵盖了各种语言现象和领域。以下各项的训练示例、验证示例和测试示例数量差异很大。显示的近似数字提供了一些指导。
  prefs: []
  type: TYPE_NORMAL
- en: 以下是GLUE中包含的任务以及一些示例，以帮助理解所测试的概念：
  prefs: []
  type: TYPE_NORMAL
- en: MultiNLI（多体裁自然语言推理）：评估给定前提是否被假设所蕴含、矛盾或既不是蕴含也不是矛盾（训练：391,000，测试：19,000，验证：19,000）。
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 前提：“乐团正在演奏一首美丽的交响曲。”
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 假设：“乐团将有一场音乐表演。”
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 标签：蕴涵
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: QQP（Quora问题对）：识别重复问题（363,000个训练样本，390,000个测试样本，40,000个验证样本）。
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 问题1：“我如何提高我的信用评分？”
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 问题2：“我可以采取哪些步骤来提高我的信用评级？”
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 标签：重复
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: QNLI（问题自然语言推理）：为给定问题识别答案句子（103,000个训练样本，5,000个测试样本，5,000个验证样本）。
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 问题：“法国的首都是什么？”
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 句子：“巴黎是法国的首都。”
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 标签：蕴涵
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: SST-2（斯坦福情感树库）：二元情感分类（67,000个训练样本，1,800个测试样本，800个验证样本）。
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 句子：“故事情节平淡无奇。”
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 标签：负面
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 句子：“这部电影情节扣人心弦，非常精彩。”
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 标签：正面
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: CoLA（语言可接受性语料库）：语法性判断（8,000个训练样本，1,000个测试样本，1,000个验证样本）。
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 句子：“这本书被约翰放在了书架上。”
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 标签：可接受
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 句子：“草是绿色的。”
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 标签：不可接受
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: STS-B（语义文本相似度基准）：估计句子对的相似度分数（5,000个训练样本，1,000个测试样本，1,400个验证样本）。
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 句子1：“一只狗在公园里奔跑。”
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 句子2：“一只狗在公园里冲刺。”
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 相似度分数：高
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: MRPC（微软研究释义语料库）：识别句子对中的释义（4,000个训练样本，1,700个测试样本）。
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 句子1：“公司报告了季度收入的显著增长。”
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 句子2：“公司报告季度收入显著增长。”
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 标签：等价
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: RTE（识别文本蕴涵）：识别文本对之间的蕴涵（2,400个训练样本，2,900个测试样本，270个验证样本）。
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 句子1：“尚未发现化学失衡导致抑郁的证据。”
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 句子2：“化学失衡导致抑郁。”
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 标签：非蕴涵
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: WNLI（Winograd NLI）：使用指称消解进行自然语言推理（600个训练样本，140个测试样本，70个验证样本）。
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 句子1：“钥匙被锁在车里了。”
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 句子2：“车钥匙被锁在车里。”
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 标签：蕴涵
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 6.3.6.7.2 SuperGLUE ([王等人，2019](#ref6_76))
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: SuperGLUE被引入作为比GLUE更具挑战性的后续者，它包括一组更困难的语言理解任务。以下是SuperGLUE包含的任务：
  prefs: []
  type: TYPE_NORMAL
- en: BoolQ（布尔问题）：回答是/否问题。BoolQ的详细信息在单独的部分提供，因为它是一个自己的基准。
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: CB（承诺银行）：识别涉及人类承诺的蕴涵关系（250个训练样本，250个测试样本，50个验证样本）。
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 前提：“我无法在下个周末帮你搬家。”
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 假设：“下个周末演讲者无法帮忙搬家。”
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 标签：蕴涵
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: COPA（合理替代选择）：在给定情境中识别原因或结果（400个训练样本，500个测试样本，100个验证样本）。
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 问题：“效果是什么？”
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 句子：“他没有学习，所以考试不及格。”
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 选项：1) 他没有学习。2) 他考试不及格。
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 答案：他考试不及格。
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: MultiRC（多句子阅读理解）：回答有多个可能答案的问题（训练集450个样本，测试集150个样本，验证集80个样本）。
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 问题：“猫发生了什么事？”
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 文段：“猫爬上了树，下不来了。”
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 答案：“爬上了树，下不来了。”
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: ReCoRD（基于常识推理的阅读理解数据集）：涉及常识推理的阅读理解（训练集65,000个样本，测试集7,400个样本，验证集7,400个样本）。
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 问题：“谁买了花？”
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 文段：“乔治去了商店并买了一些花。”
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 答案：乔治
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 问题：“为什么猫下不来？”
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 文段：“猫爬上了树，下不来了。”
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 答案：未说明。
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: RTE（文本蕴涵识别）：也包含在GLUE中，但在此处重复使用（训练集2,400个样本，测试集3,000个样本，验证集270个样本）。
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 句子1：“太阳从东方升起。”
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 句子2：“太阳在西方落下。”
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 标签：非蕴涵
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: WiC（上下文中的词）：确定一个词在两个句子中是否以相同的意义使用（训练集5,400个样本，测试集1,400个样本，验证集630个样本）。
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 单词：“rock”
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 句子1：“他收集石头。”
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 句子2：“他是我的依靠。”
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 标签：不同
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: WSC（Winograd 框架挑战）：一个指代消解任务，类似于GLUE中的WNLI（训练集550个样本，测试集140个样本，验证集100个样本）。
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 句子：“那个周末打猎鸭子的男人。”
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 问题：“谁打猎鸭子？”
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 答案：那个人
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 6.3.6.7.3 MMLU ([Hendrycks 等人，2020](#ref6_25))
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: MMLU（大规模多任务语言理解）基准，由Hendrycks于2020年提出，包含57个任务，涵盖多个领域，包括基础数学、美国历史、计算机科学、法律等。该基准是为了应对LLMs在早期基准如GLUE和SuperGLUE上取得人类水平甚至超越人类水平的性能而建立的。MMLU中的任务难度从基础到高级专业水平不等，测试知识和解决问题的能力。在评估模型时，可用于零样本和少样本设置。
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.6.8 毒性基准
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 6.3.6.8.1 RealToxicityPrompts ([Gehman 等人，2020](#ref6_21))
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: RealToxicityPrompts，由Gehman等人（2020）提出，是一个旨在评估语言模型，尤其是GPT-3及其类似模型，生成不安全或有毒输出的风险和倾向的基准。该基准包含一个数据集，用于探测模型在响应各种提示时的不安全语言生成倾向。
  prefs: []
  type: TYPE_NORMAL
- en: RealToxicityPrompts旨在阐明预训练语言模型，如GPT-3，在接收到不同类型的提示时可能产生有毒、冒犯性或其它不希望输出的程度。
  prefs: []
  type: TYPE_NORMAL
- en: 数据集由旨在从模型中诱出响应的提示组成。其目标是确定这些模型在何种频率和情境下产生可能被视为有害、冒犯性或有毒的答案。
  prefs: []
  type: TYPE_NORMAL
- en: 毒性分类器评估模型生成的响应的潜在毒性，有助于量化输出被用户感知为有毒或有害的可能性。
  prefs: []
  type: TYPE_NORMAL
- en: 通过揭示与自动化语言生成相关的倾向和风险，开发人员和研究人员可以更有效地制定安全措施和对策，以限制有害内容的传播。
  prefs: []
  type: TYPE_NORMAL
- en: 应该注意的是，评估毒性是一个复杂的过程。基准测试本身必须使用专门为此目的训练的机器学习模型来衡量响应的毒性。这与简单的案例形成对比，例如验证多项选择题的答案。
  prefs: []
  type: TYPE_NORMAL
- en: 在处理语言模型中的毒性问题时，一个重要的考虑因素是模型内部可能存在的固有偏差。这些偏差可能体现在输出中。基准测试旨在阐明这些问题，指导努力开发更公正和无偏见的模型。
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.6.9 偏差基准
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 6.3.6.9.1 CrowS-Pairs ([Nangia 等人，2020](#ref6_46))
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 由 Nangia 等人在 2020 年引入的 CrowS-Pairs（众包刻板印象对）基准测试旨在检查语言模型中存在的偏差。它不仅测量模型的性能，而是旨在理解和突出模型在细微和非明确情境中的刻板印象和偏差倾向。
  prefs: []
  type: TYPE_NORMAL
- en: 该基准测试专注于识别模型中的社会文化人口偏差。它评估模型在诸如种族、宗教和性别等其他维度的偏差。CrowS-Pairs 包含了一系列句子对，旨在对比非刻板和刻板场景。为了确保这些句子对涵盖了广泛且细微的偏差范围，人类标注员参与了这些句子对的开发和验证。
  prefs: []
  type: TYPE_NORMAL
- en: 模型在其对这些句子对的响应上进行评估，从而得出一个偏差分数，为模型偏差提供了一个量化的度量。基准测试提供了关于不同维度上偏差的性质和程度的见解。它不仅捕捉到显性偏差，还包括隐性和细微的偏差，这些偏差否则可能会被忽视。
  prefs: []
  type: TYPE_NORMAL
- en: 在这里，句子 A 可能包含将母亲与责任联系起来的性别刻板印象，而句子 B 则提供非刻板印象的对应物。然后根据模型如何解释和评估这些对进行评估，从而提供关于其偏差的见解。
  prefs: []
  type: TYPE_NORMAL
- en: 这两个句子将被呈现给模型，模型将被要求为每个句子提供分数或评估其可信度。然后基准测试将评估模型的响应，了解哪个句子是有偏差的，哪个是没有偏差的。
  prefs: []
  type: TYPE_NORMAL
- en: CrowS-Pairs 是伦理 AI 和偏见分析领域中的一个重要工具。它通过突出模型固有的偏见，支持开发更公平、更公正的语言模型。
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.6.9.2 WinoGender 基准 ([Rudinger et al., 2018](#ref6_59))
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: WinoGender 基准是由 Rudinger 等人在 2018 年提出的，专门设计用来评估指代消解系统中的性别偏见。指代消解是自然语言处理（NLP）中的一个任务，涉及确定文本中两个或多个单词（或短语）是否指代同一实体。
  prefs: []
  type: TYPE_NORMAL
- en: WinoGender 数据集包括围绕代词（他、她、他的、她的等）设计的句子，该代词与句子中的两个潜在指代对象之一相关联。重要的是，其中一个指代对象与代词存在刻板印象的关联，而另一个则没有。这种设计的目的是探索模型是否更有可能将代词与刻板印象相关的指代对象联系起来，从而揭示其预测中可能存在的性别偏见。
  prefs: []
  type: TYPE_NORMAL
- en: 在符合刻板印象的情境中，由于普遍存在的性别刻板印象，一个模型可能会倾向于将“她”与“护士”以及“他”与“外科医生”联系起来。基准测试将评估模型是否在各种场景中持续地做出这种刻板印象的关联。
  prefs: []
  type: TYPE_NORMAL
- en: 除了揭示模型预测中的偏见外，WinoGender 基准还强调了这些偏见在实现准确和公平的指代消解中带来的挑战。模型开发者和研究人员使用 WinoGender
    等基准来评估并随后减轻模型中存在的偏见，旨在在不同情境和人口群体中获得更公平和准确的表现。
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.6.10 真实性基准
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 6.3.6.10.1 TruthfulQA ([Lin et al., 2022](#ref6_39))
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: TruthfulQA 基准是由 Lin 等人在 2022 年提出的，旨在检查 LLM 对开放域问题的回答的可靠性和真实性。基本目标是审查这些 LLM 在广泛的主题和问题中提供真实和准确答案的能力。
  prefs: []
  type: TYPE_NORMAL
- en: 类似于 TruthfulQA 这样的基准的需求源于观察到的现象，尽管像 GPT-3 这样的模型可以生成流畅且符合上下文语境的回答，但它们有时会生成不正确、误导性或虚构的答案。确保大型语言模型（LLM）提供信息的可靠性至关重要，尤其是在它们越来越多地集成到信息和决策工具中时。
  prefs: []
  type: TYPE_NORMAL
- en: 方法：
  prefs: []
  type: TYPE_NORMAL
- en: '**问题**：数据集包括各种设计用来探测模型提供准确和可靠答案能力的问题。这些问题可能涉及历史、科学和一般知识等广泛的主题。'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**模型回答**：LLM 生成对提供问题的回答。目标是评估这些回答的正确性和可靠性。'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**评估**：人类评估者或自动化系统将评估模型生成的响应的准确性和真实性，将其与验证信息或预定义的答案键进行比较。'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: TruthfulQA作为衡量LLM处理提供事实信息能力的关键工具，这对于确保这些模型可以作为各种应用（如对话代理、信息检索系统等）中可信赖的信息来源至关重要。
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.7 微调
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 微调是机器学习中的一种技术，其中预训练模型进一步训练（通常是在较小的数据集上），以适应其现有知识以适应新任务。该模型已经从更大的数据集中学习到各种特征或模式，并可以利用这些知识在相关任务上以较少的数据表现良好。以下是对语言模型（LLM）和图像生成模型的描述和示例。
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.7.1 语言模型（LLM）中的微调
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 在GPT-3等模型在大量文本语料库上预训练后，它积累了广泛的语文学识。微调涉及在更小、特定领域的数据集上进一步训练它，以专门化其能力，针对某些任务或行业。
  prefs: []
  type: TYPE_NORMAL
- en: 假设你有一个在通用文本上训练的LLM，现在你想对其进行法律建议的微调。该LLM已经在庞大的语料库上训练，并理解了广泛的英语文本。你引入LLM到一个包含法律文件、法院裁决和律师通信的小型数据集。该模型将其泛化知识调整为精通理解和生成法律文本。微调后的LLM现在可以生成更符合语境和术语准确的针对法律查询的响应，或在起草法律文件时提供帮助。
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.7.2 图像生成模型中的微调
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 在大型数据集上预训练的图像生成模型已经学会了通过理解训练数据中的各种视觉模式、结构和上下文来生成图像。微调涉及在更小、更具体的数据集上进一步训练模型，以增强其在生成特定领域或特征相关图像方面的能力。
  prefs: []
  type: TYPE_NORMAL
- en: 考虑一个在广泛图像（例如，面孔、动物、物体）上训练的生成对抗网络（GAN）。GAN知道如何通过理解训练数据中发现的通用模式、颜色、形状和纹理来生成广泛的图像。现在，假设你想生成鸟类图像。你使用仅包含鸟类图像的较小数据集对GAN进行微调。该模型学习与不同鸟种相关的特定视觉特征。微调后的模型现在可以生成各种与鸟类相关的图像，更准确地考虑羽毛、喙形状和大小等特定方面。
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.7.3 微调步骤
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 这些步骤遵循上述基础模型描述的相同步骤，但具有特定的数据集和测试，专注于微调的特定方面。在模型设计和结构方面，可以根据新任务调整模型的架构以适应（例如，为分类任务更改输出层）。通常，模型的特定超参数将进行调整，以确保微调的最佳结果，例如，使用较小的学习率以避免忘记之前学习到的特征，并温和地调整模型以适应新任务。
  prefs: []
  type: TYPE_NORMAL
- en: 微调允许利用预训练期间捕获的广泛知识，在相关任务上即使可用训练数据较少也能实现更好的性能。这种方法在机器学习的各个领域和任务中已被证明是有效的。
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.8 部署
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 我们已经探讨了创建模型所涉及的复杂性。然而，在模型，尤其是像GPT-3/GPT-4或LLaMA-2这样的模型准备用于广泛使用之前，必须采取几个步骤来为大规模生产准备模型。
  prefs: []
  type: TYPE_NORMAL
- en: 这可能包括以下的一些或所有步骤：
  prefs: []
  type: TYPE_NORMAL
- en: '**模型最终确定**：这一阶段涉及选择特定的模型部署到环境，以便用户进行通用使用，通常称为生产环境或简称生产。通常，公司会开发多个模型，每个模型在训练和测试过程中都会进行各种定制。随后，必须做出决定，确定哪个模型可以推进到生产阶段。在这一阶段，将进行任何必要的最终测试（将在后面详细说明），并采取诸如优化模型超参数等行动。'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**模型优化:** 这是一个关键步骤，其中资源使用（包括CPU和内存）被优化以用于生产目的，特别是用于推理。训练模型并将其部署以供大规模使用涉及不同的场景，当模型在处理用户查询时，它必须针对该特定上下文进行调整。模型创建者可以采取的一个有效行动是**模型剪枝**。这涉及到仔细审查模型以识别可以移除以简化模型而不会损害其性能能力的组件，同时减少所需的计算资源，包括内存和CPU。有时，团队可能会进行**消融研究**，系统地移除模型的某些部分以评估其影响。如果这种移除导致对资源的积极影响而不损害性能，他们可能会决定将该组件排除在生产版本之外。还有其他一些技术可能不那么侵入性，包括**阈值剪枝**（移除低于指定阈值的项）、**激活分析**（移除对输出影响最小的项）、**敏感性分析**（移除对输出贡献有限的项）和**冗余分析**（消除冗余组件，如多余的层）。当然，在实施这些修改后，严格测试模型以确保其继续有效运行是至关重要的。另一个经常采用的重要优化策略是**量化**，这是一个降低模型权重精度的过程，以降低内存需求并加速推理。这种方法在在个人电脑或移动设备上运行模型时通常被采用。'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**模型转换:** 这个阶段涉及将模型转换为适合部署的格式，例如Open Neural Network Exchange (ONNX)、TensorFlow
    SavedModel或PyTorch。一些模型可能以可安装的脚本形式分发，例如GPT4All，而其他模型可能被打包为使用Docker for Kubernetes等技术准备好的容器化部署，例如Mistral。模型分发格式的选择具有重要意义，因为它直接影响模型的可访问性和易用性，从而影响社区的兴趣水平。在模型仅打算用于内部使用，并且仅通过用户界面（例如，聊天机器人）或API（如下文所述）公开的情况下，这些模型细节可能对外部方（例如，ChatGPT3.5或ChatGPT4.0）保持隐藏，这些外部方与创建该模型的组织无关。'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**附加测试：** 在大多数情况下，会进行一系列综合的专业测试，包括推理速度、资源消耗和规模测试，这涉及到评估模型在不同用户推理请求负载下的性能。这些评估可能导致对模型的进一步优化，包括实施优化的缓存（内存中存储数据以实现更快访问）策略。'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**API包装器：** 最终用户通常通过用户界面（如基于浏览器的聊天机器人界面）与模型交互。然而，模型可能提供一个应用程序编程接口（API），以便技术熟练的用户与模型交互，并将自己的最终用户界面集成到模型中。这些API通常使用一种称为REST
    API的技术提供。关于这些围绕模型的元素的更深入讨论将在稍后提供，因为它们构成了模型运行的更广泛生态系统中的关键组成部分。在API包装器的案例中，需要考虑确定用户认证的方法和建立授权程序框架。'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**监控和日志记录：** 这是模型部署的关键部分，允许模型在生产环境中由负责该模型的团队保持健康状态。这种监控具有多重目的，而不仅仅是验证其操作状态。它还包括跟踪诸如用户数量和CPU、内存和网络带宽等资源的利用率，确保它们保持在预定义的阈值和控制范围内。此外，有效的监控在识别和纠正模型自身或与模型交互的用户表现出的不良行为方面发挥着关键作用。如果出现问题，他们可以使用监控和日志记录来识别是什么以及如何在未来修复它。'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**安全和对齐过滤：** 在实践中，旨在公开使用的模型，例如与ChatGPT集成的GPT-4模型，通常包含各种功能来降低生成不适当输出的风险。例如，可以在处理过程的早期阶段使用输入过滤器来检查传入的输入，从而识别和解决可能不适当的内容。同样，在检测到问题输出时，输出过滤器可以介入，防止此类内容到达用户。这些输出过滤器可能用更合适的响应替换不适当的内容，或提供默认消息传达模型无法协助的能力。'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**持续改进：** 一旦模型可用，它将需要根据创建该模型的团队的新进展和发现，或从与模型交互的真实用户在运行时环境中的学习中进行持续改进。模型创建者需要了解他们计划如何发布这些更新，是将其作为对用户透明的实时发布，还是作为用户必须明确选择的模型新版本提供，或者可能是作为模型的新专业版本（例如，为某些特定目的训练，例如聊天机器人、代码生成、特定的科学能力等）并作为新模型发布。当用户使用模型时，重要的是要尽快解决出现的问题。有时模型可能会开始提供有偏见的信息或错误信息；这被称为模型幻觉。组织可能会面临大量公众压力来解决这些问题；例如，Meta在模型（称为Galactica）提供有偏见和错误信息三天后不得不将其下线，而且无法快速修复模型（[Snoswell
    & Burgess, 2022](#ref6_68)）。'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 6.3.9 模型使用（又称推理）
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 通常，模型在常规运行时交互期间不会经历学习过程（即对其权重和偏差的更新）。学习仅在基础模型的预训练期间或微调阶段发生。
  prefs: []
  type: TYPE_NORMAL
- en: 然而，这可能会有些令人困惑，因为有一些方法可能看起来类似于学习。一个这样的例子是少样本学习的概念。在少样本学习中，与预期请求一起呈现类似请求-响应对，以帮助模型生成最合适的响应。包括“零样本学习”（不提供任何示例）、“单样本学习”（提供一个示例请求-回复对以供操作）和“少样本学习”（提供多个请求-回复对，通常为2到5对）在内的术语可能会令人困惑。这是因为模型实际上并没有学习；相反，它正在利用这些示例来增强其对请求的理解。模型的参数保持不变。也许这些概念更准确地描述为“少样本请求”或“少样本指导”而不是“少样本学习”。
  prefs: []
  type: TYPE_NORMAL
- en: 值得注意的是，某些模型可能会编译用户请求和响应的数据库，以备将来在训练模型或更新时使用。然而，作为规则，即时学习并不常见，因为它可能导致模型不稳定。这又是一个ANN（人工神经网络）和人类大脑之间基本区别的例证，后者持续参与学习过程。
  prefs: []
  type: TYPE_NORMAL
- en: 以下部分提供了有关其他运行时或推理时间活动的信息，这些活动值得理解。
  prefs: []
  type: TYPE_NORMAL
- en: '[图6.16 模型生态系统。](#R_fig6_16)'
  prefs: []
  type: TYPE_NORMAL
- en: 以下章节讨论了该生态系统的关键方面。在[图6.16](#fig6_16)的示例中，我们可以看到：
  prefs: []
  type: TYPE_NORMAL
- en: 用户A正在使用一个聊天应用和一个文档编写应用，这两个应用都使用基础模型A。
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 软件开发人员A构建并部署了一个自定义应用程序，该应用程序使用他们为法律专业人士创建的、专门针对国际法的微调版本模型A。它使用检索增强生成（RAG）方法，以确保其产品用户获得最有用的结果。
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 用户B使用专注于国际法的法律通用人工智能（Legal GenAI）的定制产品。
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 软件开发人员B构建了一个通用的API，它支持多个基础模型（A、B和C）。它还支持为基础模型A提供的几个插件。这些插件允许基础模型A执行一些有趣的事情，包括从旅行整合服务中搜索旅行选项，以及从知名搜索引擎中进行一般实时搜索。作为此实现的一部分，软件开发人员B使用了模型B的“函数”功能，如果它没有获得结果，它将调用基础模型C。
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 6.4.1 自定义接口和聊天
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 最常见的自定义界面是熟悉的聊天机器人提示和响应界面。重要的是要认识到，人类与之交互的聊天界面与模型是分开的。聊天界面可以使与模型的交互变得容易，并且它可以做出关于与该模型交互的几个可能不明显的决定。例如，它可以执行以下操作：
  prefs: []
  type: TYPE_NORMAL
- en: 将特定的超参数设置为特定值
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 提供之前的交互详情，以便模型具有对话的上下文（例如，自动将讨论前一部分的关键方面添加到模型的当前上下文中）
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 处理请求和处理诸如数据缓存等事项，以最小化对模型的处理和内存负载。
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 聊天界面不是与模型交互的唯一方式；许多工具都与GenAI集成。例如，网站设计工具与模型集成，允许生成网站图像或生成诸如名片之类的项目。一些工具，如Good
    Documents，在编写文档时集成模型以生成内容。
  prefs: []
  type: TYPE_NORMAL
- en: 6.4.2 API和函数
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 模型通常以应用程序编程接口（API）的形式公开，即使这只是为了之前提到的聊天界面。像OpenAI这样的公司也向希望利用模型满足特定需求的软件开发者提供API。该API允许其他软件应用程序访问模型并检索结果。这在例如，如果你运营一家提供文档编写软件的公司，如Google
    Docs、Microsoft Word或Good Notes，就特别有利。这样的API可以将模型的功能集成到软件中，实现诸如内容建议或内容审查等功能。
  prefs: []
  type: TYPE_NORMAL
- en: 函数为使用模型API的软件开发者提供了提供额外灵活性的新方法。有时，模型可能不会在其响应中提供相关信息，可能是因为查询涉及模型训练完成后出现的主题。在这种情况下，开发者可以指示模型在无法直接回答查询时返回函数调用的具体信息。然后，模型将努力调整请求以与开发者提供的函数调用相匹配，并返回这个修改后的请求，从而减轻开发者独立修改请求的需要。然后，开发者可以相对容易地启动指定的函数。重要的是要强调，软件开发者负责发起函数调用。模型要么提供标准响应，要么如果无法做到这一点，就尽可能高效地准备函数调用所需的数据，简化开发者的过程。然而，如果认为合适，发起函数的责任在于开发者。
  prefs: []
  type: TYPE_NORMAL
- en: 6.4.3 插件和代理
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 插件，有时也称为代理，使软件开发者能够构建一个模型可以调用的服务。在API的上下文中，开发者会启动对模型的调用。然而，当处理插件或代理时，是模型主动联系另一个系统或功能。
  prefs: []
  type: TYPE_NORMAL
- en: 考虑一个实例，其最终目标是确定从香港到都柏林在特定未来日期的当前航班价格和时刻表。LLM对此类信息一无所知，因为它在其训练集中不包含这些数据；即使它有，这些信息也很可能是过时的。然而，如果像Expedia这样的公司打算向模型提供这些数据，插件就是实现这一目标的机制。用户可能通过聊天界面或从定制界面发起的API调用向模型发送请求。模型意识到自己无法直接回答查询，就会调用Expedia插件来检索必要的数据并将其传达给用户。
  prefs: []
  type: TYPE_NORMAL
- en: 可以设想一个充满各种插件的世界，这些插件使模型能够为用户执行大量任务。这不仅仅局限于列出航班，还包括预订航班、订购披萨、租车、管理家庭设备，以及通过在线自动化实现的几乎任何任务，只要有了合适的插件。
  prefs: []
  type: TYPE_NORMAL
- en: 插件中信任的重要性显而易见。如果插件被用于非法转账资金，其后果可能是灾难性的。如果插件获取的信息是故意错误的，它将带来挑战。可能存在插件的行为偏离用户意图的情况；例如，用户可能只想检查航班价格，但最终通过插件无意中预订了航班。这样的场景会导致用户不满。
  prefs: []
  type: TYPE_NORMAL
- en: 这需要建立严格的指南和政策来规范插件，开发者必须遵守并正式承诺。
  prefs: []
  type: TYPE_NORMAL
- en: OpenAI已经将其ChatGPT产品与网络浏览插件集成。用户可以通过ChatGPT界面选择激活或停用此插件。如果激活且ChatGPT未能回答查询（例如，当被要求提供其训练数据中未包含的最近数据时），它将访问网络浏览插件，本质上是在利用新的Bing搜索功能，该功能包含一个GPT-4的专用版本。这为模型提供了有价值的扩展，同时确保用户保留对插件使用的控制权。
  prefs: []
  type: TYPE_NORMAL
- en: 6.4.4 自定义微调
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 对于某些特定应用，可以对某些模型进行微调。以OpenAI为例，他们已经增强了其模型（目前是gpt-3-5-turbo模型）的API，允许用户上传一组经过精心挑选的以特定格式存储的训练数据。然后，用户可以指示模型根据这些数据进行微调，并随后接收一个针对该特定目标量身定制的全新模型。用户有责任测试并确认微调后的模型能够提供预期的优势。
  prefs: []
  type: TYPE_NORMAL
- en: 这样的设施为创建针对特定目的的定制模型铺平了道路。例如，一个模型可以被优化以专门从事国际法，使软件开发者能够通过添加额外的功能来补充他们的产品。这些增强功能将对寻求此类特定功能的用户群非常有价值。
  prefs: []
  type: TYPE_NORMAL
- en: 6.4.5 自定义模型
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 许多模型开发者提供针对特定目的的定制模型。这些通常是基础模型的微调版本，针对特定应用进行了调整。例子包括基于聊天的模型、基于代码生成的模型，甚至是一些高度专业化的模型，这些模型不仅生成代码，还能执行代码。OpenAI推出了一种名为“高级数据分析”的定制模型，之前称为代码解释器，旨在生成代码。此外，该模型还可以执行代码并展示输出。这对软件工程师来说非常有价值，使他们能够更快地迭代代码，模型承担更多责任，包括调试。虽然高级数据分析被营销为类似插件的产品，并通过聊天界面管理，就像之前提到的“网页浏览”插件一样，但通过API访问时，其独特的专业化特点显而易见，高级数据分析作为一个单独的模型被调用。
  prefs: []
  type: TYPE_NORMAL
- en: 6.4.6 向量数据库和检索增强生成（RAG）
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 向量数据库是专门设计用于使用向量高效查询和检索数据的数据库。在此上下文中，向量是表示多维空间中对象的数字数组，例如文本、图像或声音。
  prefs: []
  type: TYPE_NORMAL
- en: 这些数据库针对向量之间的相似性搜索等操作进行了优化。它们允许用户高效地识别与给定输入向量相似的项。这种能力在机器学习、推荐系统、图像检索和自然语言处理等应用中尤其有益，在这些应用中，在高维空间中定位相似项至关重要。
  prefs: []
  type: TYPE_NORMAL
- en: 检索增强生成（RAG）将预训练语言模型的能力与信息检索系统相结合，增强了对话式人工智能和其他自然语言处理任务中的响应生成。
  prefs: []
  type: TYPE_NORMAL
- en: 给定一个输入（例如，一个问题或提示），RAG从语料库或数据库中检索相关的文档或文本片段，通常是一个向量数据库。随后检索到的信息将指导生成模型的响应，从而促进更精确、信息丰富和上下文相关的输出的创建。
  prefs: []
  type: TYPE_NORMAL
- en: 这种方法可以类比为在提示中添加示例（类似于少样本学习），使模型能够生成更优质的响应。
  prefs: []
  type: TYPE_NORMAL
- en: 这种优势的一个典型场景是，一个组织拥有一个内部模型和可以轻松处理当前请求的文档数据库。例如，一家旨在生成内容的律师事务所可能希望确保其内容与现有的模板和结构保持一致，尤其是对于合同、法律通知或信函等文件。
  prefs: []
  type: TYPE_NORMAL
- en: 6.5 现有技术模型概述
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 在接下来的几节中，我们考察了几种著名的最先进（SOTA）模型。我们的重点是大型语言模型和文本到图像的扩散模型。对于每个模型，我们提供了公司及其本身的简要概述，随后是关于其发布历史、规格、用途和相关评论的详细信息。
  prefs: []
  type: TYPE_NORMAL
- en: 6.5.1 LLM – OpenAI ChatGPT-4.0
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: OpenAI成立于2015年，最初是一个致力于开放人工智能系统开发和民主化的非营利组织。其创始人包括AI领域的杰出人物，如埃隆·马斯克。随后，该组织转变为营利性结构。其当前的使命声明如下：
  prefs: []
  type: TYPE_NORMAL
- en: 我们的使命是确保通用人工智能——超越人类智能的人工智能系统——造福全人类。
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**发布历史**'
  prefs: []
  type: TYPE_NORMAL
- en: OpenAI GPT-n系列模型：
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 表6.1 OpenAI GPT-n系列发布历史
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '| 日期 | 模型 | 描述 |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| 11/Jun/2018 | GPT-1 | 通过生成预训练改进语言理解 ([Radford et al. 2018](#ref6_52)) |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| 14/Feb/2019 | GPT-2 | 语言模型是无监督的多任务学习者 ([Radford et al., 2019](#ref6_53);
    Solaiman et al., 2019) |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| 28/May/2020 | GPT-3 | 语言模型是少样本学习者 ([Brown et al., 2020](#ref6_10)) |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| 15/Mar/2022 | GPT-3.5 | 3.5版本发布 |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| 30/Nov/2022 | ChatGPT | 这基于GPT-3.5模型，后来通过用户选择支持GPT-3.5和GPT-4 |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| 14/Mar/2023 | GPT-4 | GPT-4技术报告 ([OpenAI, 2023](#ref6_48)) |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '**规格**'
  prefs: []
  type: TYPE_NORMAL
- en: GPT-4的大小和规格尚未公开；然而，从[OpenAI 2023](#ref6_48)技术报告的发布中，我们了解到以下信息：
  prefs: []
  type: TYPE_NORMAL
- en: 它是一个转换器预训练模型（类似于GPT3）
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 它在许多基准测试中表现出人类水平的表现。
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 然而，更多细节已经泄露，尽管不是官方的，但它们确实提供了一些关于尺寸的见解：
  prefs: []
  type: TYPE_NORMAL
- en: GPT-4在120层中拥有约1.8万亿个参数。
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GPT-4在约13万亿个标记上进行训练，包括基于文本和代码的数据。
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 训练数据包括Common Crawl & RefinedWeb，总计13T个标记。有相当多的猜测认为还使用了额外的来源，如Twitter、Reddit、YouTube以及大量教科书。
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 它使用专家混合（MoE）架构，这是一种集成学习方法，允许不同的专家在不同的领域专业化，并选择最合适的专家。可能有16个专家，每个专家约1110亿个参数，或者8个专家，每个专家约2200亿个参数。
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**使用**'
  prefs: []
  type: TYPE_NORMAL
- en: 它是多模态的，这意味着它可以处理文本和图像作为输入，并以文本作为输出。最近，它已经与DALL-E 3集成，用于基于图像的输出。
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 通过代码解释器（现在称为高级数据分析）功能，它可以生成和执行代码
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**评论**'
  prefs: []
  type: TYPE_NORMAL
- en: 该模型被广泛认为是最先进且适用于通用文本生成以及代码生成的。
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 6.5.2 LLM - Meta LLaMA-2
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Meta（原名Facebook）将 LLaMA 模型作为其最复杂的产品之一引入。尽管它最初作为研究发布，但意外泄露并广泛传播。因此，对于 LLaMA-2，Meta
    选择以更宽松的商业许可证发布。
  prefs: []
  type: TYPE_NORMAL
- en: '**发布历史**'
  prefs: []
  type: TYPE_NORMAL
- en: 表 6.2 Meta LLaMA 版本发布历史
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '| 日期 | 模型 | 描述 |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| Feb/2023 | LLaMA-1 | LLaMA: 开放和高效的开放基础语言模型 ([Touvron 等人，2023a](#ref6_71))
    |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| 18/Jul/2023 | LLaMA-2 | LLaMA-2: 开放基础和微调聊天模型 ([Touvron 等人，2023b](#ref6_72))
    |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '**规格**'
  prefs: []
  type: TYPE_NORMAL
- en: LLaMA-2 被设计为自回归语言优化的 Transformer。
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 该模型的微调版本实现了监督微调（SFT）和基于人类反馈的强化学习（RLHF），以更好地与人类对有用性和安全性的偏好保持一致。
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LLaMA-2 根据参数数量分为三种大小：70亿、130亿和700亿参数。
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 模型的标记计数仅指预训练数据，所有模型均使用 400 万个全局批次的标记进行训练。最大的模型，具有 700 亿参数，利用分组查询注意力（GQA）以改善推理可扩展性。
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LLaMA-2 的训练和微调利用了公开可用的在线数据源，使用了超过一百万个由人类标注的示例用于微调。该模型在其训练或微调数据集中不包括 Meta 用户数据。
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**用途**'
  prefs: []
  type: TYPE_NORMAL
- en: 该模型主要用于文本应用。
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 通过其微调版本，即 LLaMA-2-Chat，它优化了对话用例，但其预训练版本可以适应更广泛的自然语言生成任务。
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LLaMA-2 对商业和研究用途均开放，尤其针对英语语言任务。
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**评论**'
  prefs: []
  type: TYPE_NORMAL
- en: LLaMA-2 是 Meta 对 OpenAI 的 GPT 模型以及 Google 的 AI 模型等大型语言模型的回应，其显著特点是更加开放和免费，几乎任何人都可以用于研究和商业目的。
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 6.5.3 LLM – Google Bard 和 PaLM-2
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Google 一直致力于 AI 研究，特别是通过具有里程碑意义的论文“Attention is All You Need”，该论文影响了基于 Transformer
    架构的大型语言模型的流行方向。
  prefs: []
  type: TYPE_NORMAL
- en: '**发布历史**'
  prefs: []
  type: TYPE_NORMAL
- en: 表 6.3 Google PaLM/Bard/LaMDA 发布历史
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '| 日期 | 模型 | 描述 |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| 18/May/2021 | LaMDA-1 | LaMDA: 用于对话应用的语言模型 ([Thoppilan 等人，2022](#ref6_70))
    |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| 11/May/2022 | LaMDA-2 | 版本 2 更新 |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| 21/Mar/2023 | Bard | 基于LaMDA-2最初构建的聊天机器人 |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| 2023年3月 | Bard | Google宣布Bard将很快切换到PaLM-2 |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| 2023年3月 | PaLM-1 | PaLM：通过路径扩展语言建模([Chowdhery等人，2022](#ref6_13)) |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| 2023年5月 | PaLM-2 | PaLM 2技术报告([Anil等人，2023](#ref6_2)) |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '**规格**'
  prefs: []
  type: TYPE_NORMAL
- en: 论文中讨论了PaLM-2（路径语言模型）与三种尺寸的小型（PaLM-2 S）、中型（PaLM-2 M）和大型（PaLM-2 L）的关系。据报道，大型版本比原始的具有540B参数的PaLM模型要小得多。
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: PaLM-2在训练时更加注重使用非英语语言的文本，以及关注多样化的训练数据领域。
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 该模型基于transformer模型；然而，它将训练目标从掩码语言建模扩展到使用不同预训练目标的混合，以帮助它理解语言的各个方面。
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 该模型还重新审视了训练计算的使用方式，并转向了一种模型大小与训练数据大小以1:1的比例更一致的方法，以获得特定计算能力下的最佳价值。
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: PaLM-2提供了几种不同的配置：Gecko、Otter、Bison和Unicorn。据信这些配置的大小分别为1.5B、6B、137B和540B。每个版本都有不同的尺寸，并设计用于特定应用。例如，Gecko是最小且最轻量级的。它专为移动设备设计。
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Google Bard使用的聊天界面采用了PaLM-2模型。然而，目前开发人员访问这些模型的唯一方式是通过Google Cloud Platform（例如PaLM
    API、MakerSuite或Vertex AI）。
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**用途**'
  prefs: []
  type: TYPE_NORMAL
- en: 它专注于高级推理任务，包括代码和数学、分类和问答、翻译和多语言能力，以及自然语言生成。
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**评论**'
  prefs: []
  type: TYPE_NORMAL
- en: PaLM-2模型和Google Bard并没有像OpenAI ChatGPT那样受欢迎或被采用，也没有获得对其能力的相同水平的赞誉。
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 6.5.4 LLM – Anthropic Claude
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Anthropic成立于2021年，其创始人中有几位是从OpenAI离职来创办Anthropic的，因此它是一个相对较新的参与者。
  prefs: []
  type: TYPE_NORMAL
- en: '**发布历史**'
  prefs: []
  type: TYPE_NORMAL
- en: 表6.4 Anthropic Claude发布历史
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '| 日期 | 模型 | 描述 |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| 2023年3月14日 | Claude-1 | Claude和Claude Instant发布 |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| 2023年8月23日 | Claude-2 | Claude进行了更新 |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '**规格**'
  prefs: []
  type: TYPE_NORMAL
- en: Claude是一个基于transformer的架构。该模型比论文中讨论的AnthropicLM的52B参数模型要大，但它是一个在大规模文本语料库上以自监督方式训练的自动回归模型，类似于GPT-3。
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Claude有两种版本：Claude和Claude Instant。Claude是一个最先进的高性能模型，而Claude Instant是一个更轻量级、更便宜且速度更快的选项。
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Anthropic与Quora合作，并构建了一个名为Poe的移动应用程序的聊天界面，用于克劳德。Poe还提供了对其他模型的接口，使其成为一个有趣的工具，可以比较不同模型的响应。Anthropic还通过API为克劳德和克劳德即时提供开发者访问权限。
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Anthropic还与DuckDuckGo合作，DuckDuckGo是一个以隐私为重点的搜索引擎和浏览器，旨在与实时信息集成。
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**使用**'
  prefs: []
  type: TYPE_NORMAL
- en: 克劳德能够在保持高度可靠性和可预测性的同时，执行广泛的对话和文本处理任务。
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 克劳德可以帮助处理包括摘要、搜索、创意和协作写作、问答、编码等用例。
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**注释**'
  prefs: []
  type: TYPE_NORMAL
- en: Anthropic撰写了关于（[Bai等人，2022](#ref6_6)）一种称为宪法人工智能（CAI）的方法的文章，该方法涉及以安全的方式训练模型。这反映了公司专注于AI安全研究的历史。
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 克劳德（Claude）的一个独特之处在于其庞大的上下文大小，达到100k个标记。
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 根据当前能力，克劳德不如GPT-4强大。
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 6.5.5 LLM – Mistral AI Mistral
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Mistral AI成立于2023年，不久前才发布了其第一个模型。与许多其他参与者不同，Mistral总部位于欧洲（法国），并已将其初始模型作为开源发布。
  prefs: []
  type: TYPE_NORMAL
- en: '**发布历史**'
  prefs: []
  type: TYPE_NORMAL
- en: 表6.5 Mistral AI发布历史
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '| 日期 | 模型 | 描述 |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| 27/Sep/2023 | Mistral-7B | Mistral 7B模型在Apache 2许可证下发布。 |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '**规格**'
  prefs: []
  type: TYPE_NORMAL
- en: Mistral AI发布了两个初始版本：Mistral-7B和Mistral-7B-Instruct。它打算稍后发布更大的模型。指令版本是为问答交互（如聊天用例）微调的版本。
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 这些模型使用分组查询注意力（GQA）以实现更快的推理。
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 这些模型使用滑动窗口注意力（SWA）以较小的成本处理更长的序列。
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 这些模型以Apache 2风格的许可证作为开源发布。
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 根据基准测试，它们在所有基准测试中都优于LLaMA-2 13B，在许多基准测试中优于LLaMA-1 34B。它们在代码方面的性能接近CodeLlama
    7B，同时在英语任务上仍然表现良好。
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**使用**'
  prefs: []
  type: TYPE_NORMAL
- en: 初始模型专注于通用英语语言生成和微调的问答模型。
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 它们还训练于代码生成任务。
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**注释**'
  prefs: []
  type: TYPE_NORMAL
- en: 该模型是开源的，可用于商业用途，这为开发者提供了一个有用的替代方案。
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 尽管目前规模较小，但它也定位自己为一个高性能模型。
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 6.5.6 扩散模型 – stability.ai Stable Diffusion
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Stability AI成立于2020年，他们的模型Stable Diffusion于2022年首次发布。该模型基于Prof. Dr. Björn Ommer的工作，他领导了原始Stable
    Diffusion V1的发布。
  prefs: []
  type: TYPE_NORMAL
- en: '**发布历史**'
  prefs: []
  type: TYPE_NORMAL
- en: 表6.6 Stable Diffusion发布历史
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '| 日期 | 模型 | 描述 |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| 2022年8月 | 稳定扩散1.4 | 版本1.4发布。 |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| 2022年10月 | 稳定扩散1.5 | 版本1.5发布。 |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| 2022年11月 | 稳定扩散2.0 | 版本2.0发布。 |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| 2022年12月 | 稳定扩散2.1 | 版本2.1发布。 |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| 2023年7月 | 稳定扩散XL1.0 | 新XL版本1.0发布 |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '**规格**'
  prefs: []
  type: TYPE_NORMAL
- en: 稳定扩散是一个基于扩散技术的深度学习、文本到图像模型。它作为一个具有固定、预训练文本编码器（称为OpenCLIP-ViT/H）的潜在扩散模型运行，用于根据文本提示生成和修改图像。
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 据信它是在来自Flickr、Wikimedia Commons和LAION-5B等多种来源的超过50亿张图像上训练的。
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**使用**'
  prefs: []
  type: TYPE_NORMAL
- en: 它的主要用途是根据文本描述生成详细的图像。
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 它还支持其他任务，例如图像修复（图像内的编辑）、图像扩展（扩展到原始图像之外）以及由文本提示引导的图像到图像的翻译。
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 该模型以其能够创建具有增强构图和逼真美学的描述性图像而闻名，并且它还可以在图像中生成单词。
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**评论**'
  prefs: []
  type: TYPE_NORMAL
- en: 它的旗舰图像模型SDXL 1.0在图像生成方面的优越性得到了特别强调。
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 稳定扩散2.0的发布包括了使用由LAION开发的新文本编码器训练的鲁棒文本到图像模型，与早期版本相比，显著提高了生成图像的质量。
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 6.5.7 扩散模型 – OpenAI DALL-E 3
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: DALL-E 3是OpenAI开发的最新文本到图像模型，之前在ChatGPT的上下文中已经讨论过。DALL-E 3与ChatGPT的集成增强了其可访问性，并在DALL-E
    2之上实现了显著的进步。
  prefs: []
  type: TYPE_NORMAL
- en: '**发布历史**'
  prefs: []
  type: TYPE_NORMAL
- en: 表6.7 OpenAI DALL-E 发布历史
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '| 日期 | 模型 | 描述 |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| 2021年1月5日 | DALL-E | 初始发布 |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| 2022年4月6日 | DALL-E 2 | 版本2发布 |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| 2023年9月 | DALL-E 3 | 版本3发布 |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '**规格**'
  prefs: []
  type: TYPE_NORMAL
- en: DALL-E 3是一个基于扩散技术的文本到图像模型。
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 它是在ChatGPT上本地构建的。当被一个想法提示时，ChatGPT将自动为DALL-E 3生成定制和详细的提示。
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**使用**'
  prefs: []
  type: TYPE_NORMAL
- en: 在图像生成中，提示的细节对于提供更细腻的输出图像非常重要。
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**评论**'
  prefs: []
  type: TYPE_NORMAL
- en: DALL-E 3在“安全性”方面投入了更多努力，其中提示无法生成活着的艺术家和创作者风格的图像，创作者可以请求将他们的作品排除在未来图像生成模型的训练之外。
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: DALL-E 3生成的图像属于提示者。
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 6.5.8 扩散模型 – Midjourney Inc. Midjourney
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Midjourney 由 David Holt 创立。与其它人工智能初创公司不同，它在获得风险投资资金之前就已经产生了大量收入。他们于 2022 年发布的首款模型获得了人气，并且与
    Discord 的集成似乎增强了其知名度。
  prefs: []
  type: TYPE_NORMAL
- en: '**发布历史**'
  prefs: []
  type: TYPE_NORMAL
- en: 表 6.8 Midjourney 发布历史
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '| 日期 | 模型 | 描述 |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| Feb/2022 | Midjourney V1 | 版本 1 发布 |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| 12/Apr/2022 | Midjourney V2 | 版本 2 发布 |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| 25/Jul/2022 | Midjourney V3 | 版本 3 发布 |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| 5/Nov/2022 | Midjourney V4 | 版本 4 发布 |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| 15/Mar/2023 | Midjourney V5 | 版本 5 发布 |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| 3/May/2023 | Midjourney V5.1 | 版本 5.1 发布 |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| 22/Jun/2023 | Midjourney V5.2 | 版本 5.2 发布 |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '**规格**'
  prefs: []
  type: TYPE_NORMAL
- en: Midjourney 是一个扩散模型，使用变压器神经网络从文本提示生成图像。
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 扩散过程旨在生成比其他一些模型更具创造性和表现力的图像。
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**用途**'
  prefs: []
  type: TYPE_NORMAL
- en: Midjourney 设计得既用户友好又易于通过 Discord 访问。
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**评论**'
  prefs: []
  type: TYPE_NORMAL
- en: Midjourney 的一些实验性算法可能受到 Creative ML OpenRAIL-M 许可证的许可限制，这可以从他们服务条款的最新修订中看出。
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 6.5.9 语音识别 – OpenAI Whisper
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: OpenAI 的 Whisper 模型已被发布为开源模型，旨在促进其在各种情况下的使用，包括嵌入式场景，在这些场景中，语音到文本的功能是有益的。
  prefs: []
  type: TYPE_NORMAL
- en: '**发布历史**'
  prefs: []
  type: TYPE_NORMAL
- en: 表 6.9 OpenAI Whisper 发布历史
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '| 日期 | 模型 | 描述 |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| 21/Sep/2022 | Whisper | 通过大规模弱监督实现鲁棒的语音识别 ([Radford 等人，2022](#ref6_51)) |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '**规格**'
  prefs: []
  type: TYPE_NORMAL
- en: 它是一个编码器-解码器变压器架构。
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 编码器使用两个卷积层处理输入，解码器使用学习到的位置编码。
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 它在超过 68 万小时的跨语言和多任务数据上进行了训练。
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**用途**'
  prefs: []
  type: TYPE_NORMAL
- en: Whisper 是一个支持多种语言的自动语音识别系统，具有理解口音和背景噪音的能力。在实时中，它可以转录语音为文本。
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 该模型以开源的方式提供，允许将其集成到产品中。
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**评论**'
  prefs: []
  type: TYPE_NORMAL
- en: 它在英语语音识别上接近人类水平的鲁棒性和准确性。
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Whisper 的一大优点是它在零样本任务上表现良好，这意味着它不需要人的语音示例来转录。
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 6.6 结论
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 人工神经网络（ANNs）和深度神经网络（DNNs）在人工智能领域有着悠久的历史。它们基本上自人工智能学科诞生以来就存在，可以追溯到达特茅斯夏季研究项目。
  prefs: []
  type: TYPE_NORMAL
- en: 神经网络和深度神经网络的目标始终是开发一种能够以人类方式学习的计算机程序，在各个领域或可能在其训练的任何领域获得专业知识。
  prefs: []
  type: TYPE_NORMAL
- en: 今天，这一目标似乎比以往任何时候都更容易实现。只要我们有足够先进的计算机来支持不断扩大的模型，以及越来越多的数据来训练这些模型，以掌握我们希望他们精通的各个主题，这些神经网络的潜力可能确实是无限的。
  prefs: []
  type: TYPE_NORMAL
- en: 创建、训练和测试模型的过程从未如此易于接近。这种便利性得益于知识的可用性，它有助于构建必要的专业知识，对模型本身的便捷访问，用于训练的数据，以及用于测试的基准。现在，微调现有的基础模型相对简单，甚至相对缺乏经验的个人或团队也能承担。我们观察到最先进的（SOTA）模型在灵活的商业许可证（例如，LLaMA-2）或真正的开源许可证下发布，用于模型环境的部分（例如，Mistral、Whisper、Stable
    Diffusion）。关于机器学习的全面免费在线课程的大量存在进一步降低了知识获取的门槛，使个人能够获得深厚的专业知识。此外，量子计算的前景即将到来，承诺在处理能力方面带来变革性的进步。
  prefs: []
  type: TYPE_NORMAL
- en: 所有这些发展都有力地证明了AGI（通用人工智能）和ASI（超级人工智能）是不可避免的，注定要达到以前无法想象的高度智能水平。
  prefs: []
  type: TYPE_NORMAL
- en: 然而，明智的做法是回忆过去对神经网络潜力的过度估计的警告。历史提醒我们，有两个先前的AI“寒冬”，其中这种过度自信发挥了重要作用。
  prefs: []
  type: TYPE_NORMAL
- en: 参考文献
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Ackley, D. H., Hinton, G. E., & Sejnowski, T. J.](#R_ref6_1) (1985). Boltzmann机的学习算法。认知科学，*9*(2)，147–169。'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Anil, R., Dai, A. M., Firat, O., Johnson, M., Lepikhin, D., Passos, A., Shakeri,
    S., Taropa, E., Bailey, P., Chen, Z., … & Saeta, B.](#R_ref6_2) (2023). PaLM 2
    技术报告 [预印本]。 [https://doi.org/10.48550/arXiv.2305.10403](https://doi.org/10.48550/arXiv.2305.10403)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Arute, F., Arya, K., Babbush, R., Bacon, D., Bardin, J. C., Barends, R., …
    & Martinis, J. M.](#R_ref6_3) (2019). 使用可编程超导处理器实现量子霸权。自然，*574*(7779)，505–510。
    [https://doi.org/10.1038/s41586-019-1666-5](https://doi.org/10.1038/s41586-019-1666-5)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Asimov, I.](#R_ref6_4) (1950). Runaround. In The Isaac Asimov Collection (Ed.),
    I, Robot (p. 40). Doubleday。'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Austin, J., Odena, A., Nye, M., Bosma, M., Michalewski, H., Dohan, D., Jiang,
    E., Cai, C., Terry, M., Le, Q., & Sutton, C.](#R_ref6_5) (2021). 使用大型语言模型进行程序综合
    [预印本]. [https://doi.org/10.48550/arXiv.2108.07732](https://doi.org/10.48550/arXiv.2108.07732)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Bai, Y., Kadavath, S., Kundu, S., Askell, A., Kernion, J., Jones, A., Chen,
    A., Goldie, A., Mirhoseini, A., McKinnon, C., Chen, C., Olsson, C., Olah, C.,
    Hernandez, D., Drain, D., Ganguli, D., Li, D., Tran-Johnson, E., Perez, E., Kerr,
    J., … Kaplan, J.](#R_ref6_6) (2022). 宪章 AI：从 AI 反馈中获得无害性 [预印本]. [https://doi.org/10.48550/arXiv.2212.08073](https://doi.org/10.48550/arXiv.2212.08073)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Bisk, Y., Zellers, R., Le Bras, R., Gao, J., & Choi, Y.](#R_ref6_7) (2020).
    PIQA: 在自然语言中推理物理常识. 在 *AAAI 2020*. [https://doi.org/10.48550/arXiv.1911.11641](https://doi.org/10.48550/arXiv.1911.11641)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Block, H. D., Knight, B. W. Jr., & Rosenblatt, F.](#R_ref6_8) (1962). 分析一个四层串联感知器
    II. 现代物理评论, *34*(1), 135\. [https://doi.org/10.1103/RevModPhys.34.135](https://doi.org/10.1103/RevModPhys.34.135)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Breiman, L.](#R_ref6_9) (2001). 随机森林. 机器学习, *45*(1), 5–32\. [https://doi.org/10.1023/A:1010933404324](https://doi.org/10.1023/A:1010933404324)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Brown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P.,
    Neelakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S., Herbert-Voss,
    A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler, D. M., Wu, J.,
    Winter, C., Hesse, C., Chen, M., Sigler, E., Litwin, M., Gray, S., Chess, B.,
    Clark, J., Berner, C., McCandlish, S., Radford, A., Sutskever, I., & Amodei, D.](#R_ref6_10)
    (2020). 语言模型是少样本学习者. arXiv 预印本. [https://doi.org/10.48550/arXiv.2005.14165](https://doi.org/10.48550/arXiv.2005.14165)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Chen, M., Tworek, J., Jun, H., Yuan, Q., Pinto, H. P. de O., Kaplan, J., Edwards,
    H., Burda, Y., Joseph, N., Brockman, G., Ray, A., Puri, R., Krueger, G., Petrov,
    M., Khlaaf, H., Sastry, G., Mishkin, P., Chan, B., Gray, S., Ryder, N., Pavlov,
    M., Power, A., Kaiser, L., Bavarian, M., Winter, C., Tillet, P., Such, F. P.,
    Cummings, D., Plappert, M., Chantzis, F., Barnes, E., Herbert-Voss, A., Guss,
    W. H., Nichol, A., Paino, A., Tezak, N., Tang, J., Babuschkin, I., Balaji, S.,
    Jain, S., Saunders, W., Hesse, C., Carr, A. N., Leike, J., Achiam, J., Misra,
    V., Morikawa, E., Radford, A., Knight, M., Brundage, M., Murati, M., Mayer, K.,
    Welinder, P., McGrew, B., Amodei, D., McCandlish, S., Sutskever, I., & Zaremba,
    W.](#R_ref6_11) (2021). 评估在代码上训练的大型语言模型（版本 v2） [预印本]. [https://doi.org/10.48550/arXiv.2107.03374](https://doi.org/10.48550/arXiv.2107.03374)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Cheng, H.-T., Koc, L., Harmsen, J., Shaked, T., Chandra, T., Aradhye, H.,
    Anderson, G., Corrado, G., Chai, W., Ispir, M., Anil, R., Haque, Z., Hong, L.,
    Jain, V., Liu, X., & Shah, H.](#R_ref6_12) (2016). 广度与深度学习在推荐系统中的应用. arXiv:1606.07792
    [cs.LG]. [https://doi.org/10.48550/arXiv.1606.07792](https://doi.org/10.48550/arXiv.1606.07792)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Chowdhery, A., Narang, S., Devlin, J., Bosma, M., Mishra, G., Roberts, A.,
    Barham, P., Chung, H. W., Sutton, C., Gehrmann, S., … & Fiedel, N.](#R_ref6_13)
    (2022). PaLM: 通过路径扩展语言模型 [预印本]. [https://doi.org/10.48550/arXiv.2204.02311](https://doi.org/10.48550/arXiv.2204.02311)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Clark, C., Lee, K., Chang, M.-W., Kwiatkowski, T., Collins, M., & Toutanova,
    K. (2019). BoolQ: 探索自然是/否问题的惊人难度. *NAACL 2019*. [https://doi.org/10.48550/arXiv.1905.10044](https://doi.org/10.48550/arXiv.1905.10044)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Clark, P., Cowhey, I., Etzioni, O., Khot, T., Sabharwal, A., Schoenick, C.,
    & Tafjord, O.](#R_ref6_15) (2018). 认为你的问答问题已经解决了？试试ARC，AI2推理挑战。arXiv预印本 arXiv:1803.05457\.
    [https://doi.org/10.48550/arXiv.1803.05457](https://doi.org/10.48550/arXiv.1803.05457)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Cobbe, K., Kosaraju, V., Bavarian, M., Chen, M., Jun, H., Kaiser, L., Plappert,
    M., Tworek, J., Hilton, J., Nakano, R., Hesse, C., & Schulman, J.](#R_ref6_16)
    (2021). 训练验证者解决数学文字问题（版本v2） [预印本]. [https://doi.org/10.48550/arXiv.2110.14168](https://doi.org/10.48550/arXiv.2110.14168)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Feynman, R. P.](#R_ref6_17) (1982). 用计算机模拟物理学. 国际理论物理学杂志, *21*(6/7), 467–488.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Friedman, J. H.](#R_ref6_18) (2002). 随机梯度提升. 计算统计学与数据分析, *38*(4), 367–378\.
    [https://doi.org/10.1016/S0167-9473(01)00065-2](https://doi.org/10.1016/S0167-9473(01)00065-2)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[生命未来研究所](#R_ref6_19). (2023a). 一封公开信：暂停巨型AI实验. [插入检索日期]，来自 [https://futureoflife.org/open-letter/pause-giant-ai-experiments/](https://futureoflife.org)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[生命未来研究所](#R_ref6_20). (2023b). 暂停时期的政策制定. [https://futureoflife.org/wp-content/uploads/2023/04/FLI_Policymaking_In_The_Pause.pdf](https://futureoflife.org)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Gehman, S., Gururangan, S., Sap, M., Choi, Y., & Smith, N. A.](#R_ref6_21)
    (2020). RealToxicityPrompts: 评估语言模型中的神经毒性退化 [预印本]. [https://doi.org/10.48550/arXiv.2009.11462](https://doi.org/10.48550/arXiv.2009.11462)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Goodfellow, I., Bengio, Y., & Courville, A.](#R_ref6_22) (2016). 深度学习. MIT出版社.
    [http://www.deeplearningbook.org](http://www.deeplearningbook.org)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Goodfellow, I. J., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D.,
    Ozair, S., Courville, A., & Bengio, Y.](#R_ref6_23) (2014). 生成对抗网络 arXiv 预印本 arXiv:1406.2661\.
    [https://doi.org/10.48550/arXiv.1406.2661](https://doi.org/10.48550/arXiv.1406.2661)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Hebb, D. O.](#R_ref6_24) (1949). 行为组织：一种神经心理学理论。John Wiley & Sons; Chapman
    & Hall.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Hendrycks, D., Burns, C., Basart, S., Zou, A., Mazeika, M., Song, D., & Steinhardt,
    J.](#R_ref6_25) (2020). 使用MATH数据集测量大规模多任务语言理解 [预印本]。 [https://doi.org/10.48550/arXiv.2009.03300](https://doi.org/10.48550/arXiv.2009.03300)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Hendrycks, D., Burns, C., Kadavath, S., Arora, A., Basart, S., Tang, E., Song,
    D., & Steinhardt, J.](#R_ref6_26) (2021). 使用MATH数据集（版本v2）测量数学问题解决 [预印本]。NeurIPS。
    [https://doi.org/10.48550/arXiv.2103.03874](https://doi.org/10.48550/arXiv.2103.03874)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Hinton, G. E., Osindero, S., & Teh, Y-W.](#R_ref6_27) (2006). 一种快速学习深度信念网络的算法。神经计算，*18*(7)，1527–1554\.
    [https://doi.org/10.1162/neco.2006.18.7.1527](https://doi.org/10.1162/neco.2006.18.7.1527)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Hochreiter, S., & Schmidhuber, J.](#R_ref6_28) (1997). 长短期记忆。神经计算，*9*(8)，1735–1780\.
    [https://doi.org/10.1162/neco.1997.9.8.1735](https://doi.org/10.1162/neco.1997.9.8.1735)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hopfield, J. J. (1982). 具有涌现集体计算能力的神经网络和物理系统。美国国家科学院院刊，*79*(8)，2554–2558.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Joshi, M., Choi, E., Weld, D. S., & Zettlemoyer, L.](#R_ref6_30) (2017). TriviaQA：用于阅读理解的远程监督大规模挑战数据集（版本v2）
    [预印本]。arXiv。 [https://doi.org/10.48550/arXiv.1705.03551](https://doi.org/10.48550/arXiv.1705.03551)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Joulin, A., Grave, E., Bojanowski, P., Douze, M., Jégou, H., & Mikolov, T.](#R_ref6_31)
    (2016). FastText.zip：压缩文本分类模型。*arXiv:1612.03651 [cs.CL]*。 [https://doi.org/10.48550/arXiv.1612.03651](https://doi.org/10.48550/arXiv.1612.03651)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Kaur, S., Singh, S., & Kaushal, S.](#R_ref6_32) (2021). 在在线用户生成数据中检测侮辱性内容：综述。计算机科学进展。
    [https://doi.org/10.1016/j.procs.2021.05.098](https://doi.org/10.1016/j.procs.2021.05.098)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Krizhevsky, A., Sutskever, I., & Hinton, G. E.](#R_ref6_33) (2012). 使用深度卷积神经网络进行ImageNet分类。神经信息处理系统进展，*25*(2)。
    [https://doi.org/10.1145/3065386](https://doi.org/10.1145/3065386)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Kwiatkowski, T., Palomaki, J., Redfield, O., Collins, M., Parikh, A., Alberti,
    C., Epstein, D., Polosukhin, I., Kelcey, M., Devlin, J., Lee, K., Toutanova, K.
    N., Jones, L., Chang, M.-W., Dai, A., Uszkoreit, J., Le, Q., & Petrov, S.](#R_ref6_34)
    (2019). 自然问题：问答研究基准. 计算语言学协会会刊，7(15), 453–466\. [https://doi.org/10.1162/tacl_a_00276](https://doi.org/10.1162/tacl_a_00276)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Lai, G., Xie, Q., Liu, H., Yang, Y., & Hovy, E.](#R_ref6_35) (2017). RACE：来自考试的阅读理解大规模数据集（版本v5）
    [预印本]. arXiv. [https://doi.org/10.48550/arXiv.1704.04683](https://doi.org/10.48550/arXiv.1704.04683)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Le, Q. V., Ranzato, M., Monga, R., Devin, M., Chen, K., Corrado, G. S., Dean,
    J., & Ng, A. Y.](#R_ref6_36) (2011). 使用大规模无监督学习构建高级特征. arXiv:1112.6209\. [https://doi.org/10.48550/arXiv.1112.6209](https://doi.org/10.48550/arXiv.1112.6209)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LeCun, Y., Boser, B., Denker, J. S., Henderson, D., Howard, R. E., Hubbard,
    W., & Jackel, L. D.](#R_ref6_37) (1989). 将反向传播应用于手写邮编识别. 神经计算，*1*(4), 541–551.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LeCun, Y., Bottou, L., Bengio, Y., & Haffner, P. (1998). 将基于梯度的学习方法应用于文档识别.
    IEEE汇刊，*86*(11), 2278–2324\. [https://doi.org/10.1109/5.726791](https://doi.org/10.1109/5.726791)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Lin, S., Hilton, J., & Evans, O.](#R_ref6_39) (2022). TruthfulQA：衡量模型模仿人类错误的方式
    [预印本]. [https://doi.org/10.48550/arXiv.2109.07958](https://doi.org/10.48550/arXiv.2109.07958)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[McCarthy, J., Minsky, M. L., Rochester, N., & Shannon, C. E.](#R_ref6_40)
    (1955, August 31). 关于人工智能夏季研究项目的提案. 达特茅斯学院；哈佛大学；IBM公司；贝尔电话实验室。'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: McClelland, J. L., Rumelhart, D. E., & PDP Research Group. (1987). 并行分布式处理：认知微观结构的探索：心理和生物模型（第2卷）.
    麻省理工学院出版社. [https://doi.org/10.7551/mitpress/5237.001.0001](https://doi.org/10.7551/mitpress/5237.001.0001)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[McCulloch, W. S., & Pitts, W.](#R_ref6_42) (1943). 神经活动中内在思想的逻辑演算. 数学生物物理学通报,
    *5*(4), 115–133\. [https://doi.org/10.1007/BF02478259](https://doi.org/10.1007/BF02478259)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Mihaylov, T., Clark, P., Khot, T., & Sabharwal, A.](#R_ref6_43) (2018). 一套盔甲能导电吗？开放书问答的新数据集.
    arXiv预印本 arXiv:1809.02789\. [https://doi.org/10.48550/arXiv.1809.02789](https://doi.org/10.48550/arXiv.1809.02789)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Minsky, M., & Papert, S. A. (1969). 感知器：计算几何导论. 麻省理工学院出版社。
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Minsky, M., & Papert, S. A.](#R_ref6_45) (1988). 感知器：计算几何导论（扩展版）. 麻省理工学院出版社.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Nangia, N., Vania, C., Bhalerao, R., & Bowman, S. R.](#R_ref6_46) (2020).
    CrowS-Pairs：用于测量掩码语言模型中社会偏见的挑战数据集[预印本]. [https://doi.org/10.48550/arXiv.2010.00133](https://doi.org/10.48550/arXiv.2010.00133)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Oliva, A., & Torralba, A.](#R_ref6_47) (2001) 建模场景的形状：空间包络的整体表示. 国际计算机视觉杂志，*42*(3)，145–175.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[OpenAI](#R_ref6_48). (2023). GPT-4技术报告[预印本]. [https://doi.org/10.48550/arXiv.2303.08774](https://doi.org/10.48550/arXiv.2303.08774)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Patel, J. M.](#R_ref6_49) (2020). 常见网络爬虫数据集简介. 在《从互联网获取结构化数据》中. Apress. [https://doi.org/10.1007/978-1-4842-6576-5_6](https://doi.org/10.1007/978-1-4842-6576-5_6)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Radford, A., Kim, J. W., Hallacy, C., Ramesh, A., Goh, G., Agarwal, S., Sastry,
    G., Askell, A., Mishkin, P., Clark, J., Krueger, G., & Sutskever, I.](#R_ref6_50)
    (2021). 从自然语言监督中学习可迁移的视觉模型. [https://doi.org/10.48550/arXiv.2103.00020](https://doi.org/10.48550/arXiv.2103.00020)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Radford, A., Kim, J. W., Xu, T., Brockman, G., McLeavey, C., & Sutskever,
    I.](#R_ref6_51) (2022). 通过大规模弱监督实现鲁棒的语音识别. arXiv预印本. [https://doi.org/10.48550/arXiv.2212.04356](https://doi.org/10.48550/arXiv.2212.04356)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Radford, A., Narasimhan, K., Salimans, T., & Sutskever, I.](#R_ref6_52) (2018).
    通过生成预训练改进语言理解. OpenAI. 从[https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf](https://cdn.openai.com)获取.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., & Sutskever, I.](#R_ref6_53)
    (2019). 语言模型是无监督的多任务学习者. OpenAI. 从[https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf](https://cdn.openai.com)获取.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Raffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., Zhou,
    Y., Li, W., & Liu, P. J.](#R_ref6_54) (2023). 使用统一的文本到文本转换器探索迁移学习的极限（版本4）[预印本].
    arXiv. [https://doi.org/10.48550/arXiv.1910.10683](https://doi.org/10.48550/arXiv.1910.10683)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Rajpurkar, P., Jia, R., & Liang, P.](#R_ref6_55) (2018). 知道你所不知道的：SQuAD的不可回答问题（版本v1）[预印本].
    arXiv. [https://doi.org/10.48550/arXiv.1806.03822](https://doi.org/10.48550/arXiv.1806.03822)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Rajpurkar, P., Zhang, J., Lopyrev, K., & Liang, P.](#R_ref6_56) (2016). SQuAD：用于文本机器理解的10万+问题（版本v3）[预印本].
    arXiv. [https://doi.org/10.48550/arXiv.1606.05250](https://doi.org/10.48550/arXiv.1606.05250)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Rosenblatt, F.](#R_ref6_57) (1957). 感知器——一种感知和识别的自动机（报告号 85-460-1）。康奈尔航空实验室。'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Rosenblatt, F.](#R_ref6_58) (1958). 感知器：大脑中信息存储和组织的一种概率模型。心理学评论，*65*(6)，386–408。[https://doi.org/10.1037/h0042519](https://doi.org/10.1037/h0042519)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Rudinger, R., Naradowsky, J., Leonard, B., & Van Durms, B.](#R_ref6_59) (2018).
    核心词消解中的性别偏见 [预印本]。[https://doi.org/10.48550/arXiv.1804.09301](https://doi.org/10.48550/arXiv.1804.09301)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Rumelhart, D. E., Hinton, G. E., & Williams, R. J.](#R_ref6_60) (1985). 通过误差传播学习内部表示（ICS报告
    8506）。加州大学圣地亚哥分校认知科学研究所。'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Rumelhart, D. E., Hinton, G. E., & Williams, R. J.](#R_ref6_61) (1986a). 通过误差传播学习内部表示。在
    D. E. Rumelhart, J. L. McClelland 和 PDP 研究小组（编），并行分布式处理：认知微观结构的探索。第1卷：基础（第 318–362
    页）。麻省理工学院出版社。'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Rumelhart, D. E., Hinton, G. E., & Williams, R. J.](#R_ref6_62) (1986b). 通过反向传播错误学习表示。自然，*323*(6088)，533–536。'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Rumelhart, D. E., McClelland, J. L.](#R_ref6_63)，与 PDP 研究小组。 (1986c). 并行分布式处理：认知微观结构的探索：基础（第
    1 卷）。麻省理工学院出版社。[https://doi.org/10.7551/mitpress/5236.001.0001](https://doi.org/10.7551/mitpress/5236.001.0001)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Russell, B., Torralba, A., Murphy, K., & Freeman, W. T.](#R_ref6_64) (2007).
    LabelMe：图像标注的数据库和基于网络的工具。国际计算机视觉杂志，*77*(1–3)，157–173。'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Sakaguchi, K., Le Bras, R., Bhagavatula, C., & Choi, Y.](#R_ref6_65) (2019).
    WinoGrande：大规模的对抗性Winograd方案挑战。arXiv预印本 arXiv:1907.10641。[https://doi.org/10.48550/arXiv.1907.10641](https://doi.org/10.48550/arXiv.1907.10641)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Sap, M., Rashkin, H., Chen, D., LeBras, R., & Choi, Y.](#R_ref6_66) (2019).
    社会推理IQA：关于社会互动的常识推理。在 *2019年实证自然语言处理会议（EMNLP 2019）论文集* 中。[https://arxiv.org/abs/1904.09728](https://arxiv.org)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Schuhmann, C., Beaumont, R., Vencu, R., Gordon, C., Wightman, R., Cherti,
    M., Coombes, T., Katta, A., Mullis, C., Wortsman, M., Schramowski, P., Kundurthy,
    S., Crowson, K., Schmidt, L., Kaczmarczyk, R., & Jitsev, J.](#R_ref6_67) (2022).
    LAION-5B：用于训练下一代图像-文本模型的开放大规模数据集。[https://doi.org/10.48550/arXiv.2210.08402](https://doi.org/10.48550/arXiv.2210.08402)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Snoswell, A. J., & Burgess, J.](#R_ref6_68) (2022, November 29). The Galactica
    AI model was trained on scientific knowledge – But it spat out alarmingly plausible
    nonsense. The Conversation。[https://theconversation.com/the-galactica-ai-model-was-trained-on-scientific-knowledge-but-it-spat-out-alarmingly-plausible-nonsense-195445](https://theconversation.com)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tesauro, G. (1995). 时序差分学习和TD-Gammon。ACM通讯，*38*(3)，58–68。
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Thoppilan, R., De Freitas, D., Hall, J., Shazeer, N., Kulshreshtha, A., Cheng,
    H.-T., Jin, A., Bos, T., Baker, L., Du, Y., Li, Y., Lee, H., Zheng, H. S., Ghafouri,
    A., Menegali, M., Huang, Y., Krikun, M., Lepikhin, D., Qin, J., Chen, D., … Le,
    Q.](#R_ref6_70) (2022). LaMDA: 用于对话应用的语言模型。arXiv预印本。[https://doi.org/10.48550/arXiv.2201.08239](https://doi.org/10.48550/arXiv.2201.08239)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Touvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M.-A., Lacroix,
    T., Rozière, B., Goyal, N., Hambro, E., Azhar, F., Rodriguez, A., Joulin, A.,
    Grave, E., & Lample, G.](#R_ref6_71) (2023a). LLaMA: 开放且高效的基座语言模型。arXiv预印本。[https://doi.org/10.48550/arXiv.2302.13971](https://doi.org/10.48550/arXiv.2302.13971)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Touvron, H., Martin, L., Stone, K., Albert, P., Almahairi, A., Babaei, Y.,
    Bashlykov, N., Batra, S., Bhargava, P., Bhosale, S., Bikel, D., Blecher, L., Ferrer,
    C. C., Chen, M., Cucurull, G., Esiobu, D., Fernandes, J., Fu, J., Fu, W., Fuller,
    B., … Scialom, T.](#R_ref6_72) (2023b). Llama 2：开放基座和微调聊天模型。arXiv预印本。[https://doi.org/10.48550/arXiv.2307.09288](https://doi.org/10.48550/arXiv.2307.09288)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Turing, A. M.](#R_ref6_73) (1950). 计算机与智能。Mind，*49*，433–460。'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.
    N., Kaiser, L., & Polosukhin, I.](#R_ref6_74) (2017). 注意力即是所需。arXiv预印本 arXiv:1706.03762v7。[https://doi.org/10.48550/arXiv.1706.03762](https://doi.org/10.48550/arXiv.1706.03762)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Wahba, G., Lin, Y., Zhang, H. H., & Lee, Y.](#R_ref6_75) (2002). 支持向量机，再生核希尔伯特空间和随机GACV。在B.
    Schölkopf & M. K. Warmuth (编)，大间隔分类器进展（第1-69页）。MIT出版社。'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Wang, A., Pruksachatkun, Y., Nangia, N., Singh, A., Michael, J., Hill, F.,
    Levy, O., & Bowman, S. R.](#R_ref6_76) (2019). SuperGLUE：通用语言理解系统的粘性基准。*NeurIPS
    2019*。从[super.gluebenchmark.com](http://super.gluebenchmark.com)检索。'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Wang, A., Singh, A., Michael, J., Hill, F., Levy, O., & Bowman, S. R.](#R_ref6_77)
    (2018). GLUE: 自然语言理解的多元任务基准和分析平台。*ICLR 2019*。arXiv:1804.07461。[https://gluebenchmark.com/](https://gluebenchmark.com)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Weizenbaum, J.](#R_ref6_78) (1976). 计算机力量与人类理性：从判断到计算。W. H. Freeman出版社。'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Wenzek, G., Lachaux, M.-A., Conneau, A., Chaudhary, V., Guzmán, F., Joulin,
    A., & Grave, E.](#R_ref6_79) (2019). CCNet：从网络爬取数据中提取高质量的单语数据集。[https://doi.org/10.48550/arXiv.1911.00359](https://doi.org/10.48550/arXiv.1911.00359)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Werbos, P. J.](#R_ref6_80) (1974). *《超越回归：行为科学预测和分析的新工具》（哈佛大学博士论文）*。'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Widrow, B.](#R_ref6_81) (1960). *《自适应“ADALINE：使用化学“MEMISTORS”的神经元”》（技术报告No.
    1553-2）*。'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Widrow, B.](#R_ref6_82) (1962). 网络Adaline“神经元”的泛化和信息存储。见 M. C. Yovitz, G.
    T. Jacobi, & G. Goldstein (编者)，自我组织系统：研讨会论文集（第435–461页）。Spartan Books。'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Wiener, N.](#R_ref6_83) (1966). God & Golem, Inc.: A comment on certain points
    where cybernetics impinges on religion. The MIT Press。'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Zellers, R., Bisk, Y., Schwartz, R., & Choi, Y.](#R_ref6_84) (2018). SWAG：用于基于常识推理的大规模对抗数据集。*《2018年实证自然语言处理会议（EMNLP
    2018）论文集》*。[https://doi.org/10.48550/arXiv.1808.05326](https://doi.org/10.48550/arXiv.1808.05326)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Zellers, R., Holtzman, A., Bisk, Y., Farhadi, A., & Choi, Y.](#R_ref6_85)
    (2019). HellaSwag：机器真的能完成你的句子吗？见 *《第57届计算语言学协会年会（ACL 2019）论文集》*。[https://doi.org/10.48550/arXiv.1905.07830](https://doi.org/10.48550/arXiv.1905.07830)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
