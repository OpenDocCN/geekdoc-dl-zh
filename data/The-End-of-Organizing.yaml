- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: COT 专栏'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 分类：COT 专栏
- en: 'date: 2024-05-08 11:12:10'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-05-08 11:12:10
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: The End of Organizing
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 组织的终结
- en: 来源：[https://every.to/chain-of-thought/the-end-of-organizing](https://every.to/chain-of-thought/the-end-of-organizing)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://every.to/chain-of-thought/the-end-of-organizing](https://every.to/chain-of-thought/the-end-of-organizing)
- en: Sponsor Every
  id: totrans-6
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 赞助 Every
- en: 'Do you run a software company looking to reach an audience of early-adopters?
    Consider [sponsoring](https://modern-ton-234.notion.site/Sponsor-Every-8b00e6337c3d4dc68012c48a03ed2e90)
    our smart long-form essays on tech, AI, and productivity:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 您是否经营着一家希望吸引早期采用者受众的软件公司？考虑一下在技术、人工智能和生产力方面赞助我们的智能长篇文章：
- en: I hate to be the bearer of bad news, but all of the time we’ve spent organizing
    our notes was probably wasted.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 我不想成为带来坏消息的人，但我们花在组织笔记上的所有时间可能都是浪费的。
- en: Instead, in the immediate future, our notes will be organized for us by large
    language models (LLMs) like [GPT-3](/c/ai-and-gpt3). Let’s explore.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，在不久的将来，我们的笔记将由像[GPT-3](/c/ai-and-gpt3)这样的大型语言模型（LLMs）为我们组织。让我们来探索一下。
- en: . . .
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: . . .
- en: Note taking is building a relationship with a future version of yourself.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 做笔记是在与未来版本的自己建立关系。
- en: Notes record facts, quotes, ideas, events, and more so they can eventually be
    used to make better decisions, create more interesting writing, and find solutions
    to problems.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 笔记记录了事实、引语、想法、事件等等，以便最终能够用于做出更好的决策，创作更有趣的文字，以及找到解决问题的方案。
- en: For a long time, the way we’ve tried to make this relationship work is by creating
    organizational systems. The best way to make sure future versions of ourselves
    had the right notes at the right time was by constructing Rube Goldberg machines
    of tags, notebook hierarchies, and bi-directional links so that we could pull
    up our notes when we needed them. Or at the very least, we could easily find them
    through search if we knew what we were looking for.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 长时间以来，我们试图让这种关系发挥作用的方式是创建组织系统。确保未来版本的自己在正确的时间有正确的笔记的最佳方法是通过构建标签、笔记本层次结构和双向链接的鲁伯·戈尔德堡机器，以便我们在需要时可以找到我们的笔记。或者至少，如果我们知道我们在找什么，我们可以通过搜索轻松找到它们。
- en: 'But ultimately, the organizing solutions we’ve built are brittle. We build
    and abandon new systems all the time, and rarely, if ever, go back to look at
    old notes. Tags get created and then abandoned. Links rarely get followed. And
    we feel guilty: there’s a lot of value locked up in what we’ve collected over
    the years, if we could just figure out how to use it. Paying for a new notes tool
    is like signing up for a gym membership on January 1\. You know you’ll abandon
    it, but the money you spend soothes your anxiety about not making the most of
    what you have.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 但归根结底，我们建立的组织解决方案都是脆弱的。我们一直在建立和放弃新系统，很少，如果有的话，回头看旧笔记。标签被创建然后被放弃。链接很少被点击。而我们感到内疚：多年来我们收集的内容中蕴藏着很大的价值，如果我们能弄清楚如何使用它的话。购买新的笔记工具就像在一月一日注册健身房会员一样。你知道你会放弃它，但你花的钱可以缓解你对没有充分利用你所拥有的东西的焦虑。
- en: AI changes this equation. A better way to unlock the value in your old notes
    is to use intelligence to surface the right note, at the right time, and in the
    right format for you to use it most effectively. When you have intelligence at
    your disposal, you don’t need to organize.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能改变了这个方程式。解锁您旧笔记中的价值的更好方法是利用智能，在您最有效地使用它时为您呈现正确的笔记、在正确的时间和正确的格式。当您拥有智能时，您就不需要组织。
- en: If we want to understand how AI fixes organizing, first we need to understand
    why organizing notes is so hard. Then we can talk about what might be different
    about it in the future.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想要理解人工智能如何解决组织问题，首先我们需要了解为什么组织笔记是如此困难的。然后我们可以谈论未来可能有什么不同之处。
- en: Why organizing notes is so hard
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为什么组织笔记是如此困难的
- en: The more precisely we know what to use a piece of information for, the more
    easily we can organize it.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们越准确地知道如何使用一条信息，就越容易对其进行组织。
- en: The problem is, we put things into notes *because* we don't know what we'll
    use them for. You write down a quote from a book because you could eventually
    use it in 1,000 different ways. You could use it to help you make a decision,
    or write an essay, or lift a friend’s spirit when they’re going through a tough
    time (and you might use it for all three). Same thing for writing down notes from
    a meeting, or thoughts about a new person you met.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 问题在于，我们将事物记录到笔记中*是因为*我们不知道我们将来会用它们做什么。你从书中摘录一句引用，因为你可能以1000种不同的方式使用它。你可以用它来帮助你做决定，或写一篇文章，或在朋友情绪低落时振奋他们的精神（你可能会用它做这三件事）。对于记录下的会议笔记，或者对遇到的新人的想法，也是同样的道理。
- en: As I argued in “[The Notetaking Cold War](https://every.to/superorganizers/the-notetaking-cold-war-591898),”
    this makes finding a single organizing system for your notes quite challenging. You’ll
    continually reorganize your system, or feel a pull to put a note in many different
    places, or tag it to make sure it pops up again in different contexts.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 如我在[《笔记冷战》](https://every.to/superorganizers/the-notetaking-cold-war-591898)中所提到的，这使得为你的笔记找到一个统一的组织系统变得非常具有挑战性。你会不断重新组织你的系统，或者感觉需要把一个笔记放在许多不同的地方，或者标记它以确保它在不同的上下文中再次出现。
- en: 'This usually doesn’t work so well, and even when you do bump into an old note
    at the right time, you’re faced with another problem:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 通常这样做效果不是很好，即使你在合适的时候遇到了一条旧笔记，你还会面临另一个问题：
- en: Looking at old notes is a bit like looking at stale garbage.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 查看旧笔记有点像查看变质的垃圾。
- en: A note that’s been dashed off in a meeting or hurriedly taken down in the middle
    of the night when you get an idea is usually hard to understand, and takes a while
    to parse. As I wrote in “[The Fall of Roam](https://every.to/superorganizers/the-notetaking-cold-war-591898),”
    when you read an old note you have to load its context back into your head about
    when you took it and why before you understand what it’s saying, and whether or
    not it’s relevant to the task at hand.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在会议上匆匆记录下的笔记或在半夜匆忙记录下的想法通常很难理解，并且需要一段时间来解析。正如我在[《Roam的崛起》](https://every.to/superorganizers/the-notetaking-cold-war-591898)中所写的那样，当你阅读一条旧笔记时，你必须将它的背景重新加载到你的头脑中，弄清楚你何时记录下它以及为什么，然后才能理解它在说什么，以及它是否与手头的任务相关。
- en: So you rarely go back to use your old notes. It’s too cognitively expensive
    and not rewarding enough. For an old note to be helpful it needs to be presented
    to Future You in a way that *clicks* into what you’re working on instantly—with
    as little processing as possible.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 所以你很少回顾你的旧笔记。这太费认知了，而且回报不够。要想一条旧笔记有帮助，它需要以一种*立即与你正在做的事情相契合*的方式呈现给未来的你——尽可能少地处理。
- en: This is where large language models come in.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是大型语言模型的用武之地。
- en: How AI models solve the note organizing problem
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AI模型如何解决笔记组织问题
- en: AI models like GPT-3 can solve organizing in a few key ways.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-3之类的AI模型可以通过几种关键方式解决笔记组织问题。
- en: '**First**, they can automatically tag and link notes together with no manual
    work required. It doesn’t even require an LLM—there are less advanced, cheaper
    models that can do this out of the box today.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '**首先**，它们可以自动标记和链接笔记，无需任何手动操作。甚至不需要LLM——今天已经有更简单的、更便宜的模型可以做到这一点。'
- en: '**Second**, they can enrich notes as you’re writing them and synthesize them
    into research reports, eliminating much of the need for tagging and linking in
    the first place.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '**其次**，在你编写笔记时，它们可以丰富笔记并将它们综合成研究报告，从而大大减少了标记和链接的需求。'
- en: '**Third**, they can resurface key information from previous notes into a [CoPilot-like
    experience](https://every.to/superorganizers/the-knee-of-the-exponential-curve)
    for note-taking. This makes searching through old notes unnecessary and helps
    you bring to bear *all of the information* you’ve ever written down every time
    you tap a key.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '**第三**，它们可以将先前笔记中的关键信息重新呈现为一种类似[CoPilot的体验](https://every.to/superorganizers/the-knee-of-the-exponential-curve)，用于记笔记。这使得搜索旧笔记变得不必要，并帮助你在每次敲击键盘时都能发挥出你曾经记录的*所有信息*。'
- en: Let’s break down each of these.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们逐个来分析这些。
- en: Automatic tagging, linking, and taxonomies
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 自动标记、链接和分类
- en: At the most basic level, the tagging and linking required by current note-taking
    systems can be done by an LLM (or another, simpler machine learning model).
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在最基本的层面上，当前笔记系统所需的标记和链接可以由LLM（或其他更简单的机器学习模型）完成。
- en: Entity recognition is cheap and reliable enough for a model to find people,
    places, companies, books, and other things that repeatedly pop up in your notes.
    Researchers like Linus Lee, [who I interviewed previously](https://every.to/superorganizers/linus-lee-is-living-with-ai),
    are building versions of this for themselves. His demo doesn’t even use entity
    recognition, just word frequency tracking, to make the backlinks. These technologies
    will get more advanced over time.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 实体识别已经足够便宜和可靠，让模型能够找到在你的笔记中反复出现的人物、地点、公司、书籍和其他事物。像[我之前采访过的林思聪](https://every.to/superorganizers/linus-lee-is-living-with-ai)这样的研究人员正在为自己构建这样的版本。他的演示甚至不使用实体识别，只是使用词频跟踪来创建反向链接。这些技术将随着时间的推移变得更加先进。
- en: '*Source: Linus Lee *'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '*来源：林思聪*'
- en: 'Beyond tagging and linking, LLMs can help create an automated taxonomy of your
    notes that makes it easier for you to navigate through them. Think something like
    the Apple Photos experience, but for your notes:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 除了标记和链接之外，LLMs还可以帮助创建一个自动化的笔记分类法，使您更容易浏览。想象一下类似于苹果照片体验，但适用于您的笔记：
- en: '*Source: Me playing around in Figma.*'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '*来源：我在Figma中玩耍。*'
- en: These taxonomies can even be created on the fly for new projects, so as your
    needs change, your notes can reorganize themselves into new views that help you
    navigate them more effectively. A simple example might be something like an automatically
    updating list of every book you’ve read this year. I’ve been [banging on this
    drum](https://every.to/superorganizers/the-opportunity-in-productivity-621007?sid=13273)
    for the last two years, and the time has finally come for these kinds of automated
    taxonomies to happen.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 这些分类甚至可以针对新项目实时创建，因此随着您的需求变化，您的笔记可以重新组织成新的视图，帮助您更有效地导航。一个简单的例子可能是一个自动更新的今年阅读过的每本书列表。在过去的两年里，我一直在[强调这一点](https://every.to/superorganizers/the-opportunity-in-productivity-621007?sid=13273)，现在是这些自动分类的时候了。
- en: The real power of AI models for organizing goes beyond taxonomizing, though.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: AI模型组织的真正力量不仅在于分类，还在于其它方面。
- en: Automated research reports
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 自动化研究报告
- en: LLMs can enrich and write your notes for you. They can synthesize and write
    a report based on everything you’ve ever written about a topic, so you can load
    it into your brain without having to ever go back through your archive.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs可以为您丰富和撰写笔记。它们可以基于您以往关于某一主题的所有写作，综合并撰写一份报告，这样您就可以加载到您的大脑中，而不必回顾您的存档。
- en: Think about starting a project—maybe you’re writing an article about a new topic—and
    having an LLM automatically write and present to you a report outlining key quotes
    and ideas from books you’ve read that are relevant to the article you’re writing.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 想想开始一个项目——也许你正在写一篇关于一个新主题的文章——并让LLM自动撰写并呈现给你一份报告，概述了你阅读过的与你正在写的文章相关的关键引语和思想。
- en: '*Source: This is one thing I imagine ChatGPT will do in the future.*'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '*来源：我想ChatGPT未来会做的一件事。*'
- en: If you were confident that this would be done for you in a high-quality way,
    you’d never worry about how to tag or link a quote from a book or an article again.
    You’d just file it into your notes archive and feel confident that the software—acting
    as a research assistant—would find and present it later for you.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您有信心这将以高质量的方式完成，您将不再担心如何标记或链接书籍或文章中的引语。您只需将其归档到您的笔记存档中，并确信软件——作为一个研究助手——以后会为您找到并呈现它。
- en: There are deeper implications, though. Our notes are a reflection of our lives.
    Think about using an LLM to summarize a key relationship or pattern in your thinking
    over time. It could produce a history of your mind on a particular topic, including
    a summary and a timeline of key events that could help you understand yourself,
    and your world, better.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 深层含义很丰富。我们的笔记是我们生活的反映。想象一下，使用LLM总结你长期思考中的关键关系或模式。它可以产生关于特定主题的你思想历史，包括关键事件的摘要和时间线，这有助于你更好地了解自己和世界。
- en: This is possible today—someone just needs to build it.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 今天已经有可能实现这一点——只是需要有人来构建它。
- en: CoPilot for notes
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 笔记的CoPilot
- en: Research reports are valuable, but what you really want is to mentally download
    your entire note archive every time you touch your keyboard. Imagine an autocomplete
    experience—like GitHub CoPilot—that uses your note archive to try to fill in whatever
    you’re writing.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 研究报告很有价值，但您真正想要的是每次接触键盘时都能在头脑中下载您的整个笔记存档。想象一下，一个自动完成的体验——就像GitHub CoPilot一样——它使用您的笔记存档来尝试填写您正在写的任何内容。
- en: 'Here are some examples:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一些例子：
- en: When you make a point in an article you’re writing, it could suggest a quote
    to illustrate it.
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当你在写一篇文章时提出一个观点时，它可以建议一个引用来说明它。
- en: When you’re writing about a decision, it could suggest supporting (or disconfirming)
    evidence from the past.
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当你写关于一个决定时，它可以建议过去的支持（或反驳）证据。
- en: When you’re writing an email, it could pull previous meeting notes to help you
    make your point.
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当你写电子邮件时，它可以提取以前的会议记录来帮助你表达观点。
- en: An experience like this turns your note archive into an intimate thought partner
    that uses everything you’ve ever written to make you smarter as you type.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这样的体验将把你的笔记存档转变成一个亲密的思想伴侣，它利用你曾经写过的一切来让你在键入时更聪明。
- en: Again, all of this is possible today. It’s just a matter of building it.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，今天所有这一切都是可能的。只是建立它的问题。
- en: The future of note-taking
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 笔记的未来
- en: Organizing is going to become unnecessary because no one actually wants to go
    back and look at their old notes.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 组织将变得不再必要，因为没有人真正想回去看他们的旧笔记。
- en: What you really want is the *information* in your notes, synthesized and presented
    to you at the right place and at the right time.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 你真正想要的是你笔记中的*信息*，在正确的时间和地点合成并呈现给你。
- en: The way this is done should be personal to you. It should be lively and surprising.
    It should help you see new patterns, look at what you’ve collected in new ways,
    and bring back facts, people, and events that you’d long forgotten about. It should
    help you learn from and utilize everything you’ve written down previously to the
    task at hand.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 这样做的方式应该是个人化的。它应该生动而令人惊讶。它应该帮助你看到新的模式，以新的方式看待你已经收集到的东西，并带回你早已忘记的事实、人物和事件。它应该帮助你从之前记录下来的一切中学习并将其应用于手头的任务。
- en: LLMs can truly turn your notes into a second brain. They can enrich notes as
    you’re writing them to create more context, automatically taxonomize and synthesize
    them, and present them back to you in a way that clicks later on—so you can actually
    use them.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs 真的可以将你的笔记变成第二个大脑。它们可以在你写作时丰富笔记以创建更多的背景，自动对其进行分类和合成，并在以后以一种符合你的方式呈现给你，以便你真正使用它们。
- en: In the future, notes won’t be organized by us—they’ll be organized for us. The
    ultimate tool for thought is tools that think.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在未来，笔记不再由我们组织，它们将为我们组织。思维的终极工具是能够思考的工具。
- en: '* * *'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '*Note: if you''re waiting for access to the* [*Huberman Lab*](https://every.to/superorganizers/i-trained-a-gpt-3-chatbot-on-every-episode-of-my-favorite-podcast)
    *chat bot and source code, it''s coming this weekend for paying subscribers!*'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '*注意：如果你正在等待获取*[*Huberman 实验室*](https://every.to/superorganizers/i-trained-a-gpt-3-chatbot-on-every-episode-of-my-favorite-podcast)*的聊天机器人和源代码，它将在本周末提供给付费订阅者！*'
