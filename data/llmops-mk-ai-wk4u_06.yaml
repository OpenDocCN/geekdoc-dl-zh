- en: 1.3 Advanced Moderation
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1.3 高级适度
- en: 原文：[https://boramorka.github.io/LLM-Book/en/CHAPTER-1/1.3%20Advanced%20Moderation/](https://boramorka.github.io/LLM-Book/en/CHAPTER-1/1.3%20Advanced%20Moderation/)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[https://boramorka.github.io/LLM-Book/en/CHAPTER-1/1.3%20Advanced%20Moderation/](https://boramorka.github.io/LLM-Book/en/CHAPTER-1/1.3%20Advanced%20Moderation/)'
- en: 'Content moderation in modern products starts with a clear understanding of
    how and at what stage to automate pre‑publication checks. The OpenAI Moderation
    API provides an out‑of‑the‑box mechanism for analyzing user content in real time
    across platforms — from social networks and forums to media‑sharing services.
    The model automatically detects and flags materials that violate community rules,
    terms of use, or the law, and it covers the key data types: text, images, and
    video. In practice, teams integrate the API on the backend using client libraries
    (Python, JS, Ruby, etc.). You get the most value when moderation is built directly
    into the publishing flow: every comment, post, or image upload first passes through
    the Moderation API; then, depending on the result, the content is published, returned
    to the author for edits, blocked, or escalated for manual review. Despite comprehensive
    built‑in categories, each platform has its own standards and compliance requirements,
    so you can tune sensitivity and focus by adding allow/deny lists and refining
    priorities and thresholds.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 现代产品中的内容适度始于对如何以及在哪个阶段进行预发布检查的明确理解。OpenAI 适度 API 提供了一种现成的机制，用于实时跨平台分析用户内容——从社交网络和论坛到媒体共享服务。模型自动检测并标记违反社区规则、使用条款或法律的材料，并涵盖了关键数据类型：文本、图像和视频。在实践中，团队使用客户端库（Python、JS、Ruby
    等）在后台集成 API。当适度直接构建到发布流程中时，您将获得最大价值：每个评论、帖子或图像上传首先通过适度 API；然后，根据结果，内容被发布、返回给作者进行编辑、阻止或升级以进行人工审查。尽管内置了全面的分类，但每个平台都有自己的标准和合规要求，因此您可以通过添加允许/拒绝列表以及细化优先级和阈值来调整敏感度和焦点。
- en: 'To illustrate a basic check, consider a simple text‑moderation snippet that
    sends content to the model and prints the analysis result:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明基本检查，考虑一个简单的文本-适度片段，它将内容发送到模型并打印分析结果：
- en: '[PRE0]'
  id: totrans-4
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The same approach scales to collections of items, enabling you not only to
    flag problematic cases but also to apply human‑readable categories and downstream
    actions — from a gentle warning to deletion and moderator escalation. Below is
    an extended example that iterates over a set of messages, classifies violations
    (Hate Speech, Spam, other mismatches), and prints recommendations:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 同样的方法可以扩展到项目集合，不仅使您能够标记问题案例，还可以应用人类可读的分类和下游操作——从温和的警告到删除和版主升级。以下是一个扩展示例，它遍历一组消息，分类违规行为（仇恨言论、垃圾邮件、其他不匹配），并打印出建议：
- en: '[PRE1]'
  id: totrans-6
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Beyond classic moderation, protection against prompt injections is crucial
    — attempts by users to override system instructions through cleverly crafted input.
    A basic technique is isolating user data from commands with explicit delimiters:
    this makes boundaries obvious to both humans and systems and reduces the risk
    that user text will be interpreted as control instructions. The example shows
    how to choose a delimiter, sanitize input (remove delimiter occurrences), and
    construct a message to the model so that the user fragment remains data, not commands:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 除了经典的适度控制之外，防止即时注入攻击至关重要——用户通过精心设计的输入来绕过系统指令的尝试。一种基本的技术是将用户数据与命令通过明确的分隔符隔离：这使得边界对人类和系统来说都很明显，并降低了用户文本被解释为控制指令的风险。以下示例展示了如何选择分隔符、清理输入（移除分隔符出现），以及向模型构建消息，以确保用户片段保持数据，而不是命令：
- en: '[PRE2]'
  id: totrans-8
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Delimiters are simply a rare sequence of characters that almost never occurs
    in normal data. It’s important to: (1) pick such a token; (2) sanitize user input
    by removing or escaping all found delimiters; and (3) explicitly search for these
    markers when parsing messages to ensure boundaries are correctly identified. Complement
    this with additional measures: validate the type, length, and format of incoming
    data; follow least‑privilege for components; use allow‑lists of permitted commands
    or templates; apply regular expressions to detect control sequences; enable monitoring
    and logging to spot anomalies; and educate users about safe input practices.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 分隔符仅仅是几乎不会出现在正常数据中的罕见字符序列。重要的是：(1) 选择这样的标记；(2) 通过移除或转义所有找到的分隔符来清理用户输入；以及(3)
    在解析消息时明确搜索这些标记，以确保边界被正确识别。补充以下额外措施：验证传入数据的类型、长度和格式；遵循组件的最小权限原则；使用允许的命令或模板的允许列表；应用正则表达式来检测控制序列；启用监控和日志记录以发现异常；并教育用户关于安全输入实践。
- en: 'Below is a compact, self‑contained example that combines validation, sanitization,
    and a model call while preserving the system instruction about the response language:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是一个紧凑的、自包含的示例，它结合了验证、清理和模型调用，同时保留了关于响应语言的系统指令：
- en: '[PRE3]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Another practical technique is direct input assessment for injections: ask
    the model to first classify the message as an attempt to override instructions
    (answer “Y”) or safe (answer “N”), then act accordingly. This check is transparent
    and easy to plug into existing pipelines:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种实用技术是直接输入评估以检测注入：要求模型首先将消息分类为尝试覆盖指令（回答“Y”）或安全（回答“N”），然后相应地行动。这项检查是透明的，并且很容易集成到现有的管道中：
- en: '[PRE4]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'After detecting a possible injection, it helps to combine several responses:
    notify the user about the risk and briefly explain safe‑input principles; suggest
    rephrasing the request to preserve UX quality; in complex cases, isolate and send
    the item to a moderator; and dynamically adjust sensitivity by trust level and
    context. As an illustration of adapting sensitivity and response logic, here’s
    a short session that tracks trust and uses a heuristic for risky commands:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在检测到可能的注入后，结合几个响应会有帮助：通知用户风险并简要解释安全输入原则；建议重新措辞请求以保持用户体验质量；在复杂情况下，隔离并发送项目给审查员；并根据信任级别和上下文动态调整敏感性。以下是一个简短的会话示例，它跟踪信任并使用一个用于风险命令的启发式方法来调整敏感性和响应逻辑：
- en: '[PRE5]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: In summary, these approaches offer accuracy, adaptability, and a good user experience;
    the challenges are the effort required to build and maintain them, the evolving
    nature of attacks, and the perpetual trade‑off between usability and security.
    By combining the Moderation API with defenses against prompt injections, you can
    significantly improve the safety and integrity of user‑generated content (UGC)
    platforms. Next, study the OpenAI documentation and AI ethics and safety practices
    to further refine your processes.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，这些方法提供了准确性、适应性和良好的用户体验；挑战在于构建和维护它们所需的努力、攻击的演变性质以及可用性和安全性之间的持续权衡。通过将审查API与针对提示注入的防御措施相结合，您可以显着提高用户生成内容（UGC）平台的安全性和完整性。接下来，研究OpenAI文档和AI伦理与安全实践，以进一步细化您的流程。
- en: Theory Questions
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理论问题
- en: What are the key steps for integrating the OpenAI Moderation API into a platform?
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将OpenAI审查API集成到平台中的关键步骤是什么？
- en: How do you tune moderation rules to align with community standards and compliance
    requirements?
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如何调整审查规则以符合社区标准和合规要求？
- en: How can you extend moderation to images and video?
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如何将审查扩展到图片和视频？
- en: How do delimiters help prevent prompt injections?
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 分隔符如何帮助防止提示注入？
- en: Why does isolating commands with delimiters improve security?
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为什么使用分隔符隔离命令可以提高安全性？
- en: Which additional strategies (beyond delimiters) strengthen protection against
    prompt injections?
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 除了分隔符之外，哪些额外策略可以加强防止提示注入的保护？
- en: How can you implement direct input assessment for injections?
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如何实现直接输入评估以检测注入？
- en: What response actions should you take when an injection attempt is detected?
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当检测到注入尝试时，应采取哪些响应行动？
- en: What are the pros and cons of direct injection assessment?
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 直接注入评估的优点和缺点是什么？
- en: How does the combination of the Moderation API and defensive strategies improve
    the safety of UGC platforms?
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Moderation API和防御策略的结合如何提高UGC平台的安全性？
- en: Practical Tasks
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实践任务
- en: Write a Python function using the OpenAI API that moderates a single text fragment
    and returns `True` if it is flagged, otherwise `False`.
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 OpenAI API 编写一个 Python 函数，用于审查单个文本片段，如果被标记则返回 `True`，否则返回 `False`。
- en: Implement `sanitize_delimiter(input_text, delimiter)` to remove the delimiter
    from user input.
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实现 `sanitize_delimiter(input_text, delimiter)` 函数，用于从用户输入中移除分隔符。
- en: Write a `validate_input_length` function that checks the input length is within
    acceptable bounds.
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编写一个 `validate_input_length` 函数，用于检查输入长度是否在可接受的范围内。
