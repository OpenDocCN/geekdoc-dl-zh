- en: Tool Use & Function Calling
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工具使用与函数调用
- en: Language models using tools is a natural way to expand their capabilities, especially
    for high-precision tasks where external tools contain the information or for agents
    that need to interact with complex web systems. These can be thought of in a few
    strategies where tool use is the general category. An AI model uses any external
    tools by outputting special tokens to trigger a certain endpoint. These can be
    anything from highly specific tools, such as functions that return the weather
    at a specific place, to code interpreters or search engines that act as fundamental
    building blocks of complex behaviors. This chapter provides an overview of the
    origins of tool-use in modern language models, its fundamentals and formatting,
    and current trade-offs in utilizing tools well in leading models.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 使用工具的语言模型是扩展其能力的一种自然方式，尤其是在外部工具包含所需信息或需要与复杂网络系统交互的智能体中，这种方式尤其适用于高精度任务。这些策略可以被视为工具使用的一般类别。一个AI模型通过输出特殊标记来触发特定端点，从而使用任何外部工具。这些工具可以是高度具体的，例如返回特定地点天气的功能，也可以是代码解释器或搜索引擎，它们是复杂行为的基本构建块。本章概述了现代语言模型中工具使用的起源、其基本原理和格式，以及当前在主要模型中有效利用工具的权衡。
- en: The exact origin of the term “tool use” is not clear, but the origins of the
    idea far predates the post ChatGPT world where RLHF proliferated. Early examples
    circa 2015 attempted to build systems predating modern language models, such as
    Neural Programmer-Interpreters (NPI) [[290]](ch021.xhtml#ref-reed2015neural),
    “a recurrent and compositional neural network that learns to represent and execute
    programs.” As language models became more popular, many subfields were using integrations
    with external capabilities to boost performance. To obtain information outside
    of just the weights many used retrieval augmented generation [[291]](ch021.xhtml#ref-lewis2020retrieval)
    or web browsing [[4]](ch021.xhtml#ref-nakano2021webgpt). Soon after, others were
    exploring language models integrated with programs [[292]](ch021.xhtml#ref-gao2023pal)
    or tools [[293]](ch021.xhtml#ref-parisi2022talm).
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: “工具使用”这一术语的确切起源尚不明确，但这一想法的起源远早于ChatGPT时代，那时强化学习与人类反馈（RLHF）得到了广泛的应用。大约在2015年，早期例子试图构建现代语言模型之前的系统，如神经程序员解释器（NPI）[[290]](ch021.xhtml#ref-reed2015neural)，“一种循环和组合的神经网络，它学会表示和执行程序。”随着语言模型的普及，许多子领域都在使用外部能力的集成来提升性能。为了获取除了权重之外的信息，许多人使用了检索增强生成[[291]](ch021.xhtml#ref-lewis2020retrieval)或网络浏览[[4]](ch021.xhtml#ref-nakano2021webgpt)。不久之后，其他人开始探索与程序[[292]](ch021.xhtml#ref-gao2023pal)或工具[[293]](ch021.xhtml#ref-parisi2022talm)集成的语言模型。
- en: As the field matured, these models gained more complex abilities in addition
    to the vast improvements to the underlying language modeling. For example, ToolFormer
    could use “a calculator, a Q&A system, two different search engines, a translation
    system, and a calendar” [[294]](ch021.xhtml#ref-schick2023toolformerlanguagemodelsteach).
    Soon after, Gorilla was trained to use 1645 APIs (from PyTorch Hub, TensorFlow
    Hub v2, and HuggingFace) and its evaluation APIBench became a foundation of the
    popular Berkeley Function Calling Leaderboard [[295]](ch021.xhtml#ref-patil2023gorilla).
    Since these early models, the diversity of actions called has grown substantially.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 随着该领域的成熟，这些模型在底层语言模型的大幅改进之外，还获得了更复杂的能力。例如，ToolFormer可以使用“计算器、问答系统、两个不同的搜索引擎、翻译系统和日历”[[294]](ch021.xhtml#ref-schick2023toolformerlanguagemodelsteach)。不久之后，Gorilla被训练使用1645个API（来自PyTorch
    Hub、TensorFlow Hub v2和HuggingFace），其评估APIBench成为流行伯克利函数调用排行榜[[295]](ch021.xhtml#ref-patil2023gorilla)的基础。自这些早期模型以来，被调用的动作种类已经大幅增加。
- en: Tool-use models are now deeply intertwined with regular language model interactions.
    Model Context Protocol (MCP) emerged as a common formatting used to connect language
    models to external data sources (or tools) [[296]](ch021.xhtml#ref-anthropic_mcp_2024).
    With stronger models and better formats, tool-use language models are used in
    many situations, including productivity copilots within popular applications such
    as Microsoft Office or Google Workspace, scientific domains [[297]](ch021.xhtml#ref-bran2023chemcrow),
    medical domains [[298]](ch021.xhtml#ref-li2024mmedagent), coding agents [[299]](ch021.xhtml#ref-zhang2024codeagent)
    such as Claude Code or Cursor, integrations with databases, and many other autonomous
    workflows.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 工具使用模型现在与常规语言模型交互深度融合。模型上下文协议（MCP）作为一种常见的格式出现，用于将语言模型连接到外部数据源（或工具）[[296]](ch021.xhtml#ref-anthropic_mcp_2024)。随着模型的增强和格式的改进，工具使用语言模型被用于许多场景，包括在流行的应用程序如Microsoft
    Office或Google Workspace中的生产力副驾驶，科学领域 [[297]](ch021.xhtml#ref-bran2023chemcrow)，医学领域
    [[298]](ch021.xhtml#ref-li2024mmedagent)，编码代理 [[299]](ch021.xhtml#ref-zhang2024codeagent)
    如Claude Code或Cursor，与数据库的集成，以及许多其他自主工作流程。
- en: Interweaving Tool Calls in Generation
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 生成过程中的工具调用交织
- en: 'Function calling agents are presented data very similarly to other post-training
    stages. The addition is the content in the system prompt that instructs the model
    what tools it has available. An example formatted data point with the system prompt
    and tools available in JSON format is shown below:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 函数调用代理呈现数据的方式与其他后训练阶段非常相似。新增的内容是系统提示中的内容，指导模型它有哪些可用的工具。以下是一个带有系统提示和可用工具的JSON格式示例格式化数据点：
- en: '[PRE0]'
  id: totrans-7
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: While the language model is generating, if following the above example, it would
    generate the tokens `search_torrents("Star Wars")` to search for Star Wars. This
    is often encoded inside special formatting tokens, and then the next tokens inserted
    into the sequence will contain the tool outputs. With this, models can learn to
    accomplish more challenging tasks than many simple standalone models.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 当语言模型生成时，如果遵循上述示例，它将生成`search_torrents("Star Wars")`这样的标记来搜索《星球大战》。这通常编码在特殊的格式化标记中，然后下一个插入序列的标记将包含工具输出。通过这种方式，模型可以学会完成比许多简单独立模型更具挑战性的任务。
- en: A popular form of tool use is code-execution, allowing the model to get precise
    answers to complex logic or mathematics problems. For example, code-execution
    within a language model execution can occur during the thinking tokens of a reasoning
    model. As with function calling, there are tags first for the code to execute
    (generated by the model) and then a separate tag for output.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 工具使用的一种流行形式是代码执行，允许模型对复杂的逻辑或数学问题获得精确答案。例如，在语言模型执行期间，代码执行可以发生在推理模型的思考标记中。与函数调用一样，首先是对要执行的代码（由模型生成）的标签，然后是输出标签。
- en: '[PRE1]'
  id: totrans-10
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Multi-step Tool Reasoning
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多步工具推理
- en: 'OpenAI’s o3 model represented a substantial step-change in how multi-step tool-use
    can be integrated with language models. This behavior is related to research trends
    much earlier in the community. For example, ReAct [[300]](ch021.xhtml#ref-yao2023react),
    showcased how actions and reasoning can be interleaved into one model generation:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI的o3模型在多步工具使用如何与语言模型集成方面迈出了实质性的飞跃。这种行为与社区中较早的研究趋势相关。例如，ReAct [[300]](ch021.xhtml#ref-yao2023react)
    展示了如何将动作和推理交织到一个模型生成中：
- en: 'In this paper, we explore the use of LLMs to generate both reasoning traces
    and task-specific actions in an interleaved manner, allowing for greater synergy
    between the two: reasoning traces help the model induce, track, and update action
    plans as well as handle exceptions, while actions allow it to interface with and
    gather additional information from external sources such as knowledge bases or
    environments.'
  id: totrans-13
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在本文中，我们探讨了以交织方式使用LLM生成推理痕迹和特定任务动作，从而在两者之间实现更大的协同作用：推理痕迹帮助模型诱导、跟踪和更新行动计划，以及处理异常，而动作则允许它与外部来源（如知识库或环境）交互并收集更多信息。
- en: With the solidification of tool-use capabilities and the take-off of reasoning
    models, multi-turn tool-use has grown into an exciting area of research [[286]](ch021.xhtml#ref-wang2025ragenunderstandingselfevolutionllm).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 随着工具使用能力的巩固和推理模型的起飞，多轮工具使用已成为一个令人兴奋的研究领域 [[286]](ch021.xhtml#ref-wang2025ragenunderstandingselfevolutionllm)。
- en: Model Context Protocol (MCP)
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型上下文协议（MCP）
- en: Model Context Protocol (MCP) is a standard for connecting language models to
    external data sources and information systems [[296]](ch021.xhtml#ref-anthropic_mcp_2024).
    Rather than focusing on specific tool call formatting per external system, MCP
    enables models to access rich contextual information through a standardized protocol.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 模型上下文协议（MCP）是一种连接语言模型到外部数据源和信息系统的标准 [[296]](ch021.xhtml#ref-anthropic_mcp_2024)。MCP并非关注每个外部系统特定的工具调用格式，而是通过标准化协议使模型能够访问丰富的上下文信息。
- en: 'MCP is a simple addition on top of the tool-use content in this chapter – it
    is how applications pass context (data + actions) to language models in a predictable
    JSON schema. MCP servers that the models interact with have core primitives: resources
    (read-only data blobs), prompts (templated messages/workflows), and tools (functions
    the model can call). With this, the MCP architecture can be summarized as:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: MCP是本章工具使用内容上的简单补充——它是如何以可预测的JSON模式将上下文（数据+操作）传递给语言模型的。与模型交互的MCP服务器具有核心原语：资源（只读数据块）、提示（模板化消息/工作流程）和工具（模型可以调用的函数）。因此，MCP架构可以总结如下：
- en: MCP servers wrap a specific data source or capability.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MCP服务器封装特定的数据源或能力。
- en: MCP clients (e.g., Claude Desktop, IDE plug-ins) aggregate one or more servers.
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MCP客户端（例如，Claude桌面版，IDE插件）聚合一个或多个服务器。
- en: Hosts, e.g. Claude or ChatGPT applications, provide the user/LLM interface;
    switching model vendors or back-end tools only means swapping the client in the
    middle.
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 主机，例如Claude或ChatGPT应用，提供用户/LLM界面；切换模型供应商或后端工具仅意味着交换中间的客户端。
- en: MCP enables developers of tool-use models to use the same infrastructure to
    attach their servers or clients to different models, and at the same time models
    have a predictable format they can use to integrate external components. These
    together make for a far more predictable development environment for tool-use
    models in real-world domains.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: MCP使工具使用模型的开发者能够使用相同的架构将他们的服务器或客户端连接到不同的模型，同时模型也有一个可预测的格式，可以用来集成外部组件。这些共同为工具使用模型在实际应用领域提供了一个更加可预测的开发环境。
- en: Implementation
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实现
- en: 'There are multiple formatting and masking decisions when implementing a tool-use
    model:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在实现工具使用模型时，有多个格式化和遮蔽决策：
- en: '**Python vs. JSON formatting**: In this chapter, we included examples that
    format tool use as both JSON data-structures and Python code. Models tend to select
    one structure, different providers across the industry use different formats.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Python与JSON格式**：在本章中，我们包括了将工具使用格式化为JSON数据结构和Python代码的示例。模型倾向于选择一种结构，而行业中的不同提供商使用不同的格式。'
- en: '**Masking tool outputs**: An important detail when training tool-use models
    is that the tokens in the tool output are masked from the model’s training loss.
    This ensures the model is not learning to predict the output of the system that
    it does not directly generate in use (similar to prompt masking for other post-training
    stages).'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**遮蔽工具输出**：在训练工具使用模型时，一个重要的细节是工具输出中的标记被从模型的训练损失中遮蔽。这确保了模型不会学习预测它在使用中直接生成的系统之外的输出（类似于其他训练后阶段的提示遮蔽）。'
- en: '**Multi-turn formatting for tool invocations**: It is common practice when
    implementing tool-calling models to add more structure to the dataloading format.
    Standard practice for post-training datasets is a list of messages alternating
    between user and assistant (and often a system message). The overall structure
    is the same for tool-use, but the turns of the model are split into subsections
    of content delimited by each tool call. An example is below.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**多轮格式化工具调用**：在实现工具调用模型时，通常会将数据加载格式添加更多结构。训练后数据集的标准做法是用户和助手（以及通常的系统消息）之间的消息列表交替。工具使用的整体结构相同，但模型的轮次被分割成由每个工具调用分隔的内容子部分。以下是一个示例。'
- en: '[PRE2]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '**Tokenization and message format details**: Tool calls in OpenAI messages
    format often undergo tokenization through chat templates (the code for controlling
    format of messages sent to the model), converting structured JSON representations
    into raw token streams. This process varies across model architectures—some use
    special tokens to demarcate tool calls, while others maintain structured formatting
    within the token stream itself. [Chat template playgrounds](https://huggingface.co/spaces/huggingfacejs/chat-template-playground?modelId=Qwen/Qwen3-8B)
    provides an interactive environment to explore how different models convert message
    formats to token streams.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**标记化和消息格式细节**：在 OpenAI 消息格式中，工具调用通常通过聊天模板（控制发送给模型的格式代码）进行标记化，将结构化的 JSON 表示转换为原始标记流。这个过程在不同模型架构中有所不同——一些使用特殊标记来界定工具调用，而另一些则在标记流本身中保持结构化格式。[聊天模板游乐场](https://huggingface.co/spaces/huggingfacejs/chat-template-playground?modelId=Qwen/Qwen3-8B)提供了一个交互式环境，可以探索不同模型如何将消息格式转换为标记流。'
- en: '**Reasoning token continuity**: As reasoning models have emerged, with their
    separate token stream of “reasoning” before an answer, different implementations
    exist for how they’re handled with tool-use in the loop. Some models preserve
    reasoning tokens between tool-calling steps within a single turn, maintaining
    context across multiple tool invocations. However, these tokens are typically
    erased between turns to minimize serving cost.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**推理标记连续性**：随着推理模型的出现，它们在答案之前有独立的“推理”标记流，对于如何在循环中使用工具处理这些标记存在不同的实现。一些模型在单个回合的工具调用步骤之间保留推理标记，以保持多个工具调用的上下文。然而，这些标记通常在回合之间被清除，以最小化服务成本。'
- en: '**API formatting across providers** (As of July 2025): Different providers
    use conceptually similar but technically distinct formats. OpenAI uses `tool_calls`
    arrays with unique IDs, Anthropic employs detailed `input_schema` specifications
    with `<thinking>` tags, and Gemini offers function calling modes (AUTO/ANY/NONE).
    When using these models via an API, the tools available are defined in a JSON
    format and then the tool outputs in the model response are stored in a separate
    field from the standard “tokens generated.” For another example, the open-source
    vLLM inference codebase implements extensive parsing logic supporting multiple
    tool calling modes and model-specific parsers, providing insights into lower-level
    implementation considerations [[301]](ch021.xhtml#ref-kwon2023efficient).'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**不同提供商的 API 格式**（截至 2025 年 7 月）：不同的提供商使用概念上相似但技术上不同的格式。OpenAI 使用具有唯一 ID 的
    `tool_calls` 数组，Anthropic 采用详细的 `input_schema` 规范，并使用 `<thinking>` 标签，而 Gemini
    提供函数调用模式（AUTO/ANY/NONE）。当通过 API 使用这些模型时，可用的工具以 JSON 格式定义，然后模型响应中的工具输出存储在标准“生成的标记”之外的一个单独字段中。例如，开源的
    vLLM 推理代码库实现了广泛的解析逻辑，支持多种工具调用模式和特定于模型的解析器，为底层实现考虑提供了见解 [[301]](ch021.xhtml#ref-kwon2023efficient)。'
