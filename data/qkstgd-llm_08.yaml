- en: '6'
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '6'
- en: Customizing Embeddings and Model Architectures
  id: totrans-1
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 自定义嵌入和模型架构
- en: Introduction
  id: totrans-2
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 引言
- en: Two full chapters of prompt engineering equipped us with the knowledge of how
    to effectively interact with (prompt) LLMs, acknowledging their immense potential
    as well as their limitations and biases. We have also fine-tuned models both open
    and closed source to expand on an LLM’s pre-training to better solve our own specific
    tasks. We have even seen a full case study of how semantic search and embedding
    spaces can help us retrieve relevant information from a dataset with speed and
    ease.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 两章完整的提示工程使我们掌握了如何有效地与（提示）LLMs 互动的知识，承认它们巨大的潜力以及它们的局限性和偏见。我们还对开源和闭源模型进行了微调，以扩展
    LLM 的预训练，以更好地解决我们自己的特定任务。我们甚至看到了一个完整的案例研究，展示了语义搜索和嵌入空间如何帮助我们快速、轻松地从数据集中检索相关信息。
- en: To further broaden our horizons, we will utilize lessons learned from earlier
    chapters and dive into the world of fine-tuning embedding models and customizing
    pre-trained LLM architectures to unlock even greater potential in our LLM implementations.
    By refining the very foundations of these models, we can cater to specific business
    use cases and foster improved performance.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进一步拓宽我们的视野，我们将利用前几章学到的经验，深入到微调嵌入模型和定制预训练 LLM 架构的世界，以在我们的 LLM 实现中解锁更大的潜力。通过完善这些模型的基础，我们可以满足特定的业务用例，并促进性能的改进。
- en: Foundation models, while impressive on their own, can be adapted and optimized
    to suit a variety of tasks through minor to major tweaks in their architectures.
    This customization enables us to address unique challenges and tailor LLMs to
    specific business requirements. The underlying embeddings form the basis for these
    customizations, as they are responsible for capturing the semantic relationships
    between data points and can significantly impact the success of various tasks.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 基础模型虽然本身令人印象深刻，但可以通过对其架构进行从微小到重大的调整来适应和优化，以适应各种任务。这种定制化使我们能够应对独特的挑战，并将大型语言模型（LLMs）定制到特定的业务需求中。这些定制的底层嵌入构成了这些定制化的基础，因为它们负责捕捉数据点之间的语义关系，并且可以显著影响各种任务的成功。
- en: Recalling our semantic search example, we identified that the original embeddings
    from OpenAI were designed to preserve semantic similarity, but the bi-encoder
    was further tuned to cater to asymmetric semantic search, matching short queries
    with longer passages. In this chapter, we will expand upon this concept, exploring
    techniques to train a bi-encoder that can effectively capture other business use
    cases. By doing so, we will uncover the potential of customizing embeddings and
    model architectures to create even more powerful and versatile LLM applications.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 回顾我们的语义搜索示例，我们确定 OpenAI 的原始嵌入是为了保留语义相似性而设计的，但双编码器进一步调整以适应非对称语义搜索，将短查询与较长的段落相匹配。在本章中，我们将扩展这一概念，探讨训练双编码器的技术，使其能够有效地捕捉其他商业用例。通过这样做，我们将揭示定制嵌入和模型架构以创建更强大、更通用的
    LLM 应用程序的可能性。
- en: Case Study – Building a Recommendation System
  id: totrans-7
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 案例研究 – 构建推荐系统
- en: The majority of this chapter will explore the role of embeddings and model architectures
    in designing a recommendation engine using a real-world dataset as our case study.
    Our objective is to highlight the importance of customizing embeddings and model
    architectures in achieving better performance and results tailored to specific
    use cases.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的大部分内容将探讨嵌入和模型架构在利用真实世界数据集作为案例研究来设计推荐引擎中的作用。我们的目标是强调定制嵌入和模型架构在实现更好性能和针对特定用例的结果方面的重要性。
- en: Setting Up the Problem and the Data
  id: totrans-9
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 设置问题和数据
- en: 'To demonstrate the power of customized embeddings, we will be using the MyAnimeList
    2020 dataset, which can be accessed on Kaggle at the following link: MyAnimeList
    2020 Dataset. This dataset contains information about anime titles, ratings (from
    1-10), and user preferences, offering a rich source of data to build a recommendation
    engine. [Figure 6.1](ch06.html#ch06fig01) shows a snippet of the dataset on the
    Kaggle page:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 为了展示定制嵌入的力量，我们将使用 MyAnimeList 2020 数据集，该数据集可以在 Kaggle 上通过以下链接访问：MyAnimeList
    2020 Dataset。该数据集包含有关动漫标题、评分（1-10分）和用户偏好的信息，为构建推荐引擎提供了丰富的数据来源。[图6.1](ch06.html#ch06fig01)显示了
    Kaggle 页面上的数据集片段：
- en: '![Images](graphics/06fig01.jpg)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![图片](graphics/06fig01.jpg)'
- en: '**Figure 6.1** *The MyAnimeList database is one of the largest datasets we
    have worked with to date. It can be found on Kaggle and it has tens of millions
    of rows of ratings and thousands of anime titles complete with dense text features
    describing each anime title.*'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 6.1** *MyAnimeList 数据库是我们迄今为止工作过的最大数据集之一。它可以在 Kaggle 上找到，包含数千万行的评分和数千个动漫标题，每个动漫标题都有描述其的密集文本特征。*'
- en: To ensure a fair evaluation of our recommendation engine, we will divide the
    dataset into separate training and testing sets. This process allows us to train
    our model on one portion of the data and evaluate its performance on a separate,
    unseen portion, thereby providing an unbiased assessment of its effectiveness.
    [Listing 6.1](ch06.html#list6_1) shows a snippet of our code to load the anime
    titles and split them into a train and test split.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确保对推荐引擎的评估公平，我们将数据集划分为独立的训练集和测试集。这个过程使我们能够在数据的一部分上训练我们的模型，并在另一部分未见过的数据上评估其性能，从而提供对其有效性的无偏评估。[列表
    6.1](ch06.html#list6_1) 展示了我们加载动漫标题并将它们拆分为训练和测试分割的代码片段。
- en: '**Listing 6.1** *Loading and splitting our anime data*'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '**列表 6.1** *加载和拆分我们的动漫数据*'
- en: '[PRE0]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: With our data loaded up and split, let’s take some time to better define what
    we are actually trying to solve.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在加载数据并拆分后，让我们花些时间更好地定义我们实际上试图解决的问题。
- en: Defining the Problem of Recommendation
  id: totrans-17
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 定义推荐问题
- en: Developing an effective recommendation system is, to put it mildly, a complex
    task. Human behavior and preferences can be intricate and difficult to predict
    (understatement of the millennium). The challenge lies in understanding and predicting
    what users will find appealing or interesting, which is influenced by a multitude
    of factors.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 开发一个有效的推荐系统，简单地说，是一个复杂的工作。人类的行为和偏好可能很复杂，难以预测（千年之不足）。挑战在于理解和预测用户会发现什么吸引人或有兴趣，这受到众多因素的影响。
- en: Recommendation systems need to take into account both user features and item
    features to generate personalized suggestions. User features can include demographic
    information like age, browsing history, and past item interactions (which will
    be the focus of our work in this chapter), while item features can encompass characteristics
    like genre, price, or popularity. However, these factors alone may not paint the
    complete picture, as human mood and context also play a significant role in shaping
    preferences. For instance, a user's interest in a particular item might change
    depending on their current emotional state or the time of day.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐系统需要考虑用户特征和项目特征来生成个性化的建议。用户特征可以包括人口统计信息，如年龄、浏览历史和过去的项目互动（这是我们本章工作的重点），而项目特征可以包括如类型、价格或流行度等特征。然而，仅凭这些因素可能无法描绘出完整的画面，因为人类情绪和环境也起着显著的作用，在塑造偏好方面。例如，用户对特定项目的兴趣可能会根据他们当前的情绪状态或一天中的时间而变化。
- en: Striking the right balance between exploration and pattern exploitation is also
    important in recommendation systems. By pattern exploitation, I’m referring to
    a system recommending items that it is confident the user will like based on their
    past preferences or are just simply similar to things they have interacted with
    before, while exploration involves suggesting items that the user might not have
    considered before. Striking this balance ensures that users continue to discover
    new content while still receiving recommendations that align with their interests.
    We will consider both of these factors.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在推荐系统中，在探索和模式利用之间取得适当的平衡也很重要。通过模式利用，我指的是基于用户过去的偏好或与之前互动过的事物相似，系统有信心推荐用户可能会喜欢的项目，而探索则涉及建议用户之前可能没有考虑过的项目。这种平衡的取得确保用户在继续发现新内容的同时，仍然收到与其兴趣相符的推荐。我们将考虑这两个因素。
- en: Defining the problem of recommendation is a multifaceted challenge that requires
    considering various factors such as user and item features, human mood, the number
    of recommendations to optimize, and the balance between exploration and exploitation.
    Given all of this, let’s dive in!
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 定义推荐问题是一个多方面的挑战，需要考虑各种因素，如用户和项目特征、人类情绪、要优化的推荐数量以及探索与利用之间的平衡。考虑到所有这些，让我们深入探讨！
- en: Content versus Collaborative Recommendations
  id: totrans-22
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 内容推荐与协同推荐
- en: 'Recommendation engines can be broadly categorized into two main approaches:
    content-based and collaborative filtering. **Content-based recommendations** focus
    on the attributes of the items being recommended, utilizing item features to suggest
    similar content to users based on their past interactions. In contrast, **collaborative
    filtering** capitalizes on the preferences and behavior of users, generating recommendations
    by identifying patterns among users with similar interests or tastes.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐引擎可以大致分为两种主要方法：基于内容和协同过滤。**基于内容的推荐**关注被推荐物品的属性，利用物品特征根据用户的过去互动向用户推荐类似的内容。相比之下，**协同过滤**利用用户的偏好和行为，通过识别具有相似兴趣或品味的用户之间的模式来生成推荐。
- en: In content-based recommendations, the system extracts relevant features from
    items, such as genre, keywords, or themes, to build a profile for each user. This
    profile helps the system understand the user's preferences and suggest items with
    similar characteristics. For instance, if a user has previously enjoyed action-packed
    anime titles, the content-based recommendation engine would suggest other anime
    series with similar action elements.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在基于内容的推荐中，系统从物品中提取相关特征，如类型、关键词或主题，为每个用户构建一个档案。这个档案有助于系统理解用户的偏好，并推荐具有相似特征的物品。例如，如果一个用户之前喜欢充满动作的动漫标题，基于内容的推荐引擎会建议其他具有类似动作元素的动漫系列。
- en: On the other hand, collaborative filtering can be further divided into user-based
    and item-based approaches. User-based collaborative filtering finds users with
    similar preferences and recommends items that those users have liked or interacted
    with. Item-based collaborative filtering, instead, focuses on finding items that
    are similar to those the user has previously liked, based on the interactions
    of other users. In both cases, the underlying principle is to leverage the wisdom
    of the crowd to make personalized recommendations.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，协同过滤可以进一步分为基于用户和基于物品的方法。基于用户的协同过滤寻找具有相似偏好的用户，并推荐那些用户喜欢或与之互动的物品。相反，基于物品的协同过滤则侧重于根据其他用户的互动来寻找与用户之前喜欢的物品相似的物品。在这两种情况下，基本原理是利用大众的智慧来做出个性化推荐。
- en: In our case study, we plan to fine-tune a bi-encoder (like the one we saw in
    [chapter 2](ch02.html#ch02)) to generate embeddings for anime features. Our goal
    is to minimize the cosine similarity loss in such a way that the similarity between
    embeddings reflects how common it is that users like both animes.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的案例研究中，我们计划微调一个双编码器（就像我们在[第2章](ch02.html#ch02)中看到的那样）来生成动漫特征的嵌入。我们的目标是最小化余弦相似度损失，使得嵌入之间的相似性反映了用户同时喜欢两个动漫的普遍程度。
- en: In fine-tuning a bi-encoder our goal is to create a recommendation system that
    can effectively identify similar anime titles based on the preferences of promoters
    and **not** just because they are semantically similar. [Figure 6.2](ch06.html#ch06fig02)
    shows what this might look like. The resulting embeddings will enable our model
    to make recommendations that are more likely to align with the tastes of users
    who are enthusiastic about the content.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在微调双编码器时，我们的目标是创建一个推荐系统，该系统能够根据推广者的偏好有效地识别相似的动漫标题，而不仅仅是它们在语义上相似。[图6.2](ch06.html#ch06fig02)展示了这可能是什么样子。生成的嵌入将使我们的模型能够做出更可能与对内容热情的用户口味相符合的推荐。
- en: '![Images](graphics/06fig02.jpg)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![图片](graphics/06fig02.jpg)'
- en: '**Figure 6.2** *Embedders are generally pre-trained to place embedded data
    near each other if they are semantically similar. In our case, we want an embedder
    that places embedded data near each other if they are similar in terms of **user-preferences**.*'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '**图6.2** *嵌入器通常被预训练，以便在语义相似的情况下将嵌入数据放置在一起。在我们的案例中，我们希望嵌入器在**用户偏好**相似的情况下将嵌入数据放置在一起。*'
- en: In terms of recommendation techniques, our approach combines elements of both
    content-based and collaborative recommendations. We leverage content-based aspects
    by using the features of each anime as input to the bi-encoder. At the same time,
    we incorporate collaborative filtering by considering the Jaccard score of promoters,
    which is based on the preferences and behavior of users. This hybrid approach
    allows us to take advantage of the strengths of both techniques to create a more
    effective recommendation system.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在推荐技术方面，我们的方法结合了基于内容和协同推荐的两方面元素。我们通过使用每个动漫的特征作为双编码器的输入来利用基于内容方面的优势。同时，我们通过考虑推广者的Jaccard分数来结合协同过滤，该分数基于用户的偏好和行为。这种混合方法使我们能够利用两种技术的优势，创建一个更有效的推荐系统。
- en: I got lost here tracking exactly what we’re trying to do. Maybe explaining how
    we’re going to construct this embedder, and how it will combine collaborative
    filtering and semantic similarity would be helpful. I realized later that we’re
    trying this model on the collaborative filtering as a label.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里追踪我们试图做什么时，我感到困惑。也许解释我们将如何构建这个嵌入器，以及它是如何结合协同过滤和语义相似性会有所帮助。我后来意识到，我们正在尝试将这个模型作为标签应用于协同过滤。
- en: 'To summarize, our plan is to:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，我们的计划是：
- en: 1\. Define/construct a text embedding model, either using them as is, or fine-tuning
    them on user-preference data
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 1\. 定义/构建一个文本嵌入模型，要么直接使用，要么在用户偏好数据上微调。
- en: 2\. Define a hybrid approach of collaborative filtering (using the jaccard score
    to define user/anime similarities) and content filtering (semantic similarity
    of anime titles by way of descriptions, etc) that will influence our user-preference
    data structure as well as how we score recommendations given to us by the pipeline
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. 定义一种混合方法，结合协同过滤（使用Jaccard分数定义用户/动漫相似度）和内容过滤（通过描述等手段的动漫标题语义相似度），这将影响我们的用户偏好数据结构以及我们根据管道给出的评分方式。
- en: 3\. Fine-tune open-source LLMs on a training set of user-preference data
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 3\. 在用户偏好数据的训练集上微调开源的LLM。
- en: 4\. Run our system on a testing set of user preference data to decide which
    embedder was responsible for the best anime title recommendations
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 4\. 在用户偏好数据的测试集上运行我们的系统，以决定哪个嵌入器负责最佳的动漫标题推荐。
- en: A 10,000 Foot View of Our Recommendation System
  id: totrans-37
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 我们推荐系统的10,000英尺视角
- en: 'Our recommendation process will generate personalized anime recommendations
    for a given user based on their past ratings. Here''s an explanation of the steps
    in our recommendation engine:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的推荐过程将根据用户的过去评分生成针对特定用户的个性化动漫推荐。以下是我们的推荐引擎步骤的解释：
- en: '1\. **Input**: The input for the recommendation engine is a user ID and an
    integer k (example 3).'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '1\. **输入**: 推荐引擎的输入是一个用户ID和一个整数k（例如3）。'
- en: '2\. **Identify highly-rated animes**: For each anime title that the user has
    rated as a 9 or 10 (a promoting score on the NPS scale), identify k other relevant
    animes by finding nearest matches in the anime’s embedding space. From these,
    we consider both how often an anime was recommended and how high the resulting
    cosine score was in the embedding space to take the top k results for the user.
    [Figure 6.3](ch06.html#ch06fig03) outlines this process. The pseudo code would
    look like:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '2\. **识别高评分的动漫**: 对于用户评分9或10（NPS尺度上的推广评分）的每个动漫标题，通过在动漫嵌入空间中找到最近匹配项来识别k个其他相关动漫。在这些动漫中，我们考虑动漫被推荐的频率和在嵌入空间中的余弦分数，以取用户的前k个结果。[图6.3](ch06.html#ch06fig03)概述了此过程。伪代码看起来可能如下：'
- en: '![Images](graphics/06fig03.jpg)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![图片](graphics/06fig03.jpg)'
- en: '**Figure 6.3** *Step 2 takes in the user and finds k animes **for each** user-promoted
    (gave a score of 9 or 10) anime. For example if the user promoted 4 animes (6345,
    4245, 249, 120) and we set k=3, the system will first retrieve 12 semantically
    similar animes (3 per promoted animes with duplicates allowed) and then de-duplicate
    any animes that came up multiple times by weighing it slightly more than the original
    cosine scores. We then take the top k unique recommended anime titles considering
    both cosine scores to promoted animes and how often occurred in the original list
    of 12.*'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**图6.3** *步骤2接收用户信息并找到每个用户推广的动漫（评分9或10）的k个动漫。例如，如果用户推广了4部动漫（6345, 4245, 249,
    120）并且我们设置k=3，系统将首先检索12部语义相似的动漫（每部推广动漫3部，允许重复），然后通过略微增加原始余弦分数的权重来去重任何出现多次的动漫。然后，我们考虑余弦分数和原始12部列表中出现的频率，取k个独特的推荐动漫标题。*'
- en: '[PRE1]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The github has the full code to run this step with examples too! For example,
    given k=3 and user id `205282`, the result of step two would result in the following
    dictionary where each key represents a different embedding model used and the
    values are anime title ids and corresponding cosine similarity scores to promoted
    titles the user liked:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: GitHub上有运行此步骤的完整代码示例！例如，给定k=3和用户ID `205282`，第二步的结果将产生以下字典，其中每个键代表一个不同的嵌入模型，值是动漫标题ID和对应于用户喜欢的推荐标题的余弦相似度分数：
- en: '[PRE2]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '3\. **Score relevant animes**: For each of the relevant animes identified in
    the previous step, if the anime is not present in the testing set for that user,
    ignore it. If we have a user rating for the anime in the testing set, we assign
    a score to the recommended anime given the NPS-inspired rules:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 3. **评分相关动漫**：对于在之前步骤中识别出的每个相关动漫，如果该动漫不在该用户的测试集中，则忽略它。如果我们有用户在测试集中的动漫评分，我们将根据NPS启发的规则为推荐的动漫分配一个分数：
- en: '![Images](graphics/square.jpg) If the rating in the testing set for the user
    and the recommended anime was 9 or 10, the anime is considered a “Promoter” and
    the system receives +1 points.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](graphics/square.jpg) 如果用户和推荐的动漫在测试集中的评分是9或10，则动漫被认为是“推广者”，系统获得+1分。'
- en: '![Images](graphics/square.jpg) If the rating is 7 or 8, the anime is considered
    “Passive” and receives 0 points.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](graphics/square.jpg) 如果评分是7或8，则动漫被认为是“被动”的，并获得0分。'
- en: '![Images](graphics/square.jpg) If the rating is between 1 and 6, the anime
    is considered a “Detractor” and receives -1 point.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](graphics/square.jpg) 如果评分在1到6之间，则动漫被认为是“负面评论者”，并获得-1分。'
- en: The final output of this recommendation engine is a ranked list of top N (depending
    on how many we wish to show the user) animes that are most likely to be enjoyed
    by the user and a score of how well the system did given a testing ground truth
    set. [Figure 6.4](ch06.html#ch06fig04) shows this entire process at a high level.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 该推荐引擎的最终输出是按排名列出前N个（取决于我们希望向用户展示多少）动漫，以及系统在给定测试真实集的情况下表现如何的分数。[图6.4](ch06.html#ch06fig04)以高层次展示了整个流程。
- en: '![Images](graphics/06fig04.jpg)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![图片](graphics/06fig04.jpg)'
- en: '**Figure 6.4** *The overall recommendation process involves using an embedder
    to retrieve similar animes from a user’s already promoted titles. It then assigns
    a score to the recommendations given if they were present in the testing set of
    ratings.*'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '**图6.4** *整体推荐过程涉及使用嵌入器从用户的已推广标题中检索相似动漫。然后，如果这些推荐在评分测试集中存在，则对它们分配一个分数。*'
- en: Generating a custom description field to compare items
  id: totrans-53
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 生成用于比较项目的自定义描述字段
- en: To compare different anime titles and generate recommendations more effectively,
    we will create our own custom generated description field that incorporates several
    relevant features from the dataset (Shown in [Figure 6.5](ch06.html#ch06fig05)).
    This approach offers several advantages and enables us to capture a more comprehensive
    context of each anime title, resulting in a richer and more nuanced representation
    of the content.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更有效地比较不同的动漫标题并生成推荐，我们将创建一个自定义生成的描述字段，该字段结合了数据集中的一些相关特征（如图6.5所示[链接](ch06.html#ch06fig05)）。这种方法具有多个优点，使我们能够捕捉到每个动漫标题的更全面背景，从而实现内容的更丰富和更细腻的呈现。
- en: '![Images](graphics/06fig05.jpg)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![图片](graphics/06fig05.jpg)'
- en: '**Figure 6.5** *Our custom generated description of each anime combines many
    raw features including the title, genre list, synopsis, producers, and more. This
    approach can be contrary to how many developers think because instead of generating
    a structured, tabular dataset, we are deliberately creating natural text representation
    of our anime titles and we will let our LLM-based embedders capture that in a
    vector (tabular) form.*'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '**图6.5** *我们为每个动漫创建的自定义描述结合了许多原始特征，包括标题、类型列表、简介、制作公司等。这种方法可能与许多开发者的想法相反，因为我们不是生成结构化的表格数据集，而是故意创建我们动漫标题的自然文本表示，并将让基于LLM的嵌入器以向量（表格）形式捕捉它。*'
- en: By combining multiple features, such as plot summaries, character descriptions,
    and genres, we can create a multidimensional representation of each anime title
    which allows our model to consider a broader range of information when comparing
    titles and identifying similarities, leading to more accurate and meaningful recommendations.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 通过结合多个特征，如剧情摘要、角色描述和类型，我们可以创建每个动漫标题的多维表示，这允许我们的模型在比较标题和识别相似性时考虑更广泛的信息，从而实现更准确和有意义的推荐。
- en: Incorporating various features from the dataset into a single description field
    can also aid in overcoming potential limitations in the dataset, such as missing
    or incomplete data. By leveraging the collective strength of multiple features,
    we ensure that our model has access to a more robust and diverse set of information
    and mitigates the effect of individual titles missing pieces of information.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 将数据集中的各种特征合并到一个描述字段中也有助于克服数据集中可能存在的潜在限制，如缺失或不完整的数据。通过利用多个特征的集体优势，我们确保我们的模型能够访问到一个更强大和多样化的信息集，并减轻单个标题缺失信息片段的影响。
- en: In addition, using a custom generated description field enables our model to
    adapt to different user preferences more effectively. Some users may prioritize
    plot elements, while others may be more interested in genres or mediums (TV series
    vs movies). By capturing a wide range of features in our description field, we
    can cater to a diverse set of user preferences and deliver personalized recommendations
    that align with individual tastes.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，使用自定义生成的描述字段可以使我们的模型更有效地适应不同的用户偏好。一些用户可能更重视剧情元素，而其他人可能对类型或媒介（电视剧与电影）更感兴趣。通过在我们的描述字段中捕捉广泛的特征，我们可以满足多样化的用户偏好，并提供与个人口味相符合的个性化推荐。
- en: Overall, This approach of creating our own custom description field from several
    individual fields ultimately should result in a recommendation engine that delivers
    more accurate and relevant content suggestions. [Listing 6.2](ch06.html#list6_2)
    provides a snippet of the code used to generate these descriptions.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，从多个个体字段创建我们自己的自定义描述字段的方法最终应该导致一个提供更准确和相关性内容建议的推荐引擎。[列表6.2](ch06.html#list6_2)提供了生成这些描述所使用的代码片段。
- en: '**Listing 6.2** *Generating custom descriptions from multiple anime fields*'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '**列表6.2** *从多个动漫字段生成自定义描述*'
- en: '[PRE3]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Setting a Baseline with Foundation Embedders
  id: totrans-63
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 使用基础嵌入器设置基线
- en: 'Before customizing our embeddings, we will establish a baseline performance
    using two foundation embedders: OpenAI''s powerful Ada-002 embedder and a small
    open-source bi-encoder based on a distilled RoBERTa model. These pre-trained models
    offer a starting point for comparison, helping us to quantify the improvements
    achieved through customization. We will start with these two models and eventually
    work our way up to comparing four different embedders – 1 closed-sourced and 3
    open-sourced.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在自定义我们的嵌入之前，我们将使用两个基础嵌入器来建立基线性能：OpenAI强大的Ada-002嵌入器和基于蒸馏RoBERTa模型的小型开源双编码器。这些预训练模型为我们提供了一个比较的起点，帮助我们量化通过定制所取得的改进。我们将从这两个模型开始，最终逐步比较四个不同的嵌入器——1个闭源和3个开源。
- en: Preparing our fine-tuning data
  id: totrans-65
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 准备我们的微调数据
- en: To attempt to create a robust recommendation engine, we will fine-tune open-source
    embedders using the Sentence Transformers library. We will begin by calculating
    the Jaccard Similarity between promoted animes from the training set.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 为了尝试创建一个健壮的推荐引擎，我们将使用Sentence Transformers库对开源嵌入器进行微调。我们将首先计算训练集中推广动漫的Jaccard相似度。
- en: '**Jaccard similarity** is a simple method to measure the similarity between
    two sets of data based on the number of elements they share. The Jaccard similarity
    is calculated by dividing the number of elements that both groups have in common
    by the total number of distinct elements in both groups combined.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '**Jaccard相似度**是一种基于两组数据共享元素数量来衡量它们之间相似度的简单方法。Jaccard相似度是通过将两组共有的元素数量除以两组中所有不同元素的总数来计算的。'
- en: Let's say we have two anime shows, Anime A and Anime B.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有两个动漫节目，动漫A和动漫B。
- en: 'Suppose we have the following people who like these shows:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有以下喜欢这些节目的人：
- en: '![Images](graphics/square.jpg) People who like Anime A: Alice, Bob, Carol,
    David'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](graphics/square.jpg) 喜欢动漫A的人：Alice、Bob、Carol、David'
- en: '![Images](graphics/square.jpg) People who like Anime B: Bob, Carol, Ethan,
    Frank'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](graphics/square.jpg) 喜欢动漫B的人：Bob、Carol、Ethan、Frank'
- en: To calculate the Jaccard similarity, we first find the people who like both
    Anime A and Anime B. In this case, it's Bob and Carol.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 要计算Jaccard相似度，我们首先找出同时喜欢动漫A和动漫B的人。在这个例子中，是Bob和Carol。
- en: Next, we find the total number of distinct people who like either Anime A or
    Anime B. Here, we have Alice, Bob, Carol, David, Ethan, and Frank.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们找出喜欢动漫A或动漫B的不同人数。这里包括Alice、Bob、Carol、David、Ethan和Frank。
- en: Now, we can calculate the Jaccard similarity by dividing the number of common
    elements (2, as Bob and Carol like both shows) by the total number of distinct
    elements (6, as there are 6 unique people in total).
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以通过将共同元素的数量（2，因为Bob和Carol都喜欢这两个节目）除以总的不同元素数量（6，因为总共有6个独特的人）来计算Jaccard相似度。
- en: Jaccard similarity = 2/6 = 1/3 ≈ 0.33
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: Jaccard相似度 = 2/6 = 1/3 ≈ 0.33
- en: So, the Jaccard similarity between Anime A and Anime B, based on the people
    who like them, is about 0.33 or 33%. This means that 33% of the distinct people
    who like either show have similar tastes in anime, as they enjoy both Anime A
    and Anime B. [Figure 6.6](ch06.html#ch06fig06) shows another example.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，基于喜欢它们的观众，动漫A和动漫B之间的Jaccard相似度约为0.33或33%。这意味着33%的喜欢任意一个节目的独特观众在动漫口味上有相似之处，因为他们都喜欢动漫A和动漫B。[图6.6](ch06.html#ch06fig06)显示了另一个例子。
- en: '![Images](graphics/06fig06.jpg)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![图片](graphics/06fig06.jpg)'
- en: '**Figure 6.6** *To convert our raw ratings into pairs of animes with associated
    scores, we will consider every pair of anime titles and compute the jaccard score
    between promoting users.*'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '**图6.6** *为了将我们的原始评分转换为带有相关分数的动漫对，我们将考虑每个动漫标题的对，并计算促进用户的Jaccard分数。*'
- en: We will apply this logic to calculate the Jaccard similarity for every pair
    of animes using a training set of the ratings DataFrame and only keep scores above
    a certain threshold as “positive examples” (label of 1) and the rest will be considered
    “negative” (label of 0).
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将应用这种逻辑，使用评分DataFrame的训练集计算每对动漫的Jaccard相似度，并且只保留高于一定阈值的分数作为“正面示例”（标签为1），其余将被视为“负面”（标签为0）。
- en: 'Important Note: We are free to label any anime pairs with a label between -1
    and 1 but I am only using 0 and 1 because I’m only using promoting scores to create
    my data so it’s not fair to say that if the jaccard score between animes is low
    then the users totally disagree on the anime. That’s not necessarily true! If
    I expanded this case study I would want to explicitly label animes as -1 if and
    only if users were genuinely rating them opposite (most users who promote one
    are detractors of the other).'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示：我们可以自由地将任何动漫对标记为介于-1和1之间的任何标签，但我只使用0和1，因为我只使用促进分数来创建我的数据，所以不能说如果动漫之间的Jaccard分数低，那么用户在动漫上完全不同意。这并不一定正确！如果我要扩展这个案例研究，我只想在用户真正对动漫进行相反评分的情况下，明确地将动漫标记为-1。
- en: Once we have jaccard scores for anime ides, we will need to convert them into
    tuples of anime descriptions and the cosine label (in our case either 0 or 1)
    and then we are ready to update our open-source embedders and experiment with
    different token windows (shown in [Figure 6.7](ch06.html#ch06fig07)).
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们有了动漫ID的Jaccard分数，我们需要将它们转换为包含动漫描述和余弦标签（在我们的案例中为0或1）的元组，然后我们就可以更新我们的开源嵌入器并尝试不同的标记窗口（如图6.7所示）。
- en: '![Images](graphics/06fig07.jpg)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![图片](graphics/06fig07.jpg)'
- en: '**Figure 6.7** *Jaccard scores are converted into cosine labels and then fed
    into our bi-encoder so it may attempt to learn patterns between the generated
    anime descriptions and how users co-like the titles.*'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '**图6.7** *将Jaccard分数转换为余弦标签，然后输入到我们的双编码器中，以便它可能尝试学习生成的动漫描述和用户共同喜欢的标题之间的模式。*'
- en: Once we have Jaccard similarities between anime pairs, we can convert these
    to labels for our bi-encoder with a simple rule. In our case, if the score is
    above 0.3, then we label the pair as positive (label 1) and if the label is <
    0.1, we label is as “negative” (label 0).
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们有了动漫对的Jaccard相似度，我们可以通过一个简单的规则将这些相似度转换为我们的双编码器的标签。在我们的例子中，如果分数高于0.3，则将这对标签为正面（标签1），如果标签小于0.1，则将其标记为“负面”（标签0）。
- en: Adjusting Model Architectures
  id: totrans-85
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 调整模型架构
- en: When working with open-source embedders, we have so much more flexibility to
    change things around if we need to. For example, the open source model I want
    to use was pre-trained with the ability to only take in 128 tokens at a time and
    truncate anything longer than that. [Figure 6.8](ch06.html#ch06fig08) shows the
    histogram of the token lengths for our generated anime descriptions which clearly
    shows that we have many descriptions that are over 128 tokens, some in the 600
    range!
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用开源嵌入器工作时，如果我们需要改变某些东西，我们拥有更多的灵活性。例如，我想使用的开源模型是预先训练的，一次只能接受128个标记，并且会截断任何超过这个长度的内容。[图6.8](ch06.html#ch06fig08)显示了我们的生成动漫描述的标记长度直方图，它清楚地表明我们有很多描述超过128个标记，有些甚至达到600个标记！
- en: '![Images](graphics/06fig08.jpg)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![图片](graphics/06fig08.jpg)'
- en: '**Figure 6.8** *We have several animes that, after tokenizing, are hundreds
    of tokens long, some have over 600 tokens.*'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '**图6.8** *我们有一些动漫，在标记化后长度达到数百个标记，其中一些超过600个标记。*'
- en: In [Listing 6.3](ch06.html#list6_3), we change the input sequence length to
    be 384 instead of 128.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在[列表6.3](ch06.html#list6_3)中，我们将输入序列长度更改为384而不是128。
- en: '**Listing 6.3** *Modifying an open-source bi-encoder’s max sequence length*'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '**列表6.3** *修改开源双编码器的最大序列长度*'
- en: '[PRE4]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Why 384? Well:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么是384？好吧：
- en: '![Images](graphics/square.jpg) The histogram of token lengths shows that 384
    would capture most of our animes in their entirely and would truncate the rest'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '![图像](graphics/square.jpg) 标记长度的直方图显示，384将能够完全捕获我们的大部分动漫，并且会截断其余部分'
- en: '![Images](graphics/square.jpg) 384 = 256 + 128, the sum of 2 binary numbers
    and we like binary numbers -Modern hardware components, especially GPUs, are designed
    to perform optimally with binary numbers so they can split up workloads evenly.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '![图像](graphics/square.jpg) 384 = 256 + 128，两个二进制数的和，我们喜欢二进制数——现代硬件组件，尤其是GPU，被设计成以二进制数最优性能运行，这样它们可以平均分配工作负载。'
- en: '![Images](graphics/square.jpg) Why not 512 then to capture more training data?
    I still want to be conservative here. The more I increase this max token window
    size, the more data I would need to train the system because we are adding parameters
    to our model and therefore there is more to learn. It will also take more time
    and compute resources to load, run, and update the larger model.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '![图像](graphics/square.jpg) 为什么不使用512来捕获更多的训练数据呢？我仍然想保持保守。我增加这个最大标记窗口大小的程度越大，我需要训练系统的数据就越多，因为我们正在向模型添加参数，因此有更多东西需要学习。这也会需要更多的时间和计算资源来加载、运行和更新更大的模型。'
- en: • For what it’s worth, I did initially try this process with an embedding size
    of 512 and got worse results while taking about 20% longer on my machine.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: • 值得注意的是，我最初尝试使用512个嵌入大小进行这个过程，结果更差，同时在我的机器上花费了大约20%的时间。
- en: To be explicit, anytime we alter an original pre-trained foundation model in
    any capacity the model must learn something from scratch. In this case, the model
    will learn, from scratch, how text longer than 128 tokens can be formatted and
    how to assign attention scores across a longer text span. It can be difficult
    to make these model architecture adjustments but often well worth the effort in
    terms of performance! In our case, changing the max input length to 384 is only
    the starting line because this model now has to learn about text longer than 128
    tokens.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 要明确的是，无论我们以何种方式修改原始预训练的基础模型，模型都必须从头开始学习。在这种情况下，模型将从头开始学习如何格式化超过128个标记的文本以及如何在较长的文本跨度内分配注意力分数。调整这些模型架构可能很困难，但通常在性能方面值得付出努力！在我们的案例中，将最大输入长度更改为384只是一个起点，因为现在这个模型必须学习关于超过128个标记的文本。
- en: With modified bi-encoder architectures, data prepped and ready to go, we are
    ready to fine-tune!
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 使用修改后的双编码器架构，数据准备就绪，我们可以准备微调了！
- en: Fine-tuning Open-Source Embedders Using Sentence Transformers
  id: totrans-99
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 使用Sentence Transformers微调开源嵌入器
- en: It’s time to fine-tune our open-source embedders using Sentence Transformers.
    Sentence Transformers as a reminder is a library built on top of the Hugging Face
    Transformers library.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 是时候使用Sentence Transformers微调我们的开源嵌入器了。Sentence Transformers作为一个提醒，是建立在Hugging
    Face Transformers库之上的库。
- en: We create a custom training loop using the Sentence Transformers library shown
    in [Listing 6.4](ch06.html#list6_4). We use the provided training and evaluation
    functionalities of the library, such as the 'fit()' method for training and the
    'evaluate()' method for validation.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用[列表6.4](ch06.html#list6_4)中所示的Sentence Transformers库创建一个自定义训练循环。我们使用库提供的训练和评估功能，例如使用'fit()'方法进行训练和使用'evaluate()'方法进行验证。
- en: Before we begin the fine-tuning process, we need to decide on several hyperparameters,
    such as learning rate, batch size, and the number of training epochs. I have experimented
    with various hyperparameter settings to find a good combination that leads to
    optimal model performance. I will dedicate all of [chapter 8](ch08.html#ch08)
    to discussing dozens of open-source fine-tuning hyper parameters so if you are
    looking for a deeper discussion on how I came to these numbers, please refer to
    [Chapter 8](ch08.html#ch08).
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始微调过程之前，我们需要决定几个超参数，例如学习率、批处理大小和训练轮数。我已经尝试了各种超参数设置，以找到导致最佳模型性能的良好组合。我将把[第8章](ch08.html#ch08)的全部内容用于讨论数十个开源微调超参数，所以如果你想要更深入地了解我是如何得到这些数字的，请参阅[第8章](ch08.html#ch08)。
- en: We gauge how well the model learned by checking the change in the cosine similarity
    which jumped up to the high .8, .9s! That’s great.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过检查余弦相似度的变化来衡量模型学习的好坏，相似度跃升至0.8，0.9！这太棒了。
- en: '**Listing 6.4** *Fine-tuning a bi-encoder*'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '**列表6.4** *微调双编码器*'
- en: '[PRE5]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: With our fine-tuned bi-encoder, we can generate embeddings for new anime descriptions
    and compare them with the embeddings of our existing anime database. By calculating
    the cosine similarity between the embeddings, we can recommend animes that are
    most similar to the user's preferences.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 使用我们的微调双编码器，我们可以为新的动漫描述生成嵌入，并将它们与我们的现有动漫数据库中的嵌入进行比较。通过计算嵌入之间的余弦相似度，我们可以推荐与用户偏好最相似的动漫。
- en: It’s worth noting that once we go through the process of fine-tuning a single
    custom embedder using our user preference data, we can then pretty easily swap
    out different models with similar architectures and run the same code, rapidly
    expanding our universe of embedder options. For this case study, I also fine-tuned
    another LLM called `all-mpnet-base-v2` which (at the time of writing) is regarded
    as a very good open-source embedder for semantic search and clustering purposes.
    It is a bi-encoder as well so we can simply swap out references to our Roberta
    model with mpnet and change virtually no code (see the github for the complete
    case study).
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，一旦我们使用用户偏好数据微调了一个定制的嵌入器，我们就可以轻松地用具有相似架构的不同模型替换，并运行相同的代码，快速扩展我们的嵌入器选项集。对于这个案例研究，我还微调了另一个名为`all-mpnet-base-v2`的LLM，它在撰写本文时被认为是非常好的开源嵌入器，用于语义搜索和聚类目的。它也是一个双编码器，因此我们可以简单地用mpnet替换对Roberta模型的引用，几乎不需要更改代码（请参阅github上的完整案例研究）。
- en: Summary of Results
  id: totrans-108
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 结果摘要
- en: 'In the course of this case study we:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个案例研究的过程中，我们：
- en: '![Images](graphics/square.jpg) Generated a custom anime description field using
    several raw fields from the original dataset'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](graphics/square.jpg) 使用原始数据集的几个原始字段生成了一个定制的动漫描述字段'
- en: '![Images](graphics/square.jpg) Created training data for a bi-encoder from
    user-anime ratings using a combination of NPS/Jaccard scoring and our generated
    descriptions'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](graphics/square.jpg) 使用NPS/Jaccard评分和我们的生成描述的组合为用户动漫评分创建了一个双编码器的训练数据'
- en: '![Images](graphics/square.jpg) Modified an open source architecture to accept
    a larger token window to account for our longer description field.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](graphics/square.jpg) 修改了开源架构以接受更大的标记窗口，以适应我们较长的描述字段。'
- en: '![Images](graphics/square.jpg) Fine-tuned two bi-encoders with our training
    data to attempt to create a model that mapped our descriptions to an embedding
    space more aligned to our user’s preferences'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](graphics/square.jpg) 使用我们的训练数据微调了两个双编码器，试图创建一个将我们的描述映射到与用户偏好更一致的嵌入空间的模型'
- en: '![Images](graphics/square.jpg) Defined an evaluation system using NPS-scoring
    to reward a promoted recommendation (the user giving it a 9 or a 10 in the testing)
    and punishing detracted titles (users giving it a 1-6 in the testing set)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![图片](graphics/square.jpg) 使用NPS评分定义了一个评估系统，以奖励提升推荐（在测试中用户给出9或10分）并惩罚负面标题（在测试集中用户给出1-6分）'
- en: 'We had four candidates for our embedders:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 我们为嵌入器选定了四个候选者：
- en: '![Images](graphics/square.jpg) `**text-embedding-002**` - OpenAI’s recommended
    embedder for all use-cases, mostly optimized for semantic similarity'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](graphics/square.jpg) `**text-embedding-002**` - OpenAI推荐的适用于所有用例的嵌入器，主要优化语义相似度'
- en: '![Images](graphics/square.jpg) `**paraphrase-distilroberta-base-v1**` - An
    open source model pre-trained to summarize short pieces of text'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](graphics/square.jpg) `**paraphrase-distilroberta-base-v1**` - 预训练用于总结短文本的开源模型'
- en: '![Images](graphics/square.jpg) `**anime_encoder**` - The distilroberta model
    with a modified 384 token window and fine-tuned on our user preference data'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](graphics/square.jpg) `**anime_encoder**` - 经过修改的384标记窗口的distilroberta模型，并在我们的用户偏好数据上进行了微调'
- en: '![Images](graphics/square.jpg) `**anime_encoder_bigger**` - A larger open source
    model (`all-mpnet-base-v2`) that was pre-trained with a token window size of 512
    which I further fine-tuned on our user preference data, same as `anime_encoder`.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](graphics/square.jpg) `**anime_encoder_bigger**` - 一个更大的开源模型（`all-mpnet-base-v2`），它使用512个标记窗口大小进行预训练，我进一步在用户偏好数据上进行了微调，与`anime_encoder`相同。'
- en: '[Figure 6.9](ch06.html#ch06fig09) shows our final results for our four embedder
    candidates across lengthening recommendation windows (how many recommendations
    we show the user).'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '[图6.9](ch06.html#ch06fig09) 显示了我们四个嵌入器候选人在延长推荐窗口（向用户展示多少个推荐）的最终结果。'
- en: '![Images](graphics/06fig09.jpg)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![图片](graphics/06fig09.jpg)'
- en: '**Figure 6.9** *Our larger open-source model (anime_encoder_bigger) consistently
    outperforms OpenAI’s embedder in recommending anime titles to our users based
    on historical preferences.*'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '**图6.9** *我们更大的开源模型（anime_encoder_bigger）在根据历史偏好向用户推荐动漫标题方面，始终优于OpenAI的嵌入器。*'
- en: Each tick on the x axis here represents showing the user a list of that many
    anime titles and the y axis is a aggregated score for the embedder using the scoring
    system outlined before where we also further reward the model if a correct recommendation
    was placed closer to the front of the list and likeways punish it more if it recommends
    something that the user is a detractor for closer to the beginning of the list.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里x轴上的每个刻度代表向用户展示包含那么多动漫标题的列表，y轴是使用之前概述的评分系统计算出的嵌入器的聚合分数，其中如果正确的推荐被放置在列表的前面，我们还会进一步奖励模型；如果它推荐了用户可能不喜欢的标题，我们则会更多地惩罚它。
- en: 'Some interesting takeaways:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 一些有趣的发现：
- en: '![Images](graphics/square.jpg) The best performing model is our larger fine-tuned
    model and it consistently outperforms OpenAI’s embedder!'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](graphics/square.jpg) 表现最好的模型是我们的更大规模的微调模型，并且它始终优于OpenAI的嵌入器！'
- en: '![Images](graphics/square.jpg) The fine-tuned distilroberta model (anime_encoder)
    underperforms it’s pre-trained cousin who can only take in 128 tokens at a time.
    This is most likely because:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](graphics/square.jpg) 微调的distilroberta模型（anime_encoder）的表现不如它的预训练版本，后者一次只能处理128个token。这很可能是由于：'
- en: '![Images](graphics/square.jpg) The model doesn’t have enough parameters in
    it’s attention layersto capture the recommendation problem well and its non fine-tuned
    cousin is simply relying on recommending semantically similar titles.'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](graphics/square.jpg) 模型在它的注意力层中参数不足，无法很好地捕捉推荐问题，并且它的未微调的版本只是依赖于推荐语义上相似的电影标题。'
- en: '![Images](graphics/square.jpg) The model might require more than 384 tokens
    to capture all possible relationships.'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](graphics/square.jpg) 模型可能需要超过384个token来捕捉所有可能的关系。'
- en: '![Images](graphics/square.jpg) All models start to degrade in performance as
    it is expected to recommend more and more titles which is fair. The more titles
    anything recommends, the less confident it will be as it goes down the list.'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](graphics/square.jpg) 所有模型在推荐越来越多的标题时性能开始下降，这是预期的。任何推荐越多，它对列表中后面的推荐就越不自信。'
- en: Exploring Exploration
  id: totrans-130
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 探索探索
- en: Earlier I mentioned that a recommendation system’s level of “exploration” can
    be defined as how often it recommends something that the user may not have watched
    before. We didn’t take any explicit measures to try and encourage exploration
    but it is still worth seeing how our embedders stack up. [Figure 6.10](ch06.html#ch06fig10)
    shows a graph of the raw number of animes recommended to all of the users in our
    test dataset.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 我之前提到，推荐系统的“探索”水平可以定义为它推荐用户可能之前没有观看过的内容的频率。我们没有采取任何明确的措施来尝试鼓励探索，但仍然值得看看我们的嵌入器如何排列。[图6.10](ch06.html#ch06fig10)显示了测试数据集中所有用户被推荐动漫的原始数量图。
- en: '![Images](graphics/06fig10.jpg)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![图片](graphics/06fig10.jpg)'
- en: '**Figure 6.10** *Comparing how many unique animes were recommended during the
    course of the testing process.*'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '**图6.10** *比较在测试过程中推荐了多少独特的动漫。*'
- en: OpenAI’s ada and our bigger encoder gave out more recommendations than the two
    other options but OpenAI clearly seems to be in the lead of diversity of unique
    animes recommended. This could be a sign (not proof) that our users are not that
    explorative and tend to gravitate towards the same animes and our fine-tuned bi-encoder
    is picking up on that and delivering fewer unique results. It could also simply
    be that the OpenAI ada embedder was trained on such a diverse set of data and
    is so large in terms of parameters that it is simply better than our fine-tuned
    model at delivering consistently favored animes at scale.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI的ada和我们的更大编码器给出的推荐比其他两种选项多，但OpenAI在推荐独特动漫的多样性方面显然处于领先地位。这可能是一个迹象（不是证据），表明我们的用户并不那么喜欢探索，倾向于倾向于相同的动漫，并且我们的微调双编码器正在捕捉这一点，并产生较少的独特结果。这也可能仅仅是因为OpenAI的ada嵌入器在如此多样化的数据集上进行了训练，并且在参数方面如此之大，因此在提供大量受欢迎的动漫方面比我们的微调模型更好。
- en: 'To answer these questions and more, we would want to continue our research
    by, for example we could:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 为了回答这些问题以及更多，我们希望通过以下方式继续我们的研究，例如我们可以：
- en: '![Images](graphics/square.jpg) Try new open sourced models and closed sourced
    models'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](graphics/square.jpg) 尝试新的开源模型和闭源模型'
- en: '![Images](graphics/square.jpg) Design new metrics for quality assurance to
    test our embedders on a more holistic scale'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](graphics/square.jpg) 设计新的质量保证指标，以更全面地测试我们的嵌入器'
- en: '![Images](graphics/square.jpg) Calculate new training datasets that use other
    metrics like correlation coefficients instead of jaccard'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](graphics/square.jpg) 计算使用其他指标（如相关系数）而不是贾卡德系数的新训练数据集'
- en: '![Images](graphics/square.jpg) Toggle recommendation system hyper parameters
    like K. We only ever considered grabbing the first K=3 animes for each promoted
    anime but what if we let that number vary as well?'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](graphics/square.jpg) 切换推荐系统超参数，如K。我们之前只考虑了抓取每个推广动漫的前K=3部动漫，但如果我们让这个数字也变化会怎样呢？'
- en: '![Images](graphics/square.jpg) Run some pre-training on blogs and wikis about
    anime recommendation and theory so the model has some latent access to information
    about how to consider recommendations'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](graphics/square.jpg) 在关于动漫推荐和理论的博客和维基上运行一些预训练，以便模型能够获取一些关于如何考虑推荐的信息'
- en: Honestly that last one is a bit pie in the sky and would really work best if
    we could also combine that with some chain of thought prompting on a different
    LLM but still, this is a big question and sometimes that means we need big ideas
    and big answers. So I leave it to you now; go have big ideas!
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，最后一个目标有点不切实际，如果我们还能结合一些不同LLM上的思维链提示，那将更加完美。但无论如何，这是一个大问题，有时这意味着我们需要大想法和大答案。所以现在就交给你了；去发挥你的想象力吧！
- en: Conclusion
  id: totrans-142
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 结论
- en: In this chapter, I showed you the process of fine-tuning open-source embedding
    models for a specific use case, which in our case, was generating high-quality
    anime recommendations based on users' historical preferences. By comparing the
    performance of our customized models with that of OpenAI's embedder, we observed
    that a fine-tuned model could consistently outperform OpenAI's embedder.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我向你展示了为特定用例微调开源嵌入模型的过程，在我们的案例中，是根据用户的以往偏好生成高质量的动漫推荐。通过比较我们定制模型与OpenAI的嵌入器的性能，我们发现微调模型能够持续优于OpenAI的嵌入器。
- en: Customizing embedding models and their architectures for specialized tasks can
    lead to improved performance and provide a viable alternative to closed-source
    models, especially when access to labeled data and resources for experimentation
    is available.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 为特定任务定制嵌入模型及其架构可以提高性能，并提供一种可行的替代方案，尤其是在可以访问标记数据和实验资源的情况下，尤其是当可以访问标记数据和实验资源时。
- en: I hope that the success of our fine-tuned model in recommending anime titles
    serves as a testament to the power and flexibility that open-source models offer,
    paving the way for further exploration, experimentation, and application in whatever
    tasks you might have.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 我希望我们微调模型在推荐动漫标题方面的成功能够证明开源模型所提供的力量和灵活性，为进一步的探索、实验和应用于你可能会有的任何任务铺平道路。
