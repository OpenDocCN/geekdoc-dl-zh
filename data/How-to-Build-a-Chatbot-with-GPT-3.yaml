- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: COT 专栏'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：COT 专栏
- en: 'date: 2024-05-08 11:11:30'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-05-08 11:11:30
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: How to Build a Chatbot with GPT-3
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何用GPT-3构建一个聊天机器人
- en: 来源：[https://every.to/chain-of-thought/how-to-build-a-chatbot-with-gpt-3](https://every.to/chain-of-thought/how-to-build-a-chatbot-with-gpt-3)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://every.to/chain-of-thought/how-to-build-a-chatbot-with-gpt-3](https://every.to/chain-of-thought/how-to-build-a-chatbot-with-gpt-3)
- en: 'On a Friday night a few weeks ago I woke up to an email from [Lenny Rachitsky](https://twitter.com/lennysan),
    writer of [Lenny’s Newsletter](http://lennysnewsletter.com/), one of the largest
    newsletters on Substack. He wanted to know how I built one of our Every chatbots:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 几周前的一个星期五晚上，我醒来收到了一封来自[Lenny Rachitsky](https://twitter.com/lennysan)的电子邮件，他是[Lenny's
    Newsletter](http://lennysnewsletter.com/)的作者，是Substack上最大的通讯之一。他想知道我是如何构建我们Every的一个聊天机器人的：
- en: I
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 我
- en: '*love*'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '*爱*'
- en: Lenny. He’s a major inspiration for us at Every, so to see him interested in
    chatbots was exciting. It also created an opportunity for me to test a theory
    I’d been
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: Lenny。他对Every是一个重要的灵感，所以看到他对聊天机器人感兴趣真是令人兴奋。这也为我提供了一个机会，可以测试我一直以来的一个理论
- en: '[playing around with](https://every.to/chain-of-thought/i-trained-a-gpt-3-chatbot-on-every-episode-of-my-favorite-podcast)'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[玩弄](https://every.to/chain-of-thought/i-trained-a-gpt-3-chatbot-on-every-episode-of-my-favorite-podcast)'
- en: ':'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: ：
- en: '*Chatbots are a new and valuable content format for creators.*'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '*聊天机器人是创作者的一种新而有价值的内容格式*。'
- en: 'I knew Lenny’s audience would be a perfect way to test this theory:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我知道Lenny的观众会是测试这个理论的完美方式：
- en: It’s large (he has 300,000 subscribers).
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它很大（他有30万订阅者）。
- en: They’re highly engaged.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 他们的参与度很高。
- en: All of his posts are evergreen.
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 他的所有帖子都是长青的。
- en: They’re often used as reference material.
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它们经常被用作参考资料。
- en: For all of these reasons, making his posts available in a chatbot format made
    sense. Rather than having to scroll through his archive to answer a product question,
    any of his subscribers could ask the bot instead and get instant answers.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 出于这些原因，将他的帖子以聊天机器人的形式提供是有意义的。与其不得不浏览他的存档来回答一个产品问题，他的任何订阅者都可以问机器人，而且会立即得到答案。
- en: 'I knew it would be pretty easy to build one for him based on the work we’d
    already done—so I offered to make it for him:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我知道基于我们已经完成的工作，为他构建一个这样的机器人会很容易——所以我提出了为他制作一个的建议：
- en: 'He said yes, and the next day I woke up early and delivered him a Lenny chatbot
    built to give answers from his newsletter archives:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 他说好，第二天我一早醒来就给他交付了一个Lenny聊天机器人，它可以根据他的通讯档案提供答案：
- en: Over the next couple of weeks I also wrote an essay,
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的几周里，我还写了一篇文章，
- en: '[published as a guest post on his newsletter](https://www.lennysnewsletter.com/p/39b613d6-063b-45df-9a8e-40fece9d6bde)'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '[以客座帖子的形式发布在他的通讯中](https://www.lennysnewsletter.com/p/39b613d6-063b-45df-9a8e-40fece9d6bde)'
- en: ', about how I built the bot. It’s a detailed, step-by-step guide to how GPT-3
    works and how it can be used to create Q&A chatbots like this easily—no programming
    experience required. It went live on Tuesday and became Lenny’s highest trafficked
    day ever:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: ，关于我如何构建机器人。这是对GPT-3如何工作以及如何使用它轻松创建像这样的问答机器人的详细、逐步指南——无需编程经验。它在星期二上线，成为Lenny有史以来流量最高的一天：
- en: It was a wild ride, and I’m syndicating the full post below for all of you.
    There is also
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一次疯狂的旅程，我正在为你们所有人同步全文。还有
- en: '**a section at the bottom exclusively for Every paying subscribers with**'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '**一个专门为每位付费订阅者准备的底部部分**。'
- en: ':'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: ：
- en: A retrospective on launch day including metrics
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 发布日回顾，包括指标
- en: Server-side code samples
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 服务器端代码示例。
- en: Client-side chatbot code samples
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 客户端聊天机器人代码示例。
- en: 'If you want to read the full post, including code samples, subscribe here:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想阅读完整的文章，包括代码示例，请在这里订阅：
- en: I hope you enjoy!
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 希望你喜欢！
- en: ''
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '* * *'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: "\uFEFF\uFEFFI Built a Lenny Chatbot Using GPT-3"
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我用GPT-3构建了一个Lenny聊天机器人
- en: Lenny’s Newsletter is great, but it’s one-sided. It talks *to* you, but you
    can’t talk back. Wouldn’t it be awesome if you could ask Lenny’s Newsletter a
    question?
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: Lenny的通讯很棒，但是它是单向的。它和你交谈，但你不能回答。如果你能问Lenny的通讯一个问题，那不是很棒吗？
- en: Now that’s possible.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 现在这是可能的。
- en: Over the course of a week I built an AI-powered chatbot for Lenny that uses
    his entire newsletter archive to answer any question you have about product, growth,
    and startups. It’s built with GPT-3 and took a couple hours to do, end to end.
    In this post, I’ll break down exactly how the Lenny Bot works so you can learn
    to build one yourself.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个星期的时间里，我为Lenny构建了一个AI驱动的聊天机器人，它使用他的整个通讯档案来回答您关于产品、增长和初创公司的任何问题。它是用GPT-3构建的，从头到尾只用了几个小时。在这篇文章中，我将详细解释Lenny
    Bot的工作原理，这样你就可以学会自己构建一个。
- en: You can also use it right now 👇
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以立即使用它👇
- en: AI technologies like GPT-3 are still in their infancy, but they’re going to
    be everywhere soon. Staying on top of how they work is going to be crucial to
    your career in tech, and especially in building product. The best way to prepare
    for a fast-approaching future is to dive in and get your hands dirty.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-3等AI技术仍处于起步阶段，但它们很快就会无处不在。了解它们的工作方式对你的技术职业，尤其是产品开发将至关重要。为了迎接迅速到来的未来，最好的准备方式是投入其中，动手实践。
- en: It might seem intimidating to get started, especially if you don’t have a technical
    background. But I’m going to start at the very beginning. You’ll be able to understand
    what I’m talking about and begin using it yourself,*no programming required***.**
    (And if you have any questions, you can always paste them into ChatGPT—it’ll give
    you good responses ;)
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你没有技术背景，开始可能会让人畏惧。但我将从最基础的知识开始讲起。你将能够理解我在说什么，并开始使用它，*无需编程**。*（而且，如果你有任何问题，可以随时将它们粘贴到ChatGPT中——它会给你良好的回应；）
- en: 'Preamble: GPT-3 vs. ChatGPT'
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 序言：GPT-3和ChatGPT的区别
- en: You’ve probably heard of both GPT-3 and ChatGPT. Maybe you use those terms interchangeably,
    or maybe you’re not really sure what the difference is. It’s worth taking a minute
    to understand how they differ.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能听说过GPT-3和ChatGPT。也许你将这些术语混用，或者你可能并不确定它们的区别。花点时间来理解它们的区别是值得的。
- en: GPT-3 and ChatGPT are both “large language models” (LLMs). These are machine-learning
    models that can generate natural-sounding text, code, and more. They’re trained
    using large data sets of text, which helps them master natural-language tasks,
    like answering questions, writing marketing copy, and holding conversations. So
    what’s the difference between them? And why is it important?
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-3和ChatGPT都是“大型语言模型”（LLMs）。这些是可以生成自然听起来的文本、代码等的机器学习模型。它们通过大量的文本数据集进行训练，有助于它们掌握自然语言任务，如回答问题、写营销文案和进行对话。那么它们之间的区别是什么？为什么这很重要？
- en: 'GPT-3 is a general-purpose language model: it can hold conversations, write
    code, complete a blog post, do translation tasks, and more. You can think of it
    like a flexible know-it-all that can expound on any topic you want.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-3是一个通用语言模型：它可以进行对话，编写代码，完成博客文章，进行翻译任务等。你可以把它想象成一个灵活的全能型人物，可以在你想要的任何话题上阐述。
- en: ChatGPT is a version of GPT-3 that’s been turned into a friendly, inoffensive
    extrovert. Basically, it’s been trained to be good at holding conversations. Its
    creator OpenAI does this by repeatedly holding conversations with the model, and
    rewarding it for good responses and punishing it for bad ones—a process called
    [Reinforcement Learning from Human Feedback](https://huggingface.co/blog/rlhf).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT是GPT-3的一个版本，它被打造成了一个友好、无攻击性的外向型个体。基本上，它经过训练擅长进行对话。其创造者OpenAI通过不断地与模型进行对话，对好的回应进行奖励，对不好的回应进行惩罚——这个过程被称为[人类反馈的强化学习](https://huggingface.co/blog/rlhf)。
- en: You’d think since we’re building a chatbot, we’d use ChatGPT, right? Unfortunately
    not. OpenAI hasn’t created a way for us to interact with the ChatGPT model directly—you
    can only use it through the ChatGPT web app. So it’s not suitable for our purposes.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会认为既然我们正在构建一个聊天机器人，我们会使用ChatGPT，对吧？不幸的是，OpenAI并没有为我们创建一种方式来直接与ChatGPT模型互动——你只能通过ChatGPT
    Web应用程序使用它。所以它不适合我们的目的。
- en: We want to be able to interact with the model directly, not through an intervening
    app. So instead we’ll use GPT-3 for our explorations. It’ll give us all the power
    and flexibility we need to build a chatbot.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望能够直接与模型互动，而不是通过一个中介应用。所以我们将使用GPT-3进行探索。它将为我们提供构建聊天机器人所需的所有力量和灵活性。
- en: 'We’ll do it in two ways: using [OpenAI’s Playground](https://platform.openai.com/playground)
    to start, and with a little bit of code after that. The Playground is a web app
    that lets you prompt GPT-3 and get responses back, making it a great place for
    us to experiment.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将以两种方式来进行：首先使用[OpenAI的Playground](https://platform.openai.com/playground)起步，之后再加上一点代码。Playground是一个Web应用程序，让你提示GPT-3并得到回应，让我们来实验的绝佳地方。
- en: Let’s start there and see how things go.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从这里开始，看看事情的发展情况。
- en: The basics of GPT-3
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GPT-3的基础知识
- en: The basic way to explain GPT-3 is that it likes to finish your sentences for
    you. You provide it with a starting set of words, and it tries to figure out the
    most likely set of words that follow from your input. You can provide any string
    of words. It’s very flexible and can talk about anything you want, from product
    management to astrophysics.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 解释 GPT-3 的基本方式是它喜欢帮你完成句子。你提供一组起始词，它会尝试找出从你的输入中最可能跟随的词组。你可以提供任何一组词。它非常灵活，可以谈论任何你想要的话题，从产品管理到天体物理学。
- en: The set of words you provide is called a *prompt*, and the answer you get back
    from GPT-3 is called a *completion*.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 你提供的词组称为*提示*，而你从 GPT-3 得到的答案称为*完成*。
- en: 'Below is a simple example in the [GPT-3 Playground](https://platform.openai.com/playground?model=text-davinci-003).
    The non-green text is what I typed in as a prompt, and the green text is what
    GPT-3 returned as the completion:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是 [GPT-3 游乐场](https://platform.openai.com/playground?model=text-davinci-003)
    中的一个简单示例。非绿色文本是我输入的提示，绿色文本是 GPT-3 返回的完成：
- en: You can see that GPT-3 performs well on a simple completion like this. But it
    performs well even when the prompts get more complicated.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到，GPT-3 在像这样简单的完成上表现得很好。但是即使提示变得更加复杂，它也会表现得很好。
- en: 'You can, for example, prompt it to define product-market fit:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，你可以要求它定义产品市场匹配：
- en: That’s not bad! Since it can already answer product questions, this looks like
    it will be useful for our Lenny Chatbot out of the box.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 这还不错！因为它已经能够回答产品问题，所以看起来它对我们的莱尼聊天机器人来说将会很有用。
- en: You might assume that on the back end, GPT-3 has a compendium of concepts that
    it’s using to understand your sentence and generate the right completion. But
    in reality, it’s a probability engine—one that’s very good at, given a prompt,
    finding the words that are most likely to follow it.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会认为，在后台，GPT-3 有一个概念手册，它用来理解你的句子并生成正确的完成。但实际上，它是一个概率引擎——一个非常擅长的概率引擎，在给定提示的情况下，找到最有可能跟随它的词语。
- en: It can do this because it’s been [trained by analyzing](https://en.wikipedia.org/wiki/GPT-3#Training_and_capabilities)
    the statistical probabilities of sentences from basically the entire internet,
    so it has a lot of data to learn from. (All those Medium posts about product-market
    fit are good for something!)
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 它之所以能做到这一点，是因为它通过分析整个互联网上的句子的统计概率来进行训练，所以它有很多数据可以学习。（所有关于产品市场匹配的 Medium 文章都是有用的！）
- en: If you want to learn more about how this works from a technical perspective,
    I recommend checking out Andrej Karpathy’s [videos](https://www.youtube.com/@AndrejKarpathy).
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想从技术角度了解更多关于这个工作原理的信息，我建议查看安德烈·卡尔帕西的 [视频](https://www.youtube.com/@AndrejKarpathy)。
- en: Turning GPT-3 into a chatbot
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将 GPT-3 转变成聊天
- en: Now we have the bot answering questions, but how can we get it to actually chat
    with us?
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们让机器人回答问题了，但是我们如何让它真正与我们交流呢？
- en: Ideally we want it to get messages from the user and give responses back. And
    we want to give it a little bit of personality. It would be great if it sounded
    like Lenny himself—warm, friendly, and smart.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 理想情况下，我们希望它能接收用户的消息并做出回应。我们还希望给它一点个性。如果它听起来像莱尼本人一样——温暖、友好和聪明，那就太棒了。
- en: 'That’s pretty simple to do with GPT-3 as well. We can ask it to behave in this
    way in our prompt:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 GPT-3 做到这一点也相当简单。我们可以在提示中要求它以这种方式行事：
- en: As you can see, GPT-3 has read enough chatbot transcripts and product management
    posts to be able to start a conversation with us based on this kind of prompt.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所见，GPT-3 已经阅读了足够多的聊天机器人对话和产品管理文章，以便根据这种类型的提示开始与我们对话。
- en: 'We can continue our conversation with it by writing more of the transcript:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过写更多的记录来继续与它对话：
- en: 'Notice what we’re doing: every time we run the model, we have to feed it the
    entire transcript of what came before in the conversation. That guides its responses:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 注意我们正在做什么：每次运行模型时，我们都必须向其提供先前对话中的整个记录。这指导了它的回复：
- en: Success! It’s chatting with us at a high level about product management questions,
    like how to build a roadmap.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 成功！它正在与我们就产品管理等问题进行高水平的交流，比如如何制定路线图。
- en: But what if we want to get responses to questions that are harder to answer?
    For example, one of the biggest values of Lenny’s Newsletter is the amount of
    benchmark data he provides so that you can measure how well you’re doing against
    the best in the business.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 但是如果我们想要回答更难的问题呢？例如，莱尼的新闻通讯的最大价值之一是他提供了大量基准数据，这样你就可以衡量自己在业界的表现如何。
- en: If we go back through Lenny’s archive, we find in his post about [activation
    rates](https://www.lennysnewsletter.com/p/what-is-a-good-activation-rate) that
    the average one across different kinds of products is about 34% and the median
    is 25%.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们回顾一下 Lenny 的存档，我们会发现在他关于[激活率](https://www.lennysnewsletter.com/p/what-is-a-good-activation-rate)的文章中，不同类型产品的平均激活率约为
    34%，中位数为 25%。
- en: 'Let’s ask GPT-3 and see whether it knows this:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们问问 GPT-3，看看它是否知道这个：
- en: Not bad! It’s in the right ballpark, but its estimate for a good activation
    rate is a little lower than Lenny’s data says is the average. Ideally, since it’s
    a Lenny chatbot, we want it to return the benchmark he provides in his article.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 不错！它的答案差不多，但是它对良好激活率的估计略低于 Lenny 数据显示的平均值。理想情况下，由于它是 Lenny 的聊天机器人，我们希望它返回他在文章中提供的基准值。
- en: 'Once we start really probing the bot, this kind of problem only gets bigger.
    For example, if we ask it who Substack’s first publisher was—a [topic Lenny covered](https://www.lennysnewsletter.com/p/consumer-business-find-first-users)—it
    will say it was Andrew Sullivan:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们开始真正审视这个机器人，这种问题就会变得更加严重。例如，如果我们问它 Substack 的第一个出版商是谁——Lenny 在他的文章中提到的一个[话题](https://www.lennysnewsletter.com/p/consumer-business-find-first-users)——它会说是
    Andrew Sullivan：
- en: 'This answer sounds confident, but it is incorrect. (The correct answer is [Bill
    Bishop](https://sinocism.com/).) This isn’t an isolated incident. For example,
    if I ask, “Is it best for consumer startup ideas to come from founders who are
    trying to solve their own problems?” it replies:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 这个答案听起来很自信，但是是错误的。（正确答案是 [Bill Bishop](https://sinocism.com/)。）这不是一个孤立事件。例如，如果我问：“消费者初创企业的最佳创意是否应该来自试图解决自己问题的创始人？”它回答道：
- en: This is confident—and also wrong. As Lenny covered in his post on
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 这是自信的——也是错误的。正如 Lenny 在他的文章中所说的那样
- en: '[starting and scaling consumer businesses](https://www.lennysnewsletter.com/p/kickstarting-and-scaling-a-consumer)'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '[启动和扩展消费型企业](https://www.lennysnewsletter.com/p/kickstarting-and-scaling-a-consumer)'
- en: ', less than a third of consumer startup ideas came from founders solving their
    own problems. So it’s not “absolutely” a best practice.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: ，不到三分之一的消费者初创企业创意来自解决自己问题的创始人。所以这不是“绝对”是最佳实践。
- en: 'What’s going on here? There are two intertwined problems:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 发生了什么？有两个相互交织的问题：
- en: '**GPT-3 tends to “hallucinate.”** [Hallucination](https://en.wikipedia.org/wiki/Hallucination_(artificial_intelligence))
    is a technical term that refers to the model’s propensity to return nonsensical
    or false completions depending on what’s asked of it. The model is like a smart
    and overeager 6-year-old. It will try its best to give you a good answer even
    if it doesn’t know what it’s talking about. OpenAI and other foundational-model
    companies are actively working on this problem, but it’s still common. It’s compounded
    by the second problem.'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**GPT-3 倾向于“幻觉”**。[幻觉](https://en.wikipedia.org/wiki/Hallucination_(artificial_intelligence))是一个技术术语，指的是模型倾向于根据所询问的内容返回荒谬或错误的补全。该模型就像一个聪明而热心的六岁孩子。即使它不知道自己在说什么，也会尽力给出一个好答案。OpenAI
    和其他基础模型公司正在积极解决这个问题，但这仍然很常见。第二个问题加剧了这个问题。'
- en: '**GPT-3 might not have the right data.** GPT-3 has a knowledge cutoff—meaning
    all of the information it uses to produce its responses is frozen in 2021\. Also,
    much of Lenny’s writing is behind a paywall. That means that even though GPT-3
    has read the whole internet, it won’t have the material from his newsletter available
    to construct answers.'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**GPT-3 可能没有正确的数据。** GPT-3 有一个知识截止点——这意味着它用于生成响应的所有信息都在 2021 年冻结。此外，Lenny 的许多写作都在付费墙后面。这意味着即使
    GPT-3 已经阅读了整个互联网，它也无法使用他的新闻简报材料来构建答案。'
- en: So how could we construct a chatbot with GPT-3 that solves these problems? Ideally
    we want to feed GPT-3 the information it needs to answer questions spontaneously.
    That way it will have the right information available and be less likely to make
    things up.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 那么我们如何构建一个能解决这些问题的 GPT-3 聊天机器人呢？理想情况下，我们希望向 GPT-3 提供它回答问题所需的信息。这样它就会有正确的信息可用，并且更不可能胡言乱语。
- en: There’s an easy way to do that.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 有一个简单的方法可以做到这一点。
- en: Stuffing context into the prompt
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将上下文装入提示
- en: When I was in high school, I had a physics teacher who allowed open-book tests.
    He would allow you to bring a single index card to the test with any of the formulas
    that you thought you needed to answer the questions.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 当我上高中的时候，有一位物理老师允许开卷考试。他允许你带一张索引卡去考试，上面写上你认为需要回答问题所需的任何公式。
- en: Memorizing the formulas didn’t matter so much, but what did was using your reasoning
    abilities to turn the formulas into the correct answer.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 记住公式并不重要，重要的是使用您的推理能力将公式转化为正确的答案。
- en: People would come to the test with microscopic handwriting covering every inch
    of their notecard, which was a helpful strategy. The formulas gave you the context
    you needed to think through the answers to the questions on the tests, so the
    tests became less about your memory and more about how well you understood the
    topic. (I got a B in that class, so my understanding was pretty average.)
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 人们会带着满满一页微小字迹来参加考试，这是一个有用的策略。这些公式为您提供了您需要思考测试问题答案的上下文，因此测试变得不再是关于您的记忆，而是关于您对主题的理解有多好。（我在那门课上得了
    B，所以我的理解还算平均。）
- en: You can work with GPT-3 in a similar way. If, in your prompt, you include the
    equivalent of a notecard with context to help it answer the question, it will
    often get it right. (Its reasoning capabilities are better than mine.)
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以以类似的方式与 GPT-3 合作。如果在您的提示中包含等效于便条的内容以帮助其回答问题，它通常会回答正确。（它的推理能力比我的好。）
- en: Let’s go back to an example GPT-3 failed on earlier and see if we can correct
    it with this technique.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回到之前 GPT-3 失败的一个示例，看看我们是否可以用这种技术纠正它。
- en: 'As I mentioned above, in his post on consumer businesses, Lenny notes that
    less than a third of the founders got their idea from trying to solve their own
    problem:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我上面提到的，在他关于消费型企业的帖子中，Lenny 指出不到三分之一的创始人从尝试解决自己的问题中获得了想法：
- en: Last time, when we asked GPT-3 if it was best for consumer business founders
    to try to solve their own problem, it responded, “Absolutely!” Given what’s in
    Lenny’s article, that’s wrong.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 上次，当我们问 GPT-3 消费型企业创始人是否最好尝试解决自己的问题时，它回答说：“绝对是！”考虑到 Lenny 的文章内容，这是错误的。
- en: Let’s ask GPT-3 this question again—but with a little help. We’ll feed it the
    equivalent of a notecard that has written on it the section of Lenny’s article
    with the answer. Then we’ll see if it can get it right.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再次向 GPT-3 提出这个问题——但稍微帮助一下。我们将向其提供相当于一张便条的内容，上面写着 Lenny 文章中含有答案的部分。然后我们看看它是否能回答正确。
- en: 'To make this fair, we won’t give it just the text containing the answer. We’ll
    give it some of the surrounding text in the article as well to see how it does.
    Let’s see if it works:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 为了公平起见，我们不只是提供包含答案的文本。我们还会提供文章中的一些周围文本，以查看它的表现如何。让我们看看它是否有效：
- en: Success! Now it tells us that less than a third of founders were trying to solve
    their own problem. All we have to do is write all of Lenny’s posts on a notecard
    and feed it into the model along with any question we have, and it will answer
    based on what he’s written.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 成功！现在它告诉我们，不到三分之一的创始人试图解决自己的问题。我们只需把 Lenny 的所有文章写在一张便条上，与任何问题一起输入模型，它就会根据他所写的内容回答。
- en: 'But this introduces another problem: space limitations.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 但这带来了另一个问题：空间限制。
- en: The notecard analogy is apt because there’s limited space in the prompt—right
    now, about 4,000 tokens (each token is the equivalent of three-quarters of a word).
    So we can’t feed in Lenny’s entire archive on every question. We have to be choosy
    about what we select.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 便条的类比很贴切，因为提示中的空间有限——目前约为 4,000 个标记（每个标记相当于三分之四个单词）。因此，我们不能在每个问题上都提供 Lenny 的整个存档。我们必须谨慎选择。
- en: Let’s talk about how to solve this.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们谈谈如何解决这个问题。
- en: Embedding Lenny’s archive
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 嵌入 Lenny 的存档
- en: 'At this point we’re going to have to move out of manual interactions with GPT-3’s
    Playground and start using chunks of code that work directly with the GPT-3 API.
    The code we’re building is going to do the following tasks:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们将不得不退出与 GPT-3 Playground 的手动交互，开始使用直接与 GPT-3 API 一起工作的代码块。我们正在构建的代码将执行以下任务：
- en: We need to download and store Lenny’s archive in a way that makes it easily
    searchable for our bot.
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要以一种便于我们的机器人进行轻松搜索的方式下载和存储 Lenny 的存档。
- en: We need some code that will help find relevant chunks of text from the archive
    of Lenny’s content that we created in the previous step.
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要一些代码来帮助从我们在上一步创建的 Lenny 内容的存档中找到相关文本片段。
- en: When a user asks a question, we want to use the code from the last step to get
    the chunks of text that are most likely to answer the question, and put them into
    the prompt that we send to GPT-3.
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当用户提问时，我们希望使用上一步的代码来获取最有可能回答问题的文本片段，并将它们放入我们发送给 GPT-3 的提示中。
- en: We’ll display the resulting answer to the user.
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将向用户显示生成的答案。
- en: 'This is simple to do with a library called [GPT Index](https://gpt-index.readthedocs.io/en/latest/),
    an open-source library created by [Jerry Liu](https://twitter.com/jerryjliu0).
    It’s separate from OpenAI but built to help with tasks like this. Here’s how it
    works:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以通过一个名为[GPT Index](https://gpt-index.readthedocs.io/en/latest/)的库来完成，这是一个由[Jerry
    Liu](https://twitter.com/jerryjliu0)创建的开源库。它与 OpenAI 分开，但是构建它以帮助完成这样的任务。它的工作原理如下：
- en: Create an index of article chunks.
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一组文章片段的索引。
- en: Find the most relevant chunks.
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 找到最相关的片段。
- en: Ask our question to GPT-3 using the most relevant chunk.
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用最相关的片段向 GPT-3 提问。
- en: '*Note:* This is about to get a little bit more complicated and technical. If
    you’re interested in that, read on for an explanation.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '*注意：* 这将变得有点复杂和技术性。如果你对此感兴趣，请继续阅读解释。'
- en: You can access and run the code from this article in a [Google Colab file](https://colab.research.google.com/drive/1p2AablavDkSXly6H-XNLoSylMtoz7NDG?usp=sharing).
    Colab is a cloud-based programming environment that will let you run everything
    from your browser. (If you have questions about any of this, reach out to me on
    [Twitter](https://www.twitter.com/danshipper).)
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在[Google Colab 文件](https://colab.research.google.com/drive/1p2AablavDkSXly6H-XNLoSylMtoz7NDG?usp=sharing)中访问并运行本文中的代码。Colab
    是一个基于云的编程环境，让您可以从浏览器中运行所有内容。（如果您对此有任何疑问，请在[Twitter](https://www.twitter.com/danshipper)上联系我。）
- en: If you’re not interested in the technical details, skip to the end to try out
    the chatbot for yourself.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您对技术细节不感兴趣，请跳到最后尝试聊天机器人。
- en: Still here? Great. Let’s start with index construction.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 仍然在这里吗？太好了。让我们从构建索引开始。
- en: Constructing our index
  id: totrans-110
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 构建我们的索引
- en: 'The first thing we need to do is construct our index. You can think of an index
    as a database: it stores a collection of pieces of text in a way that makes them
    easily searchable.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要做的第一件事是构建我们的索引。你可以把索引想象成一个数据库：它以一种使它们易于搜索的方式存储一系列文本片段。
- en: First we collect Lenny’s newsletter archive into a folder. Then we ask GPT Index
    to take all of the files in the folder and break each one into small, sequential
    pieces. Then we store those pieces in a searchable format.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将 Lenny 的新闻通讯存档收集到一个文件夹中。然后我们要求 GPT Index 获取文件夹中的所有文件，并将每个文件分解成小的、连续的片段。然后我们以可搜索的格式存储这些片段。
- en: 'The code looks like this:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 代码看起来像这样：
- en: When we run this function, we’ll have created a file called index.json that
    contains chunks of Lenny’s articles converted into a searchable format. These
    are called
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们运行这个函数时，我们将创建一个名为 index.json 的文件，其中包含将 Lenny 的文章转换为可搜索格式的片段。这些被称为
- en: '[embeddings](https://platform.openai.com/docs/guides/embeddings)'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '[嵌入](https://platform.openai.com/docs/guides/embeddings)'
- en: —a condensed mathematical representation of each chunk of text. Just like latitude
    and longitude can help you tell how close two cities are on a map, embeddings
    do the same kind of thing for text chunks. If you want to know if two pieces of
    text are similar, calculate the embeddings for them and compare. Text chunks with
    embeddings that are “closer” together are similar.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: —每个文本片段的简化数学表示。就像经度和纬度可以帮助您判断地图上两个城市之间有多近一样，嵌入也可以为文本片段做同样的事情。如果你想知道两个文本片段是否相似，就计算它们的嵌入并进行比较。嵌入“更接近”的文本片段是相似的。
- en: Embeddings are handy because when a user asks a question, they’ll make it easy
    to search Lenny’s archive and find articles that are most likely to answer our
    question.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 嵌入很方便，因为当用户提问时，它们将使搜索 Lenny 的存档并找到最有可能回答我们问题的文章变得容易。
- en: With that in mind, let’s run the code and see what happens.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这个想法，让我们运行代码，看看会发生什么。
- en: Success! The Lenny’s archive is fully indexed, and we can query it to find relevant
    chunks of documents and use those chunks to answer our questions. (Be careful
    if you do this with big documents, as embeddings cost $0.0004 for every 1,000
    tokens.)Asking our question
  id: totrans-119
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 成功！ Lenny 的存档已完全索引，我们可以查询它以找到相关的文档片段，并使用这些片段回答我们的问题。（如果您用大文档做这个，要小心，因为每 1,000
    个标记的嵌入成本是 0.0004 美元。）问我们的问题
- en: 'To query the index we created in the last section, all we have to do is paste
    a question into GPT Index. It will then:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 要查询我们在上一节中创建的索引，我们所要做的就是将一个问题粘贴到 GPT Index 中。然后它将：
- en: Find the chunks of our index that are most relevant to the question.
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 找到与我们问题最相关的索引片段。
- en: Combine those chunks and our question into a prompt that it sends to GPT-3.
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将这些片段和我们的问题合并成一个提示，然后发送给 GPT-3。
- en: Print the output.
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 打印输出。
- en: 'Here’s what the code looks like:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 这是代码的样子：
- en: 'If I ask it, “What is good retention for a consumer social product?” it says:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我问它，“消费者社交产品的良好留存率是多少？”它会说：
- en: “25% is good.”
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: “25% 是好的。”
- en: 'If I query it, “Is it best for consumer startup ideas to come from founders
    who are trying to solve their own problem?” it returns the right answer:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我查询：“消费者初创公司的最佳创意是来自试图解决自己问题的创始人吗？”它会返回正确的答案：
- en: '*“Based on the research, it appears that it is a good idea for consumer startup
    ideas to come from founders who are trying to solve their own problem, as this
    was the strategy used by around 30% of the most successful consumer companies. *'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '*“根据研究，似乎消费者初创公司的最佳创意来自试图解决自己问题的创始人，因为这是约 30% 最成功的消费者公司使用的策略。”*'
- en: '*However, it is not necessarily the best strategy, as other strategies such
    as paying attention to curiosity, what’s already working, and paradigm shifts
    were also used by a significant number of successful companies.”*'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '*然而，并非一定是最佳策略，因为其他策略，如关注好奇心、已经奏效的事物和范式转变，也被许多成功公司采用过。”*'
- en: We now have an end-to-end solution to turn questions into answers that are based
    on Lenny’s archive. And it only took a few lines of code!
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在有了一个端到端的解决方案，可以将问题转化为基于 Lenny 存档的答案。而且这只需要几行代码！
- en: 'If you want to see the results in action, check out the bot:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想看到结果，可以查看这个机器人：
- en: You can also access the
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以访问
- en: '[full source code](https://colab.research.google.com/drive/1p2AablavDkSXly6H-XNLoSylMtoz7NDG#scrollTo=4gHdfdtsSGEW)'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '[完整源代码](https://colab.research.google.com/drive/1p2AablavDkSXly6H-XNLoSylMtoz7NDG#scrollTo=4gHdfdtsSGEW)'
- en: for this article in this Colab notebook. More details exclusively for Every
    subscribers are at the bottom of this post.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 为了这篇文章在此 Colab 笔记本中。更多的细节专门为每位订阅者在本文的底部。
- en: What all of this means
  id: totrans-135
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 所有这一切意味着什么
- en: This is just the beginning. The horizon of possibility is shifting almost every
    day with these technologies. What’s hard to do today will be easy in a matter
    of months.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 这只是一个开始。随着这些技术的发展，可能性的地平线几乎每天都在变化。今天难以实现的事情将在几个月内变得容易。
- en: Every newsletter, book, blog, and podcast that’s used as evergreen reference
    information by its audience can now be repackaged as a chatbot.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 每个新闻通讯、书籍、博客和播客，作为受众永久参考信息使用，现在都可以重新打包成一个聊天机器人。
- en: This is great for audiences because it means that any time you want to know
    what Lenny (or any other creator) says about a topic, you’re not going to have
    to sort through an archive of articles or podcast episodes in order to get their
    answer to your question. Instead, you’ll just be able to use Lenny’s chatbot to
    get his answer instantly—and then maybe later read the article in full if you
    want more details.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 这对观众来说是很棒的，因为这意味着无论何时您想知道 Lenny（或任何其他创作者）对某个话题的看法，您都不必整理一堆文章或播客集数的存档，以获取他们对您问题的答案。相反，您只需使用
    Lenny 的聊天机器人即可立即获得他的答案，然后如果您想要更多细节，可以稍后阅读完整文章。
- en: This is also great for content creators. They now get the ability to monetize
    the content they’ve already created in new ways, and lessen the amount of repetitive
    questions they have to answer. This will (hopefully) give them more time and money
    to create great content.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 这对内容创作者也是好事。他们现在有能力以新的方式变现他们已经创作的内容，并减少他们需要回答的重复问题的数量。这将（希望）给他们更多的时间和金钱去创造优秀的内容。
- en: A new class of content creators will learn to create compelling chatbot experiences
    that combine their personality and worldview for their niche audience in the same
    way that some creators learned to create compelling YouTube videos, newsletter
    articles, or TikTok clips.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 一类新的内容创作者将学会创建引人注目的聊天机器人体验，将其个性和世界观与其特定受众结合起来，就像某些创作者学会创建引人注目的 YouTube 视频、通讯文章或
    TikTok 短片一样。
- en: If you use Lenny’s chatbot or follow the code samples, you’ll see that it’s
    promising but not yet perfect. There are tremendous returns available to the individuals
    or groups who learn to make these types of experiences incredible for users.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您使用 Lenny 的聊天机器人或者关注代码示例，您会发现它很有前景，但还不完美。对于那些学会如何让这些类型的体验对用户来说令人难以置信的个人或团体来说，将获得巨大的回报。
- en: I hope this inspires you to embark on that journey.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 我希望这能激励您踏上这段旅程。
- en: ''
  id: totrans-143
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '* * *'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: "\uFEFF\uFEFFMore details for Every subscribers"
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: "\uFEFF\uFEFF每位订阅者的更多细节"
- en: 'In this section, I’ll give an update for Every paying subscribers on:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分中，我将给每位付费订阅者更新以下内容：
- en: How launch day went
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 发布日的情况
- en: Server-side code samples
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 服务器端代码示例
- en: Client-side code samples including React code and CSS
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包括 React 代码和 CSS 的客户端代码示例
- en: Let’s dive in!
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧！
- en: '[Learn more](/)'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '[了解更多](/)'
- en: This post is for
  id: totrans-152
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 这篇文章是
- en: paying subscribers
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 付费订阅者
- en: '[Subscribe →](/subscribe?publication=chain-of-thought)'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '[订阅 →](/subscribe?publication=chain-of-thought)'
- en: Or, [login](/login).
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，[登录](/login)。
