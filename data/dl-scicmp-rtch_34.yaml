- en: 27  The Fast Fourier Transform (FFT)
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 27 快速傅里叶变换 (FFT)
- en: 原文：[https://skeydan.github.io/Deep-Learning-and-Scientific-Computing-with-R-torch/fourier_transform_fft.html](https://skeydan.github.io/Deep-Learning-and-Scientific-Computing-with-R-torch/fourier_transform_fft.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://skeydan.github.io/Deep-Learning-and-Scientific-Computing-with-R-torch/fourier_transform_fft.html](https://skeydan.github.io/Deep-Learning-and-Scientific-Computing-with-R-torch/fourier_transform_fft.html)
- en: In the last chapter, we saw that to code the Discrete Fourier Transform (DFT),
    we need just a few lines of code – notwithstanding the depth and richness of the
    theory. Surprisingly, it’s not that different for the FFT, the famous *Fast Fourier
    Transform*.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们看到要编写离散傅里叶变换 (DFT) 的代码，只需要几行代码——尽管理论深度和丰富性。令人惊讶的是，FFT（著名的快速傅里叶变换）并没有那么不同。
- en: 'In this chapter, we’ll first look at what the FFT (more precisely: its “most
    classic” version) actually does, building on the understanding we gained in the
    previous chapter.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们首先将探讨快速傅里叶变换（更确切地说：其“最经典”版本）实际上做什么，基于我们在上一章中获得的理解。
- en: 'Then, we’ll code up a few different implementations, and time their performance.
    None of the hand-coded implementations will, of course, be able to outperform
    `torch_fft_fft()`, `torch` delegating to highly optimized C++ code. But our results
    will be interesting in many ways: We’ll see that in practice, it is not just the
    algorithm per se that matters. The programming language, too, plays an essential
    role, in the sense that its properties substantially affect feasibility of improvements.
    Put differently, there is an *interaction* between algorithmic and language-inherent
    properties that will decide on the final outcome.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将编写几个不同的实现，并测量它们的性能。当然，所有手动编写的实现都无法超越 `torch_fft_fft()`，`torch` 将其委托给高度优化的
    C++ 代码。但我们的结果在许多方面都很有趣：我们会看到在实践中，不仅仅是算法本身很重要。编程语言也起着至关重要的作用，其属性在很大程度上影响着改进的可行性。换句话说，算法属性和语言固有属性之间存在一种*交互作用*，这将决定最终结果。
- en: First though, in this book’s spirit of aiming to shed a light on the ideas and
    concepts involved, we would like to understand what is involved in the Fast Fourier
    Transform.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，本着本书旨在阐明涉及的思想和概念的精神，我们希望了解快速傅里叶变换中涉及的内容。
- en: 27.1 Some terminology
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 27.1 一些术语
- en: Let me make clear right at the outset that, as compared to the DFT, the FFT
    is *not another transform*. Its output is just the same as that of the DFT. With
    the FFT, it’s all about the “fast”. Also, there is no “one” FFT. Instead, there
    are different families; and in each family, there are various sub-types.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 让我一开始就明确指出，与离散傅里叶变换 (DFT) 相比，FFT 并不是另一种变换。它的输出与 DFT 的输出完全相同。使用 FFT，关键在于“快速”。此外，没有“一个”FFT。相反，有不同系列；在每个系列中，都有各种子类型。
- en: 'Here, I’m focusing on the “classic among the classics”: the one that goes by
    *radix-2 decimation-in-time (DIT)*. Here “radix-2” refers to an implementation
    detail; it indicates that the algorithm will require input size to equal a power
    of two. “Decimation in time”, on the other hand, relates to the overall strategy
    being employed: divide-and-conquer. The input is recursively split into halves,
    and partial results are combined in a clever way. (Just as an aside, there is
    a very similar algorithm called “decimation in frequency”. There, it is the frequency
    domain where recursive splitting occurs.)'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，我专注于“经典中的经典”：即采用 *radix-2 decimation-in-time (DIT)* 的那个。这里“radix-2”指的是一个实现细节；它表示算法将需要输入大小等于2的幂。另一方面，“decimation
    in time”则与所采用的总体策略相关：分而治之。输入被递归地分成两半，并且以巧妙的方式组合部分结果。（顺便提一下，还有一个非常相似的算法称为“decimation
    in frequency”。在那里，递归分割发生在频率域。）
- en: Now, we discuss how this works. You’ll see that once we’ve worked out clearly
    what we want to do, a (naive) implementation does not require more code than the
    straightforward DFT from the last chapter. And please be assured that although
    this section has many equations, each and every manipulation will be explained
    in words.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们讨论它是如何工作的。你会看到，一旦我们清楚地确定了我们要做什么，一个（天真）的实现所需的代码并不比上一章中直接使用的 DFT 多。而且请放心，尽管这一节有很多方程式，但每个操作都会用文字解释。
- en: 27.2 Radix-2 decimation-in-time(DIT) walkthrough
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 27.2 Radix-2 decimation-in-time(DIT) 演示
- en: The simplifications resulting from *decimation in time* can be presented as
    a two-step logic. Reflecting that view, and re-using (with different semantics)
    terminology employed in the convolution chapter, I could call them “input-view
    phase” and “output-view phase”. However, these are not phases in a temporal sense,
    and more importantly – in a software-focused book – we’ll see that as ported to
    code, their respective impacts differ a lot. Therefore, I’ll name the upcoming
    two sections in ways reflecting importance instead. (I’ll still make clear what
    I mean by input and output views here, though.)
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 由 *时间抽取* 导致的简化可以表示为两步逻辑。反映这种观点，并重新使用（具有不同语义）在卷积章节中使用的术语，我可以称它们为“输入视图阶段”和“输出视图阶段”。然而，这些都不是时间意义上的阶段，更重要的是——在以软件为重点的书中——我们将看到，在转换为代码时，它们的影响差异很大。因此，我将用反映重要性的方式命名接下来的两个部分。（我仍然会在这里清楚地说明输入和输出视图的含义。）
- en: '27.2.1 The main idea: Recursive split'
  id: totrans-12
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 27.2.1 主要思想：递归拆分
- en: As we would expect for a divide-and-conquer algorithm, the main and most impactful
    observation is that if the input is split up recursively, the problem can be divided
    into sub-problems that get increasingly easier to solve – provided we know how
    to combine the partial results into a final solution.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所期望的，对于分而治之算法，主要且最有影响的观察是，如果输入被递归地拆分，问题可以被分解为越来越容易解决的子问题——前提是我们知道如何将部分结果组合成最终解决方案。
- en: 'Before we start, let me recall some notation, and make a slight modification
    that will turn out convenient. In the previous chapter, with \(N\) the size of
    the input (equivalently, the number of resulting frequency coefficients), and
    \(k\) (ranging from zero to \(N-1\)) referencing the vector in question, the DFT
    basis vectors were defined like so:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始之前，让我回顾一下一些符号，并进行一个将证明方便的微小修改。在前一章中，当 \(N\) 是输入的大小（等价于结果的频率系数数量）时，\(k\)（从零到
    \(N-1\)）指的是相关的向量，DFT 基向量被定义为如下：
- en: \[ \mathbf{w}^{kn}_N = e^{i\frac{2 \pi}{N}k n} \]
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathbf{w}^{kn}_N = e^{i\frac{2 \pi}{N}k n} \]
- en: 'Then, the \(k\)th frequency coefficient was obtained by computing the inner
    product between \(\mathbf{w}^{kn}_N\) and the input, \(\mathbf{x}_n\):'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，第 \(k\) 个频率系数是通过计算 \(\mathbf{w}^{kn}_N\) 和输入 \(\mathbf{x}_n\) 的内积得到的：
- en: \[ \begin{aligned} X_k &= \langle \mathbf{w}^{kn}_N, \mathbf{x}_n \rangle \\
    &= \sum_{n=0}^{N-1} x[n] \ w^{-nk}_N\\ \end{aligned} \]
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \begin{aligned} X_k &= \langle \mathbf{w}^{kn}_N, \mathbf{x}_n \rangle \\
    &= \sum_{n=0}^{N-1} x[n] \ w^{-nk}_N\\ \end{aligned} \]
- en: 'In this chapter, we will be working with the complex conjugates of the basis
    vectors throughout, since it’s those that actually get (element-wise) multiplied
    with the input vector. For convenience, we thus slightly change notation, and
    let \(w^{kn}_N\) refer to the conjugated complex exponential[¹](#fn1):'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将始终使用基向量的复共轭，因为正是这些向量与输入向量（逐元素）相乘。为了方便起见，我们因此稍微改变了符号，并让 \(w^{kn}_N\)
    指代共轭复指数[¹](#fn1)：
- en: \[ w^{kn}_N = e^{-i\frac{2 \pi}{N}k n} \tag{27.1}\]
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: \[ w^{kn}_N = e^{-i\frac{2 \pi}{N}k n} \tag{27.1}\]
- en: Then, abstracting over \(n\), we also have \[ w^k_N = e^{-i\frac{2 \pi}{N}k}
    \tag{27.2}\]
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，抽象地考虑 \(n\)，我们也有 \[ w^k_N = e^{-i\frac{2 \pi}{N}k} \tag{27.2}\]
- en: 'That said, we state again what we want to compute: the frequency coefficients
    \(X_k\).'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 也就是说，我们再次声明我们想要计算的内容：频率系数 \(X_k\)。
- en: \[ \begin{aligned} X_k &= \sum_{n=0}^{N-1} x[n] \ w^{nk}_N\\ \end{aligned} \]
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \begin{aligned} X_k &= \sum_{n=0}^{N-1} x[n] \ w^{nk}_N\\ \end{aligned} \]
- en: Now comes what I was thinking to refer to as the “input view”. We take the input
    sequence, and divide up the computation into two parts. One will deal with the
    even, the other, with the odd indices of the signal. So expressed, the sums only
    go up to \(N/2 - 1\).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候提到我想要称之为“输入视图”的内容了。我们取输入序列，并将计算分为两部分。一部分将处理信号的偶数索引，另一部分将处理奇数索引。这样表达，求和只进行到
    \(N/2 - 1\)。
- en: \[ \begin{aligned} X_k &= \sum_{n=0}^{(N/2-1)} x[2n] \ w^{2nk}_N + \sum_{n=0}^{N/2-1}
    x[2n+1] \ w^{(2n+1)k}_N \\ \end{aligned} \tag{27.3}\]
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \begin{aligned} X_k &= \sum_{n=0}^{(N/2-1)} x[2n] \ w^{2nk}_N + \sum_{n=0}^{N/2-1}
    x[2n+1] \ w^{(2n+1)k}_N \\ \end{aligned} \tag{27.3}\]
- en: 'Now, that second sum can be rewritten, splitting up the \(w^{2nk+k}_N\) into
    two factors:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，第二个求和可以重写，将 \(w^{2nk+k}_N\) 拆分为两个因子：
- en: \[ \sum_{n=0}^{N/2-1} x[2n+1] \ w^{2nk+k}_N = \sum_{n=0}^{N/2-1} x[2n+1] \ w^{2nk}_N
    w^{k}_N \]
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \sum_{n=0}^{N/2-1} x[2n+1] \ w^{2nk+k}_N = \sum_{n=0}^{N/2-1} x[2n+1] \ w^{2nk}_N
    w^{k}_N \]
- en: The second factor is exactly the \(w^{k}_N\) we were introducing above. Since
    it does not depend on \(n\), we can move it out of the sum. This yields
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个因子正是我们上面介绍的 \(w^{k}_N\)。由于它不依赖于 \(n\)，我们可以将其移出求和符号。这导致
- en: \[ \begin{aligned} X_k &= \sum_{n=0}^{(N/2-1)} x[2n] \ w^{2nk}_N + w^k_N \sum_{n=0}^{N/2-1}
    x[2n+1] \ w^{2nk}_N \\ \end{aligned} \]
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \begin{aligned} X_k &= \sum_{n=0}^{(N/2-1)} x[2n] \ w^{2nk}_N + w^k_N \sum_{n=0}^{N/2-1}
    x[2n+1] \ w^{2nk}_N \\ \end{aligned} \]
- en: 'Now the exponential factor is the same in both sums. Let’s inspect it a bit
    more closely. It is the multiplication factor of a DFT of size \(N\), at (frequency-by-time)
    position \(2nk\). If we write this out, we see that we can move the factor \(2\)
    from the numerator to the denominator of the fraction:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，两个求和中指数因子相同。让我们更仔细地检查一下。它是大小为 \(N\) 的离散傅里叶变换（DFT）的乘数因子，在（频率-时间）位置 \(2nk\)。如果我们展开这个表达式，我们会看到我们可以将因子
    \(2\) 从分数的分子移动到分母：
- en: \[ w^{2nk}_N = e^{-i\frac{2 \pi}{N}2nk} = e^{-i\frac{2 \pi}{N/2}nk} = w^{nk}_{N/2}
    \]
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: \[ w^{2nk}_N = e^{-i\frac{2 \pi}{N}2nk} = e^{-i\frac{2 \pi}{N/2}nk} = w^{nk}_{N/2}
    \]
- en: 'Why does this matter? The result is actually the corresponding basis vector
    of a DFT of size \(N/2\), at position \(nk\). Which means that now, we are actually
    computing a DFT of *half the size* – or rather, two such DFTs:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 这有什么意义呢？结果是大小为 \(N/2\) 的离散傅里叶变换（DFT）的对应基向量，在位置 \(nk\)。这意味着现在，我们实际上正在计算大小减半的
    DFT – 或者更确切地说，两个这样的 DFT：
- en: \[ X_k = \sum_{n=0}^{(N/2-1)} x[2n] \ w^{nk}_{N/2} + w^k_N \ \sum_{n=0}^{N/2-1}
    x[2n+1] \ w^{nk}_{N/2} \\ \tag{27.4}\]
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: \[ X_k = \sum_{n=0}^{(N/2-1)} x[2n] \ w^{nk}_{N/2} + w^k_N \ \sum_{n=0}^{N/2-1}
    x[2n+1] \ w^{nk}_{N/2} \\ \tag{27.4}\]
- en: 'Let’s write this in more readable form:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们以更易读的形式写出：
- en: \[ X_k = X^{even}_k + w^k_N \ X^{odd}_k \tag{27.5}\]
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: \[ X_k = X^{even}_k + w^k_N \ X^{odd}_k \tag{27.5}\]
- en: Now, you probably see where this is going. What we’ve done once – halve the
    size of the computation – we can do again … and again. It is this recursive halving
    that allows the FFT to obtain it famous reduction in computational cost.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你可能已经看到了这个趋势。我们曾经做过的 – 将计算大小减半 – 我们可以再次做……并且可以一直这样做。正是这种递归的减半使得快速傅里叶变换（FFT）能够获得它著名的计算成本降低。
- en: This is the main ingredient of the magic, but it is not quite everything yet.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这是魔法的主要成分，但还不是全部。
- en: 27.2.2 One further simplification
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 27.2.2 进一步简化
- en: There is one additional simplification we can make. Compared to the first, it
    is of lesser significance, at least as far as computational performance is concerned.
    However, it definitely matters from an aesthetics point of view.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以做出的一项额外简化。与第一个相比，它在计算性能方面的重要性较小，至少从美学角度来看。然而，它确实很重要。
- en: Did you notice something strange in our final formula? We are computing DFTs
    of size \(N/2\), but still, the factor \(w^k_N\) appears! This isn’t a problem,
    but it is not “nice”, either. Fortunately, for those who mind, the “inconsequence”
    can be eliminated.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 你有没有注意到我们最终公式中的奇怪之处？我们正在计算大小为 \(N/2\) 的 DFT，但仍然，因子 \(w^k_N\) 出现了！这不是问题，但也不是“好”的。幸运的是，对于那些在意的人来说，“无关紧要”的影响可以消除。
- en: What follows is what I was tempted to name the “output-side view”. That’s because
    now, we roll up things from the end, starting from the computation’s output. We
    take the set of Fourier coefficients \(X_k\), and independently consider the first
    and the second half. Note how here, like in the input-centric view, we apply a
    split-in-two strategy; just this time, the halving is done in a different way.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的是我差点给它命名为“输出端视图”的内容。这是因为现在，我们从计算的输出开始，从后往前整理事情。我们取傅里叶系数集合 \(X_k\)，并独立考虑前半部分和后半部分。注意，在这里，就像在以输入为中心的视图中一样，我们应用了分割成两半的策略；只是这次，减半的方式不同。
- en: Looking at both halves, we notice that both have their dedicated subsets of
    multiplication factors \(w^k_N\), one with \(k\) ranging from \(0\) to \(N/2-1\),
    the other, from \(N/2\) to \(N-1\). For the first, this means we can change the
    upper limit in the sum, yielding
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 观察这两半部分，我们注意到它们各自都有它们专用的乘数因子 \(w^k_N\) 的子集，一个 \(k\) 的范围从 \(0\) 到 \(N/2-1\)，另一个从
    \(N/2\) 到 \(N-1\)。对于前者，这意味着我们可以改变求和的上限，得到
- en: \[ X^{upper}_k = X^{even}_k + w^k_N \ X^{odd}_k \ , \ \ k = 0 ... N/2-1 \]
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: \[ X^{upper}_k = X^{even}_k + w^k_N \ X^{odd}_k \ , \ \ k = 0 ... N/2-1 \]
- en: For the second, we can achieve the desired result by summing over the same range,
    but adding \(N/2\) to \(k\) everywhere.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 对于第二个，我们可以通过在相同的范围内求和，但将 \(N/2\) 加到 \(k\) 的每个地方来达到预期的结果。
- en: \[ X^{lower}_{k+N/2} = \sum_{n=0}^{N/2-1} x[2n] \ w^{n (k+N/2)}_{N/2} + w^{k+N/2}_N
    \ \sum_{n=0}^{N/2-1} x[2n + 1] \ w^{n (k+ N/2)}_{N/2} \\ \]
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: \[ X^{lower}_{k+N/2} = \sum_{n=0}^{N/2-1} x[2n] \ w^{n (k+N/2)}_{N/2} + w^{k+N/2}_N
    \ \sum_{n=0}^{N/2-1} x[2n + 1] \ w^{n (k+ N/2)}_{N/2} \\ \]
- en: 'Now, in the first of the sums that make up \(X^{lower}\), the exponential can
    be factored, and we see that the factor containing the \(N/2\) evaluates to \(1\)
    (and thus, disappears):'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，在构成 \(X^{lower}\) 的第一个求和中，指数可以分解，我们看到包含 \(N/2\) 的因子评估为 \(1\)（因此，消失）：
- en: \[ \begin{aligned} w^{n(k+N/2)}_{N/2}&= e^{-i\frac{2 \pi}{N/2} n (k + N/2)}
    \\ &= e^{-i\frac{2 \pi}{N/2}n k} * e^{-i\frac{2 \pi}{N/2}n (N/2)} \\ &= e^{-i\frac{2
    \pi}{N/2}n k} * e^{-i\frac{2 \pi}{N/2}(N/2)} \\ &= e^{-i\frac{2 \pi}{N/2}n k}
    * 1 \end{aligned} \]
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \begin{aligned} w^{n(k+N/2)}_{N/2}&= e^{-i\frac{2 \pi}{N/2} n (k + N/2)}
    \\ &= e^{-i\frac{2 \pi}{N/2}n k} * e^{-i\frac{2 \pi}{N/2}n (N/2)} \\ &= e^{-i\frac{2
    \pi}{N/2}n k} * e^{-i\frac{2 \pi}{N/2}(N/2)} \\ &= e^{-i\frac{2 \pi}{N/2}n k}
    * 1 \end{aligned} \]
- en: 'As a result, the first of the sums now looks like this:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，第一个和中现在看起来是这样的：
- en: \[ X^{lower}_{k+N/2} = \sum_{n=0}^{N/2-1} x[2n] \ w^{n k}_{N/2} + [...] \]
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: \[ X^{lower}_{k+N/2} = \sum_{n=0}^{N/2-1} x[2n] \ w^{n k}_{N/2} + [...] \]
- en: 'The same thing can be done in the second sum:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 同样的事情也可以在第二个和中做：
- en: \[ X^{lower}_{k+N/2} = [...] + w^{k+N/2}_N \ \sum_{n=0}^{N/2-1} x[2n + 1] \
    w^{n k}_{N/2} \\ \]
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: \[ X^{lower}_{k+N/2} = [...] + w^{k+N/2}_N \ \sum_{n=0}^{N/2-1} x[2n + 1] \
    w^{n k}_{N/2} \\ \]
- en: 'Now there’s just one last inconvenient index of \(k + N/2\) remaining. A calculation
    similar to that above shows we can replace it by a minus sign:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 现在只剩下最后一个不便的索引 \(k + N/2\)。一个类似于上面的计算表明我们可以用减号来替换它：
- en: \[ \begin{aligned} w^{k+N/2}_N&= e^{-i\frac{2 \pi}{N} (k + N/2)} \\ &= e^{-i\frac{2
    \pi}{N} k} * e^{-i\frac{2 \pi}{N} N/2}\\ &= e^{-i\frac{2 \pi}{N} k} * e^{-i \pi}\\
    &= e^{-i\frac{2 \pi}{N} k} * (-1)\\ \end{aligned} \]
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \begin{aligned} w^{k+N/2}_N&= e^{-i\frac{2 \pi}{N} (k + N/2)} \\ &= e^{-i\frac{2
    \pi}{N} k} * e^{-i\frac{2 \pi}{N} N/2}\\ &= e^{-i\frac{2 \pi}{N} k} * e^{-i \pi}\\
    &= e^{-i\frac{2 \pi}{N} k} * (-1)\\ \end{aligned} \]
- en: 'In consequence, the complete second part can be written like this:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，完整的第二部分可以写成这样：
- en: \[ X^{lower}_{k+N/2} = \sum_{n=0}^{N/2-1} x[2n] \ w^{n k}_{N/2} - w^k_N \ \sum_{n=0}^{N/2-1}
    x[2n + 1] \ w^{n k}_{N/2} \]
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: \[ X^{lower}_{k+N/2} = \sum_{n=0}^{N/2-1} x[2n] \ w^{n k}_{N/2} - w^k_N \ \sum_{n=0}^{N/2-1}
    x[2n + 1] \ w^{n k}_{N/2} \]
- en: 'And now, the second half looks nearly like the first one, just with a change
    in sign. Here, then, is the final algorithm:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，第二部分看起来几乎和第一部分一样，只是符号发生了变化。因此，下面是最终的算法：
- en: \[ \begin{aligned} & X^{upper}_k = X^{even}_k + w^k_N \ X^{odd}_k \ , \ \ k
    = 0 ... N/2-1 \\ & X^{lower}_{k+N/2} = X^{even}_k - w^k_N \ X^{odd}_k \ , \ \
    k = 0 ... N/2-1 \end{aligned} \tag{27.6}\]
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \begin{aligned} & X^{upper}_k = X^{even}_k + w^k_N \ X^{odd}_k \ , \ \ k
    = 0 ... N/2-1 \\ & X^{lower}_{k+N/2} = X^{even}_k - w^k_N \ X^{odd}_k \ , \ \
    k = 0 ... N/2-1 \end{aligned} \tag{27.6} \]
- en: Owed to a popular form of visualization, this representation is often referred
    to as the “butterfly”. If you’re curious, you won’t have problems finding related
    diagrams on the net. Personally, I don’t find them very helpful, which is why
    I’m not reproducing them here.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 由于一种流行的可视化形式，这种表示通常被称为“蝴蝶”。如果你好奇，你不会在网上找到相关图表有困难。我个人觉得它们不太有帮助，这就是为什么我没有在这里重新制作它们。
- en: In conclusion, we’ve now arrived at a rule that tells us how to simplify an
    FFT of size \(N\) by replacing it with an FFT of size \(N/2\). The complete algorithm
    then consists in recursive application of that rule.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，我们现在已经得到了一个规则，它告诉我们如何通过将其替换为大小为 \(N/2\) 的 FFT 来简化大小为 \(N\) 的 FFT。完整的算法包括对该规则的递归应用。
- en: We’re ready to start thinking about how to implement this.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以开始思考如何实现这一点。
- en: 27.3 FFT as matrix factorization
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 27.3 FFT 作为矩阵分解
- en: 'Below, we’ll explore different ways of coding the FFT. In two of them, you’ll
    directly recognize the rule [Equation 27.6](#eq-fft-6). The third is different,
    though. It makes direct use of the fact that the DFT matrix \(\mathbf{W}_N\) can
    be factored into three sparse matrices, each materializing one of the three stages
    inherent in the rule: split up the input into even and odd indices; compute the
    two half-sized FFTs; recombine the results.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 下面，我们将探讨不同的编码 FFT 的方法。在其中的两种方法中，你将直接识别出规则[方程式27.6](#eq-fft-6)。第三种是不同的。它直接利用了事实，即
    DFT 矩阵 \(\mathbf{W}_N\) 可以分解为三个稀疏矩阵，每个矩阵代表了规则中固有的三个阶段之一：将输入拆分为偶数和奇数索引；计算两个半大小
    FFT；重新组合结果。
- en: 'For example, take \(\mathbf{W}_4\), the matrix we analyzed in the previous
    chapter:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，考虑 \(\mathbf{W}_4\)，这是我们上一章分析的矩阵：
- en: \[ \mathbf{W}_4 = \begin{bmatrix} 1 & 1 & 1 & 1\\ 1 & -i & -1 & i\\ 1 & -1 &
    1 & -1\\ 1 & i & -1 & -i\\ \end{bmatrix} \]
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathbf{W}_4 = \begin{bmatrix} 1 & 1 & 1 & 1\\ 1 & -i & -1 & i\\ 1 & -1 &
    1 & -1\\ 1 & i & -1 & -i\\ \end{bmatrix} \]
- en: 'This can be factorized into three matrices like so:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以分解为三个矩阵，如下所示：
- en: \[ \begin{aligned} \mathbf{W}_4 &= \begin{bmatrix} 1 & 1 & 1 & 1\\ 1 & -i &
    -1 & i\\ 1 & -1 & 1 & -1\\ 1 & i & -1 & -i\\ \end{bmatrix} \\ &= \begin{bmatrix}
    1 & 0 & 1 & 0\\ 0 & 1 & 0 & -i\\ 1 & 0 & -1 & 0\\ 0 & 1 & 0 & i\\ \end{bmatrix}
    \begin{bmatrix} 1 & 1 & 0 & 0\\ 1 & -1 & 0 & 0\\ 0 & 0 & 1 & 1\\ 0 & 0 & 1 & -1\\
    \end{bmatrix} \begin{bmatrix} 1 & 0 & 0 & 0\\ 0 & 0 & 1 & 0\\ 0 & 1 & 0 & 0\\
    0 & 0 & 0 & 1\\ \end{bmatrix} \end{aligned} \]
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \begin{aligned} \mathbf{W}_4 &= \begin{bmatrix} 1 & 1 & 1 & 1\\ 1 & -i &
    -1 & i\\ 1 & -1 & 1 & -1\\ 1 & i & -1 & -i\\ \end{bmatrix} \\ &= \begin{bmatrix}
    1 & 0 & 1 & 0\\ 0 & 1 & 0 & -i\\ 1 & 0 & -1 & 0\\ 0 & 1 & 0 & i\\ \end{bmatrix}
    \begin{bmatrix} 1 & 1 & 0 & 0\\ 1 & -1 & 0 & 0\\ 0 & 0 & 1 & 1\\ 0 & 0 & 1 & -1\\
    \end{bmatrix} \begin{bmatrix} 1 & 0 & 0 & 0\\ 0 & 0 & 1 & 0\\ 0 & 1 & 0 & 0\\
    0 & 0 & 0 & 1\\ \end{bmatrix} \end{aligned} \]
- en: The rightmost matrix (call it \(P\), for permutation) reorders the input. Here’s
    how it acts on a suitably-sized input vector.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 最右侧的矩阵（称为 \(P\)，表示置换）重新排列输入。以下是它在适当大小的输入向量上的作用方式。
- en: \[ \mathbf{P}_4 \mathbf{x} = \begin{bmatrix} 1 & 0 & 0 & 0\\ 0 & 0 & 1 & 0\\
    0 & 1 & 0 & 0\\ 0 & 0 & 0 & 1\\ \end{bmatrix} \begin{bmatrix} x1 \\ x2 \\ x3 \\
    x4 \\ \end{bmatrix} = \begin{bmatrix} x1 \\ x3 \\ x2 \\ x4 \\ \end{bmatrix} \]
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathbf{P}_4 \mathbf{x} = \begin{bmatrix} 1 & 0 & 0 & 0\\ 0 & 0 & 1 & 0\\
    0 & 1 & 0 & 0\\ 0 & 0 & 0 & 1\\ \end{bmatrix} \begin{bmatrix} x1 \\ x2 \\ x3 \\
    x4 \\ \end{bmatrix} = \begin{bmatrix} x1 \\ x3 \\ x2 \\ x4 \\ \end{bmatrix} \]
- en: Now that even- and odd-indexed values are nicely separated, we can construct
    a block matrix that applies a DFT to each of those groups in isolation. In this
    case, the DFT in question is of size two. If you look at the central matrix above,
    you’ll see that it contains two instances of \(\mathbf{W}_2\), with \(\mathbf{W}_2\)
    being
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 现在偶数和奇数索引的值已经很好地分离，我们可以构建一个块矩阵，对每个这样的组单独应用 DFT。在这种情况下，所涉及的 DFT 的大小是两个。如果你看看上面的中心矩阵，你会看到它包含两个
    \(\mathbf{W}_2\) 的实例，其中 \(\mathbf{W}_2\) 是
- en: \[ \mathbf{W}_2 = \begin{bmatrix} 1 & 1 \\ 1 & -1 \\ \end{bmatrix} \]
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathbf{W}_2 = \begin{bmatrix} 1 & 1 \\ 1 & -1 \\ \end{bmatrix} \]
- en: 'Taking as input the permuted signal, \(\mathbf{P}_4 \mathbf{x}\), the block
    matrix produces the following output:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 以置换信号 \(\mathbf{P}_4 \mathbf{x}\) 作为输入，该块矩阵产生以下输出：
- en: \[ \mathbf{W}_{2*2}\mathbf{P}_{4}\mathbf{x} = \begin{bmatrix} 1 & 1 & 0 & 0\\
    1 & -1 & 0 & 0\\ 0 & 0 & 1 & 1\\ 0 & 0 & 1 & -1\\ \end{bmatrix} \begin{bmatrix}
    x1 \\ x3 \\ x2 \\ x4 \\ \end{bmatrix} = \begin{bmatrix} x1+x3 \\ x1-x3 \\ x2+x4
    \\ x2-x4 \\ \end{bmatrix} \]
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathbf{W}_{2*2}\mathbf{P}_{4}\mathbf{x} = \begin{bmatrix} 1 & 1 & 0 & 0\\
    1 & -1 & 0 & 0\\ 0 & 0 & 1 & 1\\ 0 & 0 & 1 & -1\\ \end{bmatrix} \begin{bmatrix}
    x1 \\ x3 \\ x2 \\ x4 \\ \end{bmatrix} = \begin{bmatrix} x1+x3 \\ x1-x3 \\ x2+x4
    \\ x2-x4 \\ \end{bmatrix} \]
- en: Next, the two sets of coefficients need to be recombined in the correct way.
    Personally, I find it hard to mentally picture how the leftmost matrix in the
    factorization does it; so let’s try if we can build up the matrix ourselves.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，需要以正确的方式将这两组系数重新组合。我个人觉得很难在脑海中想象出分解中左边的矩阵是如何操作的；所以让我们尝试自己构建这个矩阵。
- en: 'The FFT rule [Equation 27.6](#eq-fft-6) tells us what has to happen. Here it
    is again:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: FFT 规则 [方程式 27.6](#eq-fft-6) 告诉我们必须发生什么。这里再次列出：
- en: \[ X^{upper}_k = X^{even}_k + w^k_N \ X^{odd}_k \ , \ \ k = 0 ... N/2-1 \]
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: \[ X^{upper}_k = X^{even}_k + w^k_N \ X^{odd}_k \ , \ \ k = 0 ... N/2-1 \]
- en: \[ X^{lower}_{k+N/2} = X^{even}_k - w^k_N \ X^{odd}_k \ , \ \ k = 0 ... N/2-1
    \]
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: \[ X^{lower}_{k+N/2} = X^{even}_k - w^k_N \ X^{odd}_k \ , \ \ k = 0 ... N/2-1
    \]
- en: In this example, \(N/2\) is 2; we thus need \(w^0_4\) and \(w^1_4\). Their values
    are
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，\(N/2\) 是 2；因此我们需要 \(w^0_4\) 和 \(w^1_4\)。它们的值如下
- en: \[ \begin{aligned} &w^0_4 = e^{-i\frac{2 \pi}{4}0} = 1\\ &w^1_4 = e^{-i\frac{2
    \pi}{4}1} = -i\\ \end{aligned} \]
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \begin{aligned} &w^0_4 = e^{-i\frac{2 \pi}{4}0} = 1\\ &w^1_4 = e^{-i\frac{2
    \pi}{4}1} = -i\\ \end{aligned} \]
- en: 'As an aside, we could also have read them off the transformation matrix, \(W_4\):
    These are the first two basis vectors, computed at \(n=1\), and thus are found
    right on top of the second column.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 作为旁白，我们也可以从变换矩阵 \(W_4\) 中读取它们：这些是在 \(n=1\) 时计算出的前两个基向量，因此它们正好位于第二列的顶部。
- en: Now, we just mechanically apply the rule.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们只需机械地应用这个规则。
- en: \[ \begin{aligned} &X_0 = X^{upper}_0 = X^{even}_0 + w^0_4 \ X^{odd}_0 = (x_1
    + x_3) + 1 * (x_2 + x_4) \\ &X_1 = X^{upper}_1 = X^{even}_1 + w^1_4 \ X^{odd}_1
    = (x_1 - x_3) - i * (x_2 - x_4) \\ &X_2 = X^{lower}_2 = X^{even}_0 - w^0_4 \ X^{odd}_0
    = (x_1 + x_3) - 1 * (x_2 + x_4) \\ &X_3 = X^{lower}_3 = X^{even}_1 - w^1_4 \ X^{odd}_1
    = (x_1 - x_3) + i * (x_2 - x_4) \\ \end{aligned} \]
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \begin{aligned} &X_0 = X^{upper}_0 = X^{even}_0 + w^0_4 \ X^{odd}_0 = (x_1
    + x_3) + 1 * (x_2 + x_4) \\ &X_1 = X^{upper}_1 = X^{even}_1 + w^1_4 \ X^{odd}_1
    = (x_1 - x_3) - i * (x_2 - x_4) \\ &X_2 = X^{lower}_2 = X^{even}_0 - w^0_4 \ X^{odd}_0
    = (x_1 + x_3) - 1 * (x_2 + x_4) \\ &X_3 = X^{lower}_3 = X^{even}_1 - w^1_4 \ X^{odd}_1
    = (x_1 - x_3) + i * (x_2 - x_4) \\ \end{aligned} \]
- en: 'This gives us the multiplication factors to be applied to the vector input.
    All that remains to be done is put them into a matrix. Directly reading off the
    above equations, and filling in zeroes whenever an input is not used, this is
    what we obtain for the “butterfly” matrix \(\mathbf{B}\):'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 这为我们提供了要应用于向量输入的乘数因子。剩下要做的就是将它们放入一个矩阵中。直接读取上述方程，并在不使用输入时填充零，这就是我们得到的“蝴蝶”矩阵 \(\mathbf{B}\)：
- en: \[ \mathbf{B}_4 = \begin{bmatrix} 1 & 0 & 1 & 0\\ 0 & 1 & 0 & -i\\ 1 & 0 & -1
    & 0\\ 0 & 1 & 0 & i\\ \end{bmatrix} \]
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathbf{B}_4 = \begin{bmatrix} 1 & 0 & 1 & 0\\ 0 & 1 & 0 & -i\\ 1 & 0 & -1
    & 0\\ 0 & 1 & 0 & i\\ \end{bmatrix} \]
- en: Comparing with the leftmost matrix in the factorization, we see we’ve arrived
    at the correct result.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 与分解中的最左边的矩阵进行比较，我们看到我们得到了正确的结果。
- en: 'One thing that’s not immediately clear, however, is how to implement this recursively.
    It certainly seems like a lot of overhead to compute the complete matrix factorization
    at every recursive step. Fortunately, this is not needed. For one, the sorting
    can be done just once, right in the beginning. And secondly, it turns out that
    the matrices I’ve been referring to as \(\mathbf{W}_{2*2}\) and \(\mathbf{B}_{4}\)
    are intimately related: \(\mathbf{B}_{4}\) is what would go into a block matrix
    \(\mathbf{W}_{4*4}\).'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，有一件事并不立即清楚，那就是如何递归地实现它。显然，在每次递归步骤中计算完整的矩阵分解似乎是一个很大的开销。幸运的是，这并不需要。一方面，排序只需在最初进行一次。另一方面，我发现我之前提到的
    \(\mathbf{W}_{2*2}\) 和 \(\mathbf{B}_{4}\) 矩阵密切相关：\(\mathbf{B}_{4}\) 是会进入一个块矩阵
    \(\mathbf{W}_{4*4}\) 的。
- en: 'The recursive procedure can then be laid out very clearly. Here, for example,
    is how the complete procedure would look for an input size of 8:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，递归过程可以非常清晰地展示出来。例如，对于8个输入大小的完整过程如下：
- en: \[ \mathbf{W}_8 = \mathbf{B}_8 \begin{bmatrix} \mathbf{B}_4 & \mathbf{0}\\ \mathbf{0}
    & \mathbf{B}_4\\ \end{bmatrix} \begin{bmatrix} \mathbf{B}_2 & \mathbf{0} & \mathbf{0}
    & \mathbf{0}\\ \mathbf{0} & \mathbf{B}_2 & \mathbf{0} & \mathbf{0}\\ \mathbf{0}
    & \mathbf{0} & \mathbf{B}_2 & \mathbf{0}\\ \mathbf{0} & \mathbf{0} & \mathbf{0}
    & \mathbf{B}_2\\ \end{bmatrix} \mathbf{R} \]
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathbf{W}_8 = \mathbf{B}_8 \begin{bmatrix} \mathbf{B}_4 & \mathbf{0}\\ \mathbf{0}
    & \mathbf{B}_4\\ \end{bmatrix} \begin{bmatrix} \mathbf{B}_2 & \mathbf{0} & \mathbf{0}
    & \mathbf{0}\\ \mathbf{0} & \mathbf{B}_2 & \mathbf{0} & \mathbf{0}\\ \mathbf{0}
    & \mathbf{0} & \mathbf{B}_2 & \mathbf{0}\\ \mathbf{0} & \mathbf{0} & \mathbf{0}
    & \mathbf{B}_2\\ \end{bmatrix} \mathbf{R} \]
- en: \(\mathbf{R}\) is the matrix that, once and for all, sorts the input in the
    required way. I’ve written \(\mathbf{R}\) for “bit reversal”, since that is the
    actual algorithm used. We won’t go into its workings here, but explanations are
    readily found on the web.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: \(\mathbf{R}\) 是一个矩阵，它一次就能按照所需的方式对输入进行排序。我将其写作 \(\mathbf{R}\) 表示“位反转”，因为这就是实际使用的算法。我们在这里不会深入探讨其工作原理，但网上可以找到相关的解释。
- en: Having discussed DFT matrix factorization, we’re ready to look at some code.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在讨论了DFT矩阵分解之后，我们准备查看一些代码。
- en: 27.4 Implementing the FFT
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 27.4 实现FFT
- en: We discuss and compare for performance three different implementations of the
    FFT, plus our two DFT versions from the last chapter. Let me start by listing,
    again, what we did there.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 我们讨论并比较了三种不同的FFT实现以及我们上一章中的两个DFT版本的性能。让我先再次列出我们当时所做的工作。
- en: 27.4.1 DFT, the “loopy” way
  id: totrans-91
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 27.4.1 DFT，“循环”方式
- en: This was the way we first coded the DFT, computing the dot products between
    input and each basis vector in a loop.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是我们最初编写DFT的方式，通过循环计算输入和每个基向量的点积。
- en: '[PRE0]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '*### 27.4.2 DFT, vectorized'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '*### 27.4.2 向量化DFT'
- en: Next, we went on to replace the loop by arranging the basis vectors in a matrix.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们继续通过在矩阵中排列基向量来替换循环。
- en: '[PRE1]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '*### 27.4.3 Radix-2 decimation in time FFT, recursive'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '*### 27.4.3 基数-2时间抽取FFT，递归'
- en: Just like we did for the DFT algorithm per se, we can straightforwardly, by-specification
    implement the FFT. This time, the logically-imposed design is recursive, not iterative.
    In each call to `fft()`, the input is split into even and odd indices, respective
    half-size FFTs are computed, and the two sets of outputs are combined as required.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 就像我们对DFT算法本身所做的那样，我们可以直接根据规格实现FFT。这次，逻辑上设计的是递归的，而不是迭代的。在每次调用 `fft()` 时，输入被分成偶数和奇数索引，分别计算相应的一半大小的FFT，然后将两组输出按要求合并。
- en: '[PRE2]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '*This function expects input size to equal a power of two.*  *### 27.4.4 Radix-2
    decimation in time FFT by matrix factorization'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '*此函数期望输入大小等于2的幂次。*  *### 27.4.4 通过矩阵分解的基数-2时间抽取FFT'
- en: Next, we implement the matrix-factorization strategy described above. `fft_vec()`
    is a generalization of the logic spelt out in Brad Osgood’s wonderful book on
    the Fourier Transform (Osgood ([2019](references.html#ref-Osgood))).
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们实现上述描述的矩阵分解策略。`fft_vec()`是Brad Osgood在其关于傅里叶变换的精彩书籍中阐述的逻辑的推广（Osgood ([2019](references.html#ref-Osgood))）。
- en: We sort the input tensor (a single time), apply successive block matrices of
    doubled-in-size “butterflies”, and multiply the result with a single butterfly
    matrix of size matching the number of inputs.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对输入张量（一次）进行排序，应用连续的加倍大小的“蝴蝶”矩阵块，并将结果与一个与输入数量相匹配的单个蝴蝶矩阵相乘。
- en: The sorting may conveniently be done using `bitrevorder()`, a function provided
    by the R package `gsignal`.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 可以方便地使用`bitrevorder()`函数进行排序，该函数由R包`gsignal`提供。
- en: 'In the loop, you can see how the butterfly matrices are built: They consist
    of a combination of identity matrices with diagonal matrices holding the \(w^k_N\).'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在循环中，你可以看到蝴蝶矩阵是如何构建的：它们是由单位矩阵和包含\(w^k_N\)的对角矩阵的组合。
- en: '[PRE3]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '*### 27.4.5 Radix-2 decimation in time FFT, optimized for vectorization'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '*### 27.4.5 基于向量化的Radix-2时域分解FFT'
- en: Finally, let me present one more implementation. It is a literal translation
    of the Python code published by [Jake van der Plas](http://jakevdp.github.io/blog/2013/08/28/understanding-the-fft/#Vectorized-Numpy-Version)
    on his blog. Although it looks more involved than the recursive `fft()` above,
    it really implements the same algorithm, all while making use of vectorization
    as much as possible. In other words, it is to `fft()` what `dft_vec()` is to `dft()`.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我再介绍一种实现方式。这是对[Jake van der Plas](http://jakevdp.github.io/blog/2013/08/28/understanding-the-fft/#Vectorized-Numpy-Version)在其博客上发布的Python代码的直译。尽管它看起来比上面的递归`fft()`更复杂，但它实际上实现了相同的算法，同时尽可能多地使用了向量化。换句话说，它对`fft()`的作用就像`dft_vec()`对`dft()`的作用一样。
- en: '[PRE4]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '*### 27.4.6 Checking against `torch_fft_fft()`'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '*### 27.4.6 与`torch_fft_fft()`的比较'
- en: Now, before we compare those five functions performance-wise, let’s check whether
    they yield the same results as `torch_fft_fft()`. We don’t expect identity over
    a large number of decimal places; but it will be good to know about eventual differences
    in accuracy between the different implementations.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，在我们比较这五个函数的性能之前，让我们检查它们是否与`torch_fft_fft()`产生相同的结果。我们不期望在大量小数位上完全一致；但了解不同实现之间最终准确性的差异将是有益的。
- en: '[PRE5]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '*[PRE6]'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE6]'
- en: Reassuringly, the FFT implementations all seem sufficiently accurate.*  *###
    27.4.7 Comparing performance
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 令人放心的是，FFT实现似乎都足够准确。*  *### 27.4.7 性能比较
- en: To assess relative performance, we again use `bench::mark()`, with twenty iterations
    per function ([fig. 27.1](#fig-fft-perf)).
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估相对性能，我们再次使用`bench::mark()`，每个函数迭代二十次（[图27.1](#fig-fft-perf)）。
- en: '[PRE7]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '*![Density plots of execution times, one row per FFT implementation. See main
    text for details.](../Images/9ea7c777bfddbb5c90fa52879e68839f.png)'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '*![执行时间的密度图，每行对应一个FFT实现。详细信息请参阅正文。](../Images/9ea7c777bfddbb5c90fa52879e68839f.png)'
- en: 'Figure 27.1: Benchmarking various FFT and DFT implementations (see text). Also
    includes `torch_fft_fft()` for reference.'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 图27.1：比较各种FFT和DFT实现（见正文）。还包括`torch_fft_fft()`作为参考。
- en: 'Unsurprisingly, none of the implementations comes close to `torch_fft_fft()`.
    Intriguingly, though, we see enormous differences in execution time between our
    manual implementations. There is an important insight to be had. Algorithmic properties
    are like Platonic ideas: pure and noble in theory, but often, hard to enliven
    in the lowlands of everyday life. Here, the hard facts of reality concern the
    defining features of the software stack one is using, and in particular, the characteristics
    of the programming language involved. Let me elaborate.'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 出乎意料的是，没有任何一种实现接近`torch_fft_fft()`。然而，令人好奇的是，我们在手动实现之间看到了巨大的执行时间差异。这里有一个重要的见解。算法属性就像柏拉图的理念：在理论上纯洁而崇高，但在日常生活中往往难以生动体现。在这里，现实的硬事实涉及一个人所使用的软件栈的定义特征，特别是所涉及编程语言的特征。让我详细说明。
- en: 'In `torch` as well as in R, the language, vectorized operations are much more
    efficient than iteration (let alone recursion). In that light, we can make sense
    of the results like so:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在`torch`以及R语言中，向量化的操作比迭代（更不用说递归）要高效得多。从这个角度来看，我们可以这样理解结果：
- en: '`dft()` and `fft()`, the straightforward realizations, are slowest, since they
    don’t use vectorized operations. Among those two, `fft()`, which – in theory –
    should be superior, is severely punished for relying on recursion, whose use is
    strongly discouraged in R.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dft()`和`fft()`，这两种直接实现，由于没有使用向量操作，速度最慢。在这两者中，`fft()`——在理论上应该更优越——由于依赖于递归（在R中强烈不建议使用递归）而受到了严重的惩罚。'
- en: Both vectorized implementations, `dft_vec()` and `fft_vec()`, perform decidedly
    better than their un-vectorized counterparts. Among these, `fft_vec()` is a lot
    faster than `dft_vec()`, which is exactly what we’d like to see.
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*两种向量化实现，`dft_vec()`和`fft_vec()`，在性能上明显优于它们的非向量化版本。在这些中，`fft_vec()`比`dft_vec()`快得多，这正是我们所期望的。*'
- en: Given its conceptual and aesthetic appeal, the outcome for `fft_matrix()` is
    a bit disappointing.
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*鉴于其概念和美学吸引力，`fft_matrix()`的结果有些令人失望。*'
- en: Inspired by wishful thinking, is there anything we could do?*  *### 27.4.8 Making
    use of Just-in-Time (JIT) compilation
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '*受美好愿望的启发，我们能做些什么呢？* *### 27.4.8 利用即时（JIT）编译*'
- en: 'We can try. In `torch`, a functionality named Just-in-Time (JIT) compilation
    allows us to *trace* a function, or a model, to obtain a highly optimized graph
    representation. This capability is useful in a number of ways: to reduce execution
    time, evidently; but also if, for example, you’d like to deploy a model (trained
    in R) in an environment that does not have R installed. If you’re interested,
    please see the [vignette](https://github.com/mlverse/torch/blob/main/vignettes/torchscript.Rmd),
    as well as a dedicated [blog post](https://blogs.rstudio.com/ai/posts/2021-08-10-jit-trace-module/).
    Here, we’ll just directly put JIT compilation to practical use.'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以尝试。在`torch`中，一个名为即时（JIT）编译的功能允许我们跟踪一个函数或模型，以获得高度优化的图表示。这种能力在许多方面都很有用：显然可以减少执行时间；例如，如果您想在没有安装R的环境中部署一个模型（在R中训练），这也很有用。如果您感兴趣，请参阅[vignette](https://github.com/mlverse/torch/blob/main/vignettes/torchscript.Rmd)，以及一个专门的[博客文章](https://blogs.rstudio.com/ai/posts/2021-08-10-jit-trace-module/)。在这里，我们只是直接将JIT编译应用到实际中。
- en: All we have to do is call a function, `jit_trace()`, with a dummy tensor, whose
    shape has to match the shape of future intended inputs. We want to do this for
    the two most promising FFT implementations, `fft_vec()` and `fft_matrix()`, as
    well as `torch`’s own `torch_fft_fft()`. The one thing to be aware of is that,
    should we think the improvement is worth it, we will need to trace the function
    for all input shapes we’re interested in. (Considering that our implementations
    expect input size to be a power of two, that wouldn’t be too much of a problem.)
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '*我们只需调用一个函数，`jit_trace()`，并传递一个哑变量张量，其形状必须与未来预期输入的形状相匹配。我们希望对两个最有希望的FFT实现，`fft_vec()`和`fft_matrix()`，以及`torch`自己的`torch_fft_fft()`进行此操作。需要注意的是，如果我们认为改进是值得的，我们将需要跟踪所有我们感兴趣的输入形状。（考虑到我们的实现期望输入大小是2的幂，这不会造成太大的问题。）*'
- en: 'Above, the input size we used for benchmarking amounted to 2^13, so this is
    what we’ll use for tracing, too. Here, first, we run `jit_trace()` for `fft_vec()`
    and `torch_fft_fft()`:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '*在上面，我们用于基准测试的输入大小是2^13，因此我们也将使用这个大小进行跟踪。在这里，首先，我们运行`jit_trace()`对`fft_vec()`和`torch_fft_fft()`进行跟踪：*'
- en: '[PRE8]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '*The case of `fft_matrix()`, however, is a bit special: Inside, we’re calling
    `bitrevorder()`, a function that should not be part of the `torch` graph. A workaround,
    however, is quickly found: Just move that part of the logic outside the function
    – it scarcely contributes to execution time, anyway. The redefined function now
    looks like this:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '*`fft_matrix()`的情况却有些特殊：在内部，我们调用了`bitrevorder()`函数，这个函数不应该成为`torch`图的一部分。然而，一个解决方案很快就被找到了：只需将这部分逻辑移出函数之外——无论如何，它对执行时间的影响微乎其微。重新定义的函数现在看起来是这样的：*'
- en: '[PRE9]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '*We trace it with pre-sorted input:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '*我们使用预先排序的输入进行跟踪：*'
- en: '[PRE10]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '*In benchmarking, we call `fft_matrix_jit()` with a pre-sorted tensor, as well.
    Here, then, is a comparison of `fft_vec(),` `fft_matrix()`, `torch_fft_fft()`,
    and their respective optimized versions ([fig. 27.2](#fig-fft-perf-jit)):'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '*在基准测试中，我们也用预先排序的张量调用`fft_matrix_jit()`。以下是`fft_vec()`、`fft_matrix()`、`torch_fft_fft()`及其各自优化版本的比较（[图27.2](#fig-fft-perf-jit)）：*'
- en: '[PRE11]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '*![Density plots of execution times, one row per FFT implementation. See main
    text for details.](../Images/43e2ab5d61b40065a6fb467d4d6b7589.png)'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '*![执行时间的密度图，每行对应一个FFT实现。详细信息请参阅正文。](../Images/43e2ab5d61b40065a6fb467d4d6b7589.png)*'
- en: 'Figure 27.2: Exploring the effect of Just-in-Time Compilation (JIT) on the
    performance of `fft_vec(),` `fft_matrix()`, and `torch_fft_fft()`.'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 图27.2：探索即时编译（JIT）对`fft_vec()`、`fft_matrix()`和`torch_fft_fft()`性能的影响。
- en: Two things, I’d say, are remarkable about this result. First, each of the three
    implementations benefits from getting JIT-compiled, even `torch_fft_fft()`.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为，这个结果有两个显著之处。首先，这三个实现都从即时编译中受益，即使是`torch_fft_fft()`。
- en: 'Second, there is one that profits *a lot*: namely, `fft_vec()`. In its compiled
    version, it is nearly as fast as `torch_fft_fft()` – a function that, remember,
    has all calculations done in highly optimized C++ code. This again underlines
    the enormous impact “linguistic fit” has on final performance outcomes.'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 第二，有一个受益**很多**：即`fft_vec()`。在其编译版本中，它的速度几乎与`torch_fft_fft()`相当——请记住，这是一个所有计算都在高度优化的C++代码中完成的函数。这再次强调了“语言匹配”对最终性能结果产生的巨大影响。
- en: 'By now, we’ve learned a lot about the Discrete Fourier Transform, including
    how to implement it in an efficient way. With all that knowledge, we should feel
    comfortable enough making direct use of `torch_fft_ftt()`. This is exactly what
    we’ll do in the next – and final – chapter: We’ll complement classic Fourier Analysis
    with its younger counterpart, *wavelets*.'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 到现在为止，我们已经学到了很多关于离散傅里叶变换的知识，包括如何以高效的方式实现它。有了所有这些知识，我们应该足够自信地直接使用`torch_fft_ftt()`。这正是我们将在下一章——也是最后一章——要做的：我们将经典傅里叶分析与其年轻的同行，*小波*相结合。
- en: Osgood, Brad. 2019\. *Lectures on the Fourier Transform and Its Applications*.
    American Mathematical Society.*********** **** * *
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: Osgood, Brad. 2019\. *傅里叶变换及其应用讲义*. 美国数学会.*********** **** * *
- en: Note that now we have a scalar, not a vector.[↩︎](#fnref1)***
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 注意，现在我们有一个标量，而不是一个向量。[↩︎](#fnref1)***
